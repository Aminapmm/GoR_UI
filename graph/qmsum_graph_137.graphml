<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." />
    <node id="Speaker: Postdoc A&#10;Content: Oh . Oh .&#10;Speaker: PhD F&#10;Content: which {disfmarker} which seemed reasonable given that , you know , the models weren't tuned for {disfmarker} {vocalsound} for it .&#10;Speaker: Grad G&#10;Content: Hmm !&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: And the grammar wasn't tuned either .&#10;Speaker: PhD B&#10;Content: And it didn't matter whether it was the lapel or whether it was the {disfmarker}&#10;Speaker: PhD F&#10;Content: It was just a @ @ . I haven't split it up that way ,&#10;Speaker: PhD D&#10;Content: But there 's no overlap during the digit readings , so it shouldn't really matter .&#10;Speaker: PhD F&#10;Content: but it would be {disfmarker}&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: No , but there 's a little difference ,&#10;Speaker: PhD" />
    <node id=" doesn't work for lapel stuff , we can just not use that&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: I haven't {disfmarker} I ha just haven't had the time to , um , do the same procedure on one of the {disfmarker} so I would need a k I would need a channel that has {vocalsound} a speaker whose {disfmarker} who has a lot of overlap but s you know , is a non - lapel mike . And , um , {vocalsound} {vocalsound} where preferably , also there 's someone sitting next to them who talks a lot .&#10;Speaker: Grad E&#10;Content: Hmm !&#10;Speaker: PhD F&#10;Content: So , I {disfmarker}&#10;Speaker: Grad E&#10;Content: So a meeting with me in it .&#10;Speaker: PhD F&#10;Content: maybe someone can help me find a good candidate and then I would be willing to&#10;Speaker: PhD B&#10;Content: We c you know what ? Maybe the best way to find that" />
    <node id="s possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the reject model to the {disfmarker} to {disfmarker} to all the other speech . Um , so&#10;Speaker: PhD B&#10;Content: Could you {disfmarker} could you at the same time adapt the reject model to the speech from all the other channels ?&#10;Speaker: Professor C&#10;Content: That 's what he just said .&#10;Speaker: Grad E&#10;Content: That 's what he was saying .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: That 's what I just said .&#10;Speaker: PhD B&#10;Content: Oh , not just the speech from that {disfmarker} of the other people from that channel ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: but the speech from the a actual other channels .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Oh , oh , I see . Um ,&#10;Speaker: Professor C&#10;Content: Oh" />
    <node id=" Oh , MNCM . &#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: We don't really care about like intermediate word boundaries , so {disfmarker}&#10;Speaker: PhD F&#10;Content: No , that 's how I 've been looking at it .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I mean , I don't care that the individual words are aligned correctly ,&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {vocalsound} you don't wanna , uh , infer from the alignment that someone spoke who didn't .&#10;Speaker: PhD B&#10;Content: Right , exactly . So that 's why I was wondering if it {disfmarker}&#10;Speaker: PhD F&#10;Content: so , so {disfmarker}&#10;Speaker: PhD B&#10;Content: I mean , maybe if it doesn't work for lapel stuff , we can just not use that&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;" />
    <node id="disfmarker}&#10;Speaker: Professor C&#10;Content: So , they 're {disfmarker} they 're looking at a mixed signal , or they 're looking {disfmarker} what {disfmarker} what are they looking at visually ?&#10;Speaker: Postdoc A&#10;Content: Well , they have a choice . They could choose any signal to look at . I 've tried lookin but usually they look at the mixed . But I 've {disfmarker} I 've tried looking at the single signal and {disfmarker} and in order to judge when it {disfmarker} when it was speech and when it wasn't ,&#10;Speaker: Grad E&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;Content: but the problem is then you have breaths which {disfmarker} which show up on the signal .&#10;Speaker: Professor C&#10;Content: But the procedure that you 're imagining , I mean , people vary from this , is that they have the mixed signal wave form in front of them ,&#10;Speaker: Postdoc A&#10;Content: Yes .&#10;Speaker: PhD F&#10;Content: &#10;Speaker" />
    <node id=" a good candidate and then I would be willing to&#10;Speaker: PhD B&#10;Content: We c you know what ? Maybe the best way to find that would be to look through these .&#10;Speaker: PhD F&#10;Content: you know , hand&#10;Speaker: PhD B&#10;Content: Cuz you can see the seat numbers , and then you can see what type of mike they were using . And so we just look for , you know , somebody sitting next to Adam at one of the meetings {disfmarker}&#10;Speaker: PhD D&#10;Content: Actually y we can tell from the data that we have ,&#10;Speaker: PhD F&#10;Content: From the insertions , maybe ?&#10;Speaker: PhD D&#10;Content: um , yeah , there 's a way to tell .&#10;Speaker: PhD F&#10;Content: fr fr from the {disfmarker}&#10;Speaker: PhD D&#10;Content: It might not be a single person who 's always overlapping that person but any number of people ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: and , um , if you align the two hypothesis files across the channels , you know , just word" />
    <node id="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." />
    <node id="aker: PhD B&#10;Content: and then we go in and adjust the boundaries .&#10;Speaker: Postdoc A&#10;Content: Yeah that 's right . Yeah , we haven't done that . I {disfmarker} I could set someone on that tomorrow .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: And time how long it takes .&#10;Speaker: PhD B&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: I think they 're coming {disfmarker}&#10;Speaker: PhD B&#10;Content: And we probably don't have to do necessarily a whole meeting for that if we just wanna send them a sample to try .&#10;Speaker: Postdoc A&#10;Content: OK . What would be a good number of minutes ?&#10;Speaker: PhD B&#10;Content: I don't know , maybe we can figure out how long it 'll take @ @ to {disfmarker} to do .&#10;Speaker: Grad E&#10;Content: Um , I don't know , it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker" />
    <node id=" it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker: Professor C&#10;Content: Yes except that if they had {disfmarker} if there was a choice between having fifteen minutes that was fully the way you wanted it , and having a whole meeting that didn't get at what you wanted for them {disfmarker} It 's just dependent of how much {disfmarker}&#10;Speaker: Grad E&#10;Content: Like I {disfmarker} I mean I guess if we have to do it again anyway , but , uh&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: I guess , the only thing I 'm not sure about is , um , how quickly can the transcribers scan over and fix the boundaries ,&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: and {disfmarker} I mean , is it pretty easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow" />
    <node id=" A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}&#10;Speaker: Professor C&#10;Content: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?&#10;Speaker: PhD B&#10;Content: Well I {disfmarker} I {disfmarker} I mean , I don't know .&#10;Speaker: Grad E&#10;Content: That was the question . Though .&#10;Speaker: Professor C&#10;Content: So if we {disfmarker} if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing .&#10;Speaker: PhD B&#10;Content: Yeah . Uh . That {disfmarker" />
    <node id=" of sending him a sample one to {disfmarker} f&#10;Speaker: Grad E&#10;Content: Yeah , maybe it doesn't matter .&#10;Speaker: Postdoc A&#10;Content: Great .&#10;Speaker: PhD B&#10;Content: I {disfmarker} I don't think it matte&#10;Speaker: Postdoc A&#10;Content: I 'll {disfmarker} I 'll {disfmarker} I 'll , um , get {disfmarker} make that available .&#10;Speaker: Grad E&#10;Content: OK , and has it been corrected ?&#10;Speaker: Postdoc A&#10;Content: Oh , well , wait . Um {disfmarker}&#10;Speaker: Grad E&#10;Content: Hand - checked ? Cuz that was one of the {vocalsound} processes we were talking about as well .&#10;Speaker: PhD B&#10;Content: Right , so we need to run Thilo 's thing on it ,&#10;Speaker: Postdoc A&#10;Content: That 's right .&#10;Speaker: PhD B&#10;Content: and then we go in and adjust the boundaries .&#10;Speaker: Postdoc A&#10;Content: Yeah that 's right" />
    <node id=" types of things . I 've {disfmarker} I 've discussed it with Thilo and I mean {disfmarker} in terms of not him doing it , but we {disfmarker} we discussed some of the parameters of that and how hard it would be to {disfmarker} in principle {disfmarker} to write something that would do that .&#10;Speaker: PhD D&#10;Content: I mean , I guess in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have a good idea of where the forced alignment is constrained to .&#10;Speaker: Postdoc A&#10;Content: Well , it 's just , you know , a matter of we had the revolution {disfmarker} we had the revolution of improved , uh , interface , um , one month too late ,&#10;Speaker: PhD D&#10;Content: So I 'm no I don't know if this&#10;Speaker: Grad E&#10;Content: Oh . Tools .&#10;Speaker: Postdoc A&#10;Content: but it 's like , you know , it 's wonderful to have the revolution ,&#10;Speaker: PhD D&#10;" />
    <node id=" the same speaker , so now sometimes you get a ni microphone pop and , uh , I mean , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . It 's not a simple {disfmarker} not a simple problem .&#10;Speaker: PhD D&#10;Content: Anyway , quick question , though , at a high level do people think , let 's just say that we 're moving to this new era of like using the , um , pre - segmented t you know , non - synchronous conversations , does it make sense to try to take what we have now , which are the ones that , you know , we have recognition on which are synchronous and not time - tightened , and try to get something out of those for sort of purposes of illustrating the structure and the nature of the meetings , or is it better to just , you know , forget that and tr I mean , it 's {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , I think we 'll have to , eventually . And my hope was that we would be able to use the forced alignment to get it .&#10;Speaker: PhD D&#10;Content: Right . That was everybody" />
    <node id="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." />
    <node id="&#10;Content: so .&#10;Speaker: Professor C&#10;Content: Hmm , no connection .&#10;Speaker: Grad E&#10;Content: It 's {disfmarker} i they 're called temp files , but they 're not actually in the temp directory they 're in the scratch , so . They 're not backed up , but they 're not erased either on power failure .&#10;Speaker: PhD D&#10;Content: But that 's usually the meeting that I recorded , and it neve it doesn't crash on me .&#10;Speaker: PhD B&#10;Content: Well this wasn't {disfmarker} Actually , this wasn't a before your meeting , this was , um , Tuesday afternoon when , um , uh , Robert just wanted to do a little recording ,&#10;Speaker: Grad E&#10;Content: Oh well .&#10;Speaker: PhD D&#10;Content: Oh {disfmarker} Oh , right .&#10;Speaker: PhD B&#10;Content: and the power had gone out earlier in the day .&#10;Speaker: PhD D&#10;Content: OK . Huh , OK .&#10;Speaker: Professor C&#10;Content: I don't know when would be a good excuse for it , but I just" />
    <node id="Speaker: PhD B&#10;Content: I thought he 's just saying you have to look over a longer time window when you do it .&#10;Speaker: Grad E&#10;Content: Um - hmm .&#10;Speaker: PhD D&#10;Content: and the {disfmarker} but there are some issues of this timing , um , in the recordings&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: So you just have to look over longer time when you 're trying to align the things , you can't {disfmarker} you can't just look {disfmarker}&#10;Speaker: Grad E&#10;Content: Well . are you talking about the fact that the recording software doesn't do time - synchronous ? Is that what you 're referring to ?&#10;Speaker: Professor C&#10;Content: &#10;Speaker: Grad E&#10;Content: That seems to me you can do that over the entire file and get a very accurate {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't thi I d" />
    <node id="} just something really wrong with {disfmarker}&#10;Speaker: Grad G&#10;Content: I 'm sorry , I don't {disfmarker}&#10;Speaker: Grad E&#10;Content: A bug is what I mean ,&#10;Speaker: PhD F&#10;Content: In the recording&#10;Speaker: Grad G&#10;Content: Oh .&#10;Speaker: Grad E&#10;Content: so that it 's like {disfmarker}&#10;Speaker: Grad G&#10;Content: Oh , OK .&#10;Speaker: PhD F&#10;Content: And there was this one meeting , I forget which one it was , where like , uh , six out of the eight channels were all , like {disfmarker} had a hundred percent error .&#10;Speaker: Grad G&#10;Content: I see .&#10;Speaker: Grad E&#10;Content: Which probably means like there was a {disfmarker} th the recording interface crashed ,&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: or there was a short {disfmarker} you know , someone was jiggling with a cord&#10;Speaker: PhD F&#10;Content: But {disfmarker}" />
    <node id=" , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from something else , and adapting , and how well that works . Uh , so in {disfmarker} in fact it was pretty related to what Liz and Andreas did , uh , except that this was not with meeting stuff , it was with&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: uh , like I think they s didn't they start off with Broadcast News system ? And then they went to {disfmarker}&#10;Speaker: Grad E&#10;Content: The - their Broadcast News was their acoustic models and then all the other tasks were much simpler .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So they were command and control and that sort of thing .&#10;Speaker: Professor C&#10;Content: TI - digits was one of them , and , uh , Wall Street Journal .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: What was their rough {disfmarker} what was their conclusion ?&#10;Speaker: Grad E&#10;" />
    <node id="Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Grad G&#10;Content: How about channel&#10;Speaker: Professor C&#10;Content: Yeah , go ahead .&#10;Speaker: Grad E&#10;Content: We 're recording .&#10;Speaker: Grad G&#10;Content: Alright .&#10;Speaker: Professor C&#10;Content: Alright , and no crash .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: I pre - crashed it .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Pre - crashed !&#10;Speaker: PhD D&#10;Content: It never crashes on me .&#10;Speaker: Grad E&#10;Content: I think it 's actually {disfmarker}&#10;Speaker: PhD D&#10;Content: What is {disfmarker} what is that ?&#10;Speaker: Grad E&#10;Content: it depends on if the temp files are there or not , that {disfmarker} at least that 's my current working hypothesis ,&#10;Speaker: PhD D&#10;Content: Ah .&#10;Speaker: Grad E&#10;Content: that I think what happens is it tries to clear the temp files" />
    <node id="Speaker: PhD D&#10;Content: Ah .&#10;Speaker: Grad E&#10;Content: that I think what happens is it tries to clear the temp files and if they 're too big , it crashes .&#10;Speaker: PhD D&#10;Content: Ah .&#10;Speaker: PhD B&#10;Content: When the power went out the other day and I restarted it , it crashed the first time .&#10;Speaker: Grad E&#10;Content: Oh , that 's right .&#10;Speaker: PhD B&#10;Content: After the power out&#10;Speaker: PhD D&#10;Content: So then there would be no temp files .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: OK . {comment} Hmm .&#10;Speaker: Grad E&#10;Content: Uh , no , it doesn't {disfmarker} it doesn't clear those necessarily ,&#10;Speaker: PhD D&#10;Content: Oh wait {disfmarker} It {disfmarker} it doesn't clear them , OK .&#10;Speaker: Grad E&#10;Content: so .&#10;Speaker: Professor C&#10;Content: Hmm , no connection .&#10;Speaker: Grad E&#10;Content: It 's {" />
    <node id="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." />
    <node id=" easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow , excuse me , two or more times real time , right ? Cuz they have to at least listen to it .&#10;Speaker: Professor C&#10;Content: Can we pipeline it so that say there 's , uh , the transcriber gets done with a quarter of the meeting and then we {disfmarker} you run it through this other {disfmarker} other stuff ? Uh ,&#10;Speaker: Grad E&#10;Content: Well the other stuff is I B I 'm just thinking that from a data {disfmarker} keeping - track - of - the - data point of view , it may be best to send them whole meetings at a time and not try to send them bits and pieces .&#10;Speaker: Professor C&#10;Content: OK , so . Oh , that 's right . So the first thing is the automatic thing , and then it 's {disfmarker} then it 's {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Spe" />
    <node id="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I" />
    <node id="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." />
    <node id=" are because the recognition 's so poor . Right ?&#10;Speaker: PhD B&#10;Content: Yeah , we were never just gonna go with these as the final alignments .&#10;Speaker: PhD D&#10;Content: And so you 're {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I agree . I agree .&#10;Speaker: PhD B&#10;Content: We were always gonna run them past somebody .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Absolutely .&#10;Speaker: PhD D&#10;Content: So we need some way to push these first chunk of meetings into a state where we get good alignments .&#10;Speaker: PhD F&#10;Content: I 'm probably going to spend another day or so trying to improve things by , um , {vocalsound} {vocalsound} by using , um , acoustic adaptation . Um , the {disfmarker} {vocalsound} Right now I 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the" />
    <node id=" haven't checked those yet .&#10;Speaker: Grad E&#10;Content: C&#10;Speaker: PhD F&#10;Content: It 's very tedious to check these .&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: PhD F&#10;Content: Um , we would really need , ideally , a transcriber {vocalsound} to time mark the {disfmarker} you know , the be at least the beginning and s ends {comment} of contiguous speech . Um , {vocalsound} {vocalsound} and , you know , then with the time marks , you can do an automatic comparison of your {disfmarker} of your forced alignments .&#10;Speaker: PhD B&#10;Content: Because {disfmarker} really the {disfmarker} the {disfmarker} at least in terms of how we were gonna use this in our system was to get an ideal {disfmarker} an idea , uh , for each channel about the start and end boundaries .&#10;Speaker: Grad E&#10;Content: Oh , MNCM . &#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: We" />
    <node id=" I {disfmarker} I wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , you know , actual numbers . Like if we {disfmarker} if we had hand - transcribed pe good alignments or hand - checked alignments , then we could do this paper . It 's not that we need it to be automatic . But without knowing where the real words are , in time {disfmarker}&#10;Speaker: PhD B&#10;Content: So it was to get {disfmarker} it was to get more data and better {disfmarker} to {disfmarker} to squeeze the boundaries in .&#10;Speaker: PhD D&#10;Content: To {disfmarker} to know what an overlap really {disfmarker} if it 's really an overlap , or if it 's just a {disfmarker} a {disfmarker} a segment correlated with an overlap ,&#10;Speaker: PhD B&#10;Content: Ah , OK . Yeah .&#10;Speaker: PhD D&#10;Content: and I guess that 's the difference to me between like a real paper and a sort of ," />
    <node id="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present." />
    <node id=" was {disfmarker}&#10;Speaker: Professor C&#10;Content: Columbia have anything ? No .&#10;Speaker: PhD D&#10;Content: no it was {disfmarker}&#10;Speaker: Grad E&#10;Content: Wasn't {disfmarker} Who {disfmarker} who {disfmarker} who did the order one ?&#10;Speaker: PhD D&#10;Content: this was Wednesday morning . The sentence ordering one , was that Barselou , and these guys ?&#10;Speaker: Grad E&#10;Content: Ugh ! {comment} I 'm just so bad at that .&#10;Speaker: Postdoc A&#10;Content: Oh .&#10;Speaker: PhD D&#10;Content: Anyway , I {disfmarker} I {disfmarker} it 's in the program , I should have read it to remind myself , but that 's sort of useful and I think like when Mari and Katrin and Jeff are here it 'd be good to figure out some kinds of things that we can start doing maybe just on the transcripts cuz we already have {disfmarker}&#10;Speaker: Professor C&#10;Content: Mm - hmm .&#10;Speaker:" />
    <node id="Speaker: PhD D&#10;Content: No .&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor C&#10;Content: No , we just had some discussions , various discussions with them .&#10;Speaker: Grad E&#10;Content: It 's just informal .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm . Mm - hmm . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .&#10;Speaker: PhD B&#10;Content: What was the , um {disfmarker} the paper by , um , Lori Lamel that you mentioned ?&#10;Speaker: Professor C&#10;Content: Um , yeah , we sh we should just have you {disfmarker} have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,&#10;Speaker: Postdoc A&#10;Content: Mmm , yeah .&#10;Speaker: Professor C&#10;Content: but , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from" />
    <node id="aker: PhD D&#10;Content: But I think what 's interesting is there 's all these different evaluations , like {disfmarker} just , you know , how do you evaluate whether the summary is good or not ,&#10;Speaker: Grad E&#10;Content: I always write down the wrong things .&#10;Speaker: Postdoc A&#10;Content: I do take notes .&#10;Speaker: PhD D&#10;Content: and that 's what 's {disfmarker} was sort of interesting to me is that there 's different ways to do it ,&#10;Speaker: Grad E&#10;Content: A judge .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: Was SRA one of the groups talking about summarization , no ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Hm - umm . No .&#10;Speaker: Postdoc A&#10;Content: It was an interesting session . One of those w&#10;Speaker: Grad E&#10;Content: And as I said , I like the Microsoft talk on {pause} scaling issues in , uh , word sense disambiguation ,&#10;Speaker" />
    <node id="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." />
    <node id=" whatever they had gotten up to , would be better than nothing .&#10;Speaker: PhD B&#10;Content: Yeah . Uh . That {disfmarker} I agree . I agree .&#10;Speaker: Grad E&#10;Content: Well , I don't think {disfmarker} I mean , h they {disfmarker} they typically work for what , four hours , something like that ?&#10;Speaker: Postdoc A&#10;Content: Hmm , I gue hmm .&#10;Speaker: Grad E&#10;Content: I think the they should be able to get through a whole meeting in one sitting . I would think , unless it 's a lot harder than we think it is , which it could be , certainly .&#10;Speaker: Postdoc A&#10;Content: If it 's got like for speakers then I guess {disfmarker} I mean if {disfmarker}&#10;Speaker: PhD B&#10;Content: We 're just doing the individual channels ,&#10;Speaker: Grad E&#10;Content: Or seven or eight .&#10;Speaker: PhD B&#10;Content: right ?&#10;Speaker: Postdoc A&#10;Content: Individual channels . Yeah .&#10;Speaker: PhD B&#10;Content: So" />
    <node id="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." />
    <node id=" conferences , it 's not {disfmarker} these are conferences that have d really different emphases . Whereas HLT and {disfmarker} and Eurospeech , pretty {disfmarker} pretty {disfmarker} pretty similar , so I {disfmarker} I {disfmarker} I can't see really just putting in the same thing ,&#10;Speaker: Grad E&#10;Content: Are too close , yeah .&#10;Speaker: PhD D&#10;Content: No , I d I don't think that paper is really {disfmarker}&#10;Speaker: Professor C&#10;Content: but {disfmarker}&#10;Speaker: PhD D&#10;Content: the HLT paper is really more of a introduction - to - the - project paper , and , um {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , for Eurospeech we want some results if we can get them .&#10;Speaker: PhD D&#10;Content: Well , yeah , it {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some" />
    <node id=": Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: That {disfmarker} I don't wanna do that ,&#10;Speaker: Grad E&#10;Content: Yeah , I 'm doing that for AVIOS .&#10;Speaker: Professor C&#10;Content: but .&#10;Speaker: PhD D&#10;Content: Yeah . But I think we 're {disfmarker} oh , Morgan 's talk went very well , I think .&#10;Speaker: Professor C&#10;Content: Bleep .&#10;Speaker: Grad E&#10;Content: Uh , &quot; bleep &quot; . Yeah , really .&#10;Speaker: PhD D&#10;Content: I think Morgan 's talk went very well it woke {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Excellent .&#10;Speaker: PhD D&#10;Content: you know , it was really a well presented {disfmarker} and got people laughing {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content:" />
    <node id=" cross - talk in the adaptation , and it 's just sort of blurred .&#10;Speaker: PhD F&#10;Content: That 's a good point .&#10;Speaker: PhD B&#10;Content: If you {disfmarker}&#10;Speaker: PhD F&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: And that we know , I mean , we have that . And it 's about roughly two - thirds , I mean , very roughly averaged .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: That 's not completely negligible . Like a third of it is bad for adaptation or so .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cool . I thought it was higher than that , that 's pr&#10;Speaker: PhD D&#10;Content: It really {disfmarker} it depends a lot . This is just sort of an overall {disfmarker}&#10;Speaker: PhD F&#10;Content: So .&#10;Speaker: Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker" />
    <node id=" {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some {disfmarker} or some {disfmarker} I mean , I would see Eurospeech {disfmarker} if we have some Eurospeech papers , these will be paper p p uh , submissions .&#10;Speaker: PhD D&#10;Content: but {disfmarker}&#10;Speaker: Professor C&#10;Content: These will be things that are particular things , aspects of it that we 're looking at , rather than , you know , attempt at a global paper about it .&#10;Speaker: PhD D&#10;Content: Right , right .&#10;Speaker: Grad E&#10;Content: Detail , yeah . Overall .&#10;Speaker: Postdoc A&#10;Content: I did go through one of these meetings . I had , uh , one of the transcribers go through and tighten up the bins on one of the , uh , NSA meetings , and then I went through afterwards and double - checked it so that one is really very {disfmarker} very accurate .&#10;Speaker: PhD D&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;" />
    <node id=" sounds like .&#10;Speaker: PhD B&#10;Content: Practically , huh . With all the overlaps .&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: What are we doing ?&#10;Speaker: Grad E&#10;Content: I {disfmarker} Since I 've been gone all week , I didn't send out a reminder for an agenda , so .&#10;Speaker: Professor C&#10;Content: Yeah , and I 'm just {disfmarker}&#10;Speaker: Grad E&#10;Content: Do we have anything to talk about or should we just read digits and go ?&#10;Speaker: PhD B&#10;Content: I wouldn't mind hearing how the conference was .&#10;Speaker: Professor C&#10;Content: What conference ?&#10;Speaker: PhD D&#10;Content: Uh , I had one question about {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , really . It 's all a blur .&#10;Speaker: PhD D&#10;Content: Aren't the UW folks coming this weekend ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: No . The next ,&#10;Speaker: PhD D" />
    <node id="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription." />
    <node id=" . Yeah .&#10;Speaker: PhD D&#10;Content: and I guess that 's the difference to me between like a real paper and a sort of , promissory paper . So , um , if we d it might be possible to take Thilo 's output and like if you have , um , like right now these meetings are all ,&#10;Speaker: Grad E&#10;Content: Ugh ! I forgot the digital camera again .&#10;Speaker: PhD D&#10;Content: um ,&#10;Speaker: Grad E&#10;Content: Every meeting !&#10;Speaker: PhD D&#10;Content: you know , they 're time - aligned , so if these are two different channels and somebody 's talking here and somebody else is talking here , just that word , if Thilo can tell us that there 're boundaries here , we should be able to figure that out&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: because the only thing transcribed in this channel is this word . But , um , you know , if there are things {disfmarker}&#10;Speaker: Grad E&#10;Content: Two words .&#10;Speaker: PhD D&#10;Content: Yeah , if you" />
    <node id=" A&#10;Content: He generated , um , a channel - wise presegmented version of a meeting , but it was Robustness rather than EDU so I guess depends on whether we 're willing to use Robustness ?&#10;Speaker: PhD B&#10;Content: Well for this experiment I think we can use pre pretty much anything .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: PhD B&#10;Content: This experiment of just {disfmarker}&#10;Speaker: Grad E&#10;Content: Well we had {disfmarker} we had talked about doing maybe EDU as a good choice , though . Well , {vocalsound} whatever we have .&#10;Speaker: PhD B&#10;Content: Well we 've talked about that as being the next ones we wanted to transcribe .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: PhD B&#10;Content: But for the purpose of sending him a sample one to {disfmarker} f&#10;Speaker: Grad E&#10;Content: Yeah , maybe it doesn't matter .&#10;" />
    <node id=" PhD B&#10;Content: right ?&#10;Speaker: Postdoc A&#10;Content: Individual channels . Yeah .&#10;Speaker: PhD B&#10;Content: So it 's gonna be , depending on the number of people in the meeting , um ,&#10;Speaker: Postdoc A&#10;Content: I guess there is this issue of , you know , if {disfmarker} if the segmenter thought there was no speech on {disfmarker} on a particular stretch , on a particular channel ,&#10;Speaker: Grad E&#10;Content: Well {disfmarker}&#10;Speaker: Postdoc A&#10;Content: and there really was , then , if it didn't show up in a mixed signal to verify , then it might be overlooked , so , I mean , the question is &quot; should {disfmarker} should a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? &quot; And I th eh so far as I 'm concerned it 's fine to base it on the mixed signal at this point , and {disfmarker}&#10;Speaker: Grad E&#10;Content: That 's what it seems to me too , in that if they need to , just like" />
    <node id="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." />
    <node id="}&#10;Speaker: PhD D&#10;Content: yeah it 's {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I 've thought about this , um , and I 've discussed {disfmarker} I 've discussed it with Thilo ,&#10;Speaker: PhD D&#10;Content: I mean , if you have any ideas . I would {disfmarker}&#10;Speaker: Postdoc A&#10;Content: um , the , I mean , I {disfmarker} I {disfmarker} in principle I could imagine writing a script which would approximate it to some degree , but there is this problem of slippage ,&#10;Speaker: Grad E&#10;Content: Well maybe {disfmarker} Maybe that will get enough of the cases to be useful .&#10;Speaker: Postdoc A&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: Right . I mean , that {disfmarker} that would be really helpful . That was sort of another possibility .&#10;Speaker: Grad E&#10;Content: You know s cuz it seemed like most of the cases are in fact the single word sorts , or at least a single phrase&#10;Speaker:" />
    <node id=" things {disfmarker}&#10;Speaker: Grad E&#10;Content: Two words .&#10;Speaker: PhD D&#10;Content: Yeah , if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you , so , um {disfmarker}&#10;Speaker: PhD B&#10;Content: Thilo 's won't put down two separate marks in that case {disfmarker}&#10;Speaker: PhD D&#10;Content: Well it w it would , but , um , we don't know exactly where the words are because the transcriber gave us two words in this time bin&#10;Speaker: Grad E&#10;Content: Thilo 's will . But .&#10;Speaker: PhD D&#10;Content: and we don't really know , I mean ,&#10;Speaker: Postdoc A&#10;Content: Well it 's a merging problem . If you had a {disfmarker} if you had a s if you had a script which would {disfmarker}&#10;Speaker: PhD D&#10;Content: yeah it 's {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I '" />
    <node id="Content: You know s cuz it seemed like most of the cases are in fact the single word sorts , or at least a single phrase&#10;Speaker: Postdoc A&#10;Content: Well they {disfmarker} they can be stretched .&#10;Speaker: Grad E&#10;Content: in most of the bins .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Postdoc A&#10;Content: I wouldn't make that generalization cuz sometimes people will say , &quot; And then I &quot; and there 's a long pause&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: and finish the sentence and {disfmarker} and sometimes it looks coherent and {disfmarker} and the {disfmarker} I mean it 's {disfmarker} it 's not a simple problem . But it 's really {disfmarker} And then it 's coupled with the problem that sometimes , you know , with {disfmarker} with a fricative you might get the beginning of the word cut off and so it 's coupled with the problem that Thilo 's isn't perfect either . I mean , we" />
    <node id=" might get the beginning of the word cut off and so it 's coupled with the problem that Thilo 's isn't perfect either . I mean , we 've i th it 's like you have a merging problem plus {disfmarker} so merging plus this problem of , uh , not {disfmarker}&#10;Speaker: Grad E&#10;Content: Right . Hmm !&#10;Speaker: Postdoc A&#10;Content: y i i if the speech - nonspeech were perfect to begin with , the detector , that would already be an improvement , but that 's impossible , you know , i that 's too much to ask .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yes .&#10;Speaker: Postdoc A&#10;Content: And so i and may you know , I mean , it 's {disfmarker} I think that there always {disfmarker} th there would have to be some hand - tweaking , but it 's possible that a script could be written to merge those two types of things . I 've {disfmarker} I 've discussed it with Thilo and I mean {disfmarker} in terms" />
    <node id=" kept saying , &quot; Can I see that slide again ? &quot;&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah ,&#10;Speaker: Postdoc A&#10;Content: and then they 'd make a comment , and one person said , well - known person said , um , you know , &quot; Before you dismiss forty - five years including my work {disfmarker} &quot;&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Grad E&#10;Content: Forty - five years of research .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: But th you know , the same thing has happened in computational linguistics , right ? You look at the ACL papers coming out , and now there 's sort of a turn back towards , OK we 've learned statistic {disfmarker} you know , we 're basically getting what we expect out of some statistical methods , and , you know , the there 's arguments on both sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker" />
    <node id="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system." />
    <node id="marker} everybody {disfmarker} every place in the room ,&#10;Speaker: PhD D&#10;Content: and video , right .&#10;Speaker: Professor C&#10;Content: uh , the {disfmarker} yeah {disfmarker} the {disfmarker} the mikes in the middle , the head - mounted mikes , the lapel mikes , the array , uh , with {disfmarker} well , there 's some discussion of fifty - nine ,&#10;Speaker: Grad E&#10;Content: Fifty - nine elements .&#10;Speaker: Professor C&#10;Content: they might go down to fifty - seven Because , uh , there is , uh , some pressure from a couple people at the meeting for them to use a KEMAR head . I forget what KEMAR , uh , stands for ,&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: but what it is is it 's dummy head that is very specially designed ,&#10;Speaker: Grad E&#10;Content: Oh , that 's right .&#10;Speaker: Professor C&#10;Content: and {disfmarker} and {disfmarker}" />
    <node id="Content: Oh , that 's right .&#10;Speaker: Professor C&#10;Content: and {disfmarker} and {disfmarker} and , so what they 're actually doing is they 're really {disfmarker} there 's really two recording systems .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: That 's a great idea .&#10;Speaker: Professor C&#10;Content: So they may not be precisely synchronous , but the but there 's two {disfmarker} two recording systems , one with , I think , twenty - four channels , and one with sixty - four channels . And the sixty - four channel one is for the array , but they 've got some empty channels there , and anyway they {disfmarker} like they 're saying they may give up a couple or something if {disfmarker} for {disfmarker} for the KEMAR head if they go {disfmarker} go with that .&#10;Speaker: Grad E&#10;Content: Right . Yeah , it is a good idea .&#10;Speaker: Professor C&#10;Content" />
    <node id="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics." />
    <node id=" here , and then you have a little segment here . Well , is that part of the speech ? Is it part of the nonspeech ? I mean , w what do you embed it in ?&#10;Speaker: PhD D&#10;Content: There 's something nice , though , about keeping , and this is probably another discussion , keeping the stuff that Thilo 's detector detected as possible speech and just marking it as not speech than deleting it . Because then when you align it , then the alignment can {disfmarker} you can put a reject model or whatever ,&#10;Speaker: Grad E&#10;Content: Oh , I see . So then they could just like put {disfmarker} Oh that 's what you meant by just put an &quot; X &quot; there .&#10;Speaker: PhD D&#10;Content: and you 're consistent with th the automatic system ,&#10;Speaker: Grad E&#10;Content: Uh , that 's an interesting idea .&#10;Speaker: PhD D&#10;Content: whereas if you delete it {disfmarker}&#10;Speaker: Grad E&#10;Content: So {disfmarker} so all they {disfmarker} So that all they would have to do is put like an &quot;" />
    <node id=" A&#10;Content: I think it 's easier to add than delete , frankly ,&#10;Speaker: PhD D&#10;Content: and then you can get {disfmarker} Yeah , or&#10;Speaker: Postdoc A&#10;Content: because you have to , uh , maneuver around on the {disfmarker} on both windows then .&#10;Speaker: Grad E&#10;Content: To add or to delete ?&#10;Speaker: Postdoc A&#10;Content: To delete .&#10;Speaker: PhD D&#10;Content: Anyways , so I {disfmarker} I guess {disfmarker}&#10;Speaker: Grad E&#10;Content: OK . That {disfmarker} Maybe that 's an interface issue that might be addressable .&#10;Speaker: Postdoc A&#10;Content: It 's possible .&#10;Speaker: Grad E&#10;Content: But I think it 's the semantics that are {disfmarker} that are questionable to me , that you delete something {disfmarker} So let 's say someone is talking to here , and then you have a little segment here . Well , is that part of the speech ? Is it part of the nonspeech ? I mean ," />
    <node id="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." />
    <node id=" more computation and some are {disfmarker} are hav have limited kind of discrimination , but are just easy to use , and others are {disfmarker}&#10;Speaker: PhD B&#10;Content: But doesn't their conclusion just sort of {disfmarker} you could have guessed that before they even started ? Because if you assume that these learning things get better and better and better ,&#10;Speaker: Professor C&#10;Content: You would guess {disfmarker}&#10;Speaker: PhD B&#10;Content: then as you approach {disfmarker} there 's a point where you can't get any better , right ? You get everything right .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: It 's just no {disfmarker}&#10;Speaker: Grad E&#10;Content: But {disfmarker}&#10;Speaker: PhD B&#10;Content: So they 're all approaching .&#10;Speaker: Grad E&#10;Content: No , but there was still a spread . They weren't all up They weren't converging .&#10;Speaker: PhD B&#10;Content: But what I 'm saying is that th they have to , as" />
    <node id="Content: Yeah .&#10;Speaker: PhD D&#10;Content: Huh .&#10;Speaker: Professor C&#10;Content: Yeah , could well be . So {disfmarker} so , I mean , that was {disfmarker} that was kind of , you know , it 's a good point , but the problem I had with it was that the implications out of this was that , uh , the kind of choices you make about learning machines were therefore irrelevant which is not at {disfmarker} n t as for as I know in {disfmarker} in tasks I 'm more familiar with @ @ is not at all true . What i what is {disfmarker} is true is that different learning machines have different properties , and you wanna know what those properties are . And someone else sort of implied that well we s you know , a all the study of learning machine we still don't know what those properties are . We don't know them perfectly , but we know that some kinds use more memory and {disfmarker} and some other kinds use more computation and some are {disfmarker} are hav have limited kind of discrimination , but are just easy to use , and others are {d" />
    <node id=" sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker: Grad E&#10;Content: I think the matters is the thing that {disfmarker} that was misleading .&#10;Speaker: Postdoc A&#10;Content: That was very offending , very offending .&#10;Speaker: PhD D&#10;Content: Yeah , yeah .&#10;Speaker: Grad E&#10;Content: Is that {disfmarker} all {disfmarker} all of them are based on all the others , right ? Just , you {disfmarker} you can't say {disfmarker}&#10;Speaker: PhD B&#10;Content: Maybe they should have said &quot; focus &quot; or something .&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yeah . I mean , so . {disfmarker} And I 'm saying the same thing happened with speech recognition , right ? For a long time people were hand - c coding linguistic rules and then they discovered machine - learning worked better . And now they 're throwing more and more data and worrying {disfmarker} perhaps worrying less and less about" />
    <node id=" they discovered machine - learning worked better . And now they 're throwing more and more data and worrying {disfmarker} perhaps worrying less and less about , uh , the exact details of the algorithms .&#10;Speaker: PhD D&#10;Content: And {disfmarker} and then you hit this {disfmarker}&#10;Speaker: Grad E&#10;Content: Except when they have a Eurospeech paper .&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Anyway .&#10;Speaker: Professor C&#10;Content: Anyway , tea is {disfmarker} tea is , uh , starting .&#10;Speaker: Grad E&#10;Content: Shall we read some digits ? Are we gonna do one at a time ? Or should we read them all agai at once again .&#10;Speaker: Professor C&#10;Content: Let 's do it all at once .&#10;Speaker: Postdoc A&#10;Content: Yeah , that 's good .&#10;Speaker: Professor C&#10;Content: We {disfmarker} @ @ {disfmarker} let 's try that again .&#10;Speaker: PhD D&#10;" />
    <node id=" more data is better , right ? You 're {disfmarker} you 're {disfmarker} you can assume similar distributions ,&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: but if you wanted to do disambiguation on a different type of , uh , test data then your training data , then that extra data wouldn't generalize ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: so .&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: But , I think one of their p They {disfmarker} they had a couple points . w {comment} Uh , I think one of them was that &quot; Well , maybe simpler algorithms and more data are {disfmarker} is better &quot; . Less memory , faster operation , simpler . Right ? Because their simplest , most brain - dead algorithm did pretty darn well&#10;Speaker: Professor C&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: when you got {disfmarker} gave it a lot more data . And then also they were saying , &quot; Well , m You" />
    <node id="marker} yeah {disfmarker} yeah {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , it sort of was .&#10;Speaker: Professor C&#10;Content: was it w was it word - sense ? Yes .&#10;Speaker: Grad E&#10;Content: But it was {disfmarker} it was a very simple case of &quot; to &quot; versus &quot; too &quot; versus &quot; two &quot; and &quot; there &quot; , &quot; their &quot; , &quot; they 're &quot; {disfmarker}&#10;Speaker: PhD D&#10;Content: And there and their and {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah , yeah . OK .&#10;Speaker: PhD D&#10;Content: and that you could do better with more data , I mean , that 's clearly statistically {disfmarker}&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: And so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about {d" />
    <node id="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." />
    <node id="aker: Professor C&#10;Content: down from Seattle .&#10;Speaker: Grad E&#10;Content: They 're flying from somewhere to somewhere ,&#10;Speaker: Professor C&#10;Content: Yeah , and they 'll end up here . So b and also Brian Kingsbury is actually flying from , uh , the east coast on that {disfmarker} that morning .&#10;Speaker: Postdoc A&#10;Content: Excellent .&#10;Speaker: Professor C&#10;Content: So , i I {disfmarker} I will be {disfmarker} I mean , he 's taking a very early flight&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: Professor C&#10;Content: and we do have the time work difference running the right way , but I still think that there 's no way we could start before eleven . It might end up really being twelve . So when we get closer we 'll find people 's plane schedules , and let everybody know . Uh , So . That 's good .&#10;Speaker: Grad E&#10;Content: But , uh , yeah maybe an agenda , or at least some things to talk about would be a good idea .&#10;Speaker: Professor C&#10;Content: Well we" />
    <node id=" , are we {disfmarker} do we have like an agenda or anything that we should be {disfmarker}&#10;Speaker: Professor C&#10;Content: No , but that would be a good idea .&#10;Speaker: PhD D&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Why don't we w&#10;Speaker: PhD F&#10;Content: So {disfmarker} so the deal is that I can , um , {vocalsound} uh , I can be available after , uh , like ten thirty or something . I don't know how s how early you wanted to {disfmarker}&#10;Speaker: Professor C&#10;Content: They 're not even gonna be here until eleven or so .&#10;Speaker: Grad E&#10;Content: That 's good .&#10;Speaker: PhD F&#10;Content: Oh , OK . So {disfmarker}&#10;Speaker: Professor C&#10;Content: Cuz they 're flying up that day .&#10;Speaker: PhD D&#10;Content: Wait , this is on {disfmarker} on Sunday ?&#10;Speaker: Professor C&#10;Content: Saturday .&#10;Speaker: PhD D&#10;Content: Or Saturday ?" />
    <node id="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript." />
    <node id="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." />
    <node id=": OK . Huh , OK .&#10;Speaker: Professor C&#10;Content: I don't know when would be a good excuse for it , but I just can't wait to be giving a talk t and {disfmarker} and {disfmarker} and use the example from last week with everybody t doing the digits at once .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: That was fun .&#10;Speaker: Professor C&#10;Content: I 'd love to play somebody that .&#10;Speaker: Postdoc A&#10;Content: That was fun .&#10;Speaker: PhD D&#10;Content: It was quick .&#10;Speaker: Professor C&#10;Content: It was . It was really efficient .&#10;Speaker: PhD B&#10;Content: Talk about a good noise shield . You know ? You wanted to pe keep people from listening in , you could like have that playing outside the room . Nobody could listen in .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Well , I had this idea we could make our whole meeting faster that way .&#10;Speaker: Professor C&#10;Content: Yeah . Everybody give the reports about what they" />
    <node id="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings." />
    <node id="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team." />
    <node id="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group." />
    <node id=" this , but probably the five of us should pick out a paper or two that {disfmarker} that , uh , you know , got our interest , and we should go around the room at one of the Tuesday lunch meetings and say , you know , what {disfmarker} what was good about the conference ,&#10;Speaker: Grad E&#10;Content: Present . Yep . Do a trip report .&#10;Speaker: Professor C&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: Well , the summarization stuff was interesting , I mean , I don't know anything about that field , but for this proposal on meeting summarization , um , I mean , it 's sort of a far cry because they weren't working with meeting type data , but he got sort of an overview on some of the different approaches ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Do you remember who the groups were that we 're doing ?&#10;Speaker: PhD D&#10;Content: so . Well there 're {disfmarker} this was the last day ,&#10;Speaker: Grad E&#10;Content: A lot of different ones .&#10;Speaker: Postdoc A&#10;Content" />
    <node id="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis." />
    <node id=" could scientifically say is overlap , it 's just whether or not the , um , the segments that were all synchronized , whether there was some overlap somewhere .&#10;Speaker: Grad E&#10;Content: c High correlation .&#10;Speaker: PhD D&#10;Content: And , you know , that pointed out some differences , so he thought well if we can do something quick and dirty because Dan said the cross - cancellation , it 's not straight - forward . If it were straight - forward then we would try it , but {disfmarker} so , it 's sort of good to hear that it was not straight - forward , thinking if we can get decent forced alignments , then at least we can do sort of a overall report of what happens with actual overlap in time , but , um {disfmarker}&#10;Speaker: PhD B&#10;Content: I didn't think that his message said it wasn't straight - forward .&#10;Speaker: Grad E&#10;Content: Well if we 'd just {disfmarker}&#10;Speaker: Professor C&#10;Content: Well&#10;Speaker: PhD B&#10;Content: I thought he 's just saying you have to look over a longer time window when you do it .&#10;Speaker" />
    <node id="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds." />
    <node id=" Oh they can {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , but then they have to do {disfmarker} but then they {disfmarker} for this meeting they would have to do seven times real time , and it would probably be more than that .&#10;Speaker: Postdoc A&#10;Content: Yeah , that 's it . Yeah .&#10;Speaker: Grad E&#10;Content: Right ? Because they 'd have to at least listen to each channel all the way through .&#10;Speaker: Postdoc A&#10;Content: And if {disfmarker}&#10;Speaker: PhD B&#10;Content: But i but it 's very quick ,&#10;Speaker: Postdoc A&#10;Content: Uh - huh .&#10;Speaker: PhD B&#10;Content: right ? I mean , you scan {disfmarker} I mean , if you have a display of the waveform .&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Oh , you 're talking about visually .&#10;Speaker: Postdoc A&#10;Content: w Well , the other problem is the breaths&#10;Speaker: Grad E&#10;Content: I just don" />
    <node id="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation." />
    <node id=" , {vocalsound} I actually went through all of those , there were I think fifty - five segments , {vocalsound} um , in {disfmarker} in X Waves , and {disfmarker} and sort of did a crude check , and {vocalsound} more often than not , it {disfmarker} it gets it wrong . So there 's either the beginning , mostly the beginning word , {vocalsound} where th you , um , you know , Chuck talks somewhere into the segment , but the first , um , word of what he says , often &quot; I &quot; but it 's very reduced &quot; I , &quot; that 's just aligned {vocalsound} to the beginning of someone else 's speech , uh in that segment , which is cross - talk . So , {vocalsound} um , {vocalsound} I 'm still tinkering with it , but it might well be that we can't get clean alignments out of this {disfmarker} out of those , uh , {vocalsound} channels , so .&#10;Speaker: Professor C&#10;Content: Unless maybe we do this , uh , um , cancellation business .&#10;Speaker:" />
    <node id="isfmarker} I haven't done {disfmarker} I mean , the only way to check this right now was for me to actually {vocalsound} load these into X Waves and , you know , plus the alignments , and s play them and see where the {disfmarker}&#10;Speaker: Professor C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: And it looks {disfmarker} And so I looked at all of the utterances from you , Chuck , in that one conversation , I don't know which {disfmarker} You probably know which one I mean , it 's where you were on the lapel {vocalsound} and Morgan was sitting next to you and we can hear everything Morgan says .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: But {disfmarker} and {disfmarker} and some of what you {disfmarker} I mean , you also appear quite a bit in that cross - talk . So , {vocalsound} I actually went through all of those , there were I think fifty - five segments , {vocalsound} um , in {" />
    <node id=" and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about {disfmarker} about , &quot; Oh my {disfmarker} my kind of learning machine is better than your kind of learning machine . &quot; And , uh , they were {disfmarker} started off with a million words that they used , which was evidently a number that a lot of people doing that particular kind of task had been using . So they went up , being Microsoft , they went up to a billion . And then they had this log scale showing a {disfmarker} you know , and {disfmarker} and naturally everything gets {disfmarker}&#10;Speaker: Grad E&#10;Content: Them being beep , {comment} they went off to a billion .&#10;Speaker: Professor C&#10;Content: they {disfmarker} well , it 's a big company , I didn't {disfmarker} I didn't mean it as a ne anything negative ,&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: but i i i&#10;Speaker: PhD D&#10;Content:" />
    <node id="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;" />
    <node id=" question actually .&#10;Speaker: Grad E&#10;Content: I mean cuz for the corpus it would be nice if everything were {disfmarker}&#10;Speaker: PhD D&#10;Content: Actually that 's a good question because we 'd have to completely redo those meetings , and we have like ten of them now .&#10;Speaker: Grad E&#10;Content: We wouldn't have to re - do them , we would just have to edit them .&#10;Speaker: Postdoc A&#10;Content: Well , and also , I mean , I still haven't {disfmarker} I still haven't given up on forced alignment .&#10;Speaker: PhD D&#10;Content: No , you 're right , actually {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I think that when Brian comes , this 'll be uh an interesting aspect to ask him as well b&#10;Speaker: Grad E&#10;Content: When {disfmarker}&#10;Speaker: Postdoc A&#10;Content: when Brian Kingsbury comes .&#10;Speaker: Grad E&#10;Content: Oh , Brian . You s I thought you said Ryan . And it 's like , &quot; Who 's Ryan ? &quot;&#10;Spe" />
    <node id=" Grad E&#10;Content: Oh , Brian . You s I thought you said Ryan . And it 's like , &quot; Who 's Ryan ? &quot;&#10;Speaker: Postdoc A&#10;Content: Yeah , good question .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Well , Ryan could come .&#10;Speaker: PhD D&#10;Content: Uh , no , that 's a good point , though , because for feature extraction like for prosody or something , I mean , the meetings we have now , it 's a good chunk of data {disfmarker}&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: we need to get a decent f OK .&#10;Speaker: Postdoc A&#10;Content: That 's what my hope has been ,&#10;Speaker: PhD D&#10;Content: So we should at least try it even if we can't ,&#10;Speaker: Postdoc A&#10;Content: and that 's what {disfmarker} that 's what {disfmarker} you know , ever since the {disfmarker} the February meeting that I transcribed from last year , forced alignment has been" />
    <node id="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials." />
    <node id=" difference .&#10;Speaker: Grad E&#10;Content: Right , which should be pretty straight forward .&#10;Speaker: PhD D&#10;Content: Which a at least is well defined , and&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: um , but then if you add the dynamic aspect of adapting distances , then it wasn't {disfmarker} I guess it just wasn't something that he could do quickly {pause} and not {disfmarker} in time for us to be able to do something by two weeks from now , so . Well less than a week . So {disfmarker} um , so I don't know what we can do if anything , that 's sort of worth , you know , a Eurospeech paper at this point .&#10;Speaker: PhD B&#10;Content: Well , Andreas , how well did it work on the non - lapel stuff ?&#10;Speaker: Grad E&#10;Content: Yeah . That 's what I was gonna say .&#10;Speaker: PhD F&#10;Content: I haven't checked those yet .&#10;Speaker: Grad E&#10;Content: C&#10;Speaker: PhD F&#10;Content: It 's very tedious to check" />
    <node id=": Right .&#10;Speaker: PhD D&#10;Content: and , um , if you align the two hypothesis files across the channels , you know , just word alignment , you 'd be able to find that . So {disfmarker} so I guess that 's sort of a last {disfmarker} ther there 're sort of a few things we could do . One is just do like non - lapels if we can get good enough alignments . Another one was to try to get {disfmarker} somehow align Thilo 's energy segmentations with what we have . But then you have the problem of not knowing where the words are because these meetings were done before that segmentation . But maybe there 's something that could be done .&#10;Speaker: PhD B&#10;Content: What {disfmarker} what is {disfmarker} why do you need the , um , the forced alignment for the HLT {disfmarker} I mean for the Eurospeech paper ?&#10;Speaker: PhD D&#10;Content: Well , I guess I {disfmarker} I wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report" />
    <node id=" 's fine . Yeah , it 's true .&#10;Speaker: Grad E&#10;Content: So you can definitely streamline that with the i with the interface .&#10;Speaker: Postdoc A&#10;Content: Yeah , it could be faster , but , you know , I mean , th in the ideal world {disfmarker} Yeah .&#10;Speaker: Grad E&#10;Content: What ?&#10;Speaker: Postdoc A&#10;Content: No I {disfmarker} I agree that 'd be nice . Yeah . OK .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: So , um , Done with that ?  Does any {disfmarker} I forget , does anybody , uh , working on any {disfmarker} any Eurospeech submission related to this ?&#10;Speaker: Grad E&#10;Content: I would like to try to do something on digits but I just don't know if we have time . I mean , it 's due next Friday so we have to do the experiments and write the paper . So , I 'm gonna try , but , uh , we 'll just have to see . So actually I wanna get together with both Andreas and" />
    <node id="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference." />
    <node id="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit." />
    <node id=" to your size , which is not really what we want .&#10;Speaker: PhD B&#10;Content: The other thing that would do it would be to hang a five pound weight off the back .&#10;Speaker: Professor C&#10;Content: Yeah&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: that 's good !&#10;Speaker: Postdoc A&#10;Content: What did you say ?&#10;Speaker: PhD D&#10;Content: A little ,&#10;Speaker: Grad E&#10;Content: wh&#10;Speaker: Professor C&#10;Content: Hang a five pound weight off the {disfmarker} off the back .&#10;Speaker: PhD B&#10;Content: Hang a five pound weight off the back .&#10;Speaker: PhD D&#10;Content: um ,&#10;Speaker: Grad E&#10;Content: We did that {disfmarker}&#10;Speaker: Professor C&#10;Content: Weight .&#10;Speaker: Grad E&#10;Content: We {disfmarker} at Boeing I used {disfmarker} I was doing augmented reality so they had head - mounts on , and we {disfmarker} we had a little jury - rigged one with a welder '" />
    <node id="isfmarker} that {disfmarker} that tilts , right ? In lots and lots of different ways .&#10;Speaker: PhD D&#10;Content: So I 'm not saying anything about bias towards small headsize ,&#10;Speaker: Grad E&#10;Content: About heads ?&#10;Speaker: PhD D&#10;Content: but does seem , uh {disfmarker}&#10;Speaker: PhD B&#10;Content: It would be an advantage .&#10;Speaker: Postdoc A&#10;Content: Well , wonder if it 's {disfmarker} if {disfmarker} if he was wearing it over his hair instead of under his hair .&#10;Speaker: Professor C&#10;Content: Well , we should {disfmarker} We shou we should work on compressing the heads , and {disfmarker}&#10;Speaker: Grad E&#10;Content: I think probably it was {disfmarker} Yeah . It probably just wasn't tight enough to the back of his head . I mean , so the directions do talk about bending it to your size , which is not really what we want .&#10;Speaker: PhD B&#10;Content: The other thing that would do it would be to hang" />
    <node id="} go with that .&#10;Speaker: Grad E&#10;Content: Right . Yeah , it is a good idea .&#10;Speaker: Professor C&#10;Content: So .&#10;Speaker: Grad E&#10;Content: Yeah , h uh , J Jonathan Fiscus did say that , uh , they have lots of software for doing calibration for skew and offset between channels&#10;Speaker: PhD D&#10;Content: Mm - hmm&#10;Speaker: Grad E&#10;Content: and that they 've found that 's just not a big deal .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So .&#10;Speaker: Professor C&#10;Content: Yeah , I 'm not {pause} too worried about that . I was thinking {disfmarker}&#10;Speaker: PhD D&#10;Content: But they 're still planning to do like fake {disfmarker}&#10;Speaker: Grad E&#10;Content: Scenario - based .&#10;Speaker: PhD D&#10;Content: they have to do something like that ,&#10;Speaker: Grad E&#10;Content: Y right .&#10;Speaker: PhD D&#10;Content: right .&#10;Speaker: Grad E&#10;Content: Their {" />
    <node id="Content: I think that if we decide that we need {disfmarker} that they need to see the visuals , we need to change the interface so that they can do that .&#10;Speaker: Postdoc A&#10;Content: Yeah . Yeah .&#10;Speaker: Professor C&#10;Content: So {disfmarker}&#10;Speaker: PhD D&#10;Content: That 's actually what I thought of , loading the chopped up waveforms , I mean , you know , that {disfmarker} that would make it faster {disfmarker}&#10;Speaker: Grad E&#10;Content: An But isn't {disfmarker}&#10;Speaker: Grad G&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: The chopped up waveforms .&#10;Speaker: PhD B&#10;Content: The problem is if {disfmarker} if anything 's cut off , you can't expand it from the chopped up {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Grad E&#10;Content: Isn't that {disfmarker}&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: Right , but if" />
    <node id="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy." />
    <node id=" one is really very {disfmarker} very accurate .&#10;Speaker: PhD D&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;Content: I men I mentioned the link . I sent {disfmarker} You know that one ?&#10;Speaker: PhD D&#10;Content: Oh , so {disfmarker}&#10;Speaker: Grad G&#10;Content: The {disfmarker} which one ? I 'm sorry .&#10;Speaker: Postdoc A&#10;Content: Um , I 'm trying to remember {disfmarker} I don't remember the number off hand .&#10;Speaker: Grad E&#10;Content: Those are all {disfmarker}&#10;Speaker: Postdoc A&#10;Content: It 's one of the NSA 's . I sent email before the conference , before last week .&#10;Speaker: Grad G&#10;Content: Oh , OK .&#10;Speaker: Postdoc A&#10;Content: Bef - What I mean is Wednesday , Thursday .&#10;Speaker: PhD D&#10;Content: That might {disfmarker} might have been the one {disfmarker} one of the ones that we did .&#10;Speaker: Grad G&#10;Content" />
    <node id="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript." />
    <node id="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample." />
    <node id="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly." />
    <node id=": Grad G&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: No , but there 's a little difference ,&#10;Speaker: PhD F&#10;Content: So it should {disfmarker}&#10;Speaker: Grad E&#10;Content: There 's a lot .&#10;Speaker: Professor C&#10;Content: and we haven't looked at it for digits ,&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: right ?&#10;Speaker: PhD B&#10;Content: Yeah , so I was curious about that .&#10;Speaker: Professor C&#10;Content: And so , cuz {disfmarker} because what he was {disfmarker} what I was saying when I looked at those things is it {disfmarker} it {disfmarker} I was almost gonna call it quadrimodal because {vocalsound} {disfmarker} because there was a whole lot of cases where it was zero percent .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: They just plain got it all right . And then there {disfmarker} and then there was another" />
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="Speaker: Postdoc A&#10;Content: Oh . Oh .&#10;Speaker: PhD F&#10;Content: which {disfmarker} which seemed reasonable given that , you know , the models weren't tuned for {disfmarker} {vocalsound} for it .&#10;Speaker: Grad G&#10;Content: Hmm !&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: And the grammar wasn't tuned either .&#10;Speaker: PhD B&#10;Content: And it didn't matter whether it was the lapel or whether it was the {disfmarker}&#10;Speaker: PhD F&#10;Content: It was just a @ @ . I haven't split it up that way ,&#10;Speaker: PhD D&#10;Content: But there 's no overlap during the digit readings , so it shouldn't really matter .&#10;Speaker: PhD F&#10;Content: but it would be {disfmarker}&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: No , but there 's a little difference ,&#10;Speaker: PhD">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target=" doesn't work for lapel stuff , we can just not use that&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: I haven't {disfmarker} I ha just haven't had the time to , um , do the same procedure on one of the {disfmarker} so I would need a k I would need a channel that has {vocalsound} a speaker whose {disfmarker} who has a lot of overlap but s you know , is a non - lapel mike . And , um , {vocalsound} {vocalsound} where preferably , also there 's someone sitting next to them who talks a lot .&#10;Speaker: Grad E&#10;Content: Hmm !&#10;Speaker: PhD F&#10;Content: So , I {disfmarker}&#10;Speaker: Grad E&#10;Content: So a meeting with me in it .&#10;Speaker: PhD F&#10;Content: maybe someone can help me find a good candidate and then I would be willing to&#10;Speaker: PhD B&#10;Content: We c you know what ? Maybe the best way to find that">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="s possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the reject model to the {disfmarker} to {disfmarker} to all the other speech . Um , so&#10;Speaker: PhD B&#10;Content: Could you {disfmarker} could you at the same time adapt the reject model to the speech from all the other channels ?&#10;Speaker: Professor C&#10;Content: That 's what he just said .&#10;Speaker: Grad E&#10;Content: That 's what he was saying .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: That 's what I just said .&#10;Speaker: PhD B&#10;Content: Oh , not just the speech from that {disfmarker} of the other people from that channel ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: but the speech from the a actual other channels .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Oh , oh , I see . Um ,&#10;Speaker: Professor C&#10;Content: Oh">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target=" Oh , MNCM . &#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: We don't really care about like intermediate word boundaries , so {disfmarker}&#10;Speaker: PhD F&#10;Content: No , that 's how I 've been looking at it .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I mean , I don't care that the individual words are aligned correctly ,&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {vocalsound} you don't wanna , uh , infer from the alignment that someone spoke who didn't .&#10;Speaker: PhD B&#10;Content: Right , exactly . So that 's why I was wondering if it {disfmarker}&#10;Speaker: PhD F&#10;Content: so , so {disfmarker}&#10;Speaker: PhD B&#10;Content: I mean , maybe if it doesn't work for lapel stuff , we can just not use that&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="disfmarker}&#10;Speaker: Professor C&#10;Content: So , they 're {disfmarker} they 're looking at a mixed signal , or they 're looking {disfmarker} what {disfmarker} what are they looking at visually ?&#10;Speaker: Postdoc A&#10;Content: Well , they have a choice . They could choose any signal to look at . I 've tried lookin but usually they look at the mixed . But I 've {disfmarker} I 've tried looking at the single signal and {disfmarker} and in order to judge when it {disfmarker} when it was speech and when it wasn't ,&#10;Speaker: Grad E&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;Content: but the problem is then you have breaths which {disfmarker} which show up on the signal .&#10;Speaker: Professor C&#10;Content: But the procedure that you 're imagining , I mean , people vary from this , is that they have the mixed signal wave form in front of them ,&#10;Speaker: Postdoc A&#10;Content: Yes .&#10;Speaker: PhD F&#10;Content: &#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target=" a good candidate and then I would be willing to&#10;Speaker: PhD B&#10;Content: We c you know what ? Maybe the best way to find that would be to look through these .&#10;Speaker: PhD F&#10;Content: you know , hand&#10;Speaker: PhD B&#10;Content: Cuz you can see the seat numbers , and then you can see what type of mike they were using . And so we just look for , you know , somebody sitting next to Adam at one of the meetings {disfmarker}&#10;Speaker: PhD D&#10;Content: Actually y we can tell from the data that we have ,&#10;Speaker: PhD F&#10;Content: From the insertions , maybe ?&#10;Speaker: PhD D&#10;Content: um , yeah , there 's a way to tell .&#10;Speaker: PhD F&#10;Content: fr fr from the {disfmarker}&#10;Speaker: PhD D&#10;Content: It might not be a single person who 's always overlapping that person but any number of people ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: and , um , if you align the two hypothesis files across the channels , you know , just word">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD F needs a channel with a speaker who has a lot of overlap in their speech.&#10;2. The speaker should not be using a lapel microphone, as the current setup does not work for lapel stuff.&#10;3. A non-lapel microphone should be used for the speaker.&#10;4. PhD F needs to find a channel with another person talking a lot nearby.&#10;5. Simultaneous adaptation of phone models to the specific speaker and rejection model to all other speech is required.&#10;6. The rejection model should be adapted to speech from all other channels, not just the one being analyzed.&#10;7. It would be preferable if there was someone sitting next to the speaker who talks a lot.&#10;8. Suitable candidates for this procedure need to have mixed signal waveforms available visually for analysis." target="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Postdoc A&#10;Content: Oh . Oh .&#10;Speaker: PhD F&#10;Content: which {disfmarker} which seemed reasonable given that , you know , the models weren't tuned for {disfmarker} {vocalsound} for it .&#10;Speaker: Grad G&#10;Content: Hmm !&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: And the grammar wasn't tuned either .&#10;Speaker: PhD B&#10;Content: And it didn't matter whether it was the lapel or whether it was the {disfmarker}&#10;Speaker: PhD F&#10;Content: It was just a @ @ . I haven't split it up that way ,&#10;Speaker: PhD D&#10;Content: But there 's no overlap during the digit readings , so it shouldn't really matter .&#10;Speaker: PhD F&#10;Content: but it would be {disfmarker}&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: No , but there 's a little difference ,&#10;Speaker: PhD" target="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit.">
      <data key="d0">1</data>
    </edge>
    <edge source="s possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the reject model to the {disfmarker} to {disfmarker} to all the other speech . Um , so&#10;Speaker: PhD B&#10;Content: Could you {disfmarker} could you at the same time adapt the reject model to the speech from all the other channels ?&#10;Speaker: Professor C&#10;Content: That 's what he just said .&#10;Speaker: Grad E&#10;Content: That 's what he was saying .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: That 's what I just said .&#10;Speaker: PhD B&#10;Content: Oh , not just the speech from that {disfmarker} of the other people from that channel ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: but the speech from the a actual other channels .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Oh , oh , I see . Um ,&#10;Speaker: Professor C&#10;Content: Oh" target="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns.">
      <data key="d0">1</data>
    </edge>
    <edge source="s possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the reject model to the {disfmarker} to {disfmarker} to all the other speech . Um , so&#10;Speaker: PhD B&#10;Content: Could you {disfmarker} could you at the same time adapt the reject model to the speech from all the other channels ?&#10;Speaker: Professor C&#10;Content: That 's what he just said .&#10;Speaker: Grad E&#10;Content: That 's what he was saying .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: That 's what I just said .&#10;Speaker: PhD B&#10;Content: Oh , not just the speech from that {disfmarker} of the other people from that channel ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: but the speech from the a actual other channels .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Oh , oh , I see . Um ,&#10;Speaker: Professor C&#10;Content: Oh" target="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="aker: PhD B&#10;Content: and then we go in and adjust the boundaries .&#10;Speaker: Postdoc A&#10;Content: Yeah that 's right . Yeah , we haven't done that . I {disfmarker} I could set someone on that tomorrow .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: And time how long it takes .&#10;Speaker: PhD B&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: I think they 're coming {disfmarker}&#10;Speaker: PhD B&#10;Content: And we probably don't have to do necessarily a whole meeting for that if we just wanna send them a sample to try .&#10;Speaker: Postdoc A&#10;Content: OK . What would be a good number of minutes ?&#10;Speaker: PhD B&#10;Content: I don't know , maybe we can figure out how long it 'll take @ @ to {disfmarker} to do .&#10;Speaker: Grad E&#10;Content: Um , I don't know , it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target=" it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker: Professor C&#10;Content: Yes except that if they had {disfmarker} if there was a choice between having fifteen minutes that was fully the way you wanted it , and having a whole meeting that didn't get at what you wanted for them {disfmarker} It 's just dependent of how much {disfmarker}&#10;Speaker: Grad E&#10;Content: Like I {disfmarker} I mean I guess if we have to do it again anyway , but , uh&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: I guess , the only thing I 'm not sure about is , um , how quickly can the transcribers scan over and fix the boundaries ,&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: and {disfmarker} I mean , is it pretty easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target=" A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}&#10;Speaker: Professor C&#10;Content: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?&#10;Speaker: PhD B&#10;Content: Well I {disfmarker} I {disfmarker} I mean , I don't know .&#10;Speaker: Grad E&#10;Content: That was the question . Though .&#10;Speaker: Professor C&#10;Content: So if we {disfmarker} if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing .&#10;Speaker: PhD B&#10;Content: Yeah . Uh . That {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target=" of sending him a sample one to {disfmarker} f&#10;Speaker: Grad E&#10;Content: Yeah , maybe it doesn't matter .&#10;Speaker: Postdoc A&#10;Content: Great .&#10;Speaker: PhD B&#10;Content: I {disfmarker} I don't think it matte&#10;Speaker: Postdoc A&#10;Content: I 'll {disfmarker} I 'll {disfmarker} I 'll , um , get {disfmarker} make that available .&#10;Speaker: Grad E&#10;Content: OK , and has it been corrected ?&#10;Speaker: Postdoc A&#10;Content: Oh , well , wait . Um {disfmarker}&#10;Speaker: Grad E&#10;Content: Hand - checked ? Cuz that was one of the {vocalsound} processes we were talking about as well .&#10;Speaker: PhD B&#10;Content: Right , so we need to run Thilo 's thing on it ,&#10;Speaker: Postdoc A&#10;Content: That 's right .&#10;Speaker: PhD B&#10;Content: and then we go in and adjust the boundaries .&#10;Speaker: Postdoc A&#10;Content: Yeah that 's right">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target=" types of things . I 've {disfmarker} I 've discussed it with Thilo and I mean {disfmarker} in terms of not him doing it , but we {disfmarker} we discussed some of the parameters of that and how hard it would be to {disfmarker} in principle {disfmarker} to write something that would do that .&#10;Speaker: PhD D&#10;Content: I mean , I guess in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have a good idea of where the forced alignment is constrained to .&#10;Speaker: Postdoc A&#10;Content: Well , it 's just , you know , a matter of we had the revolution {disfmarker} we had the revolution of improved , uh , interface , um , one month too late ,&#10;Speaker: PhD D&#10;Content: So I 'm no I don't know if this&#10;Speaker: Grad E&#10;Content: Oh . Tools .&#10;Speaker: Postdoc A&#10;Content: but it 's like , you know , it 's wonderful to have the revolution ,&#10;Speaker: PhD D&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target=" the same speaker , so now sometimes you get a ni microphone pop and , uh , I mean , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . It 's not a simple {disfmarker} not a simple problem .&#10;Speaker: PhD D&#10;Content: Anyway , quick question , though , at a high level do people think , let 's just say that we 're moving to this new era of like using the , um , pre - segmented t you know , non - synchronous conversations , does it make sense to try to take what we have now , which are the ones that , you know , we have recognition on which are synchronous and not time - tightened , and try to get something out of those for sort of purposes of illustrating the structure and the nature of the meetings , or is it better to just , you know , forget that and tr I mean , it 's {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , I think we 'll have to , eventually . And my hope was that we would be able to use the forced alignment to get it .&#10;Speaker: PhD D&#10;Content: Right . That was everybody">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The estimated time to adjust the boundaries was not explicitly discussed in the transcript. However, Grad E suggested timing how long it takes when they assign someone to do it the next day.&#10;2. It seems that a full meeting does not need to be held just for adjusting the boundaries. PhD B proposed sending a sample to try instead of holding a whole meeting, and this idea was met with agreement from Postdoc A and Professor C.&#10;3. Grad E brought up the point that they would have to transcribe the whole meeting anyway at some point, but Professor C mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option.&#10;4. Postdoc A and PhD B discussed sending IBM a sample one to two times real-time after running Thilo's thing on it and adjusting the boundaries. This seems to be the group's plan for moving forward." target="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD B&#10;Content: and then we go in and adjust the boundaries .&#10;Speaker: Postdoc A&#10;Content: Yeah that 's right . Yeah , we haven't done that . I {disfmarker} I could set someone on that tomorrow .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: And time how long it takes .&#10;Speaker: PhD B&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: I think they 're coming {disfmarker}&#10;Speaker: PhD B&#10;Content: And we probably don't have to do necessarily a whole meeting for that if we just wanna send them a sample to try .&#10;Speaker: Postdoc A&#10;Content: OK . What would be a good number of minutes ?&#10;Speaker: PhD B&#10;Content: I don't know , maybe we can figure out how long it 'll take @ @ to {disfmarker} to do .&#10;Speaker: Grad E&#10;Content: Um , I don't know , it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker" target="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker: Professor C&#10;Content: Yes except that if they had {disfmarker} if there was a choice between having fifteen minutes that was fully the way you wanted it , and having a whole meeting that didn't get at what you wanted for them {disfmarker} It 's just dependent of how much {disfmarker}&#10;Speaker: Grad E&#10;Content: Like I {disfmarker} I mean I guess if we have to do it again anyway , but , uh&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: I guess , the only thing I 'm not sure about is , um , how quickly can the transcribers scan over and fix the boundaries ,&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: and {disfmarker} I mean , is it pretty easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow" target="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source=" it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .&#10;Speaker: Professor C&#10;Content: Yes except that if they had {disfmarker} if there was a choice between having fifteen minutes that was fully the way you wanted it , and having a whole meeting that didn't get at what you wanted for them {disfmarker} It 's just dependent of how much {disfmarker}&#10;Speaker: Grad E&#10;Content: Like I {disfmarker} I mean I guess if we have to do it again anyway , but , uh&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: I guess , the only thing I 'm not sure about is , um , how quickly can the transcribers scan over and fix the boundaries ,&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: and {disfmarker} I mean , is it pretty easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow" target="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}&#10;Speaker: Professor C&#10;Content: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?&#10;Speaker: PhD B&#10;Content: Well I {disfmarker} I {disfmarker} I mean , I don't know .&#10;Speaker: Grad E&#10;Content: That was the question . Though .&#10;Speaker: Professor C&#10;Content: So if we {disfmarker} if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing .&#10;Speaker: PhD B&#10;Content: Yeah . Uh . That {disfmarker" target="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source=" types of things . I 've {disfmarker} I 've discussed it with Thilo and I mean {disfmarker} in terms of not him doing it , but we {disfmarker} we discussed some of the parameters of that and how hard it would be to {disfmarker} in principle {disfmarker} to write something that would do that .&#10;Speaker: PhD D&#10;Content: I mean , I guess in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have a good idea of where the forced alignment is constrained to .&#10;Speaker: Postdoc A&#10;Content: Well , it 's just , you know , a matter of we had the revolution {disfmarker} we had the revolution of improved , uh , interface , um , one month too late ,&#10;Speaker: PhD D&#10;Content: So I 'm no I don't know if this&#10;Speaker: Grad E&#10;Content: Oh . Tools .&#10;Speaker: Postdoc A&#10;Content: but it 's like , you know , it 's wonderful to have the revolution ,&#10;Speaker: PhD D&#10;" target="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the same speaker , so now sometimes you get a ni microphone pop and , uh , I mean , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . It 's not a simple {disfmarker} not a simple problem .&#10;Speaker: PhD D&#10;Content: Anyway , quick question , though , at a high level do people think , let 's just say that we 're moving to this new era of like using the , um , pre - segmented t you know , non - synchronous conversations , does it make sense to try to take what we have now , which are the ones that , you know , we have recognition on which are synchronous and not time - tightened , and try to get something out of those for sort of purposes of illustrating the structure and the nature of the meetings , or is it better to just , you know , forget that and tr I mean , it 's {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , I think we 'll have to , eventually . And my hope was that we would be able to use the forced alignment to get it .&#10;Speaker: PhD D&#10;Content: Right . That was everybody" target="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="&#10;Content: so .&#10;Speaker: Professor C&#10;Content: Hmm , no connection .&#10;Speaker: Grad E&#10;Content: It 's {disfmarker} i they 're called temp files , but they 're not actually in the temp directory they 're in the scratch , so . They 're not backed up , but they 're not erased either on power failure .&#10;Speaker: PhD D&#10;Content: But that 's usually the meeting that I recorded , and it neve it doesn't crash on me .&#10;Speaker: PhD B&#10;Content: Well this wasn't {disfmarker} Actually , this wasn't a before your meeting , this was , um , Tuesday afternoon when , um , uh , Robert just wanted to do a little recording ,&#10;Speaker: Grad E&#10;Content: Oh well .&#10;Speaker: PhD D&#10;Content: Oh {disfmarker} Oh , right .&#10;Speaker: PhD B&#10;Content: and the power had gone out earlier in the day .&#10;Speaker: PhD D&#10;Content: OK . Huh , OK .&#10;Speaker: Professor C&#10;Content: I don't know when would be a good excuse for it , but I just">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="Speaker: PhD B&#10;Content: I thought he 's just saying you have to look over a longer time window when you do it .&#10;Speaker: Grad E&#10;Content: Um - hmm .&#10;Speaker: PhD D&#10;Content: and the {disfmarker} but there are some issues of this timing , um , in the recordings&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: So you just have to look over longer time when you 're trying to align the things , you can't {disfmarker} you can't just look {disfmarker}&#10;Speaker: Grad E&#10;Content: Well . are you talking about the fact that the recording software doesn't do time - synchronous ? Is that what you 're referring to ?&#10;Speaker: Professor C&#10;Content: &#10;Speaker: Grad E&#10;Content: That seems to me you can do that over the entire file and get a very accurate {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't thi I d">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="} just something really wrong with {disfmarker}&#10;Speaker: Grad G&#10;Content: I 'm sorry , I don't {disfmarker}&#10;Speaker: Grad E&#10;Content: A bug is what I mean ,&#10;Speaker: PhD F&#10;Content: In the recording&#10;Speaker: Grad G&#10;Content: Oh .&#10;Speaker: Grad E&#10;Content: so that it 's like {disfmarker}&#10;Speaker: Grad G&#10;Content: Oh , OK .&#10;Speaker: PhD F&#10;Content: And there was this one meeting , I forget which one it was , where like , uh , six out of the eight channels were all , like {disfmarker} had a hundred percent error .&#10;Speaker: Grad G&#10;Content: I see .&#10;Speaker: Grad E&#10;Content: Which probably means like there was a {disfmarker} th the recording interface crashed ,&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: or there was a short {disfmarker} you know , someone was jiggling with a cord&#10;Speaker: PhD F&#10;Content: But {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target=" , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from something else , and adapting , and how well that works . Uh , so in {disfmarker} in fact it was pretty related to what Liz and Andreas did , uh , except that this was not with meeting stuff , it was with&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: uh , like I think they s didn't they start off with Broadcast News system ? And then they went to {disfmarker}&#10;Speaker: Grad E&#10;Content: The - their Broadcast News was their acoustic models and then all the other tasks were much simpler .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So they were command and control and that sort of thing .&#10;Speaker: Professor C&#10;Content: TI - digits was one of them , and , uh , Wall Street Journal .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: What was their rough {disfmarker} what was their conclusion ?&#10;Speaker: Grad E&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Grad G&#10;Content: How about channel&#10;Speaker: Professor C&#10;Content: Yeah , go ahead .&#10;Speaker: Grad E&#10;Content: We 're recording .&#10;Speaker: Grad G&#10;Content: Alright .&#10;Speaker: Professor C&#10;Content: Alright , and no crash .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: I pre - crashed it .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Pre - crashed !&#10;Speaker: PhD D&#10;Content: It never crashes on me .&#10;Speaker: Grad E&#10;Content: I think it 's actually {disfmarker}&#10;Speaker: PhD D&#10;Content: What is {disfmarker} what is that ?&#10;Speaker: Grad E&#10;Content: it depends on if the temp files are there or not , that {disfmarker} at least that 's my current working hypothesis ,&#10;Speaker: PhD D&#10;Content: Ah .&#10;Speaker: Grad E&#10;Content: that I think what happens is it tries to clear the temp files">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="Speaker: PhD D&#10;Content: Ah .&#10;Speaker: Grad E&#10;Content: that I think what happens is it tries to clear the temp files and if they 're too big , it crashes .&#10;Speaker: PhD D&#10;Content: Ah .&#10;Speaker: PhD B&#10;Content: When the power went out the other day and I restarted it , it crashed the first time .&#10;Speaker: Grad E&#10;Content: Oh , that 's right .&#10;Speaker: PhD B&#10;Content: After the power out&#10;Speaker: PhD D&#10;Content: So then there would be no temp files .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: OK . {comment} Hmm .&#10;Speaker: Grad E&#10;Content: Uh , no , it doesn't {disfmarker} it doesn't clear those necessarily ,&#10;Speaker: PhD D&#10;Content: Oh wait {disfmarker} It {disfmarker} it doesn't clear them , OK .&#10;Speaker: Grad E&#10;Content: so .&#10;Speaker: Professor C&#10;Content: Hmm , no connection .&#10;Speaker: Grad E&#10;Content: It 's {">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team.">
      <data key="d0">1</data>
    </edge>
    <edge source="On Tuesday afternoon, Robert needed to do a recording. However, there was an issue with the recording due to a power failure that had occurred earlier in the day. The power outage might have caused some disruption in the recording software or its settings, resulting in the problem during the meeting recording that did not normally crash. This situation deviated from the usual meeting that the professor had recorded, which typically did not encounter such issues." target="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD B&#10;Content: I thought he 's just saying you have to look over a longer time window when you do it .&#10;Speaker: Grad E&#10;Content: Um - hmm .&#10;Speaker: PhD D&#10;Content: and the {disfmarker} but there are some issues of this timing , um , in the recordings&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: So you just have to look over longer time when you 're trying to align the things , you can't {disfmarker} you can't just look {disfmarker}&#10;Speaker: Grad E&#10;Content: Well . are you talking about the fact that the recording software doesn't do time - synchronous ? Is that what you 're referring to ?&#10;Speaker: Professor C&#10;Content: &#10;Speaker: Grad E&#10;Content: That seems to me you can do that over the entire file and get a very accurate {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't thi I d" target="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from something else , and adapting , and how well that works . Uh , so in {disfmarker} in fact it was pretty related to what Liz and Andreas did , uh , except that this was not with meeting stuff , it was with&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: uh , like I think they s didn't they start off with Broadcast News system ? And then they went to {disfmarker}&#10;Speaker: Grad E&#10;Content: The - their Broadcast News was their acoustic models and then all the other tasks were much simpler .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So they were command and control and that sort of thing .&#10;Speaker: Professor C&#10;Content: TI - digits was one of them , and , uh , Wall Street Journal .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: What was their rough {disfmarker} what was their conclusion ?&#10;Speaker: Grad E&#10;" target="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target=" easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow , excuse me , two or more times real time , right ? Cuz they have to at least listen to it .&#10;Speaker: Professor C&#10;Content: Can we pipeline it so that say there 's , uh , the transcriber gets done with a quarter of the meeting and then we {disfmarker} you run it through this other {disfmarker} other stuff ? Uh ,&#10;Speaker: Grad E&#10;Content: Well the other stuff is I B I 'm just thinking that from a data {disfmarker} keeping - track - of - the - data point of view , it may be best to send them whole meetings at a time and not try to send them bits and pieces .&#10;Speaker: Professor C&#10;Content: OK , so . Oh , that 's right . So the first thing is the automatic thing , and then it 's {disfmarker} then it 's {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Pipelining: Professor C suggested pipelining the transcription process so that as soon as a quarter of the meeting is transcribed, it can be run through other processes for further analysis. This would allow for real-time or near real-time transcription and analysis of the meeting.&#10;2. Sending Whole Meetings: Grad E suggested sending whole meetings at a time instead of in bits and pieces, as this might be more efficient from a data-keeping perspective. This could also be useful for pipelining, as it would allow for continuous processing of the meeting once the transcription is complete.&#10;3. Adjusting Boundaries: The group discussed adjusting boundaries, which may refer to editing or correcting the transcription. It seems that sending a sample to try instead of holding a whole meeting could be an option for this. Additionally, it was mentioned that assigning someone to time how long it takes to adjust the boundaries the next day could help estimate the time required for this task.&#10;4. Simultaneous Adaptation: For specific speakers, such as PhD F, simultaneous adaptation of phone models to the speaker's voice and rejection model to all other speech is necessary. This would allow for more accurate real-time transcription for individual speakers.&#10;5. Visual Analysis: Suitable candidates for this procedure need mixed signal waveforms available visually for analysis, which could help improve the accuracy of real-time transcription." target="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample.">
      <data key="d0">1</data>
    </edge>
    <edge source=" easy ?&#10;Speaker: Grad E&#10;Content: I think it 's gonna be one or two times real time at {disfmarker} Wow , excuse me , two or more times real time , right ? Cuz they have to at least listen to it .&#10;Speaker: Professor C&#10;Content: Can we pipeline it so that say there 's , uh , the transcriber gets done with a quarter of the meeting and then we {disfmarker} you run it through this other {disfmarker} other stuff ? Uh ,&#10;Speaker: Grad E&#10;Content: Well the other stuff is I B I 'm just thinking that from a data {disfmarker} keeping - track - of - the - data point of view , it may be best to send them whole meetings at a time and not try to send them bits and pieces .&#10;Speaker: Professor C&#10;Content: OK , so . Oh , that 's right . So the first thing is the automatic thing , and then it 's {disfmarker} then it 's {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Spe" target="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I" target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present.">
      <data key="d0">1</data>
    </edge>
    <edge source="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I" target="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I" target="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I" target="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="s {disfmarker} then it 's the transcribers tightening stuff up ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: and then it 's IBM .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm , mm - hmm .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .&#10;Speaker: Postdoc A&#10;Content: And have them fix it over the entire meeting too ?&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Right ?&#10;Speaker: PhD B&#10;Content: As of what point ? I" target="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." target=" are because the recognition 's so poor . Right ?&#10;Speaker: PhD B&#10;Content: Yeah , we were never just gonna go with these as the final alignments .&#10;Speaker: PhD D&#10;Content: And so you 're {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I agree . I agree .&#10;Speaker: PhD B&#10;Content: We were always gonna run them past somebody .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Absolutely .&#10;Speaker: PhD D&#10;Content: So we need some way to push these first chunk of meetings into a state where we get good alignments .&#10;Speaker: PhD F&#10;Content: I 'm probably going to spend another day or so trying to improve things by , um , {vocalsound} {vocalsound} by using , um , acoustic adaptation . Um , the {disfmarker} {vocalsound} Right now I 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." target=" haven't checked those yet .&#10;Speaker: Grad E&#10;Content: C&#10;Speaker: PhD F&#10;Content: It 's very tedious to check these .&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: PhD F&#10;Content: Um , we would really need , ideally , a transcriber {vocalsound} to time mark the {disfmarker} you know , the be at least the beginning and s ends {comment} of contiguous speech . Um , {vocalsound} {vocalsound} and , you know , then with the time marks , you can do an automatic comparison of your {disfmarker} of your forced alignments .&#10;Speaker: PhD B&#10;Content: Because {disfmarker} really the {disfmarker} the {disfmarker} at least in terms of how we were gonna use this in our system was to get an ideal {disfmarker} an idea , uh , for each channel about the start and end boundaries .&#10;Speaker: Grad E&#10;Content: Oh , MNCM . &#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: We">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." target=" I {disfmarker} I wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , you know , actual numbers . Like if we {disfmarker} if we had hand - transcribed pe good alignments or hand - checked alignments , then we could do this paper . It 's not that we need it to be automatic . But without knowing where the real words are , in time {disfmarker}&#10;Speaker: PhD B&#10;Content: So it was to get {disfmarker} it was to get more data and better {disfmarker} to {disfmarker} to squeeze the boundaries in .&#10;Speaker: PhD D&#10;Content: To {disfmarker} to know what an overlap really {disfmarker} if it 's really an overlap , or if it 's just a {disfmarker} a {disfmarker} a segment correlated with an overlap ,&#10;Speaker: PhD B&#10;Content: Ah , OK . Yeah .&#10;Speaker: PhD D&#10;Content: and I guess that 's the difference to me between like a real paper and a sort of ,">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." target="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." target="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion among the participants, they seem to agree that eventually they will have to use forced alignment. The existing synchronous and untimed recordings with recognition have poor quality and are not suitable for direct use in the new system. They mention that the recognition is so poor that they were never planning to use them as the final alignments, but instead planned to have a human review the transcriptions.&#10;&#10;Therefore, it would be more beneficial to solely rely on using forced alignment in the future, rather than trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. This is because the quality of the existing recordings is not sufficient and will require significant manual effort to be made usable. It would be better to focus efforts on improving the forced alignment process to ensure high-quality results in the new system." target="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source=" are because the recognition 's so poor . Right ?&#10;Speaker: PhD B&#10;Content: Yeah , we were never just gonna go with these as the final alignments .&#10;Speaker: PhD D&#10;Content: And so you 're {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I agree . I agree .&#10;Speaker: PhD B&#10;Content: We were always gonna run them past somebody .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Absolutely .&#10;Speaker: PhD D&#10;Content: So we need some way to push these first chunk of meetings into a state where we get good alignments .&#10;Speaker: PhD F&#10;Content: I 'm probably going to spend another day or so trying to improve things by , um , {vocalsound} {vocalsound} by using , um , acoustic adaptation . Um , the {disfmarker} {vocalsound} Right now I 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , uh , manage to adapt the , {vocalsound} uh , phone models to the speaker and the" target="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" I {disfmarker} I wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , you know , actual numbers . Like if we {disfmarker} if we had hand - transcribed pe good alignments or hand - checked alignments , then we could do this paper . It 's not that we need it to be automatic . But without knowing where the real words are , in time {disfmarker}&#10;Speaker: PhD B&#10;Content: So it was to get {disfmarker} it was to get more data and better {disfmarker} to {disfmarker} to squeeze the boundaries in .&#10;Speaker: PhD D&#10;Content: To {disfmarker} to know what an overlap really {disfmarker} if it 's really an overlap , or if it 's just a {disfmarker} a {disfmarker} a segment correlated with an overlap ,&#10;Speaker: PhD B&#10;Content: Ah , OK . Yeah .&#10;Speaker: PhD D&#10;Content: and I guess that 's the difference to me between like a real paper and a sort of ," target="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present." target=" was {disfmarker}&#10;Speaker: Professor C&#10;Content: Columbia have anything ? No .&#10;Speaker: PhD D&#10;Content: no it was {disfmarker}&#10;Speaker: Grad E&#10;Content: Wasn't {disfmarker} Who {disfmarker} who {disfmarker} who did the order one ?&#10;Speaker: PhD D&#10;Content: this was Wednesday morning . The sentence ordering one , was that Barselou , and these guys ?&#10;Speaker: Grad E&#10;Content: Ugh ! {comment} I 'm just so bad at that .&#10;Speaker: Postdoc A&#10;Content: Oh .&#10;Speaker: PhD D&#10;Content: Anyway , I {disfmarker} I {disfmarker} it 's in the program , I should have read it to remind myself , but that 's sort of useful and I think like when Mari and Katrin and Jeff are here it 'd be good to figure out some kinds of things that we can start doing maybe just on the transcripts cuz we already have {disfmarker}&#10;Speaker: Professor C&#10;Content: Mm - hmm .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present." target="Speaker: PhD D&#10;Content: No .&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor C&#10;Content: No , we just had some discussions , various discussions with them .&#10;Speaker: Grad E&#10;Content: It 's just informal .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm . Mm - hmm . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .&#10;Speaker: PhD B&#10;Content: What was the , um {disfmarker} the paper by , um , Lori Lamel that you mentioned ?&#10;Speaker: Professor C&#10;Content: Um , yeah , we sh we should just have you {disfmarker} have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,&#10;Speaker: Postdoc A&#10;Content: Mmm , yeah .&#10;Speaker: Professor C&#10;Content: but , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present." target="aker: PhD D&#10;Content: But I think what 's interesting is there 's all these different evaluations , like {disfmarker} just , you know , how do you evaluate whether the summary is good or not ,&#10;Speaker: Grad E&#10;Content: I always write down the wrong things .&#10;Speaker: Postdoc A&#10;Content: I do take notes .&#10;Speaker: PhD D&#10;Content: and that 's what 's {disfmarker} was sort of interesting to me is that there 's different ways to do it ,&#10;Speaker: Grad E&#10;Content: A judge .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: Was SRA one of the groups talking about summarization , no ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Hm - umm . No .&#10;Speaker: Postdoc A&#10;Content: It was an interesting session . One of those w&#10;Speaker: Grad E&#10;Content: And as I said , I like the Microsoft talk on {pause} scaling issues in , uh , word sense disambiguation ,&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present." target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys&quot; according to PhD D.&#10;2. When Mari, Katrin, and Jeff are present, some useful activities to do, as suggested by PhD D and Professor C, include figuring out kinds of things that can be started, possibly just on the transcripts since they already have them. Additionally, they mention it would be good to determine some types of tasks that can be done when the whole team is present." target="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" was {disfmarker}&#10;Speaker: Professor C&#10;Content: Columbia have anything ? No .&#10;Speaker: PhD D&#10;Content: no it was {disfmarker}&#10;Speaker: Grad E&#10;Content: Wasn't {disfmarker} Who {disfmarker} who {disfmarker} who did the order one ?&#10;Speaker: PhD D&#10;Content: this was Wednesday morning . The sentence ordering one , was that Barselou , and these guys ?&#10;Speaker: Grad E&#10;Content: Ugh ! {comment} I 'm just so bad at that .&#10;Speaker: Postdoc A&#10;Content: Oh .&#10;Speaker: PhD D&#10;Content: Anyway , I {disfmarker} I {disfmarker} it 's in the program , I should have read it to remind myself , but that 's sort of useful and I think like when Mari and Katrin and Jeff are here it 'd be good to figure out some kinds of things that we can start doing maybe just on the transcripts cuz we already have {disfmarker}&#10;Speaker: Professor C&#10;Content: Mm - hmm .&#10;Speaker:" target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD D&#10;Content: No .&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor C&#10;Content: No , we just had some discussions , various discussions with them .&#10;Speaker: Grad E&#10;Content: It 's just informal .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm . Mm - hmm . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .&#10;Speaker: PhD B&#10;Content: What was the , um {disfmarker} the paper by , um , Lori Lamel that you mentioned ?&#10;Speaker: Professor C&#10;Content: Um , yeah , we sh we should just have you {disfmarker} have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,&#10;Speaker: Postdoc A&#10;Content: Mmm , yeah .&#10;Speaker: Professor C&#10;Content: but , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from" target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD D&#10;Content: No .&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor C&#10;Content: No , we just had some discussions , various discussions with them .&#10;Speaker: Grad E&#10;Content: It 's just informal .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm . Mm - hmm . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .&#10;Speaker: PhD B&#10;Content: What was the , um {disfmarker} the paper by , um , Lori Lamel that you mentioned ?&#10;Speaker: Professor C&#10;Content: Um , yeah , we sh we should just have you {disfmarker} have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,&#10;Speaker: Postdoc A&#10;Content: Mmm , yeah .&#10;Speaker: Professor C&#10;Content: but , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from" target="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD D&#10;Content: No .&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor C&#10;Content: No , we just had some discussions , various discussions with them .&#10;Speaker: Grad E&#10;Content: It 's just informal .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm . Mm - hmm . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .&#10;Speaker: PhD B&#10;Content: What was the , um {disfmarker} the paper by , um , Lori Lamel that you mentioned ?&#10;Speaker: Professor C&#10;Content: Um , yeah , we sh we should just have you {disfmarker} have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,&#10;Speaker: Postdoc A&#10;Content: Mmm , yeah .&#10;Speaker: Professor C&#10;Content: but , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from" target="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD D&#10;Content: No .&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor C&#10;Content: No , we just had some discussions , various discussions with them .&#10;Speaker: Grad E&#10;Content: It 's just informal .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm . Mm - hmm . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .&#10;Speaker: PhD B&#10;Content: What was the , um {disfmarker} the paper by , um , Lori Lamel that you mentioned ?&#10;Speaker: Professor C&#10;Content: Um , yeah , we sh we should just have you {disfmarker} have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,&#10;Speaker: Postdoc A&#10;Content: Mmm , yeah .&#10;Speaker: Professor C&#10;Content: but , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using {disfmarker} using data from" target="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD D&#10;Content: But I think what 's interesting is there 's all these different evaluations , like {disfmarker} just , you know , how do you evaluate whether the summary is good or not ,&#10;Speaker: Grad E&#10;Content: I always write down the wrong things .&#10;Speaker: Postdoc A&#10;Content: I do take notes .&#10;Speaker: PhD D&#10;Content: and that 's what 's {disfmarker} was sort of interesting to me is that there 's different ways to do it ,&#10;Speaker: Grad E&#10;Content: A judge .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: Was SRA one of the groups talking about summarization , no ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Hm - umm . No .&#10;Speaker: Postdoc A&#10;Content: It was an interesting session . One of those w&#10;Speaker: Grad E&#10;Content: And as I said , I like the Microsoft talk on {pause} scaling issues in , uh , word sense disambiguation ,&#10;Speaker" target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD D&#10;Content: But I think what 's interesting is there 's all these different evaluations , like {disfmarker} just , you know , how do you evaluate whether the summary is good or not ,&#10;Speaker: Grad E&#10;Content: I always write down the wrong things .&#10;Speaker: Postdoc A&#10;Content: I do take notes .&#10;Speaker: PhD D&#10;Content: and that 's what 's {disfmarker} was sort of interesting to me is that there 's different ways to do it ,&#10;Speaker: Grad E&#10;Content: A judge .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: PhD B&#10;Content: Was SRA one of the groups talking about summarization , no ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Hm - umm . No .&#10;Speaker: Postdoc A&#10;Content: It was an interesting session . One of those w&#10;Speaker: Grad E&#10;Content: And as I said , I like the Microsoft talk on {pause} scaling issues in , uh , word sense disambiguation ,&#10;Speaker" target="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target=" whatever they had gotten up to , would be better than nothing .&#10;Speaker: PhD B&#10;Content: Yeah . Uh . That {disfmarker} I agree . I agree .&#10;Speaker: Grad E&#10;Content: Well , I don't think {disfmarker} I mean , h they {disfmarker} they typically work for what , four hours , something like that ?&#10;Speaker: Postdoc A&#10;Content: Hmm , I gue hmm .&#10;Speaker: Grad E&#10;Content: I think the they should be able to get through a whole meeting in one sitting . I would think , unless it 's a lot harder than we think it is , which it could be , certainly .&#10;Speaker: Postdoc A&#10;Content: If it 's got like for speakers then I guess {disfmarker} I mean if {disfmarker}&#10;Speaker: PhD B&#10;Content: We 're just doing the individual channels ,&#10;Speaker: Grad E&#10;Content: Or seven or eight .&#10;Speaker: PhD B&#10;Content: right ?&#10;Speaker: Postdoc A&#10;Content: Individual channels . Yeah .&#10;Speaker: PhD B&#10;Content: So">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers, Grad E and Postdoc A, believe that a full meeting should be able to be transcribed in one sitting, which typically lasts around four hours. However, they are open to the possibility that it could take longer than expected.&#10;2. PhD B proposes sending a sample to try instead of holding a whole meeting for adjusting boundaries, and this idea is met with agreement from Postdoc A and Professor C. This suggests that they prefer a shorter, focused session over a full meeting if it can provide them with the necessary information in a timely manner.&#10;3. Regarding the length of time it would take to complete a meeting, Grad E suggests timing how long it takes when assigning someone to adjust the boundaries the next day, but an estimated time was not explicitly discussed in the transcript." target="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target=" conferences , it 's not {disfmarker} these are conferences that have d really different emphases . Whereas HLT and {disfmarker} and Eurospeech , pretty {disfmarker} pretty {disfmarker} pretty similar , so I {disfmarker} I {disfmarker} I can't see really just putting in the same thing ,&#10;Speaker: Grad E&#10;Content: Are too close , yeah .&#10;Speaker: PhD D&#10;Content: No , I d I don't think that paper is really {disfmarker}&#10;Speaker: Professor C&#10;Content: but {disfmarker}&#10;Speaker: PhD D&#10;Content: the HLT paper is really more of a introduction - to - the - project paper , and , um {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , for Eurospeech we want some results if we can get them .&#10;Speaker: PhD D&#10;Content: Well , yeah , it {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target=": Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: That {disfmarker} I don't wanna do that ,&#10;Speaker: Grad E&#10;Content: Yeah , I 'm doing that for AVIOS .&#10;Speaker: Professor C&#10;Content: but .&#10;Speaker: PhD D&#10;Content: Yeah . But I think we 're {disfmarker} oh , Morgan 's talk went very well , I think .&#10;Speaker: Professor C&#10;Content: Bleep .&#10;Speaker: Grad E&#10;Content: Uh , &quot; bleep &quot; . Yeah , really .&#10;Speaker: PhD D&#10;Content: I think Morgan 's talk went very well it woke {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Excellent .&#10;Speaker: PhD D&#10;Content: you know , it was really a well presented {disfmarker} and got people laughing {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target=" cross - talk in the adaptation , and it 's just sort of blurred .&#10;Speaker: PhD F&#10;Content: That 's a good point .&#10;Speaker: PhD B&#10;Content: If you {disfmarker}&#10;Speaker: PhD F&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: And that we know , I mean , we have that . And it 's about roughly two - thirds , I mean , very roughly averaged .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: That 's not completely negligible . Like a third of it is bad for adaptation or so .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cool . I thought it was higher than that , that 's pr&#10;Speaker: PhD D&#10;Content: It really {disfmarker} it depends a lot . This is just sort of an overall {disfmarker}&#10;Speaker: PhD F&#10;Content: So .&#10;Speaker: Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target=" {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some {disfmarker} or some {disfmarker} I mean , I would see Eurospeech {disfmarker} if we have some Eurospeech papers , these will be paper p p uh , submissions .&#10;Speaker: PhD D&#10;Content: but {disfmarker}&#10;Speaker: Professor C&#10;Content: These will be things that are particular things , aspects of it that we 're looking at , rather than , you know , attempt at a global paper about it .&#10;Speaker: PhD D&#10;Content: Right , right .&#10;Speaker: Grad E&#10;Content: Detail , yeah . Overall .&#10;Speaker: Postdoc A&#10;Content: I did go through one of these meetings . I had , uh , one of the transcribers go through and tighten up the bins on one of the , uh , NSA meetings , and then I went through afterwards and double - checked it so that one is really very {disfmarker} very accurate .&#10;Speaker: PhD D&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target=" sounds like .&#10;Speaker: PhD B&#10;Content: Practically , huh . With all the overlaps .&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: What are we doing ?&#10;Speaker: Grad E&#10;Content: I {disfmarker} Since I 've been gone all week , I didn't send out a reminder for an agenda , so .&#10;Speaker: Professor C&#10;Content: Yeah , and I 'm just {disfmarker}&#10;Speaker: Grad E&#10;Content: Do we have anything to talk about or should we just read digits and go ?&#10;Speaker: PhD B&#10;Content: I wouldn't mind hearing how the conference was .&#10;Speaker: Professor C&#10;Content: What conference ?&#10;Speaker: PhD D&#10;Content: Uh , I had one question about {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , really . It 's all a blur .&#10;Speaker: PhD D&#10;Content: Aren't the UW folks coming this weekend ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: No . The next ,&#10;Speaker: PhD D">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers believe that the papers submitted to HLT, Eurospeech, and INTERSPEECH conferences should not be identical because these conferences have different emphases. While HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;2. The difference between the types of papers expected for each conference:&#10;   - HLT: Professor C mentions that the HLT paper is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research.&#10;   - Eurospeech: Grad E states that they want some results if possible for Eurospeech. This suggests that the papers for this conference should include actual research findings or outcomes.&#10;   - INTERSPEECH: Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences." target="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference.">
      <data key="d0">1</data>
    </edge>
    <edge source=" conferences , it 's not {disfmarker} these are conferences that have d really different emphases . Whereas HLT and {disfmarker} and Eurospeech , pretty {disfmarker} pretty {disfmarker} pretty similar , so I {disfmarker} I {disfmarker} I can't see really just putting in the same thing ,&#10;Speaker: Grad E&#10;Content: Are too close , yeah .&#10;Speaker: PhD D&#10;Content: No , I d I don't think that paper is really {disfmarker}&#10;Speaker: Professor C&#10;Content: but {disfmarker}&#10;Speaker: PhD D&#10;Content: the HLT paper is really more of a introduction - to - the - project paper , and , um {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , for Eurospeech we want some results if we can get them .&#10;Speaker: PhD D&#10;Content: Well , yeah , it {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some" target="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source=" conferences , it 's not {disfmarker} these are conferences that have d really different emphases . Whereas HLT and {disfmarker} and Eurospeech , pretty {disfmarker} pretty {disfmarker} pretty similar , so I {disfmarker} I {disfmarker} I can't see really just putting in the same thing ,&#10;Speaker: Grad E&#10;Content: Are too close , yeah .&#10;Speaker: PhD D&#10;Content: No , I d I don't think that paper is really {disfmarker}&#10;Speaker: Professor C&#10;Content: but {disfmarker}&#10;Speaker: PhD D&#10;Content: the HLT paper is really more of a introduction - to - the - project paper , and , um {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , for Eurospeech we want some results if we can get them .&#10;Speaker: PhD D&#10;Content: Well , yeah , it {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some" target="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials.">
      <data key="d0">1</data>
    </edge>
    <edge source=" conferences , it 's not {disfmarker} these are conferences that have d really different emphases . Whereas HLT and {disfmarker} and Eurospeech , pretty {disfmarker} pretty {disfmarker} pretty similar , so I {disfmarker} I {disfmarker} I can't see really just putting in the same thing ,&#10;Speaker: Grad E&#10;Content: Are too close , yeah .&#10;Speaker: PhD D&#10;Content: No , I d I don't think that paper is really {disfmarker}&#10;Speaker: Professor C&#10;Content: but {disfmarker}&#10;Speaker: PhD D&#10;Content: the HLT paper is really more of a introduction - to - the - project paper , and , um {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , for Eurospeech we want some results if we can get them .&#10;Speaker: PhD D&#10;Content: Well , yeah , it {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some" target="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: That {disfmarker} I don't wanna do that ,&#10;Speaker: Grad E&#10;Content: Yeah , I 'm doing that for AVIOS .&#10;Speaker: Professor C&#10;Content: but .&#10;Speaker: PhD D&#10;Content: Yeah . But I think we 're {disfmarker} oh , Morgan 's talk went very well , I think .&#10;Speaker: Professor C&#10;Content: Bleep .&#10;Speaker: Grad E&#10;Content: Uh , &quot; bleep &quot; . Yeah , really .&#10;Speaker: PhD D&#10;Content: I think Morgan 's talk went very well it woke {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Excellent .&#10;Speaker: PhD D&#10;Content: you know , it was really a well presented {disfmarker} and got people laughing {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content:" target="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference.">
      <data key="d0">1</data>
    </edge>
    <edge source=" cross - talk in the adaptation , and it 's just sort of blurred .&#10;Speaker: PhD F&#10;Content: That 's a good point .&#10;Speaker: PhD B&#10;Content: If you {disfmarker}&#10;Speaker: PhD F&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: And that we know , I mean , we have that . And it 's about roughly two - thirds , I mean , very roughly averaged .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: That 's not completely negligible . Like a third of it is bad for adaptation or so .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cool . I thought it was higher than that , that 's pr&#10;Speaker: PhD D&#10;Content: It really {disfmarker} it depends a lot . This is just sort of an overall {disfmarker}&#10;Speaker: PhD F&#10;Content: So .&#10;Speaker: Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker" target="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials.">
      <data key="d0">1</data>
    </edge>
    <edge source=" cross - talk in the adaptation , and it 's just sort of blurred .&#10;Speaker: PhD F&#10;Content: That 's a good point .&#10;Speaker: PhD B&#10;Content: If you {disfmarker}&#10;Speaker: PhD F&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: And that we know , I mean , we have that . And it 's about roughly two - thirds , I mean , very roughly averaged .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: That 's not completely negligible . Like a third of it is bad for adaptation or so .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cool . I thought it was higher than that , that 's pr&#10;Speaker: PhD D&#10;Content: It really {disfmarker} it depends a lot . This is just sort of an overall {disfmarker}&#10;Speaker: PhD F&#10;Content: So .&#10;Speaker: Professor C&#10;Content: Well I know what we 're not turning in to Eurospeech , a redo of the HLT paper .&#10;Speaker" target="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some {disfmarker} or some {disfmarker} I mean , I would see Eurospeech {disfmarker} if we have some Eurospeech papers , these will be paper p p uh , submissions .&#10;Speaker: PhD D&#10;Content: but {disfmarker}&#10;Speaker: Professor C&#10;Content: These will be things that are particular things , aspects of it that we 're looking at , rather than , you know , attempt at a global paper about it .&#10;Speaker: PhD D&#10;Content: Right , right .&#10;Speaker: Grad E&#10;Content: Detail , yeah . Overall .&#10;Speaker: Postdoc A&#10;Content: I did go through one of these meetings . I had , uh , one of the transcribers go through and tighten up the bins on one of the , uh , NSA meetings , and then I went through afterwards and double - checked it so that one is really very {disfmarker} very accurate .&#10;Speaker: PhD D&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;" target="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} it 's {disfmarker} probably wouldn't make sense ,&#10;Speaker: Professor C&#10;Content: Or some {disfmarker} or some {disfmarker} I mean , I would see Eurospeech {disfmarker} if we have some Eurospeech papers , these will be paper p p uh , submissions .&#10;Speaker: PhD D&#10;Content: but {disfmarker}&#10;Speaker: Professor C&#10;Content: These will be things that are particular things , aspects of it that we 're looking at , rather than , you know , attempt at a global paper about it .&#10;Speaker: PhD D&#10;Content: Right , right .&#10;Speaker: Grad E&#10;Content: Detail , yeah . Overall .&#10;Speaker: Postdoc A&#10;Content: I did go through one of these meetings . I had , uh , one of the transcribers go through and tighten up the bins on one of the , uh , NSA meetings , and then I went through afterwards and double - checked it so that one is really very {disfmarker} very accurate .&#10;Speaker: PhD D&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;" target="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription." target=" . Yeah .&#10;Speaker: PhD D&#10;Content: and I guess that 's the difference to me between like a real paper and a sort of , promissory paper . So , um , if we d it might be possible to take Thilo 's output and like if you have , um , like right now these meetings are all ,&#10;Speaker: Grad E&#10;Content: Ugh ! I forgot the digital camera again .&#10;Speaker: PhD D&#10;Content: um ,&#10;Speaker: Grad E&#10;Content: Every meeting !&#10;Speaker: PhD D&#10;Content: you know , they 're time - aligned , so if these are two different channels and somebody 's talking here and somebody else is talking here , just that word , if Thilo can tell us that there 're boundaries here , we should be able to figure that out&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: because the only thing transcribed in this channel is this word . But , um , you know , if there are things {disfmarker}&#10;Speaker: Grad E&#10;Content: Two words .&#10;Speaker: PhD D&#10;Content: Yeah , if you">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription." target=" A&#10;Content: He generated , um , a channel - wise presegmented version of a meeting , but it was Robustness rather than EDU so I guess depends on whether we 're willing to use Robustness ?&#10;Speaker: PhD B&#10;Content: Well for this experiment I think we can use pre pretty much anything .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: PhD B&#10;Content: This experiment of just {disfmarker}&#10;Speaker: Grad E&#10;Content: Well we had {disfmarker} we had talked about doing maybe EDU as a good choice , though . Well , {vocalsound} whatever we have .&#10;Speaker: PhD B&#10;Content: Well we 've talked about that as being the next ones we wanted to transcribe .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: PhD B&#10;Content: But for the purpose of sending him a sample one to {disfmarker} f&#10;Speaker: Grad E&#10;Content: Yeah , maybe it doesn't matter .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription." target=" PhD B&#10;Content: right ?&#10;Speaker: Postdoc A&#10;Content: Individual channels . Yeah .&#10;Speaker: PhD B&#10;Content: So it 's gonna be , depending on the number of people in the meeting , um ,&#10;Speaker: Postdoc A&#10;Content: I guess there is this issue of , you know , if {disfmarker} if the segmenter thought there was no speech on {disfmarker} on a particular stretch , on a particular channel ,&#10;Speaker: Grad E&#10;Content: Well {disfmarker}&#10;Speaker: Postdoc A&#10;Content: and there really was , then , if it didn't show up in a mixed signal to verify , then it might be overlooked , so , I mean , the question is &quot; should {disfmarker} should a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? &quot; And I th eh so far as I 'm concerned it 's fine to base it on the mixed signal at this point , and {disfmarker}&#10;Speaker: Grad E&#10;Content: That 's what it seems to me too , in that if they need to , just like">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription." target="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A &quot;real paper&quot; refers to a completed and fully researched academic paper, while a &quot;promissory paper&quot; is one that proposes ideas or plans for future research without having conducted the research yet. In this context, using digital tools to transcribe spoken word, a &quot;real paper&quot; would present concrete results and findings from implemented research, while a &quot;promissory paper&quot; would discuss proposed methods and potential outcomes.&#10;2. Specific technology can help identify boundaries between different speakers during a time-aligned meeting with two channels by detecting breaks or gaps in the conversation to distinguish one speaker from another. This is demonstrated in the discussion about adjusting boundaries, where the group aims to improve the accuracy of real-time transcription by editing or correcting the transcription. Sending a sample for this purpose and assigning someone to time how long it takes to adjust the boundaries can help estimate the required time for this task. Additionally, simultaneous adaptation of phone models to specific speakers' voices and rejection model to all other speech can improve individual speaker recognition in real-time transcription. Visual analysis with mixed signal waveforms available for analysis can also contribute to better accuracy in real-time transcription." target="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source=" PhD B&#10;Content: right ?&#10;Speaker: Postdoc A&#10;Content: Individual channels . Yeah .&#10;Speaker: PhD B&#10;Content: So it 's gonna be , depending on the number of people in the meeting , um ,&#10;Speaker: Postdoc A&#10;Content: I guess there is this issue of , you know , if {disfmarker} if the segmenter thought there was no speech on {disfmarker} on a particular stretch , on a particular channel ,&#10;Speaker: Grad E&#10;Content: Well {disfmarker}&#10;Speaker: Postdoc A&#10;Content: and there really was , then , if it didn't show up in a mixed signal to verify , then it might be overlooked , so , I mean , the question is &quot; should {disfmarker} should a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? &quot; And I th eh so far as I 'm concerned it 's fine to base it on the mixed signal at this point , and {disfmarker}&#10;Speaker: Grad E&#10;Content: That 's what it seems to me too , in that if they need to , just like" target="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." target="}&#10;Speaker: PhD D&#10;Content: yeah it 's {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I 've thought about this , um , and I 've discussed {disfmarker} I 've discussed it with Thilo ,&#10;Speaker: PhD D&#10;Content: I mean , if you have any ideas . I would {disfmarker}&#10;Speaker: Postdoc A&#10;Content: um , the , I mean , I {disfmarker} I {disfmarker} in principle I could imagine writing a script which would approximate it to some degree , but there is this problem of slippage ,&#10;Speaker: Grad E&#10;Content: Well maybe {disfmarker} Maybe that will get enough of the cases to be useful .&#10;Speaker: Postdoc A&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: Right . I mean , that {disfmarker} that would be really helpful . That was sort of another possibility .&#10;Speaker: Grad E&#10;Content: You know s cuz it seemed like most of the cases are in fact the single word sorts , or at least a single phrase&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." target=" things {disfmarker}&#10;Speaker: Grad E&#10;Content: Two words .&#10;Speaker: PhD D&#10;Content: Yeah , if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you , so , um {disfmarker}&#10;Speaker: PhD B&#10;Content: Thilo 's won't put down two separate marks in that case {disfmarker}&#10;Speaker: PhD D&#10;Content: Well it w it would , but , um , we don't know exactly where the words are because the transcriber gave us two words in this time bin&#10;Speaker: Grad E&#10;Content: Thilo 's will . But .&#10;Speaker: PhD D&#10;Content: and we don't really know , I mean ,&#10;Speaker: Postdoc A&#10;Content: Well it 's a merging problem . If you had a {disfmarker} if you had a s if you had a script which would {disfmarker}&#10;Speaker: PhD D&#10;Content: yeah it 's {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I '">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." target="Content: You know s cuz it seemed like most of the cases are in fact the single word sorts , or at least a single phrase&#10;Speaker: Postdoc A&#10;Content: Well they {disfmarker} they can be stretched .&#10;Speaker: Grad E&#10;Content: in most of the bins .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Postdoc A&#10;Content: I wouldn't make that generalization cuz sometimes people will say , &quot; And then I &quot; and there 's a long pause&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: and finish the sentence and {disfmarker} and sometimes it looks coherent and {disfmarker} and the {disfmarker} I mean it 's {disfmarker} it 's not a simple problem . But it 's really {disfmarker} And then it 's coupled with the problem that sometimes , you know , with {disfmarker} with a fricative you might get the beginning of the word cut off and so it 's coupled with the problem that Thilo 's isn't perfect either . I mean , we">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." target=" might get the beginning of the word cut off and so it 's coupled with the problem that Thilo 's isn't perfect either . I mean , we 've i th it 's like you have a merging problem plus {disfmarker} so merging plus this problem of , uh , not {disfmarker}&#10;Speaker: Grad E&#10;Content: Right . Hmm !&#10;Speaker: Postdoc A&#10;Content: y i i if the speech - nonspeech were perfect to begin with , the detector , that would already be an improvement , but that 's impossible , you know , i that 's too much to ask .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yes .&#10;Speaker: Postdoc A&#10;Content: And so i and may you know , I mean , it 's {disfmarker} I think that there always {disfmarker} th there would have to be some hand - tweaking , but it 's possible that a script could be written to merge those two types of things . I 've {disfmarker} I 've discussed it with Thilo and I mean {disfmarker} in terms">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." target=" kept saying , &quot; Can I see that slide again ? &quot;&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah ,&#10;Speaker: Postdoc A&#10;Content: and then they 'd make a comment , and one person said , well - known person said , um , you know , &quot; Before you dismiss forty - five years including my work {disfmarker} &quot;&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Grad E&#10;Content: Forty - five years of research .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: But th you know , the same thing has happened in computational linguistics , right ? You look at the ACL papers coming out , and now there 's sort of a turn back towards , OK we 've learned statistic {disfmarker} you know , we 're basically getting what we expect out of some statistical methods , and , you know , the there 's arguments on both sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that the &quot;slippage&quot; problem occurs when trying to approximate the alignment of speech data with corresponding transcriptions, particularly in cases where there are multiple words or phrases within the same time bin. One possible solution to handle most cases, which seem to be primarily single words or phrases, is to write a script that merges two types of things: 1) the merging problem where words may run into each other without clear separation, and 2) the issue of imperfect speech-nonspeech detectors.&#10;&#10;Postdoc A suggests that if the speech-nonspeech detector were perfect, it would already be an improvement. However, they acknowledge the need for some hand-tweaking due to the complex nature of the problem and the fact that there might be instances where fricatives cause the beginning of words to be cut off.&#10;&#10;To summarize, a possible solution is to develop a script that can accurately detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics. This would likely involve using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns." target="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics.">
      <data key="d0">1</data>
    </edge>
    <edge source=" kept saying , &quot; Can I see that slide again ? &quot;&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah ,&#10;Speaker: Postdoc A&#10;Content: and then they 'd make a comment , and one person said , well - known person said , um , you know , &quot; Before you dismiss forty - five years including my work {disfmarker} &quot;&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Grad E&#10;Content: Forty - five years of research .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: But th you know , the same thing has happened in computational linguistics , right ? You look at the ACL papers coming out , and now there 's sort of a turn back towards , OK we 've learned statistic {disfmarker} you know , we 're basically getting what we expect out of some statistical methods , and , you know , the there 's arguments on both sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker" target="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group.">
      <data key="d0">1</data>
    </edge>
    <edge source=" kept saying , &quot; Can I see that slide again ? &quot;&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah ,&#10;Speaker: Postdoc A&#10;Content: and then they 'd make a comment , and one person said , well - known person said , um , you know , &quot; Before you dismiss forty - five years including my work {disfmarker} &quot;&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Grad E&#10;Content: Forty - five years of research .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: But th you know , the same thing has happened in computational linguistics , right ? You look at the ACL papers coming out , and now there 's sort of a turn back towards , OK we 've learned statistic {disfmarker} you know , we 're basically getting what we expect out of some statistical methods , and , you know , the there 's arguments on both sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker" target="The speakers believe that the type of content to be presented at HLT, Eurospeech, and INTERSPEECH conferences should differ because these conferences have different emphases. Although HLT, PhD D's conference, and Eurospeech are quite similar, there is no point in submitting the same paper to these conferences.&#10;&#10;For HLT, the speakers mention that this conference is more of an introduction-to-the-project paper, indicating that it might be a broader overview or background information on the research. On the other hand, for Eurospeech, the speakers state that they want some results if possible. This suggests that the papers for this conference should include actual research findings or outcomes. Although not explicitly mentioned in the transcript, it is implied that INTERSPEECH conferences also expect original research contributions since identical papers should not be submitted to multiple conferences.&#10;&#10;The speakers also mention a specific example where they would not submit a redo of the HLT paper to Eurospeech. They plan to tailor their submissions to each conference's focus, ensuring that the content is relevant and valuable to each audience. In summary, the speakers believe that the type of content for these conferences should differ because of the unique emphasis and expectations of each conference.">
      <data key="d0">1</data>
    </edge>
    <edge source=" kept saying , &quot; Can I see that slide again ? &quot;&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah ,&#10;Speaker: Postdoc A&#10;Content: and then they 'd make a comment , and one person said , well - known person said , um , you know , &quot; Before you dismiss forty - five years including my work {disfmarker} &quot;&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Grad E&#10;Content: Forty - five years of research .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: But th you know , the same thing has happened in computational linguistics , right ? You look at the ACL papers coming out , and now there 's sort of a turn back towards , OK we 've learned statistic {disfmarker} you know , we 're basically getting what we expect out of some statistical methods , and , you know , the there 's arguments on both sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker" target="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system." target="marker} everybody {disfmarker} every place in the room ,&#10;Speaker: PhD D&#10;Content: and video , right .&#10;Speaker: Professor C&#10;Content: uh , the {disfmarker} yeah {disfmarker} the {disfmarker} the mikes in the middle , the head - mounted mikes , the lapel mikes , the array , uh , with {disfmarker} well , there 's some discussion of fifty - nine ,&#10;Speaker: Grad E&#10;Content: Fifty - nine elements .&#10;Speaker: Professor C&#10;Content: they might go down to fifty - seven Because , uh , there is , uh , some pressure from a couple people at the meeting for them to use a KEMAR head . I forget what KEMAR , uh , stands for ,&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: but what it is is it 's dummy head that is very specially designed ,&#10;Speaker: Grad E&#10;Content: Oh , that 's right .&#10;Speaker: Professor C&#10;Content: and {disfmarker} and {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system." target="Content: Oh , that 's right .&#10;Speaker: Professor C&#10;Content: and {disfmarker} and {disfmarker} and , so what they 're actually doing is they 're really {disfmarker} there 's really two recording systems .&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: That 's a great idea .&#10;Speaker: Professor C&#10;Content: So they may not be precisely synchronous , but the but there 's two {disfmarker} two recording systems , one with , I think , twenty - four channels , and one with sixty - four channels . And the sixty - four channel one is for the array , but they 've got some empty channels there , and anyway they {disfmarker} like they 're saying they may give up a couple or something if {disfmarker} for {disfmarker} for the KEMAR head if they go {disfmarker} go with that .&#10;Speaker: Grad E&#10;Content: Right . Yeah , it is a good idea .&#10;Speaker: Professor C&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system." target="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about reducing the number of microphone elements from fifty- nine to fifty- seven is due to the potential interest in using a specially designed dummy head, known as KEMAR, in the room. KEMAR is a highly specialized mannequin head designed for measuring and analyzing sound. Some individuals at the meeting are suggesting the use of KEMAR, which may require sacrificing a couple of microphone elements, bringing the total down to fifty- seven. This change would allow for better integration with the KEMAR head and its recording system." target="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics." target=" here , and then you have a little segment here . Well , is that part of the speech ? Is it part of the nonspeech ? I mean , w what do you embed it in ?&#10;Speaker: PhD D&#10;Content: There 's something nice , though , about keeping , and this is probably another discussion , keeping the stuff that Thilo 's detector detected as possible speech and just marking it as not speech than deleting it . Because then when you align it , then the alignment can {disfmarker} you can put a reject model or whatever ,&#10;Speaker: Grad E&#10;Content: Oh , I see . So then they could just like put {disfmarker} Oh that 's what you meant by just put an &quot; X &quot; there .&#10;Speaker: PhD D&#10;Content: and you 're consistent with th the automatic system ,&#10;Speaker: Grad E&#10;Content: Uh , that 's an interesting idea .&#10;Speaker: PhD D&#10;Content: whereas if you delete it {disfmarker}&#10;Speaker: Grad E&#10;Content: So {disfmarker} so all they {disfmarker} So that all they would have to do is put like an &quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggested approach to handle segments of a speech that were detected as possible speech but are not considered actual speech involves keeping those portions and marking them as not speech, rather than deleting them. This is proposed so that when alignment occurs, a reject model or similar can be consistently applied, maintaining consistency with the automatic system's determinations. Additionally, this method allows for potential hand-tweaking to address complex issues like fricatives causing the beginning of words to be cut off. By using advanced machine learning techniques and tailoring algorithms for individual speakers and their specific speech patterns, a more accurate script can be developed to detect speech and nonspeech segments while also addressing word merging issues and speaker-specific characteristics." target=" A&#10;Content: I think it 's easier to add than delete , frankly ,&#10;Speaker: PhD D&#10;Content: and then you can get {disfmarker} Yeah , or&#10;Speaker: Postdoc A&#10;Content: because you have to , uh , maneuver around on the {disfmarker} on both windows then .&#10;Speaker: Grad E&#10;Content: To add or to delete ?&#10;Speaker: Postdoc A&#10;Content: To delete .&#10;Speaker: PhD D&#10;Content: Anyways , so I {disfmarker} I guess {disfmarker}&#10;Speaker: Grad E&#10;Content: OK . That {disfmarker} Maybe that 's an interface issue that might be addressable .&#10;Speaker: Postdoc A&#10;Content: It 's possible .&#10;Speaker: Grad E&#10;Content: But I think it 's the semantics that are {disfmarker} that are questionable to me , that you delete something {disfmarker} So let 's say someone is talking to here , and then you have a little segment here . Well , is that part of the speech ? Is it part of the nonspeech ? I mean ,">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target=" more computation and some are {disfmarker} are hav have limited kind of discrimination , but are just easy to use , and others are {disfmarker}&#10;Speaker: PhD B&#10;Content: But doesn't their conclusion just sort of {disfmarker} you could have guessed that before they even started ? Because if you assume that these learning things get better and better and better ,&#10;Speaker: Professor C&#10;Content: You would guess {disfmarker}&#10;Speaker: PhD B&#10;Content: then as you approach {disfmarker} there 's a point where you can't get any better , right ? You get everything right .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: It 's just no {disfmarker}&#10;Speaker: Grad E&#10;Content: But {disfmarker}&#10;Speaker: PhD B&#10;Content: So they 're all approaching .&#10;Speaker: Grad E&#10;Content: No , but there was still a spread . They weren't all up They weren't converging .&#10;Speaker: PhD B&#10;Content: But what I 'm saying is that th they have to , as">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target="Content: Yeah .&#10;Speaker: PhD D&#10;Content: Huh .&#10;Speaker: Professor C&#10;Content: Yeah , could well be . So {disfmarker} so , I mean , that was {disfmarker} that was kind of , you know , it 's a good point , but the problem I had with it was that the implications out of this was that , uh , the kind of choices you make about learning machines were therefore irrelevant which is not at {disfmarker} n t as for as I know in {disfmarker} in tasks I 'm more familiar with @ @ is not at all true . What i what is {disfmarker} is true is that different learning machines have different properties , and you wanna know what those properties are . And someone else sort of implied that well we s you know , a all the study of learning machine we still don't know what those properties are . We don't know them perfectly , but we know that some kinds use more memory and {disfmarker} and some other kinds use more computation and some are {disfmarker} are hav have limited kind of discrimination , but are just easy to use , and others are {d">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target=" sides ,&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: so {disfmarker}&#10;Speaker: Grad E&#10;Content: I think the matters is the thing that {disfmarker} that was misleading .&#10;Speaker: Postdoc A&#10;Content: That was very offending , very offending .&#10;Speaker: PhD D&#10;Content: Yeah , yeah .&#10;Speaker: Grad E&#10;Content: Is that {disfmarker} all {disfmarker} all of them are based on all the others , right ? Just , you {disfmarker} you can't say {disfmarker}&#10;Speaker: PhD B&#10;Content: Maybe they should have said &quot; focus &quot; or something .&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yeah . I mean , so . {disfmarker} And I 'm saying the same thing happened with speech recognition , right ? For a long time people were hand - c coding linguistic rules and then they discovered machine - learning worked better . And now they 're throwing more and more data and worrying {disfmarker} perhaps worrying less and less about">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target=" they discovered machine - learning worked better . And now they 're throwing more and more data and worrying {disfmarker} perhaps worrying less and less about , uh , the exact details of the algorithms .&#10;Speaker: PhD D&#10;Content: And {disfmarker} and then you hit this {disfmarker}&#10;Speaker: Grad E&#10;Content: Except when they have a Eurospeech paper .&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Anyway .&#10;Speaker: Professor C&#10;Content: Anyway , tea is {disfmarker} tea is , uh , starting .&#10;Speaker: Grad E&#10;Content: Shall we read some digits ? Are we gonna do one at a time ? Or should we read them all agai at once again .&#10;Speaker: Professor C&#10;Content: Let 's do it all at once .&#10;Speaker: Postdoc A&#10;Content: Yeah , that 's good .&#10;Speaker: Professor C&#10;Content: We {disfmarker} @ @ {disfmarker} let 's try that again .&#10;Speaker: PhD D&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target=" more data is better , right ? You 're {disfmarker} you 're {disfmarker} you can assume similar distributions ,&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: but if you wanted to do disambiguation on a different type of , uh , test data then your training data , then that extra data wouldn't generalize ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: so .&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: But , I think one of their p They {disfmarker} they had a couple points . w {comment} Uh , I think one of them was that &quot; Well , maybe simpler algorithms and more data are {disfmarker} is better &quot; . Less memory , faster operation , simpler . Right ? Because their simplest , most brain - dead algorithm did pretty darn well&#10;Speaker: Professor C&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: when you got {disfmarker} gave it a lot more data . And then also they were saying , &quot; Well , m You">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target="marker} yeah {disfmarker} yeah {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , it sort of was .&#10;Speaker: Professor C&#10;Content: was it w was it word - sense ? Yes .&#10;Speaker: Grad E&#10;Content: But it was {disfmarker} it was a very simple case of &quot; to &quot; versus &quot; too &quot; versus &quot; two &quot; and &quot; there &quot; , &quot; their &quot; , &quot; they 're &quot; {disfmarker}&#10;Speaker: PhD D&#10;Content: And there and their and {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah , yeah . OK .&#10;Speaker: PhD D&#10;Content: and that you could do better with more data , I mean , that 's clearly statistically {disfmarker}&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: And so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about {d">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, according to the discussion, there was a limit to the discrimination capabilities of the computation methods. This limit is described as a point where no further improvement can be made, i.e., &quot;you get everything right&quot; (Speaker: PhD B). However, not all methods were converging to this limit as they improved. The reason for this is not explicitly mentioned in the transcript, but it can be inferred that different methods have different properties and may excel in certain areas while performing poorly in others. Furthermore, the choice of learning machines and their properties matter, as some use more memory or computation than others and may perform better in specific tasks. Therefore, even if all methods approach the limit, they might not reach it at the same time due to these differences in their properties and the nature of the tasks they are applied to." target="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} yeah {disfmarker} yeah {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , it sort of was .&#10;Speaker: Professor C&#10;Content: was it w was it word - sense ? Yes .&#10;Speaker: Grad E&#10;Content: But it was {disfmarker} it was a very simple case of &quot; to &quot; versus &quot; too &quot; versus &quot; two &quot; and &quot; there &quot; , &quot; their &quot; , &quot; they 're &quot; {disfmarker}&#10;Speaker: PhD D&#10;Content: And there and their and {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah , yeah . OK .&#10;Speaker: PhD D&#10;Content: and that you could do better with more data , I mean , that 's clearly statistically {disfmarker}&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: And so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about {d" target="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} yeah {disfmarker} yeah {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , it sort of was .&#10;Speaker: Professor C&#10;Content: was it w was it word - sense ? Yes .&#10;Speaker: Grad E&#10;Content: But it was {disfmarker} it was a very simple case of &quot; to &quot; versus &quot; too &quot; versus &quot; two &quot; and &quot; there &quot; , &quot; their &quot; , &quot; they 're &quot; {disfmarker}&#10;Speaker: PhD D&#10;Content: And there and their and {disfmarker}&#10;Speaker: Professor C&#10;Content: Yeah , yeah . OK .&#10;Speaker: PhD D&#10;Content: and that you could do better with more data , I mean , that 's clearly statistically {disfmarker}&#10;Speaker: Professor C&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: And so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about {d" target="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target="aker: Professor C&#10;Content: down from Seattle .&#10;Speaker: Grad E&#10;Content: They 're flying from somewhere to somewhere ,&#10;Speaker: Professor C&#10;Content: Yeah , and they 'll end up here . So b and also Brian Kingsbury is actually flying from , uh , the east coast on that {disfmarker} that morning .&#10;Speaker: Postdoc A&#10;Content: Excellent .&#10;Speaker: Professor C&#10;Content: So , i I {disfmarker} I will be {disfmarker} I mean , he 's taking a very early flight&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: Professor C&#10;Content: and we do have the time work difference running the right way , but I still think that there 's no way we could start before eleven . It might end up really being twelve . So when we get closer we 'll find people 's plane schedules , and let everybody know . Uh , So . That 's good .&#10;Speaker: Grad E&#10;Content: But , uh , yeah maybe an agenda , or at least some things to talk about would be a good idea .&#10;Speaker: Professor C&#10;Content: Well we">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target=" , are we {disfmarker} do we have like an agenda or anything that we should be {disfmarker}&#10;Speaker: Professor C&#10;Content: No , but that would be a good idea .&#10;Speaker: PhD D&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: Why don't we w&#10;Speaker: PhD F&#10;Content: So {disfmarker} so the deal is that I can , um , {vocalsound} uh , I can be available after , uh , like ten thirty or something . I don't know how s how early you wanted to {disfmarker}&#10;Speaker: Professor C&#10;Content: They 're not even gonna be here until eleven or so .&#10;Speaker: Grad E&#10;Content: That 's good .&#10;Speaker: PhD F&#10;Content: Oh , OK . So {disfmarker}&#10;Speaker: Professor C&#10;Content: Cuz they 're flying up that day .&#10;Speaker: PhD D&#10;Content: Wait , this is on {disfmarker} on Sunday ?&#10;Speaker: Professor C&#10;Content: Saturday .&#10;Speaker: PhD D&#10;Content: Or Saturday ?">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor C suggests starting the meeting at eleven o'clock, taking into account people's flight schedules and the time difference. However, she acknowledges that it might end up really being twelve o'clock." target="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript." target="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript." target="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript." target="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, both pipelining and sending whole meetings at a time are possible options. However, the group seemed to lean towards sending whole meetings at a time from a data-keeping perspective. Grad E suggested that this method might be more efficient for keeping track of data points. Professor C also mentioned that if there was a choice between having a fully adjusted sample in a short amount of time or having a whole meeting that didn't get at what they wanted, it would be better to go with the shorter option. However, the final decision on how to proceed was not explicitly stated in the transcript." target="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." target=": OK . Huh , OK .&#10;Speaker: Professor C&#10;Content: I don't know when would be a good excuse for it , but I just can't wait to be giving a talk t and {disfmarker} and {disfmarker} and use the example from last week with everybody t doing the digits at once .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: That was fun .&#10;Speaker: Professor C&#10;Content: I 'd love to play somebody that .&#10;Speaker: Postdoc A&#10;Content: That was fun .&#10;Speaker: PhD D&#10;Content: It was quick .&#10;Speaker: Professor C&#10;Content: It was . It was really efficient .&#10;Speaker: PhD B&#10;Content: Talk about a good noise shield . You know ? You wanted to pe keep people from listening in , you could like have that playing outside the room . Nobody could listen in .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Well , I had this idea we could make our whole meeting faster that way .&#10;Speaker: Professor C&#10;Content: Yeah . Everybody give the reports about what they">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." target="The conclusion of the research mentioned is that there is a limit to the discrimination capabilities of computational methods, referred to as a point where no further improvement can be made (&quot;you get everything right&quot;). However, not all methods were converging to this limit as they improved. This is due to differences in the properties of various methods and their applicability to specific tasks, as well as the choice of learning machines and their requirements for memory or computation. Therefore, even if all methods approach the limit, they might not reach it at the same time.&#10;&#10;In the context of Liz and Andreas's work on Broadcast News and simpler tasks like command and control, they started with acoustic models for Broadcast News and found that other tasks were much simpler. These tasks included command and control as well as digit recognition (TI digits) and Wall Street Journal readings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." target="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." target="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." target="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor C expressed her excitement about giving a talk and using the example from the previous week, where everyone participated in saying digits simultaneously. Both Grad E and Postdoc A agreed that this was fun.&#10;2. PhD B suggested playing some sort of audio outside the room to act as a good noise shield, preventing others from listening in. This idea was met with agreement from Professor C, implying they saw value in maintaining privacy during their meetings.&#10;3. The group also discussed the possibility of making the whole meeting faster by sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose. This proposal was agreed upon by Postdoc A and Professor C, showing a preference for more focused, shorter sessions when possible." target="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample.">
      <data key="d0">1</data>
    </edge>
    <edge source=": OK . Huh , OK .&#10;Speaker: Professor C&#10;Content: I don't know when would be a good excuse for it , but I just can't wait to be giving a talk t and {disfmarker} and {disfmarker} and use the example from last week with everybody t doing the digits at once .&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: That was fun .&#10;Speaker: Professor C&#10;Content: I 'd love to play somebody that .&#10;Speaker: Postdoc A&#10;Content: That was fun .&#10;Speaker: PhD D&#10;Content: It was quick .&#10;Speaker: Professor C&#10;Content: It was . It was really efficient .&#10;Speaker: PhD B&#10;Content: Talk about a good noise shield . You know ? You wanted to pe keep people from listening in , you could like have that playing outside the room . Nobody could listen in .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Well , I had this idea we could make our whole meeting faster that way .&#10;Speaker: Professor C&#10;Content: Yeah . Everybody give the reports about what they" target="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The person responsible for the sentence ordering task on Wednesday morning at Columbia was Barselou and &quot;these guys,&quot; as stated by PhD D.&#10;2. It is important for Mari, Katrin, and Jeff to figure out some kinds of things that can be started when they are present, particularly tasks related to the transcripts since they already have them. This was suggested by PhD D and Professor C because determining these tasks can help make good use of their time together as a team." target="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The paper discussed is about addressing the challenge of having insufficient data when working on a new task. It explores the idea of using data from various sources to improve the performance in such situations.&#10;2. The authors applied multiple learning machines with different amounts of data to eight different methods, demonstrating that better results can be achieved with more data.&#10;3. Although the discussion does not provide specific details about the paper's findings, it implies that using diverse datasets and appropriate learning machines can help overcome data limitations in new tasks.&#10;4. The paper was informally presented during a meeting attended by several National Institute of Standards and Technology (NIST) members, who were described as forming a good group." target=" this , but probably the five of us should pick out a paper or two that {disfmarker} that , uh , you know , got our interest , and we should go around the room at one of the Tuesday lunch meetings and say , you know , what {disfmarker} what was good about the conference ,&#10;Speaker: Grad E&#10;Content: Present . Yep . Do a trip report .&#10;Speaker: Professor C&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: Well , the summarization stuff was interesting , I mean , I don't know anything about that field , but for this proposal on meeting summarization , um , I mean , it 's sort of a far cry because they weren't working with meeting type data , but he got sort of an overview on some of the different approaches ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Do you remember who the groups were that we 're doing ?&#10;Speaker: PhD D&#10;Content: so . Well there 're {disfmarker} this was the last day ,&#10;Speaker: Grad E&#10;Content: A lot of different ones .&#10;Speaker: Postdoc A&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source=" this , but probably the five of us should pick out a paper or two that {disfmarker} that , uh , you know , got our interest , and we should go around the room at one of the Tuesday lunch meetings and say , you know , what {disfmarker} what was good about the conference ,&#10;Speaker: Grad E&#10;Content: Present . Yep . Do a trip report .&#10;Speaker: Professor C&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: Well , the summarization stuff was interesting , I mean , I don't know anything about that field , but for this proposal on meeting summarization , um , I mean , it 's sort of a far cry because they weren't working with meeting type data , but he got sort of an overview on some of the different approaches ,&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Do you remember who the groups were that we 're doing ?&#10;Speaker: PhD D&#10;Content: so . Well there 're {disfmarker} this was the last day ,&#10;Speaker: Grad E&#10;Content: A lot of different ones .&#10;Speaker: Postdoc A&#10;Content" target="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers discussed the complexity of synchronizing and identifying any overlap in segments of data, with Grad E bringing up the issue of potential overlaps between different segmented parts. They also mentioned a high correlation (Content by PhD D) related to this topic, but no explicit conclusion was reached on whether there was an overlap or not.&#10;   &#10;2. The disagreement between Speaker PhD B and Grad E about the straightforwardness of the cross-cancellation method stemmed from different interpretations of a message referring to the cross-cancellation method. Grad E thought it meant that the method was not simple, while PhD B understood it as needing a longer time window for analysis." target=" could scientifically say is overlap , it 's just whether or not the , um , the segments that were all synchronized , whether there was some overlap somewhere .&#10;Speaker: Grad E&#10;Content: c High correlation .&#10;Speaker: PhD D&#10;Content: And , you know , that pointed out some differences , so he thought well if we can do something quick and dirty because Dan said the cross - cancellation , it 's not straight - forward . If it were straight - forward then we would try it , but {disfmarker} so , it 's sort of good to hear that it was not straight - forward , thinking if we can get decent forced alignments , then at least we can do sort of a overall report of what happens with actual overlap in time , but , um {disfmarker}&#10;Speaker: PhD B&#10;Content: I didn't think that his message said it wasn't straight - forward .&#10;Speaker: Grad E&#10;Content: Well if we 'd just {disfmarker}&#10;Speaker: Professor C&#10;Content: Well&#10;Speaker: PhD B&#10;Content: I thought he 's just saying you have to look over a longer time window when you do it .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source=" could scientifically say is overlap , it 's just whether or not the , um , the segments that were all synchronized , whether there was some overlap somewhere .&#10;Speaker: Grad E&#10;Content: c High correlation .&#10;Speaker: PhD D&#10;Content: And , you know , that pointed out some differences , so he thought well if we can do something quick and dirty because Dan said the cross - cancellation , it 's not straight - forward . If it were straight - forward then we would try it , but {disfmarker} so , it 's sort of good to hear that it was not straight - forward , thinking if we can get decent forced alignments , then at least we can do sort of a overall report of what happens with actual overlap in time , but , um {disfmarker}&#10;Speaker: PhD B&#10;Content: I didn't think that his message said it wasn't straight - forward .&#10;Speaker: Grad E&#10;Content: Well if we 'd just {disfmarker}&#10;Speaker: Professor C&#10;Content: Well&#10;Speaker: PhD B&#10;Content: I thought he 's just saying you have to look over a longer time window when you do it .&#10;Speaker" target="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The challenge discussed was the need to process seven times real time for a meeting, which would likely take more than that due to the necessity of listening to each channel all the way through. This is because the current system's recognition quality is poor and not suitable for direct use in the new system, requiring human review of the transcriptions.&#10;2. A potential solution mentioned was using forced alignment instead of trying to utilize the existing synchronous and untimed recordings with recognition for illustrative purposes. Forced alignment would be more beneficial as it provides higher-quality results and eliminates the need to manually improve the poor quality of the existing recordings, allowing for better use of resources and focus on improving the new system's accuracy.&#10;3. Another potential solution mentioned was visually scanning the waveform as an alternative to listening to each channel. This would allow for a more efficient review process and make it easier to distinguish between different speakers in the conversation. However, this is not explicitly discussed as a complete solution but rather an additional feature to help with processing.&#10;4. The issue of breaths in the conversation was also raised as a challenge during the discussion. Breath sounds can sometimes be misinterpreted as speech by transcription systems, leading to inaccuracies and errors. Possible solutions for this issue were not explicitly discussed, but visual analysis or filtering options could potentially help improve accuracy when dealing with breath sounds." target=" Oh they can {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , but then they have to do {disfmarker} but then they {disfmarker} for this meeting they would have to do seven times real time , and it would probably be more than that .&#10;Speaker: Postdoc A&#10;Content: Yeah , that 's it . Yeah .&#10;Speaker: Grad E&#10;Content: Right ? Because they 'd have to at least listen to each channel all the way through .&#10;Speaker: Postdoc A&#10;Content: And if {disfmarker}&#10;Speaker: PhD B&#10;Content: But i but it 's very quick ,&#10;Speaker: Postdoc A&#10;Content: Uh - huh .&#10;Speaker: PhD B&#10;Content: right ? I mean , you scan {disfmarker} I mean , if you have a display of the waveform .&#10;Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Oh , you 're talking about visually .&#10;Speaker: Postdoc A&#10;Content: w Well , the other problem is the breaths&#10;Speaker: Grad E&#10;Content: I just don">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation." target=" , {vocalsound} I actually went through all of those , there were I think fifty - five segments , {vocalsound} um , in {disfmarker} in X Waves , and {disfmarker} and sort of did a crude check , and {vocalsound} more often than not , it {disfmarker} it gets it wrong . So there 's either the beginning , mostly the beginning word , {vocalsound} where th you , um , you know , Chuck talks somewhere into the segment , but the first , um , word of what he says , often &quot; I &quot; but it 's very reduced &quot; I , &quot; that 's just aligned {vocalsound} to the beginning of someone else 's speech , uh in that segment , which is cross - talk . So , {vocalsound} um , {vocalsound} I 'm still tinkering with it , but it might well be that we can't get clean alignments out of this {disfmarker} out of those , uh , {vocalsound} channels , so .&#10;Speaker: Professor C&#10;Content: Unless maybe we do this , uh , um , cancellation business .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation." target="isfmarker} I haven't done {disfmarker} I mean , the only way to check this right now was for me to actually {vocalsound} load these into X Waves and , you know , plus the alignments , and s play them and see where the {disfmarker}&#10;Speaker: Professor C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: And it looks {disfmarker} And so I looked at all of the utterances from you , Chuck , in that one conversation , I don't know which {disfmarker} You probably know which one I mean , it 's where you were on the lapel {vocalsound} and Morgan was sitting next to you and we can hear everything Morgan says .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: But {disfmarker} and {disfmarker} and some of what you {disfmarker} I mean , you also appear quite a bit in that cross - talk . So , {vocalsound} I actually went through all of those , there were I think fifty - five segments , {vocalsound} um , in {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speaker who went through the segments of the conversation involving &quot;Chuck&quot; is PhD F. They examined fifty-five segments of the conversation.&#10;2. To evaluate Chuck's contribution to the conversation, PhD F checked the alignments of the utterances in X Waves and found that often, the first word of what Chuck says is aligned with the beginning of someone else's speech due to cross-talk. This suggests that some of Chuck's words may be attributed to other speakers, potentially reducing his measured contribution to the conversation." target=" and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about {disfmarker} about , &quot; Oh my {disfmarker} my kind of learning machine is better than your kind of learning machine . &quot; And , uh , they were {disfmarker} started off with a million words that they used , which was evidently a number that a lot of people doing that particular kind of task had been using . So they went up , being Microsoft , they went up to a billion . And then they had this log scale showing a {disfmarker} you know , and {disfmarker} and naturally everything gets {disfmarker}&#10;Speaker: Grad E&#10;Content: Them being beep , {comment} they went off to a billion .&#10;Speaker: Professor C&#10;Content: they {disfmarker} well , it 's a big company , I didn't {disfmarker} I didn't mean it as a ne anything negative ,&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: but i i i&#10;Speaker: PhD D&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;" target=" question actually .&#10;Speaker: Grad E&#10;Content: I mean cuz for the corpus it would be nice if everything were {disfmarker}&#10;Speaker: PhD D&#10;Content: Actually that 's a good question because we 'd have to completely redo those meetings , and we have like ten of them now .&#10;Speaker: Grad E&#10;Content: We wouldn't have to re - do them , we would just have to edit them .&#10;Speaker: Postdoc A&#10;Content: Well , and also , I mean , I still haven't {disfmarker} I still haven't given up on forced alignment .&#10;Speaker: PhD D&#10;Content: No , you 're right , actually {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I think that when Brian comes , this 'll be uh an interesting aspect to ask him as well b&#10;Speaker: Grad E&#10;Content: When {disfmarker}&#10;Speaker: Postdoc A&#10;Content: when Brian Kingsbury comes .&#10;Speaker: Grad E&#10;Content: Oh , Brian . You s I thought you said Ryan . And it 's like , &quot; Who 's Ryan ? &quot;&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers have different opinions on whether they would have to redo or just edit meetings for a corpus. Grad E suggests that they wouldn't have to redo the meetings, only edit them. However, PhD D points out that if they were to make changes, they would have to completely redo ten of their meetings.&#10;2. Postdoc A was referring to Brian Kingsbury in the context. This is mentioned when Grad E mistakenly thought Postdoc A said &quot;Ryan&quot; and asked &quot;Who's Ryan?&quot; Postdoc A then clarified by saying &quot;when Brian Kingsbury comes.&quot;" target=" Grad E&#10;Content: Oh , Brian . You s I thought you said Ryan . And it 's like , &quot; Who 's Ryan ? &quot;&#10;Speaker: Postdoc A&#10;Content: Yeah , good question .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Well , Ryan could come .&#10;Speaker: PhD D&#10;Content: Uh , no , that 's a good point , though , because for feature extraction like for prosody or something , I mean , the meetings we have now , it 's a good chunk of data {disfmarker}&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: we need to get a decent f OK .&#10;Speaker: Postdoc A&#10;Content: That 's what my hope has been ,&#10;Speaker: PhD D&#10;Content: So we should at least try it even if we can't ,&#10;Speaker: Postdoc A&#10;Content: and that 's what {disfmarker} that 's what {disfmarker} you know , ever since the {disfmarker} the February meeting that I transcribed from last year , forced alignment has been">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials." target=" difference .&#10;Speaker: Grad E&#10;Content: Right , which should be pretty straight forward .&#10;Speaker: PhD D&#10;Content: Which a at least is well defined , and&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: um , but then if you add the dynamic aspect of adapting distances , then it wasn't {disfmarker} I guess it just wasn't something that he could do quickly {pause} and not {disfmarker} in time for us to be able to do something by two weeks from now , so . Well less than a week . So {disfmarker} um , so I don't know what we can do if anything , that 's sort of worth , you know , a Eurospeech paper at this point .&#10;Speaker: PhD B&#10;Content: Well , Andreas , how well did it work on the non - lapel stuff ?&#10;Speaker: Grad E&#10;Content: Yeah . That 's what I was gonna say .&#10;Speaker: PhD F&#10;Content: I haven't checked those yet .&#10;Speaker: Grad E&#10;Content: C&#10;Speaker: PhD F&#10;Content: It 's very tedious to check">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials." target=": Right .&#10;Speaker: PhD D&#10;Content: and , um , if you align the two hypothesis files across the channels , you know , just word alignment , you 'd be able to find that . So {disfmarker} so I guess that 's sort of a last {disfmarker} ther there 're sort of a few things we could do . One is just do like non - lapels if we can get good enough alignments . Another one was to try to get {disfmarker} somehow align Thilo 's energy segmentations with what we have . But then you have the problem of not knowing where the words are because these meetings were done before that segmentation . But maybe there 's something that could be done .&#10;Speaker: PhD B&#10;Content: What {disfmarker} what is {disfmarker} why do you need the , um , the forced alignment for the HLT {disfmarker} I mean for the Eurospeech paper ?&#10;Speaker: PhD D&#10;Content: Well , I guess I {disfmarker} I wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Given the tight deadline and the complexity of dynamically adapting distances, the options for creating a Eurospeech paper might be limited. However, some ideas mentioned in the transcript include:&#10;   - Focusing on non-lapel materials, if good enough alignments can be achieved.&#10;   - Attempting to align Thilo's energy segmentations with the available data, although this may present issues since the meetings occurred before the segmentation.&#10;&#10;2. The efficiency of the concept on non-lapel materials is not explicitly discussed in the transcript. It is mentioned that PhD F hasn't checked those results yet, and Grad E briefly says &quot;Yeah&quot; when non-lapel stuff is brought up. This suggests that more information is needed to provide a clear assessment of how well it functioned on non-lapel materials." target=" 's fine . Yeah , it 's true .&#10;Speaker: Grad E&#10;Content: So you can definitely streamline that with the i with the interface .&#10;Speaker: Postdoc A&#10;Content: Yeah , it could be faster , but , you know , I mean , th in the ideal world {disfmarker} Yeah .&#10;Speaker: Grad E&#10;Content: What ?&#10;Speaker: Postdoc A&#10;Content: No I {disfmarker} I agree that 'd be nice . Yeah . OK .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor C&#10;Content: So , um , Done with that ?  Does any {disfmarker} I forget , does anybody , uh , working on any {disfmarker} any Eurospeech submission related to this ?&#10;Speaker: Grad E&#10;Content: I would like to try to do something on digits but I just don't know if we have time . I mean , it 's due next Friday so we have to do the experiments and write the paper . So , I 'm gonna try , but , uh , we 'll just have to see . So actually I wanna get together with both Andreas and">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit." target=" to your size , which is not really what we want .&#10;Speaker: PhD B&#10;Content: The other thing that would do it would be to hang a five pound weight off the back .&#10;Speaker: Professor C&#10;Content: Yeah&#10;Speaker: PhD D&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: that 's good !&#10;Speaker: Postdoc A&#10;Content: What did you say ?&#10;Speaker: PhD D&#10;Content: A little ,&#10;Speaker: Grad E&#10;Content: wh&#10;Speaker: Professor C&#10;Content: Hang a five pound weight off the {disfmarker} off the back .&#10;Speaker: PhD B&#10;Content: Hang a five pound weight off the back .&#10;Speaker: PhD D&#10;Content: um ,&#10;Speaker: Grad E&#10;Content: We did that {disfmarker}&#10;Speaker: Professor C&#10;Content: Weight .&#10;Speaker: Grad E&#10;Content: We {disfmarker} at Boeing I used {disfmarker} I was doing augmented reality so they had head - mounts on , and we {disfmarker} we had a little jury - rigged one with a welder '">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit." target="isfmarker} that {disfmarker} that tilts , right ? In lots and lots of different ways .&#10;Speaker: PhD D&#10;Content: So I 'm not saying anything about bias towards small headsize ,&#10;Speaker: Grad E&#10;Content: About heads ?&#10;Speaker: PhD D&#10;Content: but does seem , uh {disfmarker}&#10;Speaker: PhD B&#10;Content: It would be an advantage .&#10;Speaker: Postdoc A&#10;Content: Well , wonder if it 's {disfmarker} if {disfmarker} if he was wearing it over his hair instead of under his hair .&#10;Speaker: Professor C&#10;Content: Well , we should {disfmarker} We shou we should work on compressing the heads , and {disfmarker}&#10;Speaker: Grad E&#10;Content: I think probably it was {disfmarker} Yeah . It probably just wasn't tight enough to the back of his head . I mean , so the directions do talk about bending it to your size , which is not really what we want .&#10;Speaker: PhD B&#10;Content: The other thing that would do it would be to hang">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit." target="} go with that .&#10;Speaker: Grad E&#10;Content: Right . Yeah , it is a good idea .&#10;Speaker: Professor C&#10;Content: So .&#10;Speaker: Grad E&#10;Content: Yeah , h uh , J Jonathan Fiscus did say that , uh , they have lots of software for doing calibration for skew and offset between channels&#10;Speaker: PhD D&#10;Content: Mm - hmm&#10;Speaker: Grad E&#10;Content: and that they 've found that 's just not a big deal .&#10;Speaker: Professor C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So .&#10;Speaker: Professor C&#10;Content: Yeah , I 'm not {pause} too worried about that . I was thinking {disfmarker}&#10;Speaker: PhD D&#10;Content: But they 're still planning to do like fake {disfmarker}&#10;Speaker: Grad E&#10;Content: Scenario - based .&#10;Speaker: PhD D&#10;Content: they have to do something like that ,&#10;Speaker: Grad E&#10;Content: Y right .&#10;Speaker: PhD D&#10;Content: right .&#10;Speaker: Grad E&#10;Content: Their {">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggested solution for adjusting the size of a device, as proposed by speakers PhD B, Professor C, and PhD D, is to hang a five-pound weight off the back of it. This idea stems from the discussion about headsets that may not fit properly or comfortably on users with different head sizes. The additional weight would help counterbalance any issues related to small head size and make the device more adjustable for a better fit." target="Content: I think that if we decide that we need {disfmarker} that they need to see the visuals , we need to change the interface so that they can do that .&#10;Speaker: Postdoc A&#10;Content: Yeah . Yeah .&#10;Speaker: Professor C&#10;Content: So {disfmarker}&#10;Speaker: PhD D&#10;Content: That 's actually what I thought of , loading the chopped up waveforms , I mean , you know , that {disfmarker} that would make it faster {disfmarker}&#10;Speaker: Grad E&#10;Content: An But isn't {disfmarker}&#10;Speaker: Grad G&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: The chopped up waveforms .&#10;Speaker: PhD B&#10;Content: The problem is if {disfmarker} if anything 's cut off , you can't expand it from the chopped up {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Grad E&#10;Content: Isn't that {disfmarker}&#10;Speaker: Grad G&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: Right , but if">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc A had the role of overseeing the improvement of the accuracy of the transcription for one of the NSA meetings. They first assigned a transcriber to go through and refine the bins for that meeting. After that, Postdoc A reviewed the work themselves to ensure its accuracy." target=" one is really very {disfmarker} very accurate .&#10;Speaker: PhD D&#10;Content: Oh .&#10;Speaker: Postdoc A&#10;Content: I men I mentioned the link . I sent {disfmarker} You know that one ?&#10;Speaker: PhD D&#10;Content: Oh , so {disfmarker}&#10;Speaker: Grad G&#10;Content: The {disfmarker} which one ? I 'm sorry .&#10;Speaker: Postdoc A&#10;Content: Um , I 'm trying to remember {disfmarker} I don't remember the number off hand .&#10;Speaker: Grad E&#10;Content: Those are all {disfmarker}&#10;Speaker: Postdoc A&#10;Content: It 's one of the NSA 's . I sent email before the conference , before last week .&#10;Speaker: Grad G&#10;Content: Oh , OK .&#10;Speaker: Postdoc A&#10;Content: Bef - What I mean is Wednesday , Thursday .&#10;Speaker: PhD D&#10;Content: That might {disfmarker} might have been the one {disfmarker} one of the ones that we did .&#10;Speaker: Grad G&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The exciting activity that Professor C led was using the example from the previous week where everyone participated in saying digits simultaneously. This activity was found to be fun by Grad E, Postdoc A, and other members of the group.&#10;   &#10;2. In terms of making their meetings more efficient, the group discussed the idea of using some sort of audio outside the room as a good noise shield to maintain privacy during their meetings. They agreed on the value of this idea, as it would prevent others from listening in. Additionally, they considered sending a sample for adjusting boundaries instead of holding an entire meeting for that purpose, showing a preference for more focused, shorter sessions when possible. The final decision on how to proceed with these suggestions was not explicitly stated in the transcript." target="Based on the discussion, an estimated time to adjust the boundaries was not explicitly provided in the transcript. However, Grad E suggested timing how long it takes when assigning someone to do it the next day. The group seems to prefer sending a sample to try instead of holding a full meeting for adjusting boundaries, as proposed by PhD B and agreed upon by Postdoc A and Professor C. This approach would likely be more time-efficient and allow for real-time or near real-time transcription and analysis of the sample.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The study that Professor C is referring to involves different kinds of learning machines and various amounts of data. They conducted eight different methods to address a task with insufficient data by using data from other tasks.&#10;2. The study includes work from Lori Lamel, as mentioned by PhD B.&#10;3. Professor C thinks the study wasn't dismissed improperly because there is a distinction between this research and previous work. The research shows that there is a difference when handling new tasks with insufficient data using methods from this study compared to older methods.&#10;4. Additionally, Professor C mentions a visual aid, possibly a graph or diagram, which showed clear distinctions in the results obtained through these newer methods. This evidence supports her belief that the study was not dismissed improperly." target=": Grad G&#10;Content: Right .&#10;Speaker: Professor C&#10;Content: No , but there 's a little difference ,&#10;Speaker: PhD F&#10;Content: So it should {disfmarker}&#10;Speaker: Grad E&#10;Content: There 's a lot .&#10;Speaker: Professor C&#10;Content: and we haven't looked at it for digits ,&#10;Speaker: Grad E&#10;Content: Yeah .&#10;Speaker: Professor C&#10;Content: right ?&#10;Speaker: PhD B&#10;Content: Yeah , so I was curious about that .&#10;Speaker: Professor C&#10;Content: And so , cuz {disfmarker} because what he was {disfmarker} what I was saying when I looked at those things is it {disfmarker} it {disfmarker} I was almost gonna call it quadrimodal because {vocalsound} {disfmarker} because there was a whole lot of cases where it was zero percent .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor C&#10;Content: They just plain got it all right . And then there {disfmarker} and then there was another">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
