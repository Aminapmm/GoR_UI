<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." />
    <node id=" try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're {vocalsound} supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure {disfmarker} I mean , having the two nets {disfmarker} Suppose you detected that it was male , it was female {disfmarker} you come up with different {disfmarker}&#10;Speaker: PhD F&#10;Content: Well , you could put them both in as separate streams or something . Uh .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Maybe .&#10;Speaker: PhD F&#10;Content: I don't know . I was just wondering if there was other information we could exploit .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . Yeah , it 's an interesting thought ." />
    <node id="&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B&#10;Content: Like , we have {pause} male , female ,&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: Bank PIN .&#10;Speaker: PhD B&#10;Content: at least .&#10;Speaker: PhD F&#10;Content: Just male f female ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: What kind of information do you mean ?&#10;Speaker: PhD F&#10;Content: Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm ." />
    <node id=" have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Is it balanced , um , in terms of gender {disfmarker} the data ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Do you know ?&#10;Speaker: PhD B&#10;Content: Almost , yeah .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disf" />
    <node id=" E&#10;Content: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker} is a much simpler categorization than figuring out a {disfmarker} a factor to , uh , squish or expand the {disfmarker} the spectrum .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , um . Y you could imagine that {disfmarker} I mean , just like we 're saying voiced - unvoiced is good to know {disfmarker} uh , male female is good to know also . Um .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But , you 'd have to figure out a way to {disfmarker} to {disfmarker} to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained" />
    <node id=" the front - end {vocalsound} also then becomes a priority for this particular test ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: and saying you don't have to do that .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So . OK . So , uh {disfmarker} What 's new with you ?&#10;Speaker: PhD B&#10;Content: Uh . So there 's nothing {pause} new . Um .&#10;Speaker: Professor E&#10;Content: Uh , what 's old with you that 's developed ?&#10;Speaker: PhD B&#10;Content: I 'm sorry ?&#10;Speaker: Professor E&#10;Content: You {disfmarker} OK . What 's old with you that has developed over the last week or two ?&#10;Speaker: PhD B&#10;Content: Mmm . Well , so we 've been mainly working on the report and {disfmarker} and {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: Mainly working on what ?&#10;Speaker: PhD B&#10;Content: On the report {pause}" />
    <node id=" formant 's kind of a reasonable compromise , and {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , I think , eh , if I recall correctly , they did something like that . And {disfmarker} and {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: But {disfmarker} Um , that doesn't work for just having one frame or something .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: You know ? That 's more like looking at third formant over {disfmarker} over a turn or something like that ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker}" />
    <node id="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." />
    <node id=" this in {disfmarker}&#10;Speaker: Professor E&#10;Content: OK . I 'm sure it 's more balanced ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think" />
    <node id="er} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {d" />
    <node id="&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?&#10;Speaker: PhD B&#10;Content: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don&#10;Speaker: Professor E&#10;Content: Yeah . But you should always look at insertions , deletions , and substitutions .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum ." />
    <node id="marker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm . Yeah . But ,&#10;Speaker: Professor E&#10;Content: Anything else ?&#10;Speaker: PhD B&#10;Content: my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Professor E&#10;Content: Well .&#10;Speaker: PhD B&#10;Content: And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content" />
    <node id=" difference was {disfmarker} at least part of it that {disfmarker} that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: Part of it might just be that the SRI system , they {disfmarker} they {disfmarker} they always adjust these things to be sort of optimized ,&#10;Speaker: PhD F&#10;Content: Is there {disfmarker} ?&#10;Speaker: Professor E&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: I wonder if there 's anything that we could do {vocalsound} to the front - end that would affect the insertion {disfmarker}&#10;Speaker: Professor E&#10;Content: Yes . I think you can .&#10;Speaker: PhD F&#10;Content: What could you do ?&#10;Speaker: Professor E&#10;Content: Well , um {disfmarker} uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range" />
    <node id="s coming from the language model .&#10;Speaker: PhD F&#10;Content: So that w Right . So , in effect , that 's changing the value of your insertion penalty .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , it 's more directly like the {disfmarker} the language scaling or the , uh {disfmarker} the model scaling or acoustic scaling ,&#10;Speaker: PhD F&#10;Content: That 's interesting .&#10;Speaker: Professor E&#10;Content: but you know that those things have kind of a similar effect to the insertion penalty&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: anyway . They 're a slightly different way of {disfmarker} of handling it .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: So , um {disfmarker}&#10;Speaker: PhD F&#10;Content: So if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,&#10;Speaker: Professor E&#10;Content: I think so .&#10;Speaker: PhD F&#10;Content: so that they {" />
    <node id="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." />
    <node id=" Yeah .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that 's {disfmarker} that 's one of the big advantages of not making much money is {vocalsound} the taxes are easier . Yeah .&#10;Speaker: PhD F&#10;Content: Unless you 're getting money in two countries .&#10;Speaker: Professor E&#10;Content: I think you are . Aren't you ?&#10;Speaker: PhD F&#10;Content: They both want their cut .&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker: Grad D&#10;Content: Hmm . Yeah .&#10;Speaker: PhD F&#10;Content: Right ?&#10;Speaker: Professor E&#10;Content: Yeah . Yeah . Huh . Canada w Canada wants a cut ?&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Have to do {disfmarker} So you {disfmarker} you have to do two returns ?&#10;Speaker: Grad D&#10;Content: Mmm . W uh , for two thousand I did . Yeah .&#10;Speaker: Professor E&#10;Content: Oh" />
    <node id="Speaker: Grad D&#10;Content: Mmm . W uh , for two thousand I did . Yeah .&#10;Speaker: Professor E&#10;Content: Oh , oh . Yeah . For tw That 's right , ju&#10;Speaker: PhD F&#10;Content: But not for this next year ?&#10;Speaker: Professor E&#10;Content: Two thousand . Yeah . Probably not this next year , I guess .&#10;Speaker: Grad D&#10;Content: Ye&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Um .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Uh , I 'll {disfmarker} I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a {disfmarker} considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .&#10;Speaker: Professor E&#10;Content: OK . Alright . Uh . Barry , do you wanna {pause} say something about your stuff here ?&#10;Speaker: Grad A&#10;Content: Oh , um . Right . I {pause} just , um , continuing looking at , uh" />
    <node id=" two knowing that we were doing that .&#10;Speaker: PhD F&#10;Content: Yeah . That 's true .&#10;Speaker: Professor E&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: And they didn't forbid us {disfmarker} right ? {disfmarker} to build models on the data ?&#10;Speaker: Professor E&#10;Content: No . But , I think {disfmarker} I think that it {disfmarker} it {disfmarker} it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that {disfmarker} that it would look bad . And I think someone would notice and would say &quot; Well , look . This is not generalizing . &quot; I would hope tha I would hope they would .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Um . But , uh , it 's true . You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other" />
    <node id=": Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . OK . Right . So . How are , uh , uh {disfmarker} how are things going with what you 're doing ?&#10;Speaker: Grad D&#10;Content: Oh . Well , um , I took a lot of time just getting my taxes out of the way {disfmarker} multi - national taxes . So , I 'm {disfmarker} I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Do you know what his schedule will be like ?&#10;Speaker: Professor E&#10;Content: Uh , he 'll be around for three days .&#10;Speaker: Grad D&#10;Content: OK . So , y&#10;Speaker: Professor E&#10;Content: Uh , we 'll have a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmark" />
    <node id=" a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So .&#10;Speaker: PhD F&#10;Content: But you said you won't {disfmarker} you won't be here next Thursday ?&#10;Speaker: Professor E&#10;Content: Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ?&#10;Speaker: Grad D&#10;Content: Mmm . Yeah .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that" />
    <node id=" range .&#10;Speaker: PhD F&#10;Content: So , would the {disfmarker} ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as {disfmarker} ?&#10;Speaker: Professor E&#10;Content: No . You don't wanna change it for different conditions . No . No . I {disfmarker} I {disfmarker} I {disfmarker} What {disfmarker} what I 'm saying {disfmarker}&#10;Speaker: PhD F&#10;Content: Oh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we {disfmarker} we wanna pick a range that we map our numbers into {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we" />
    <node id="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." />
    <node id="Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker}&#10;Speaker: Professor E&#10;Content: So , stuff that 's not based on data .&#10;Speaker: PhD F&#10;Content: Stuff that 's not based on data , necessarily .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , OK . Yeah . Yeah , OK .&#10;Speaker: PhD F&#10;Content: Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: its tenseness , laxness , things like that ,&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvoc" />
    <node id="er} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .&#10;Speaker: Professor E&#10;Content: Whose paper is it ?&#10;Speaker: Grad A&#10;Content: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen .&#10;Speaker: Professor E&#10;Content: Yeah . Huh . From , uh , University of Hamburg and Bielefeld .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between ," />
    <node id=" you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And so it 's sort of a different way of looking .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: Grad A&#10;Content: Yeah . So . Yeah .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Mm - hmm . Um {disfmark" />
    <node id=" or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind .&#10;Speaker: Professor E&#10;Content: I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event .&#10;Speaker: Grad A&#10;Content: Good . That 's great .&#10;Speaker: Professor E&#10;Content: And , uh , um , called them &quot; avents &quot; , uh , uh , uh , with an A at the front .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere ." />
    <node id=" part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .&#10;Speaker: PhD F&#10;Content: Oh . Mm - hmm .&#10;Speaker: Professor E&#10;Content: You know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But {disfmarker} but , um , that has a similar effect because it changes the scale of the numbers {disfmarker} of the differences between different candidates from the acoustic model&#10;Speaker: PhD F&#10;Content: Oh , right .&#10;Speaker: Professor E&#10;Content: as opposed to what 's coming from the language model .&#10;Speaker: PhD F&#10;Content: So that w Right . So , in effect , that 's changing the value" />
    <node id=" .&#10;Speaker: Professor E&#10;Content: There 's more to go ?&#10;Speaker: PhD B&#10;Content: Yeah . Well , so I don't know . There are small things that we started to {disfmarker} to do . But {disfmarker}&#10;Speaker: PhD F&#10;Content: Are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,&#10;Speaker: PhD B&#10;Content: Uh .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Yeah . Yeah . And {disfmarker} Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD B&#10;Content: But anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what" />
    <node id="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." />
    <node id=" Yeah .&#10;Speaker: PhD F&#10;Content: Mainly working on what ?&#10;Speaker: PhD B&#10;Content: On the report {pause} of the work that was already done .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD B&#10;Content: Um . Mm - hmm . That 's all .&#10;Speaker: PhD F&#10;Content: How about that {disfmarker} ? Any - anything new on the thing that , uh , you were working on with the , uh {disfmarker} ?&#10;Speaker: PhD C&#10;Content: I don't have results yet .&#10;Speaker: PhD F&#10;Content: No results ? Yeah .&#10;Speaker: Professor E&#10;Content: What was that ?&#10;Speaker: PhD F&#10;Content: The {disfmarker} the , uh ,&#10;Speaker: Grad A&#10;Content: Voicing thing .&#10;Speaker: PhD F&#10;Content: voicing detector .&#10;Speaker: Professor E&#10;Content: I mean , what what 's {disfmarker} what 's going on now ? What are you {pause} doing ?&#10;Speaker: PhD C&#10;Content: Uh , to try" />
    <node id=" You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other things . So it 's {disfmarker} it 's , uh {disfmarker} We should {disfmarker} we should {disfmarker} Maybe {disfmarker} that 's maybe a topic {disfmarker} Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: to , you know , double check it 's OK .&#10;Speaker: PhD F&#10;Content: Do we know anything about {pause} the speakers for each of the , uh , training utterances ?&#10;Speaker: PhD B&#10;Content: What do you mean ? We {disfmarker} we {disfmarker}&#10;Speaker: PhD F&#10;Content: Do you have speaker information ?&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B" />
    <node id=" per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {disfmarker} that 's all I wrote down .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: PhD F&#10;Content: So . I {disfmarker} I would {disfmarker} Yeah . I would need to do that .&#10;Speaker: Professor E&#10;Content: OK . So {disfmarker}&#10;Speaker: PhD F&#10;Content: I can do that for next week .&#10;Speaker: Professor E&#10;Content: Yeah . And , um {disfmarker} Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But {disfmarker} but I think it would be {disfmarker} it 'd be good to know that .&#10;Speaker: PhD F&#10;Content: OK . I just need to get , um , {vocalsound} front - end , uh , stuff from you&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker" />
    <node id=" C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ? Ah . I see .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Just summary of the experiment and the conclusion and something like that .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So that , you know {disfmarker} so that such a thing can be written . And , um {d" />
    <node id="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech." />
    <node id=" F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker} I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , if you had a first formant that was one hundred hertz before , if the fifty {disfmarker} if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at {disfmarker} So , although , you frequently get less distinct higher formants , it 's still {disfmarker} third formant 's kind of a reasonable compromise , and {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm ." />
    <node id="marker}&#10;Speaker: PhD F&#10;Content: Right . So whatever it was , it would have to be uh sort of on a per frame basis .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff .&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: Professor E&#10;Content: But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker}" />
    <node id=" are dependent on the {disfmarker} uh , if it 's speech or noi or silence .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: And there is this kind of spectral flattening after {disfmarker} if it 's silence , and {disfmarker} and s I {disfmarker} I think it 's important , um , {vocalsound} to reduce this musical noise and this {disfmarker} this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from {disfmarker} from the {disfmarker} this proposal and {disfmarker} and then just add some kind of on - line normalization in {disfmarker} in the neural network . Mmm .&#10;Speaker: Professor E&#10;Content: OK . Well , this 'll be , I think , something for discussion with Hynek next week .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . OK . Right . So . How are , uh , uh" />
    <node id=" I {disfmarker} I mean , you could maybe use the ideas {disfmarker} a similar {pause} idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance {disfmarker} like , the likelihood of each utterance . You divide the {disfmarker} the range of the likelihoods up into discrete bins and then each bin 's got some knob {disfmarker} uh , setting .&#10;Speaker: Professor E&#10;Content: Yeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that {disfmarker} and where you 're not adjusting the statistical engine at all .&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Yeah . That 's true .&#10;Speaker: Professor E&#10;Content: You know" />
    <node id="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." />
    <node id=" mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , I mean , the insertions is {disfmarker} is a symptom . It 's a symptom that there 's something , uh , wrong with the range .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: But there 's {disfmarker} uh , your {disfmarker} your {disfmarker} your substitutions tend to go up as well . So , uh , I {disfmarker} I {disfmarker} I think that ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: uh , the most obvious thing is just the insertions , @ @ . But {disfmarker} Uh {disfmarker} um . If you 're operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what" />
    <node id=" our number should be in ,&#10;Speaker: Professor E&#10;Content: I think so .&#10;Speaker: PhD F&#10;Content: so that they {pause} match with that .&#10;Speaker: Professor E&#10;Content: Yeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing {disfmarker} ? Y y&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: I 'm sure you 've already looked at this bu in these noisy cases , are {disfmarker} ? We are seeing lots of insertions . Right ? The insertion number is quite high ?&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: I know the VAD takes pre care of part of that ,&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: but {disfmarker}&#10;Speaker: PhD F&#10;Content: I" />
    <node id=" - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down {pause} that one time and {disfmarker} and that was when people were saying , well we should have a , uh , uh , voice activity detector {disfmarker}&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: that , because all that stuff {comment} that we 're getting thr the silence that 's getting through is causing insertions . So .&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I 'll bet you there 's still a lot {vocalsound} of insertions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .&#10;Speaker: PhD" />
    <node id="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner." />
    <node id=" . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere . So .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Um . A sudden change or a relatively rapid change in some spectral characteristic will {disfmarker} will do sort of this . I mean , there 's certainly a bunch of {disfmarker} a bunch of places where you know that neurons are gonna fire because something novel has happened . That was {disfmarker} that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but {disfmarker}&#10;Speaker: PhD F&#10;Content: It 's kinda like the difference between top - down and bottom - up .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I think of the acoustic {disfmarker} you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disf" />
    <node id="} on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the {disfmarker} the big picture of {disfmarker} of um , the plan .&#10;Speaker: Professor E&#10;Content: By the way , um , there 's , uh , a couple people who are gonna be here {disfmarker} I forget if I already told you this , but , a couple people who are gonna be here for six months .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh {disfmarker} uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at {vocalsound} auditory properties inspired by various , uh , brain function things .&#10;Speaker: Grad A&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are {disf" />
    <node id="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." />
    <node id=" noisy stuff , you start getting lots of insertions .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: And , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . I mean , it {disfmarker} it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um . {vocalsound} I could do more playing with that , though . And , uh {disfmarker}&#10;Speaker: Professor E&#10;Content: But you were looking at mel cepstrum .&#10;Speaker: PhD F&#10;Content: and see . Yes .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Oh , you 're talking about for th {vocalsound} for our features .&#10;Speaker: Professor E&#10;Content: Right . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the {disfmarker}" />
    <node id=" so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .&#10;" />
    <node id=" uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with {disfmarker} with LDA and KLT and neural nets and {vocalsound} all these things . In the fa past we 've always found that we had to increase the insertion penalty to {disfmarker} to correspond to such things . So , I think that 's , uh , @ @ {comment} that 's kind of a first - order thing that {disfmarker} that we should try .&#10;Speaker: PhD F&#10;Content: So for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes&#10;Speaker: Professor E&#10;Content: So by &quot; our front - end &quot;" />
    <node id=" range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor E&#10;Content: And you might wanna change that .&#10;Speaker: PhD B&#10;Content: But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input ,&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: so I don Well . I don't know .&#10;Speaker: Professor E&#10;Content: That means they 're between zero and one .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they" />
    <node id="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment." />
    <node id="} to {disfmarker} to give some more structure .&#10;Speaker: PhD B&#10;Content: Yea&#10;Speaker: Professor E&#10;Content: So . B So {disfmarker} Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .&#10;Speaker: PhD C&#10;Content: Hm - hmm .&#10;Speaker: PhD B&#10;Content: Uh , y yeah . Basically we we 've stopped , uh , experimenting ,&#10;Speaker: Professor E&#10;Content: Yes ?&#10;Speaker: PhD B&#10;Content: I mean . We 're just writing some kind of technical report . And {disfmarker}&#10;Speaker: PhD F&#10;Content: Is this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;" />
    <node id="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type." />
    <node id=" then it 's going through this transformation that 's probably pretty close to {disfmarker} It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a {disfmarker} a {disfmarker} a discrete cosine transformation is doing .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: But still it 's {disfmarker} it 's not gonna probably radically change the scale of things . I would think . And , uh {disfmarker} Yeah . It may be entirely off and {disfmarker} and it may be {disfmarker} at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be {disfmarker} So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the {disfmarker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh ," />
    <node id="Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , if it 's very different , then this is the sort of thing {disfmarker} I mean I 'm really glad Andreas brought this point up . I {pause} sort of had forgotten to discuss it . Um . You always have to look at how this {disfmarker} uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So if it {disfmarker} if in fact , uh {disfmarker} The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm" />
    <node id="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance." />
    <node id="isfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: I remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: for an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and {disfmarker} Uh , we might just not even be in the right operating range .&#10;Speaker: PhD F&#10;Content: So , would the {disfmarker} ? Uh , would a good idea be to try to" />
    <node id="re operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what these {disfmarker} these penalties and scaling factors are , you reach some point that 's a {disfmarker} that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we {disfmarker} if we see {disfmarker} Um , I mean we ca it 's if we actually could pick a {disfmarker} a {disfmarker} a more stable value for the range of these features , it , um , uh , could {disfmarker} Uh {disfmarker} Even though it 's {disfmarker} it 's {disfmarker} it 's true that in a real situation you can in fact adjust the {disfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not" />
    <node id="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." />
    <node id=" your stuff here ?&#10;Speaker: Grad A&#10;Content: Oh , um . Right . I {pause} just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um {disfmarker} Yeah . It 's {disfmarker} that 's pretty much it .&#10;Speaker: Professor E&#10;Content: Oh , well . No Um , why don't you say something about what it is ?&#10;Speaker: Grad A&#10;Content: Oh , you {disfmarker} oh , you want {disfmarker} you want details . Hmm . OK .&#10;Speaker: Professor E&#10;Content: Well , we 're all gathered here together . I thought we 'd , you know {disfmarker}&#10;Speaker: Grad A&#10;Content: I was hoping I could wave my hands . Um . So , um . So , once wa I {disfmarker} I was thinking getting {disf" />
    <node id="Speaker: Professor E&#10;Content: Let 's see . Test ? Test ? Yeah . OK .&#10;Speaker: Grad A&#10;Content: Hello ?&#10;Speaker: PhD B&#10;Content: Channel one .&#10;Speaker: Grad A&#10;Content: Hello ?&#10;Speaker: PhD C&#10;Content: Test .&#10;Speaker: Professor E&#10;Content: I was saying Hynek 'll be here next week , uh , Wednesday through Friday {disfmarker} uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh , {vocalsound} as far as I know , so {disfmarker} There we go .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: Um . So other than reading digits , what 's our agenda ?&#10;Speaker: PhD F&#10;Content: I don't really have , uh , anything new . Been working on {pause} Meeting Recorder stuff . So .&#10;Speaker:" />
    <node id="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches." />
    <node id=" .&#10;Speaker: Professor E&#10;Content: Hmm ? Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Well , there is also the spectral subtraction , which , um {disfmarker} I think maybe we should , uh , try to integrate it in {disfmarker} in our system .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mmm . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: But ,&#10;Speaker: Professor E&#10;Content: O&#10;Speaker: PhD B&#10;Content: I think that would involve to {disfmarker} {vocalsound} to mmm {vocalsound} use a big {disfmarker} a {disfmarker} al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by , {vocalsound} um , other kind of processing that 's {disfmarker} are dependent on the {disfmarker} uh , if it 's speech or noi or silence .&#10;Speaker: Professor E&#10;Content:" />
    <node id="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora." />
    <node id="&#10;Speaker: Professor E&#10;Content: That 's something I 'd like to understand before we actually use something from it ,&#10;Speaker: PhD F&#10;Content: I think it 's {disfmarker}&#10;Speaker: Professor E&#10;Content: because it would {disfmarker}&#10;Speaker: PhD F&#10;Content: it 's probably something that , mmm , the {disfmarker} you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just {pause} doing signal - processing .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: Well , it 's true ,&#10;Speaker: PhD F&#10;Content: So .&#10;Speaker: Professor E&#10;Content: except that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .&#10;Speaker: PhD F&#10;Content: Yeah . That 's true .&#10;Speaker: Professor E&#10;Content" />
    <node id=": Yeah . But we don't have res we don't have result of the AURO for Aurora yet .&#10;Speaker: Professor E&#10;Content: So .&#10;Speaker: PhD C&#10;Content: We need to train the neural network&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: and {disfmarker}&#10;Speaker: Professor E&#10;Content: So you 're training neural networks now ?&#10;Speaker: PhD C&#10;Content: No , not yet .&#10;Speaker: Professor E&#10;Content: So , what {disfmarker} wha {vocalsound} wh wha what what 's going on ?&#10;Speaker: PhD C&#10;Content: Well , we work in the report , too , because we have a lot of result ,&#10;Speaker: Professor E&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: they are very dispersed , and was necessary to {disfmarker} to look in all the directory to {disfmarker} to {disfmarker} to give some more structure .&#10;Speaker: PhD B&#10;Content: Yea&#10;Speaker: Professor E&#10;" />
    <node id=" B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: but {disfmarker}&#10;Speaker: PhD F&#10;Content: I 've seen that with the mel cepstrum . I don't {disfmarker} I don't know about {pause} the Aurora front - end , but {disfmarker}&#10;Speaker: PhD B&#10;Content: I think it 's much more balanced with , uh {disfmarker} when the front - end is more robust . Yeah . I could look at it {disfmarker} at this . Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . Wha - what 's a typical number ?&#10;Speaker: PhD B&#10;Content: I don't {disfmarker} I don't know .&#10;Speaker: Professor E&#10;Content: Do we {disfmarker} ? Oh , you {disfmarker} oh , you don't know .&#10;Speaker: PhD B&#10;Content: I don't have this in {disfmarker}&#10;Speaker: Professor E&#10;Content: OK . I 'm sure it 's more balanced ,&#10;Speaker" />
    <node id="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." />
    <node id=" {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um .&#10;Speaker: Professor E&#10;Content: That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ?&#10;Speaker: PhD B&#10;Content: Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector .&#10;Speaker: PhD C&#10;Content: Uh , for a v VAD .&#10;Speaker: PhD B&#10;Content: Right ? Um .&#10;Speaker: PhD F&#10;Content: Could you say it" />
    <node id="&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disfmarker} Um . Mmm . There is something {disfmarker} perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on {disfmarker} let 's say , on TIMIT with MSG features , they {disfmarker} they look as good as networks trained on PLP . But , um , when they are used on {disfmarker} on the SpeechDat - Car data , it 's not the case {disfmarker} oh , well . The MSG features are much worse , and so maybe they 're , um , less {disfmarker} more sensitive to different recording conditions , or {disfmarker} Shou&#10;Speaker: Professor E&#10;Content: Shouldn't be . They should be less so .&#10;Speaker: PhD B&#10;Content: Yeah . But {disfmarker}&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content" />
    <node id="&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content: But , you know , some problems are harder than others ,&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor E&#10;Content: and {disfmarker} And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so it 's {disfmarker} But it {disfmarker} but , um , i it {disfmarker} it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?&#10;Speaker: PhD B&#10;Content: Yeah . Yeah , sure .&#10;Speaker: Professor E&#10;Content: So .&#10;Speaker: PhD B&#10;Content: Uh .&#10;Speaker: Professor E&#10;Content: Hmm ? Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Well , there is also the spectral" />
    <node id="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices." />
    <node id="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes." />
    <node id="Speaker: PhD B&#10;Content: Different cars . Yeah .&#10;Speaker: Professor E&#10;Content: I mean , it was {disfmarker} it was actual different cars and so on .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: So . Um , it 's somewhat tuned . It 's tuned more than , you know , a {disfmarker} a {disfmarker} a {disfmarker} a {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: You 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But that 's not really what this contest is . So . Um , I guess it 's OK .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: That 's something I 'd like to understand before we actually use something from it ,&#10;Speaker: PhD" />
    <node id="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation." />
    <node id=": Yeah .&#10;Speaker: Professor E&#10;Content: Um . So {disfmarker} Uh {disfmarker} I just sorta think we need to explore the space . Just take a look at it a little bit .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And we {disfmarker} we {disfmarker} we may just find that {disfmarker} that we 're way off .&#10;Speaker: PhD F&#10;Content: OK . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Maybe we 're not . You know ? As for these other things , it may turn out that , uh , {vocalsound} it 's kind of reasonable . But then {disfmarker} I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future {disfmarker} of , you know , people {disfmarker} people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules ." />
    <node id=" people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say &quot; Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: when all you could do is just adjust this in the back - end with one s one knob . &quot;&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with {disfmarker} with what we 're doing . And as you say {disfmarker} as you point out {disfmarker} finding ways to then compensate for that in the front - end {vocalsound} also then becomes a priority for this particular test ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Spe" />
    <node id="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech." />
    <node id="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features." />
    <node id="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;" />
    <node id="aker: Professor E&#10;Content: So that , you know {disfmarker} so that such a thing can be written . And , um {disfmarker} When {disfmarker} when {disfmarker} when do you leave again ?&#10;Speaker: PhD C&#10;Content: Uh , in July . First of July .&#10;Speaker: Professor E&#10;Content: First of July ? OK . And that you figure on actually finishing it in {disfmarker} in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And right now it 's kind of important that we actually go forward with experiments .&#10;Speaker: PhD C&#10;Content: It 's not .&#10;Speaker: Professor E&#10;Content: So {disfmarker} so , I {disfmarker} I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and" />
    <node id="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately." />
    <node id=" F&#10;Content: we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to {disfmarker} to map everything into ?&#10;Speaker: Professor E&#10;Content: Well . It depends how much we wanna do gamesmanship and how much we wanna do {disfmarker} I mean , i if he it {disfmarker} to me , actually , even if you wanna be {disfmarker} play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the {disfmarker} set the scaling factors , uh , so that you got the best number for this point four five times the {disfmarker} {vocalsound} you know , and so on .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But they might change that {disfmarker} those weightings .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: Um . So {disfmarker} Uh {disfmarker} I just sorta" />
    <node id="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." />
    <node id="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed." />
    <node id=" hmm .&#10;Speaker: Professor E&#10;Content: And then when they finally actually evaluated things they used everything .&#10;Speaker: PhD B&#10;Content: Yeah . That 's right . Uh {disfmarker}&#10;Speaker: Professor E&#10;Content: So {disfmarker} Uh , and it is true that the performance , uh , on the German was {disfmarker} I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker} And , uh , it {disfmarker} it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that {disfmarker} that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh {disfmarker} I mean they were different drives .&#10;Speaker: PhD B&#10;Content: Different cars . Yeah .&#10;Speaker: Professor E&#10;Content: I mean , it was {disfmarker" />
    <node id=" for a v VAD .&#10;Speaker: PhD B&#10;Content: Right ? Um .&#10;Speaker: PhD F&#10;Content: Could you say it again ? What {disfmarker} what exactly did they do ?&#10;Speaker: PhD B&#10;Content: They used some parts of the , um , Italian database to train the voice activity detector , I think . It {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah . I guess the thing is {disfmarker} Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English {disfmarker} no , Italian and the Finnish and the English ? {disfmarker} were development data&#10;Speaker: PhD B&#10;Content: Yeah . And Spanish , yeah .&#10;Speaker: Professor E&#10;Content: on which you could adjust things . And the {disfmarker} and the German and Danish were the evaluation data .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And then when they finally actually evaluated things they used everything .&#10;Speaker: PhD B&#10;Content" />
    <node id="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum." />
    <node id="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner." />
    <node id="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy." />
    <node id="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions." />
    <node id="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions." />
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target=" try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're {vocalsound} supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure {disfmarker} I mean , having the two nets {disfmarker} Suppose you detected that it was male , it was female {disfmarker} you come up with different {disfmarker}&#10;Speaker: PhD F&#10;Content: Well , you could put them both in as separate streams or something . Uh .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Maybe .&#10;Speaker: PhD F&#10;Content: I don't know . I was just wondering if there was other information we could exploit .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . Yeah , it 's an interesting thought .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target="&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B&#10;Content: Like , we have {pause} male , female ,&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: Bank PIN .&#10;Speaker: PhD B&#10;Content: at least .&#10;Speaker: PhD F&#10;Content: Just male f female ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: What kind of information do you mean ?&#10;Speaker: PhD F&#10;Content: Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target=" have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Is it balanced , um , in terms of gender {disfmarker} the data ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Do you know ?&#10;Speaker: PhD B&#10;Content: Almost , yeah .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target=" E&#10;Content: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker} is a much simpler categorization than figuring out a {disfmarker} a factor to , uh , squish or expand the {disfmarker} the spectrum .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , um . Y you could imagine that {disfmarker} I mean , just like we 're saying voiced - unvoiced is good to know {disfmarker} uh , male female is good to know also . Um .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But , you 'd have to figure out a way to {disfmarker} to {disfmarker} to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target=" the front - end {vocalsound} also then becomes a priority for this particular test ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: and saying you don't have to do that .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So . OK . So , uh {disfmarker} What 's new with you ?&#10;Speaker: PhD B&#10;Content: Uh . So there 's nothing {pause} new . Um .&#10;Speaker: Professor E&#10;Content: Uh , what 's old with you that 's developed ?&#10;Speaker: PhD B&#10;Content: I 'm sorry ?&#10;Speaker: Professor E&#10;Content: You {disfmarker} OK . What 's old with you that has developed over the last week or two ?&#10;Speaker: PhD B&#10;Content: Mmm . Well , so we 've been mainly working on the report and {disfmarker} and {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: Mainly working on what ?&#10;Speaker: PhD B&#10;Content: On the report {pause}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target=" formant 's kind of a reasonable compromise , and {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , I think , eh , if I recall correctly , they did something like that . And {disfmarker} and {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: But {disfmarker} Um , that doesn't work for just having one frame or something .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: You know ? That 's more like looking at third formant over {disfmarker} over a turn or something like that ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Separate streams: One way to potentially exploit additional information when using a fixed backend and coming up with a feature vector for gender detection is by putting separate streams for different types of information, such as male and female streams.&#10;2. Gender-specific nets: Another way is by creating gender-specific nets trained only on males or females, which could help the system to better distinguish between genders.&#10;3. Vocal tract length normalization: This technique involves adjusting for differences in vocal tract length between genders, and can be used to improve the accuracy of gender detection.&#10;4. Other information about speakers: The group also discussed the possibility of using other types of information about speakers, such as social security numbers or bank PINs, although these would likely raise privacy concerns.&#10;5. Balanced data: Ensuring that the training data is balanced in terms of gender distribution can help improve the accuracy of gender detection.&#10;6. Incorporating gender information on the fly: The group also discussed the possibility of incorporating gender information into the system on the fly, rather than as part of the feature vector itself." target="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B&#10;Content: Like , we have {pause} male , female ,&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: Bank PIN .&#10;Speaker: PhD B&#10;Content: at least .&#10;Speaker: PhD F&#10;Content: Just male f female ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: What kind of information do you mean ?&#10;Speaker: PhD F&#10;Content: Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm ." target="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B&#10;Content: Like , we have {pause} male , female ,&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: Bank PIN .&#10;Speaker: PhD B&#10;Content: at least .&#10;Speaker: PhD F&#10;Content: Just male f female ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: What kind of information do you mean ?&#10;Speaker: PhD F&#10;Content: Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm ." target="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B&#10;Content: Like , we have {pause} male , female ,&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: PhD F&#10;Content: Bank PIN .&#10;Speaker: PhD B&#10;Content: at least .&#10;Speaker: PhD F&#10;Content: Just male f female ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: What kind of information do you mean ?&#10;Speaker: PhD F&#10;Content: Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm ." target="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices.">
      <data key="d0">1</data>
    </edge>
    <edge source=" have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Is it balanced , um , in terms of gender {disfmarker} the data ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Do you know ?&#10;Speaker: PhD B&#10;Content: Almost , yeah .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disf" target="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches.">
      <data key="d0">1</data>
    </edge>
    <edge source=" have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Is it balanced , um , in terms of gender {disfmarker} the data ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Do you know ?&#10;Speaker: PhD B&#10;Content: Almost , yeah .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disf" target="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices.">
      <data key="d0">1</data>
    </edge>
    <edge source=" E&#10;Content: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker} is a much simpler categorization than figuring out a {disfmarker} a factor to , uh , squish or expand the {disfmarker} the spectrum .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , um . Y you could imagine that {disfmarker} I mean , just like we 're saying voiced - unvoiced is good to know {disfmarker} uh , male female is good to know also . Um .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But , you 'd have to figure out a way to {disfmarker} to {disfmarker} to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained" target="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the front - end {vocalsound} also then becomes a priority for this particular test ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: and saying you don't have to do that .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So . OK . So , uh {disfmarker} What 's new with you ?&#10;Speaker: PhD B&#10;Content: Uh . So there 's nothing {pause} new . Um .&#10;Speaker: Professor E&#10;Content: Uh , what 's old with you that 's developed ?&#10;Speaker: PhD B&#10;Content: I 'm sorry ?&#10;Speaker: Professor E&#10;Content: You {disfmarker} OK . What 's old with you that has developed over the last week or two ?&#10;Speaker: PhD B&#10;Content: Mmm . Well , so we 've been mainly working on the report and {disfmarker} and {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: Mainly working on what ?&#10;Speaker: PhD B&#10;Content: On the report {pause}" target="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora.">
      <data key="d0">1</data>
    </edge>
    <edge source=" formant 's kind of a reasonable compromise , and {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , I think , eh , if I recall correctly , they did something like that . And {disfmarker} and {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: But {disfmarker} Um , that doesn't work for just having one frame or something .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: You know ? That 's more like looking at third formant over {disfmarker} over a turn or something like that ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker}" target="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target=" this in {disfmarker}&#10;Speaker: Professor E&#10;Content: OK . I 'm sure it 's more balanced ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="er} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {d">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?&#10;Speaker: PhD B&#10;Content: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don&#10;Speaker: Professor E&#10;Content: Yeah . But you should always look at insertions , deletions , and substitutions .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum .">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="marker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm . Yeah . But ,&#10;Speaker: Professor E&#10;Content: Anything else ?&#10;Speaker: PhD B&#10;Content: my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Professor E&#10;Content: Well .&#10;Speaker: PhD B&#10;Content: And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target=" difference was {disfmarker} at least part of it that {disfmarker} that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: Part of it might just be that the SRI system , they {disfmarker} they {disfmarker} they always adjust these things to be sort of optimized ,&#10;Speaker: PhD F&#10;Content: Is there {disfmarker} ?&#10;Speaker: Professor E&#10;Content: and {disfmarker}&#10;Speaker: PhD F&#10;Content: I wonder if there 's anything that we could do {vocalsound} to the front - end that would affect the insertion {disfmarker}&#10;Speaker: Professor E&#10;Content: Yes . I think you can .&#10;Speaker: PhD F&#10;Content: What could you do ?&#10;Speaker: Professor E&#10;Content: Well , um {disfmarker} uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="s coming from the language model .&#10;Speaker: PhD F&#10;Content: So that w Right . So , in effect , that 's changing the value of your insertion penalty .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , it 's more directly like the {disfmarker} the language scaling or the , uh {disfmarker} the model scaling or acoustic scaling ,&#10;Speaker: PhD F&#10;Content: That 's interesting .&#10;Speaker: Professor E&#10;Content: but you know that those things have kind of a similar effect to the insertion penalty&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: anyway . They 're a slightly different way of {disfmarker} of handling it .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: So , um {disfmarker}&#10;Speaker: PhD F&#10;Content: So if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,&#10;Speaker: Professor E&#10;Content: I think so .&#10;Speaker: PhD F&#10;Content: so that they {">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the old systems used for doing certain tasks, the ratio of insertions to deletions was roughly 1:2, meaning there were half as many insertions as deletions. Both numbers (insertions and deletions) were typically on the smaller side when compared to substitutions." target="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" this in {disfmarker}&#10;Speaker: Professor E&#10;Content: OK . I 'm sure it 's more balanced ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think" target="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" this in {disfmarker}&#10;Speaker: Professor E&#10;Content: OK . I 'm sure it 's more balanced ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think" target="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {d" target="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {d" target="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ?&#10;Speaker: PhD F&#10;Content: Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {d" target="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?&#10;Speaker: PhD B&#10;Content: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don&#10;Speaker: Professor E&#10;Content: Yeah . But you should always look at insertions , deletions , and substitutions .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum ." target="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?&#10;Speaker: PhD B&#10;Content: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don&#10;Speaker: Professor E&#10;Content: Yeah . But you should always look at insertions , deletions , and substitutions .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum ." target="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?&#10;Speaker: PhD B&#10;Content: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don&#10;Speaker: Professor E&#10;Content: Yeah . But you should always look at insertions , deletions , and substitutions .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum ." target="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?&#10;Speaker: PhD B&#10;Content: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don&#10;Speaker: Professor E&#10;Content: Yeah . But you should always look at insertions , deletions , and substitutions .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum ." target="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm . Yeah . But ,&#10;Speaker: Professor E&#10;Content: Anything else ?&#10;Speaker: PhD B&#10;Content: my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Professor E&#10;Content: Well .&#10;Speaker: PhD B&#10;Content: And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content" target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm . Yeah . But ,&#10;Speaker: Professor E&#10;Content: Anything else ?&#10;Speaker: PhD B&#10;Content: my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Professor E&#10;Content: Well .&#10;Speaker: PhD B&#10;Content: And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content" target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="s coming from the language model .&#10;Speaker: PhD F&#10;Content: So that w Right . So , in effect , that 's changing the value of your insertion penalty .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , it 's more directly like the {disfmarker} the language scaling or the , uh {disfmarker} the model scaling or acoustic scaling ,&#10;Speaker: PhD F&#10;Content: That 's interesting .&#10;Speaker: Professor E&#10;Content: but you know that those things have kind of a similar effect to the insertion penalty&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: anyway . They 're a slightly different way of {disfmarker} of handling it .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: So , um {disfmarker}&#10;Speaker: PhD F&#10;Content: So if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,&#10;Speaker: Professor E&#10;Content: I think so .&#10;Speaker: PhD F&#10;Content: so that they {" target="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target=" Yeah .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that 's {disfmarker} that 's one of the big advantages of not making much money is {vocalsound} the taxes are easier . Yeah .&#10;Speaker: PhD F&#10;Content: Unless you 're getting money in two countries .&#10;Speaker: Professor E&#10;Content: I think you are . Aren't you ?&#10;Speaker: PhD F&#10;Content: They both want their cut .&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker: Grad D&#10;Content: Hmm . Yeah .&#10;Speaker: PhD F&#10;Content: Right ?&#10;Speaker: Professor E&#10;Content: Yeah . Yeah . Huh . Canada w Canada wants a cut ?&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Have to do {disfmarker} So you {disfmarker} you have to do two returns ?&#10;Speaker: Grad D&#10;Content: Mmm . W uh , for two thousand I did . Yeah .&#10;Speaker: Professor E&#10;Content: Oh">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target="Speaker: Grad D&#10;Content: Mmm . W uh , for two thousand I did . Yeah .&#10;Speaker: Professor E&#10;Content: Oh , oh . Yeah . For tw That 's right , ju&#10;Speaker: PhD F&#10;Content: But not for this next year ?&#10;Speaker: Professor E&#10;Content: Two thousand . Yeah . Probably not this next year , I guess .&#10;Speaker: Grad D&#10;Content: Ye&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Um .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Uh , I 'll {disfmarker} I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a {disfmarker} considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .&#10;Speaker: Professor E&#10;Content: OK . Alright . Uh . Barry , do you wanna {pause} say something about your stuff here ?&#10;Speaker: Grad A&#10;Content: Oh , um . Right . I {pause} just , um , continuing looking at , uh">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target=" two knowing that we were doing that .&#10;Speaker: PhD F&#10;Content: Yeah . That 's true .&#10;Speaker: Professor E&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: And they didn't forbid us {disfmarker} right ? {disfmarker} to build models on the data ?&#10;Speaker: Professor E&#10;Content: No . But , I think {disfmarker} I think that it {disfmarker} it {disfmarker} it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that {disfmarker} that it would look bad . And I think someone would notice and would say &quot; Well , look . This is not generalizing . &quot; I would hope tha I would hope they would .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Um . But , uh , it 's true . You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target=": Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . OK . Right . So . How are , uh , uh {disfmarker} how are things going with what you 're doing ?&#10;Speaker: Grad D&#10;Content: Oh . Well , um , I took a lot of time just getting my taxes out of the way {disfmarker} multi - national taxes . So , I 'm {disfmarker} I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Do you know what his schedule will be like ?&#10;Speaker: Professor E&#10;Content: Uh , he 'll be around for three days .&#10;Speaker: Grad D&#10;Content: OK . So , y&#10;Speaker: Professor E&#10;Content: Uh , we 'll have a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target=" a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So .&#10;Speaker: PhD F&#10;Content: But you said you won't {disfmarker} you won't be here next Thursday ?&#10;Speaker: Professor E&#10;Content: Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ?&#10;Speaker: Grad D&#10;Content: Mmm . Yeah .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target=" range .&#10;Speaker: PhD F&#10;Content: So , would the {disfmarker} ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as {disfmarker} ?&#10;Speaker: Professor E&#10;Content: No . You don't wanna change it for different conditions . No . No . I {disfmarker} I {disfmarker} I {disfmarker} What {disfmarker} what I 'm saying {disfmarker}&#10;Speaker: PhD F&#10;Content: Oh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we {disfmarker} we wanna pick a range that we map our numbers into {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the conversation transcript, it appears that is what they are discussing. Speaker PhD F mentions that if one is getting money from two countries, &quot;they both want their cut.&quot; Later in the conversation, Speaker Grad D confirms this by saying that even though they will no longer be considered a resident of Canada for tax purposes next year, they will still have to deal with Canadian income taxes for this year and need to file returns for both countries." target="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . OK . Right . So . How are , uh , uh {disfmarker} how are things going with what you 're doing ?&#10;Speaker: Grad D&#10;Content: Oh . Well , um , I took a lot of time just getting my taxes out of the way {disfmarker} multi - national taxes . So , I 'm {disfmarker} I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: Grad D&#10;Content: Do you know what his schedule will be like ?&#10;Speaker: Professor E&#10;Content: Uh , he 'll be around for three days .&#10;Speaker: Grad D&#10;Content: OK . So , y&#10;Speaker: Professor E&#10;Content: Uh , we 'll have a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmark" target="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source=" a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So .&#10;Speaker: PhD F&#10;Content: But you said you won't {disfmarker} you won't be here next Thursday ?&#10;Speaker: Professor E&#10;Content: Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ?&#10;Speaker: Grad D&#10;Content: Mmm . Yeah .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that" target="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=" a lot of time .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So .&#10;Speaker: PhD F&#10;Content: But you said you won't {disfmarker} you won't be here next Thursday ?&#10;Speaker: Professor E&#10;Content: Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat .&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ?&#10;Speaker: Grad D&#10;Content: Mmm . Yeah .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that" target="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source=" range .&#10;Speaker: PhD F&#10;Content: So , would the {disfmarker} ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as {disfmarker} ?&#10;Speaker: Professor E&#10;Content: No . You don't wanna change it for different conditions . No . No . I {disfmarker} I {disfmarker} I {disfmarker} What {disfmarker} what I 'm saying {disfmarker}&#10;Speaker: PhD F&#10;Content: Oh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we {disfmarker} we wanna pick a range that we map our numbers into {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we" target="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately.">
      <data key="d0">1</data>
    </edge>
    <edge source="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." target="Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker}&#10;Speaker: Professor E&#10;Content: So , stuff that 's not based on data .&#10;Speaker: PhD F&#10;Content: Stuff that 's not based on data , necessarily .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , OK . Yeah . Yeah , OK .&#10;Speaker: PhD F&#10;Content: Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: its tenseness , laxness , things like that ,&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvoc">
      <data key="d0">1</data>
    </edge>
    <edge source="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." target="er} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .&#10;Speaker: Professor E&#10;Content: Whose paper is it ?&#10;Speaker: Grad A&#10;Content: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen .&#10;Speaker: Professor E&#10;Content: Yeah . Huh . From , uh , University of Hamburg and Bielefeld .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between ,">
      <data key="d0">1</data>
    </edge>
    <edge source="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." target=" you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And so it 's sort of a different way of looking .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: Grad A&#10;Content: Yeah . So . Yeah .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Mm - hmm . Um {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." target=" or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind .&#10;Speaker: Professor E&#10;Content: I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event .&#10;Speaker: Grad A&#10;Content: Good . That 's great .&#10;Speaker: Professor E&#10;Content: And , uh , um , called them &quot; avents &quot; , uh , uh , uh , with an A at the front .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere .">
      <data key="d0">1</data>
    </edge>
    <edge source="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." target=" part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .&#10;Speaker: PhD F&#10;Content: Oh . Mm - hmm .&#10;Speaker: Professor E&#10;Content: You know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But {disfmarker} but , um , that has a similar effect because it changes the scale of the numbers {disfmarker} of the differences between different candidates from the acoustic model&#10;Speaker: PhD F&#10;Content: Oh , right .&#10;Speaker: Professor E&#10;Content: as opposed to what 's coming from the language model .&#10;Speaker: PhD F&#10;Content: So that w Right . So , in effect , that 's changing the value">
      <data key="d0">1</data>
    </edge>
    <edge source="Acoustic features and acoustic events are two different concepts in linguistics. Acoustic features are characteristics of speech sounds that linguists talk about, such as height or tenseness. These features may not always be easy to measure in the acoustic signal. On the other hand, an acoustic event is a specific type of measurement that can be easily identified in the acoustic signal. Examples of acoustic events include frication (noise resulting from airflow through a narrow opening, as in consonants like /s/ or /f/) and nasality (sound resonance in the nasal cavity, as in vowels like /ɑː/).&#10;&#10;While acoustic features are often theory-driven and may not have clear acoustic correlates, acoustic events are data-driven and based on measurable characteristics of the speech signal. The discussion in the transcript revolves around using acoustic events for phoneme recognition, allowing the system to identify phones (speech sounds) based on objective measurements rather than relying solely on preconceived acoustic features.&#10;&#10;PhD F emphasizes that an acoustic event can map to a phone sometimes and not other times, depending on the context. This perspective highlights the importance of considering the variability in speech signals when analyzing and modeling them." target=" .&#10;Speaker: Professor E&#10;Content: There 's more to go ?&#10;Speaker: PhD B&#10;Content: Yeah . Well , so I don't know . There are small things that we started to {disfmarker} to do . But {disfmarker}&#10;Speaker: PhD F&#10;Content: Are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,&#10;Speaker: PhD B&#10;Content: Uh .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Yeah . Yeah . And {disfmarker} Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD B&#10;Content: But anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker}&#10;Speaker: Professor E&#10;Content: So , stuff that 's not based on data .&#10;Speaker: PhD F&#10;Content: Stuff that 's not based on data , necessarily .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , OK . Yeah . Yeah , OK .&#10;Speaker: PhD F&#10;Content: Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: its tenseness , laxness , things like that ,&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvoc" target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker}&#10;Speaker: Professor E&#10;Content: So , stuff that 's not based on data .&#10;Speaker: PhD F&#10;Content: Stuff that 's not based on data , necessarily .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , OK . Yeah . Yeah , OK .&#10;Speaker: PhD F&#10;Content: Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: its tenseness , laxness , things like that ,&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvoc" target="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker}&#10;Speaker: Professor E&#10;Content: So , stuff that 's not based on data .&#10;Speaker: PhD F&#10;Content: Stuff that 's not based on data , necessarily .&#10;Speaker: Professor E&#10;Content: Yeah . Oh , OK . Yeah . Yeah , OK .&#10;Speaker: PhD F&#10;Content: Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: its tenseness , laxness , things like that ,&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvoc" target="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .&#10;Speaker: Professor E&#10;Content: Whose paper is it ?&#10;Speaker: Grad A&#10;Content: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen .&#10;Speaker: Professor E&#10;Content: Yeah . Huh . From , uh , University of Hamburg and Bielefeld .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between ," target="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .&#10;Speaker: Professor E&#10;Content: Whose paper is it ?&#10;Speaker: Grad A&#10;Content: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen .&#10;Speaker: Professor E&#10;Content: Yeah . Huh . From , uh , University of Hamburg and Bielefeld .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between ," target="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .&#10;Speaker: Professor E&#10;Content: Whose paper is it ?&#10;Speaker: Grad A&#10;Content: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen .&#10;Speaker: Professor E&#10;Content: Yeah . Huh . From , uh , University of Hamburg and Bielefeld .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between ," target="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .&#10;Speaker: Professor E&#10;Content: Whose paper is it ?&#10;Speaker: Grad A&#10;Content: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen .&#10;Speaker: Professor E&#10;Content: Yeah . Huh . From , uh , University of Hamburg and Bielefeld .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: There 's , um {disfmarker} in my mind , anyways , there 's a difference between ," target="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And so it 's sort of a different way of looking .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: Grad A&#10;Content: Yeah . So . Yeah .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Mm - hmm . Um {disfmark" target="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=" you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And so it 's sort of a different way of looking .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: Grad A&#10;Content: Yeah . So . Yeah .&#10;Speaker: Grad D&#10;Content: OK .&#10;Speaker: Grad A&#10;Content: Mm - hmm . Um {disfmark" target="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind .&#10;Speaker: Professor E&#10;Content: I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event .&#10;Speaker: Grad A&#10;Content: Good . That 's great .&#10;Speaker: Professor E&#10;Content: And , uh , um , called them &quot; avents &quot; , uh , uh , uh , with an A at the front .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere ." target="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source=" or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind .&#10;Speaker: Professor E&#10;Content: I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event .&#10;Speaker: Grad A&#10;Content: Good . That 's great .&#10;Speaker: Professor E&#10;Content: And , uh , um , called them &quot; avents &quot; , uh , uh , uh , with an A at the front .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere ." target="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .&#10;Speaker: PhD F&#10;Content: Oh . Mm - hmm .&#10;Speaker: Professor E&#10;Content: You know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But {disfmarker} but , um , that has a similar effect because it changes the scale of the numbers {disfmarker} of the differences between different candidates from the acoustic model&#10;Speaker: PhD F&#10;Content: Oh , right .&#10;Speaker: Professor E&#10;Content: as opposed to what 's coming from the language model .&#10;Speaker: PhD F&#10;Content: So that w Right . So , in effect , that 's changing the value" target="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Professor E&#10;Content: There 's more to go ?&#10;Speaker: PhD B&#10;Content: Yeah . Well , so I don't know . There are small things that we started to {disfmarker} to do . But {disfmarker}&#10;Speaker: PhD F&#10;Content: Are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,&#10;Speaker: PhD B&#10;Content: Uh .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ?&#10;Speaker: PhD B&#10;Content: Yeah . Yeah . And {disfmarker} Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD B&#10;Content: But anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what" target="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." target=" Yeah .&#10;Speaker: PhD F&#10;Content: Mainly working on what ?&#10;Speaker: PhD B&#10;Content: On the report {pause} of the work that was already done .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD B&#10;Content: Um . Mm - hmm . That 's all .&#10;Speaker: PhD F&#10;Content: How about that {disfmarker} ? Any - anything new on the thing that , uh , you were working on with the , uh {disfmarker} ?&#10;Speaker: PhD C&#10;Content: I don't have results yet .&#10;Speaker: PhD F&#10;Content: No results ? Yeah .&#10;Speaker: Professor E&#10;Content: What was that ?&#10;Speaker: PhD F&#10;Content: The {disfmarker} the , uh ,&#10;Speaker: Grad A&#10;Content: Voicing thing .&#10;Speaker: PhD F&#10;Content: voicing detector .&#10;Speaker: Professor E&#10;Content: I mean , what what 's {disfmarker} what 's going on now ? What are you {pause} doing ?&#10;Speaker: PhD C&#10;Content: Uh , to try">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." target=" You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other things . So it 's {disfmarker} it 's , uh {disfmarker} We should {disfmarker} we should {disfmarker} Maybe {disfmarker} that 's maybe a topic {disfmarker} Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: to , you know , double check it 's OK .&#10;Speaker: PhD F&#10;Content: Do we know anything about {pause} the speakers for each of the , uh , training utterances ?&#10;Speaker: PhD B&#10;Content: What do you mean ? We {disfmarker} we {disfmarker}&#10;Speaker: PhD F&#10;Content: Do you have speaker information ?&#10;Speaker: Professor E&#10;Content: Social security number&#10;Speaker: PhD F&#10;Content: That would be good .&#10;Speaker: PhD B">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." target=" per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {disfmarker} that 's all I wrote down .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: PhD F&#10;Content: So . I {disfmarker} I would {disfmarker} Yeah . I would need to do that .&#10;Speaker: Professor E&#10;Content: OK . So {disfmarker}&#10;Speaker: PhD F&#10;Content: I can do that for next week .&#10;Speaker: Professor E&#10;Content: Yeah . And , um {disfmarker} Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But {disfmarker} but I think it would be {disfmarker} it 'd be good to know that .&#10;Speaker: PhD F&#10;Content: OK . I just need to get , um , {vocalsound} front - end , uh , stuff from you&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." target=" C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ? Ah . I see .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Just summary of the experiment and the conclusion and something like that .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So that , you know {disfmarker} so that such a thing can be written . And , um {d">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." target="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discuss a task that PhD F needs to complete, which involves gathering certain information or materials from another speaker (PhD B). They also discuss the possibility of having someone else do the task and having PhD F supervise. The specifics of the task are not clearly mentioned in the transcript, but it appears to be related to obtaining some &quot;front-end stuff&quot; for a project or experiment that PhD F is working on. It is also suggested that PhD F should put together all the relevant information and materials for this task in a clear and organized manner, so that it can serve as a basis for writing up the results in the future." target="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: PhD F&#10;Content: Mainly working on what ?&#10;Speaker: PhD B&#10;Content: On the report {pause} of the work that was already done .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD B&#10;Content: Um . Mm - hmm . That 's all .&#10;Speaker: PhD F&#10;Content: How about that {disfmarker} ? Any - anything new on the thing that , uh , you were working on with the , uh {disfmarker} ?&#10;Speaker: PhD C&#10;Content: I don't have results yet .&#10;Speaker: PhD F&#10;Content: No results ? Yeah .&#10;Speaker: Professor E&#10;Content: What was that ?&#10;Speaker: PhD F&#10;Content: The {disfmarker} the , uh ,&#10;Speaker: Grad A&#10;Content: Voicing thing .&#10;Speaker: PhD F&#10;Content: voicing detector .&#10;Speaker: Professor E&#10;Content: I mean , what what 's {disfmarker} what 's going on now ? What are you {pause} doing ?&#10;Speaker: PhD C&#10;Content: Uh , to try" target="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source=" per phone .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um , but , uh , that {disfmarker} that 's all I wrote down .&#10;Speaker: Professor E&#10;Content: OK .&#10;Speaker: PhD F&#10;Content: So . I {disfmarker} I would {disfmarker} Yeah . I would need to do that .&#10;Speaker: Professor E&#10;Content: OK . So {disfmarker}&#10;Speaker: PhD F&#10;Content: I can do that for next week .&#10;Speaker: Professor E&#10;Content: Yeah . And , um {disfmarker} Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But {disfmarker} but I think it would be {disfmarker} it 'd be good to know that .&#10;Speaker: PhD F&#10;Content: OK . I just need to get , um , {vocalsound} front - end , uh , stuff from you&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker" target="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source=" C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ? Ah . I see .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Just summary of the experiment and the conclusion and something like that .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So that , you know {disfmarker} so that such a thing can be written . And , um {d" target="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source=" C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;Speaker: PhD F&#10;Content: or {disfmarker} ? Ah . I see .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Just summary of the experiment and the conclusion and something like that .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So that , you know {disfmarker} so that such a thing can be written . And , um {d" target="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora.">
      <data key="d0">1</data>
    </edge>
    <edge source="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech." target=" F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker} I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , if you had a first formant that was one hundred hertz before , if the fifty {disfmarker} if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at {disfmarker} So , although , you frequently get less distinct higher formants , it 's still {disfmarker} third formant 's kind of a reasonable compromise , and {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .">
      <data key="d0">1</data>
    </edge>
    <edge source="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech." target="marker}&#10;Speaker: PhD F&#10;Content: Right . So whatever it was , it would have to be uh sort of on a per frame basis .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff .&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: Professor E&#10;Content: But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech." target=" are dependent on the {disfmarker} uh , if it 's speech or noi or silence .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: And there is this kind of spectral flattening after {disfmarker} if it 's silence , and {disfmarker} and s I {disfmarker} I think it 's important , um , {vocalsound} to reduce this musical noise and this {disfmarker} this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from {disfmarker} from the {disfmarker} this proposal and {disfmarker} and then just add some kind of on - line normalization in {disfmarker} in the neural network . Mmm .&#10;Speaker: Professor E&#10;Content: OK . Well , this 'll be , I think , something for discussion with Hynek next week .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . OK . Right . So . How are , uh , uh">
      <data key="d0">1</data>
    </edge>
    <edge source="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech." target=" I {disfmarker} I mean , you could maybe use the ideas {disfmarker} a similar {pause} idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance {disfmarker} like , the likelihood of each utterance . You divide the {disfmarker} the range of the likelihoods up into discrete bins and then each bin 's got some knob {disfmarker} uh , setting .&#10;Speaker: Professor E&#10;Content: Yeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that {disfmarker} and where you 're not adjusting the statistical engine at all .&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Yeah . That 's true .&#10;Speaker: Professor E&#10;Content: You know">
      <data key="d0">1</data>
    </edge>
    <edge source="When the vocal tract is shortened by 50%, the formants get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz). This is because the formants are essentially the resonances of the vocal tract, and changing the length and shape of the tract changes these resonances. The first formant tends to have a greater shift than higher formants when the vocal tract is shortened, which can affect the overall perceived pitch and quality of speech." target="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker} I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , if you had a first formant that was one hundred hertz before , if the fifty {disfmarker} if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at {disfmarker} So , although , you frequently get less distinct higher formants , it 's still {disfmarker} third formant 's kind of a reasonable compromise , and {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm ." target="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker}&#10;Speaker: PhD F&#10;Content: Right . So whatever it was , it would have to be uh sort of on a per frame basis .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff .&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: Professor E&#10;Content: But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker}" target="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker}&#10;Speaker: PhD F&#10;Content: Right . So whatever it was , it would have to be uh sort of on a per frame basis .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff .&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: Professor E&#10;Content: But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker}&#10;Speaker: PhD F&#10;Content: I don't know .&#10;Speaker: Professor E&#10;Content: So . You know , third formant {disfmarker}" target="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" are dependent on the {disfmarker} uh , if it 's speech or noi or silence .&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: And there is this kind of spectral flattening after {disfmarker} if it 's silence , and {disfmarker} and s I {disfmarker} I think it 's important , um , {vocalsound} to reduce this musical noise and this {disfmarker} this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from {disfmarker} from the {disfmarker} this proposal and {disfmarker} and then just add some kind of on - line normalization in {disfmarker} in the neural network . Mmm .&#10;Speaker: Professor E&#10;Content: OK . Well , this 'll be , I think , something for discussion with Hynek next week .&#10;Speaker: PhD B&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . OK . Right . So . How are , uh , uh" target="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target=" mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , I mean , the insertions is {disfmarker} is a symptom . It 's a symptom that there 's something , uh , wrong with the range .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: But there 's {disfmarker} uh , your {disfmarker} your {disfmarker} your substitutions tend to go up as well . So , uh , I {disfmarker} I {disfmarker} I think that ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: uh , the most obvious thing is just the insertions , @ @ . But {disfmarker} Uh {disfmarker} um . If you 're operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target=" our number should be in ,&#10;Speaker: Professor E&#10;Content: I think so .&#10;Speaker: PhD F&#10;Content: so that they {pause} match with that .&#10;Speaker: Professor E&#10;Content: Yeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing {disfmarker} ? Y y&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: I 'm sure you 've already looked at this bu in these noisy cases , are {disfmarker} ? We are seeing lots of insertions . Right ? The insertion number is quite high ?&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: I know the VAD takes pre care of part of that ,&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: but {disfmarker}&#10;Speaker: PhD F&#10;Content: I">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target=" - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down {pause} that one time and {disfmarker} and that was when people were saying , well we should have a , uh , uh , voice activity detector {disfmarker}&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: that , because all that stuff {comment} that we 're getting thr the silence that 's getting through is causing insertions . So .&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I 'll bet you there 's still a lot {vocalsound} of insertions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .&#10;Speaker: PhD">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions are considered a symptom of an underlying problem related to the range, which suggests that the number of insertions is indicative of some sort of misconfiguration or malfunction in the system. This is mentioned by Professor E when they say &quot;the insertions is {disfmarker} is a symptom . It's a symptom that there's something, uh, wrong with the range.&quot;&#10;2. Substitutions are also affected when operating in the wrong range, as they tend to increase along with insertions. This relationship between insertions and substitutions implies that both may be influenced by common factors related to the system's settings or performance. PhD F confirms this by saying &quot;Right.&quot; after Professor E's statement.&#10;3. The significance of addressing these issues lies in improving the overall performance of the system, as maintaining the correct range of insertions and substitutions is essential for optimal operation. This is why both PhD F and Professor E express interest in investigating whether their current system is &quot;way off&quot; in terms of these metrics." target="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , I mean , the insertions is {disfmarker} is a symptom . It 's a symptom that there 's something , uh , wrong with the range .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: But there 's {disfmarker} uh , your {disfmarker} your {disfmarker} your substitutions tend to go up as well . So , uh , I {disfmarker} I {disfmarker} I think that ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: uh , the most obvious thing is just the insertions , @ @ . But {disfmarker} Uh {disfmarker} um . If you 're operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what" target="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source=" - hmm .&#10;Speaker: PhD F&#10;Content: Well , this {disfmarker} the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down {pause} that one time and {disfmarker} and that was when people were saying , well we should have a , uh , uh , voice activity detector {disfmarker}&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: that , because all that stuff {comment} that we 're getting thr the silence that 's getting through is causing insertions . So .&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I 'll bet you there 's still a lot {vocalsound} of insertions .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .&#10;Speaker: PhD" target="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner." target=" . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere . So .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Um . A sudden change or a relatively rapid change in some spectral characteristic will {disfmarker} will do sort of this . I mean , there 's certainly a bunch of {disfmarker} a bunch of places where you know that neurons are gonna fire because something novel has happened . That was {disfmarker} that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but {disfmarker}&#10;Speaker: PhD F&#10;Content: It 's kinda like the difference between top - down and bottom - up .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I think of the acoustic {disfmarker} you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner." target="} on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the {disfmarker} the big picture of {disfmarker} of um , the plan .&#10;Speaker: Professor E&#10;Content: By the way , um , there 's , uh , a couple people who are gonna be here {disfmarker} I forget if I already told you this , but , a couple people who are gonna be here for six months .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh {disfmarker} uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at {vocalsound} auditory properties inspired by various , uh , brain function things .&#10;Speaker: Grad A&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner." target="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="The main focus of the discussion was on the importance of sudden or rapid changes in certain spectral characteristics, which can cause a bunch of neurons to fire and signal that something novel has happened. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes (such as phonetic features) being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The speakers also discussed a task that PhD F was working on, which involved gathering certain information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner." target="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere . So .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Um . A sudden change or a relatively rapid change in some spectral characteristic will {disfmarker} will do sort of this . I mean , there 's certainly a bunch of {disfmarker} a bunch of places where you know that neurons are gonna fire because something novel has happened . That was {disfmarker} that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but {disfmarker}&#10;Speaker: PhD F&#10;Content: It 's kinda like the difference between top - down and bottom - up .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I think of the acoustic {disfmarker} you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disf" target="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="} on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the {disfmarker} the big picture of {disfmarker} of um , the plan .&#10;Speaker: Professor E&#10;Content: By the way , um , there 's , uh , a couple people who are gonna be here {disfmarker} I forget if I already told you this , but , a couple people who are gonna be here for six months .&#10;Speaker: Grad A&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh {disfmarker} uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at {vocalsound} auditory properties inspired by various , uh , brain function things .&#10;Speaker: Grad A&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: So , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are {disf" target="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target=" noisy stuff , you start getting lots of insertions .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: And , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Um . I mean , it {disfmarker} it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um . {vocalsound} I could do more playing with that , though . And , uh {disfmarker}&#10;Speaker: Professor E&#10;Content: But you were looking at mel cepstrum .&#10;Speaker: PhD F&#10;Content: and see . Yes .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Oh , you 're talking about for th {vocalsound} for our features .&#10;Speaker: Professor E&#10;Content: Right . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target=" so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target=" uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with {disfmarker} with LDA and KLT and neural nets and {vocalsound} all these things . In the fa past we 've always found that we had to increase the insertion penalty to {disfmarker} to correspond to such things . So , I think that 's , uh , @ @ {comment} that 's kind of a first - order thing that {disfmarker} that we should try .&#10;Speaker: PhD F&#10;Content: So for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes&#10;Speaker: Professor E&#10;Content: So by &quot; our front - end &quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target=" range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor E&#10;Content: And you might wanna change that .&#10;Speaker: PhD B&#10;Content: But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input ,&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: so I don Well . I don't know .&#10;Speaker: Professor E&#10;Content: That means they 're between zero and one .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The result of PhD F's experimentation with adjusting insertion penalties when dealing with noisy data was that it didn't make a significant difference in the performance. It seemed to work well for the &quot;well-matched&quot; case, but there is room for further exploration.&#10;2. When adjusting the insertion penalties, PhD F focused on the mel cepstrum features, which are spectral features commonly used in speech recognition. The experiments were conducted to see if adjusting the insertion penalties would improve the system's ability to handle noisy data.&#10;3. Although the initial results did not show a substantial improvement, there is still potential for further investigation and fine-tuning of the insertion penalties. This could lead to better overall performance in noisy environments, especially considering that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source=" so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .&#10;" target="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type.">
      <data key="d0">1</data>
    </edge>
    <edge source=" so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor E&#10;Content: but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .&#10;" target="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor E&#10;Content: And you might wanna change that .&#10;Speaker: PhD B&#10;Content: But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input ,&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: so I don Well . I don't know .&#10;Speaker: Professor E&#10;Content: That means they 're between zero and one .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they" target="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type.">
      <data key="d0">1</data>
    </edge>
    <edge source=" range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor E&#10;Content: And you might wanna change that .&#10;Speaker: PhD B&#10;Content: But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input ,&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: so I don Well . I don't know .&#10;Speaker: Professor E&#10;Content: That means they 're between zero and one .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they" target="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment." target="} to {disfmarker} to give some more structure .&#10;Speaker: PhD B&#10;Content: Yea&#10;Speaker: Professor E&#10;Content: So . B So {disfmarker} Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .&#10;Speaker: PhD C&#10;Content: Hm - hmm .&#10;Speaker: PhD B&#10;Content: Uh , y yeah . Basically we we 've stopped , uh , experimenting ,&#10;Speaker: Professor E&#10;Content: Yes ?&#10;Speaker: PhD B&#10;Content: I mean . We 're just writing some kind of technical report . And {disfmarker}&#10;Speaker: PhD F&#10;Content: Is this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion given for improving the way of writing a summary of an experiment and its conclusion is to put together all the relevant information and materials for the task in a clear and organized manner. This will help create a clearer structure for the summary and ensure that all necessary details are included. It was also suggested that this process can serve as a basis for writing up the results in the future, making it easier to see what happened in the experiment." target="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="} to {disfmarker} to give some more structure .&#10;Speaker: PhD B&#10;Content: Yea&#10;Speaker: Professor E&#10;Content: So . B So {disfmarker} Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .&#10;Speaker: PhD C&#10;Content: Hm - hmm .&#10;Speaker: PhD B&#10;Content: Uh , y yeah . Basically we we 've stopped , uh , experimenting ,&#10;Speaker: Professor E&#10;Content: Yes ?&#10;Speaker: PhD B&#10;Content: I mean . We 're just writing some kind of technical report . And {disfmarker}&#10;Speaker: PhD F&#10;Content: Is this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: For ICSI .&#10;" target="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type." target=" then it 's going through this transformation that 's probably pretty close to {disfmarker} It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a {disfmarker} a {disfmarker} a discrete cosine transformation is doing .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: But still it 's {disfmarker} it 's not gonna probably radically change the scale of things . I would think . And , uh {disfmarker} Yeah . It may be entirely off and {disfmarker} and it may be {disfmarker} at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be {disfmarker} So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the {disfmarker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh ,">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type." target="Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , if it 's very different , then this is the sort of thing {disfmarker} I mean I 'm really glad Andreas brought this point up . I {pause} sort of had forgotten to discuss it . Um . You always have to look at how this {disfmarker} uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So if it {disfmarker} if in fact , uh {disfmarker} The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type." target="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type." target="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first step in analyzing the impact of the difference between a KLT (Karhunen-Loève Transform) transformation and a discrete cosine transformation in a given experiment would be to examine the substitutions, insertions, and deletions within the data. This will help establish a baseline understanding of how each transformation affects the data without making any adjustments.&#10;2. Compare the results for MSG, mel cepstrum, or PLP features separately, as the effects might differ between them. Since KLT and discrete cosine transformations are similar in their ability to decorrelate and reduce data dimensions, focusing on different types of features will provide insights into which transformation works better for each feature type.&#10;3. Based on the findings from the initial analysis, adjust parameters or settings related to the specific experiment, such as language scaling and insertion penalties, to fine-tune the performance of each transformation. This step might require iterative exploration and comparison of results to identify the optimal settings for each transformation type." target="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So , if it 's very different , then this is the sort of thing {disfmarker} I mean I 'm really glad Andreas brought this point up . I {pause} sort of had forgotten to discuss it . Um . You always have to look at how this {disfmarker} uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So if it {disfmarker} if in fact , uh {disfmarker} The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Mm - hmm" target="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance." target="isfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor E&#10;Content: I remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: for an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and {disfmarker} Uh , we might just not even be in the right operating range .&#10;Speaker: PhD F&#10;Content: So , would the {disfmarker} ? Uh , would a good idea be to try to">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance." target="re operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what these {disfmarker} these penalties and scaling factors are , you reach some point that 's a {disfmarker} that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we {disfmarker} if we see {disfmarker} Um , I mean we ca it 's if we actually could pick a {disfmarker} a {disfmarker} a more stable value for the range of these features , it , um , uh , could {disfmarker} Uh {disfmarker} Even though it 's {disfmarker} it 's {disfmarker} it 's true that in a real situation you can in fact adjust the {disfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance." target="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In previous systems, the optimal practice for adjusting scaling factors was to set them at a standard level after initially getting the system together and then rarely adjusting them again, as they tended to remain stable in the right operating range. This approach is important because frequent adjustments may not be necessary or beneficial, and maintaining a stable operating range for these factors helps ensure the overall performance and functionality of the system.&#10;2. The reason it is crucial to maintain a stable operating range for scaling factors is that deviations from this range can lead to issues like an increase in insertions and substitutions, which are symptoms of underlying problems within the system. These symptoms may indicate misconfiguration or malfunction, ultimately affecting the system's ability to perform tasks efficiently and accurately. By keeping the scaling factors within the appropriate range, the system can maintain its intended level of performance." target="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." target=" your stuff here ?&#10;Speaker: Grad A&#10;Content: Oh , um . Right . I {pause} just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um {disfmarker} Yeah . It 's {disfmarker} that 's pretty much it .&#10;Speaker: Professor E&#10;Content: Oh , well . No Um , why don't you say something about what it is ?&#10;Speaker: Grad A&#10;Content: Oh , you {disfmarker} oh , you want {disfmarker} you want details . Hmm . OK .&#10;Speaker: Professor E&#10;Content: Well , we 're all gathered here together . I thought we 'd , you know {disfmarker}&#10;Speaker: Grad A&#10;Content: I was hoping I could wave my hands . Um . So , um . So , once wa I {disfmarker} I was thinking getting {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." target="Speaker: Professor E&#10;Content: Let 's see . Test ? Test ? Yeah . OK .&#10;Speaker: Grad A&#10;Content: Hello ?&#10;Speaker: PhD B&#10;Content: Channel one .&#10;Speaker: Grad A&#10;Content: Hello ?&#10;Speaker: PhD C&#10;Content: Test .&#10;Speaker: Professor E&#10;Content: I was saying Hynek 'll be here next week , uh , Wednesday through Friday {disfmarker} uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh , {vocalsound} as far as I know , so {disfmarker} There we go .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: Um . So other than reading digits , what 's our agenda ?&#10;Speaker: PhD F&#10;Content: I don't really have , uh , anything new . Been working on {pause} Meeting Recorder stuff . So .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." target="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." target="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." target="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad A came up with a &quot;plan of attack&quot; regarding phonetic events, which they plan to discuss in a meeting with John Ohala and Chuck on Tuesday. However, the specific details of this plan are not provided in the conversation. Speaker Grad A mentions that they have been looking at phonetic events and developed a plan, but when prompted for more information by Professor E, Grad A only responds by saying &quot;I was hoping I could wave my hands... I was thinking getting...&quot; It is unclear what exactly this entails.&#10;&#10;It is possible that more details about the plan were discussed in the meeting with John Ohala and Chuck on Tuesday, but those details are not included in the transcript provided." target="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Professor E&#10;Content: Let 's see . Test ? Test ? Yeah . OK .&#10;Speaker: Grad A&#10;Content: Hello ?&#10;Speaker: PhD B&#10;Content: Channel one .&#10;Speaker: Grad A&#10;Content: Hello ?&#10;Speaker: PhD C&#10;Content: Test .&#10;Speaker: Professor E&#10;Content: I was saying Hynek 'll be here next week , uh , Wednesday through Friday {disfmarker} uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh , {vocalsound} as far as I know , so {disfmarker} There we go .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor E&#10;Content: Um . So other than reading digits , what 's our agenda ?&#10;Speaker: PhD F&#10;Content: I don't really have , uh , anything new . Been working on {pause} Meeting Recorder stuff . So .&#10;Speaker:" target="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches." target=" .&#10;Speaker: Professor E&#10;Content: Hmm ? Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Well , there is also the spectral subtraction , which , um {disfmarker} I think maybe we should , uh , try to integrate it in {disfmarker} in our system .&#10;Speaker: Professor E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mmm . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: But ,&#10;Speaker: Professor E&#10;Content: O&#10;Speaker: PhD B&#10;Content: I think that would involve to {disfmarker} {vocalsound} to mmm {vocalsound} use a big {disfmarker} a {disfmarker} al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by , {vocalsound} um , other kind of processing that 's {disfmarker} are dependent on the {disfmarker} uh , if it 's speech or noi or silence .&#10;Speaker: Professor E&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches." target="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches." target="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor E suggests incorporating gender information into the system &quot;on the fly&quot; rather than as part of the feature vector itself. One way to do this could be by using gender-specific nets trained only on male or female voices, as mentioned in point 2 of the supporting materials. This would allow the system to better distinguish between genders and adjust its output accordingly. Another technique mentioned by Professor E is vocal tract length normalization (point 3), which can help adjust for differences in vocal tract length between genders and improve the accuracy of gender detection.&#10;&#10;Additionally, ensuring that the training data is balanced in terms of gender distribution (point 5) could also help improve the system's ability to detect and incorporate gender information on the fly. Overall, there are several possible ways to incorporate gender categorization in speech synthesis, and Professor E seems open to exploring different approaches." target="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora." target="&#10;Speaker: Professor E&#10;Content: That 's something I 'd like to understand before we actually use something from it ,&#10;Speaker: PhD F&#10;Content: I think it 's {disfmarker}&#10;Speaker: Professor E&#10;Content: because it would {disfmarker}&#10;Speaker: PhD F&#10;Content: it 's probably something that , mmm , the {disfmarker} you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just {pause} doing signal - processing .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: Well , it 's true ,&#10;Speaker: PhD F&#10;Content: So .&#10;Speaker: Professor E&#10;Content: except that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .&#10;Speaker: PhD F&#10;Content: Yeah . That 's true .&#10;Speaker: Professor E&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora." target=": Yeah . But we don't have res we don't have result of the AURO for Aurora yet .&#10;Speaker: Professor E&#10;Content: So .&#10;Speaker: PhD C&#10;Content: We need to train the neural network&#10;Speaker: Professor E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: and {disfmarker}&#10;Speaker: Professor E&#10;Content: So you 're training neural networks now ?&#10;Speaker: PhD C&#10;Content: No , not yet .&#10;Speaker: Professor E&#10;Content: So , what {disfmarker} wha {vocalsound} wh wha what what 's going on ?&#10;Speaker: PhD C&#10;Content: Well , we work in the report , too , because we have a lot of result ,&#10;Speaker: Professor E&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: they are very dispersed , and was necessary to {disfmarker} to look in all the directory to {disfmarker} to {disfmarker} to give some more structure .&#10;Speaker: PhD B&#10;Content: Yea&#10;Speaker: Professor E&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora." target=" B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: but {disfmarker}&#10;Speaker: PhD F&#10;Content: I 've seen that with the mel cepstrum . I don't {disfmarker} I don't know about {pause} the Aurora front - end , but {disfmarker}&#10;Speaker: PhD B&#10;Content: I think it 's much more balanced with , uh {disfmarker} when the front - end is more robust . Yeah . I could look at it {disfmarker} at this . Yeah . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Yeah . Wha - what 's a typical number ?&#10;Speaker: PhD B&#10;Content: I don't {disfmarker} I don't know .&#10;Speaker: Professor E&#10;Content: Do we {disfmarker} ? Oh , you {disfmarker} oh , you don't know .&#10;Speaker: PhD B&#10;Content: I don't have this in {disfmarker}&#10;Speaker: Professor E&#10;Content: OK . I 'm sure it 's more balanced ,&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="They are currently writing a technical report to document and summarize the experiments and results they have generated. This report is intended for ICSI and not for Aurora." target="The main focus of the discussion was on the significance of rapid changes in certain spectral characteristics, which can trigger a group of neurons to fire and indicate that something novel has occurred. This concept is related to the distinction between top-down and bottom-up processes, with top-down processes being more deliberate and focused on specific features, and bottom-up processes being more automatic and driven by sensory input. The discussion also involved a task that PhD F was working on, which involved gathering information or materials related to &quot;front-end stuff&quot; for an experiment, and organizing this information in a clear and organized manner.">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target=" {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um .&#10;Speaker: Professor E&#10;Content: That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ?&#10;Speaker: PhD B&#10;Content: Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector .&#10;Speaker: PhD C&#10;Content: Uh , for a v VAD .&#10;Speaker: PhD B&#10;Content: Right ? Um .&#10;Speaker: PhD F&#10;Content: Could you say it">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disfmarker} Um . Mmm . There is something {disfmarker} perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on {disfmarker} let 's say , on TIMIT with MSG features , they {disfmarker} they look as good as networks trained on PLP . But , um , when they are used on {disfmarker} on the SpeechDat - Car data , it 's not the case {disfmarker} oh , well . The MSG features are much worse , and so maybe they 're , um , less {disfmarker} more sensitive to different recording conditions , or {disfmarker} Shou&#10;Speaker: Professor E&#10;Content: Shouldn't be . They should be less so .&#10;Speaker: PhD B&#10;Content: Yeah . But {disfmarker}&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content: But , you know , some problems are harder than others ,&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor E&#10;Content: and {disfmarker} And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so it 's {disfmarker} But it {disfmarker} but , um , i it {disfmarker} it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?&#10;Speaker: PhD B&#10;Content: Yeah . Yeah , sure .&#10;Speaker: Professor E&#10;Content: So .&#10;Speaker: PhD B&#10;Content: Uh .&#10;Speaker: Professor E&#10;Content: Hmm ? Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Well , there is also the spectral">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features.">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed.">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, they mention that this method is successful when used with TI-digits and certain features (mel cepstrum or MSG), but it does not work as well with SpeechDat-Car data. This inconsistency suggests there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. The PhD B also notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um .&#10;Speaker: Professor E&#10;Content: That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ?&#10;Speaker: PhD B&#10;Content: Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector .&#10;Speaker: PhD C&#10;Content: Uh , for a v VAD .&#10;Speaker: PhD B&#10;Content: Right ? Um .&#10;Speaker: PhD F&#10;Content: Could you say it" target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um .&#10;Speaker: Professor E&#10;Content: That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ?&#10;Speaker: PhD B&#10;Content: Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector .&#10;Speaker: PhD C&#10;Content: Uh , for a v VAD .&#10;Speaker: PhD B&#10;Content: Right ? Um .&#10;Speaker: PhD F&#10;Content: Could you say it" target="1. The issue with insertions discussed during the visit of the OGI representative was that the silence getting through in the data was causing insertions, leading to performance problems. This was due to the activation of the voice activity detector even during silence periods.&#10;2. It is still considered a potential problem for the voice activity detector because some instances may &quot;get by&quot; with it, meaning they might function adequately despite the presence of insertions. However, this does not mean that the issue is fully resolved or optimized, especially considering there could be room for improvement in noisy environments and with other features like language scaling and insertion penalties not being optimized for elements other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: PhD B&#10;Content: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disfmarker} Um . Mmm . There is something {disfmarker} perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on {disfmarker} let 's say , on TIMIT with MSG features , they {disfmarker} they look as good as networks trained on PLP . But , um , when they are used on {disfmarker} on the SpeechDat - Car data , it 's not the case {disfmarker} oh , well . The MSG features are much worse , and so maybe they 're , um , less {disfmarker} more sensitive to different recording conditions , or {disfmarker} Shou&#10;Speaker: Professor E&#10;Content: Shouldn't be . They should be less so .&#10;Speaker: PhD B&#10;Content: Yeah . But {disfmarker}&#10;Speaker: Professor E&#10;Content: R right ?&#10;Speaker: PhD B&#10;Content: Mmm .&#10;Speaker: Professor E&#10;Content" target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah . Well .&#10;Speaker: Professor E&#10;Content: But , you know , some problems are harder than others ,&#10;Speaker: PhD B&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor E&#10;Content: and {disfmarker} And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: so it 's {disfmarker} But it {disfmarker} but , um , i it {disfmarker} it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?&#10;Speaker: PhD B&#10;Content: Yeah . Yeah , sure .&#10;Speaker: Professor E&#10;Content: So .&#10;Speaker: PhD B&#10;Content: Uh .&#10;Speaker: Professor E&#10;Content: Hmm ? Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Well , there is also the spectral" target="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Gender detection on a per-frame basis: The speakers discuss the possibility of determining gender information &quot;on a per frame basis,&quot; indicating that they are considering methods to analyze and categorize speech characteristics on a frame-by-frame level, likely using short audio segments or time frames for analysis.&#10;2. Vocal tract length normalization: Professor E brings up the idea of using vocal tract length normalization as a method for improving gender detection. This technique involves adjusting for differences in vocal tract length between genders, which can affect speech characteristics and influence gender classification.&#10;3. Identifying average third formant: The speakers also discuss the possibility of using third formant analysis to differentiate between male and female voices. Third formants are related to vowel quality and can be influenced by vocal tract length differences between genders. By analyzing the average third formant, the system could potentially use this information as an indicator of gender.&#10;&#10;These methods could help improve the accuracy and reliability of gender detection on a per-frame basis, allowing for better differentiation between male and female voices." target="When the vocal tract is shortened, the formants (resonances of the vocal tract) get moved out to higher frequencies. Specifically, if the first formant starts at 100 Hertz, it would be moved to 750 Hertz (a move of 650 Hertz) when the vocal tract is shortened by 50%. The third formant, starting at 2500 Hertz, would be moved to approximately 3750 Hertz (a move of 1250 Hertz) under the same conditions. This is because changing the length and shape of the tract changes these resonances, with the first formant tending to have a greater shift than higher formants when the vocal tract is shortened. This can affect the overall perceived pitch and quality of speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="In the transcript, Professor E refers to the concept of an &quot;auditory event&quot; in the context of their SPAM (Speech Perception and Articulation by Machine) work. Auditory events were referred to as &quot;avents&quot; and were defined as something that occurs that is important to a bunch of neurons somewhere. This suggests that auditory events are related to the way that sounds are processed in the brain, rather than just the physical properties of the sound itself.&#10;&#10;Professor E and PhD F distinguish between auditory events and acoustic features. Acoustic features were described as things that linguists talk about, such as the height or tenseness of a phone, which may or may not be easy to measure in the acoustic signal. On the other hand, an acoustic event is something that can be measured more objectively in the acoustic signal, like frication or nasality.&#10;&#10;Professor E and PhD F also discuss the idea that phonetic features are often determined top-down based on the expected properties of a phone, while acoustic events are determined bottom-up by looking at the signal itself. This suggests that auditory events may be more closely tied to the physical properties of sound, while phonetic features may be influenced by higher-level linguistic and cognitive processes." target="Speaker: PhD B&#10;Content: Different cars . Yeah .&#10;Speaker: Professor E&#10;Content: I mean , it was {disfmarker} it was actual different cars and so on .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: So . Um , it 's somewhat tuned . It 's tuned more than , you know , a {disfmarker} a {disfmarker} a {disfmarker} a {disfmarker}&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: You 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But that 's not really what this contest is . So . Um , I guess it 's OK .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: That 's something I 'd like to understand before we actually use something from it ,&#10;Speaker: PhD">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation." target=": Yeah .&#10;Speaker: Professor E&#10;Content: Um . So {disfmarker} Uh {disfmarker} I just sorta think we need to explore the space . Just take a look at it a little bit .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And we {disfmarker} we {disfmarker} we may just find that {disfmarker} that we 're way off .&#10;Speaker: PhD F&#10;Content: OK . Mm - hmm .&#10;Speaker: Professor E&#10;Content: Maybe we 're not . You know ? As for these other things , it may turn out that , uh , {vocalsound} it 's kind of reasonable . But then {disfmarker} I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future {disfmarker} of , you know , people {disfmarker} people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation." target=" people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say &quot; Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: when all you could do is just adjust this in the back - end with one s one knob . &quot;&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with {disfmarker} with what we 're doing . And as you say {disfmarker} as you point out {disfmarker} finding ways to then compensate for that in the front - end {vocalsound} also then becomes a priority for this particular test ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation." target="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor E is suggesting that there may be a narrow perspective or set of rules within the &quot;tight-knit community&quot; evaluating certain matters, and they may benefit from exploring the broader space of reasonable responses and viewpoints. By acknowledging Andreas's reasonable response, he highlights the potential value in considering alternatives to the current consensus.&#10;2. He emphasizes the importance of reflecting on how adjustments made within the system affect its performance, especially when these adjustments may not be in line with the rules or practices accepted by the community. By acknowledging the possibility of being &quot;off track,&quot; he encourages a more open-minded evaluation of the situation.&#10;&#10;In summary, Professor E is advocating for a broader exploration of reasonable responses within the community evaluating these matters and underscoring the value in considering alternative viewpoints, such as Andreas's response. He also stresses the need to examine how adjustments made within the system may impact its overall performance, given that maintaining the correct range of insertions and substitutions is essential for optimal operation." target="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The transcript does not provide specific numerical values for the error rates associated with MSG, PLP, or other alternatives. However, it is mentioned that the error rate is higher for the method being discussed, which includes MSG features. Both insertions and deletions are mentioned as errors, but no direct comparison is made between MSG and PLP in terms of these specific error types.&#10;2. The discussion does highlight the importance of examining insertions, deletions, and substitutions when comparing KLT and discrete cosine transformations. This comparison should be done for each feature type (MSG, mel cepstrum, or PLP) to determine which transformation works better for each specific feature.&#10;3. The variable effectiveness of the method using MSG features suggests that further exploration and fine-tuning of parameters, such as insertion penalties, might lead to improved performance, especially in noisy environments. This implies that there is room for reducing error rates associated with MSG features by optimizing these parameters.&#10;4. Both insertions and deletions are considered symptoms of a more fundamental problem related to the range, suggesting that maintaining the correct range of insertions and substitutions is essential for optimal system performance. Therefore, investigating the current system's configuration and settings is crucial to improve error rates associated with all error types, including those related to MSG features." target="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professor E will not be available on Thursday and Friday because he will be at a faculty retreat. Instead, he plans to try to connect with people on Wednesday. This information is conveyed in the following statements made by Professor E:&#10;&#10;* &quot;Not Thursday and Friday. Cuz I will be at faculty retreat.&quot;&#10;* &quot;So. I'll try to connect with him and people as I can on Wednesday.&quot;" target="aker: Professor E&#10;Content: So that , you know {disfmarker} so that such a thing can be written . And , um {disfmarker} When {disfmarker} when {disfmarker} when do you leave again ?&#10;Speaker: PhD C&#10;Content: Uh , in July . First of July .&#10;Speaker: Professor E&#10;Content: First of July ? OK . And that you figure on actually finishing it in {disfmarker} in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And right now it 's kind of important that we actually go forward with experiments .&#10;Speaker: PhD C&#10;Content: It 's not .&#10;Speaker: Professor E&#10;Content: So {disfmarker} so , I {disfmarker} I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and">
      <data key="d0">1</data>
    </edge>
    <edge source="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately." target=" F&#10;Content: we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to {disfmarker} to map everything into ?&#10;Speaker: Professor E&#10;Content: Well . It depends how much we wanna do gamesmanship and how much we wanna do {disfmarker} I mean , i if he it {disfmarker} to me , actually , even if you wanna be {disfmarker} play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the {disfmarker} set the scaling factors , uh , so that you got the best number for this point four five times the {disfmarker} {vocalsound} you know , and so on .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: But they might change that {disfmarker} those weightings .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor E&#10;Content: Um . So {disfmarker} Uh {disfmarker} I just sorta">
      <data key="d0">1</data>
    </edge>
    <edge source="1. When choosing a range to map data, it is recommended to base it on the range obtained from the well-matched case. This ensures consistency and comparability across different conditions.&#10;2. Both PhD F and Professor E agree that picking the range based on the well-matched case is a reasonable approach, as it provides a standard reference point for evaluating and comparing data.&#10;3. Professor E briefly mentions the concept of &quot;gamesmanship&quot; and adjusting scaling factors to achieve better numbers in certain conditions. However, he also acknowledges that these weightings might change and could potentially complicate the process.&#10;4. In general, it is advisable to maintain a stable operating range for scaling factors, as frequent adjustments may not be necessary or beneficial. Deviations from this range can lead to issues like increased insertions and substitutions, which are symptoms of underlying problems within the system.&#10;5. When considering gamesmanship or potential changes in weightings, it is essential to strike a balance between optimizing performance and maintaining stability in the system's settings. Being aware of how adjustments affect overall performance will help ensure the system operates efficiently and accurately." target="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="PHP B is emphasizing that the method they are discussing has variable effectiveness - it works sometimes, but not always. Specifically, this method is successful when used with TI-digits and certain features such as mel cepstrum or MSG, but it does not work as well with SpeechDat-Car data. This inconsistency suggests that there is room for further exploration and fine-tuning of the insertion penalties, potentially leading to better performance in noisy environments. Additionally, PhD B notes that the current language scaling and insertion penalties might not be optimized for features other than mel cepstrum." target="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed." target=" hmm .&#10;Speaker: Professor E&#10;Content: And then when they finally actually evaluated things they used everything .&#10;Speaker: PhD B&#10;Content: Yeah . That 's right . Uh {disfmarker}&#10;Speaker: Professor E&#10;Content: So {disfmarker} Uh , and it is true that the performance , uh , on the German was {disfmarker} I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: So {disfmarker} And , uh , it {disfmarker} it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that {disfmarker} that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh {disfmarker} I mean they were different drives .&#10;Speaker: PhD B&#10;Content: Different cars . Yeah .&#10;Speaker: Professor E&#10;Content: I mean , it was {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The raw performance of the system on the German language was already quite good, even before applying any tuning or adjustments for that specific language. This suggests that the system has a solid foundation and could maintain its performance when switching to a different language.&#10;2. Although there were some improvements made for three or four languages, it did not seem to significantly hurt the overall performance when changing to a different language with data from different sources (drives or cars). This implies that the tuning might be applicable across various languages and data sources.&#10;3. The discussion mentions that they used parts of the Italian database to train the voice activity detector, while the Italian, Spanish, and English databases were considered development data on which adjustments could be made. In contrast, German and Danish were evaluation data, and eventually, everything was used when evaluating performance. This process might suggest a comprehensive assessment that accounts for the potential impact of language differences and varying data sources.&#10;&#10;However, the given transcript does not provide explicit evidence or results demonstrating that using everything to evaluate performance did not hurt the system's performance when switching to a different language with data from different drives or cars. To make a stronger claim, more specific information on the experimental setup and the results of each evaluation step would be needed." target=" for a v VAD .&#10;Speaker: PhD B&#10;Content: Right ? Um .&#10;Speaker: PhD F&#10;Content: Could you say it again ? What {disfmarker} what exactly did they do ?&#10;Speaker: PhD B&#10;Content: They used some parts of the , um , Italian database to train the voice activity detector , I think . It {disfmarker}&#10;Speaker: Professor E&#10;Content: Yeah . I guess the thing is {disfmarker} Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English {disfmarker} no , Italian and the Finnish and the English ? {disfmarker} were development data&#10;Speaker: PhD B&#10;Content: Yeah . And Spanish , yeah .&#10;Speaker: Professor E&#10;Content: on which you could adjust things . And the {disfmarker} and the German and Danish were the evaluation data .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Professor E&#10;Content: And then when they finally actually evaluated things they used everything .&#10;Speaker: PhD B&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy." target="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Insertions being a symptom of an underlying problem related to the range indicates that an increase in insertions may suggest misconfiguration or malfunction within the system. This is because insertions are indicative of the system not functioning optimally, as they can negatively affect performance and accuracy." target="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions.">
      <data key="d0">1</data>
    </edge>
    <edge source="The ratio of insertions to deletions in the old systems used for dealing with small numbers of substitutions, insertions, and deletions was roughly 1:2. This means that there were typically half as many insertions as deletions." target="In the old systems used for analyzing errors, the ratio of insertions to deletions was roughly 1:2. This means that there were typically half as many insertions as deletions. Both the number of insertions and deletions were typically smaller when compared to substitutions.">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
