<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." />
    <node id=" . What kind of tape drive is it ?&#10;Speaker: Grad F&#10;Content: I dunno but it 's an automatic robot so it 's very convenient .&#10;Speaker: PhD I&#10;Content: Is it {disfmarker} is {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Wh The o the one that we have ?&#10;Speaker: Grad F&#10;Content: You just run a program to restore them .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: The {disfmarker} I mean {disfmarker}&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: But it might interfere with their back - up schedule ,&#10;Speaker: PhD G&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: No , we have s we {disfmarker} Don't we have our own ?&#10;Speaker: PhD I&#10;Content: eh .&#10;Speaker: Professor D&#10;Content: Something wi th that doesn't {disfmarker} that isn't used by the back - up gang ? Don't we have something downstairs ?&#10;" />
    <node id="'t you have this {disfmarker} have a {disfmarker} this conversation with Dave Johnson tha rather than with me ?&#10;Speaker: PhD I&#10;Content: No , no . Because this is {pause} maybe something that we can do without involving Dave , and {disfmarker} and , putting more burden on him . How about we buy , uh {disfmarker} uh {disfmarker} uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all {disfmarker} all , and then {disfmarker} and we don't have to bother this @ @ up ?&#10;Speaker: Grad F&#10;Content: Actually , you know , we could do that just with the tape {disfmarker} with the current tape .&#10;Speaker: PhD I&#10;Content: I dunno what the these tapes {disfmarker} uh , at some point these {disfmarker} I dunno . What kind of tape drive is it ?&#10;Speaker: Grad F&#10;Content: I dunno but it 's an automatic robot so it 's very" />
    <node id="&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Oh . Yeah .&#10;Speaker: PhD I&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Good . It 's good .&#10;Speaker: PhD G&#10;Content: So , who 's gonna do these back - ups ? The people that collect it ?&#10;Speaker: Grad F&#10;Content: Uh Well , I 'll talk to Dave , and {disfmarker} and see what th how {disfmarker} {nonvocalsound} what the best way of doing that is .&#10;Speaker: PhD B&#10;Content: It 's probably gonna n&#10;Speaker: Grad F&#10;Content: There 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .&#10;Speaker: PhD B&#10;Content: Yeah , and we should probably make that part of the procedure for recording the meetings .&#10;Speaker: PhD G&#10;Content: Well , s&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD G&#10;Content: Yeah . That 's what I 'm wondering , if {disfmarker}&#10;Speaker: Grad" />
    <node id="&#10;Speaker: PhD G&#10;Content: Yeah . That 's what I 'm wondering , if {disfmarker}&#10;Speaker: Grad F&#10;Content: Well {pause} we 're g we 're gonna automate that .&#10;Speaker: PhD G&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: My intention is to {pause} do a script that 'll do everything .&#10;Speaker: PhD G&#10;Content: I mean , you don't have to physically put a tape in the drive ?&#10;Speaker: Grad F&#10;Content: No . It 's all tape robot ,&#10;Speaker: PhD G&#10;Content: Or s ? s ? {comment} Oh , OK .&#10;Speaker: Grad F&#10;Content: so you just sit down at your computer and you type a command .&#10;Speaker: PhD G&#10;Content: So it 's just {disfmarker} Oh , OK .&#10;Speaker: PhD I&#10;Content: Yeah , but then you 're effectively using the resources of the back - up system . Or is that a different tape robot ?&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: But not at" />
    <node id="marker} X whatever partition .&#10;Speaker: Grad F&#10;Content: Yeah . That 's not a bad idea .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's basically what I was gonna say , is that a disk is {disfmarker} is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up {pause} issue , {vocalsound} eh , to first order .&#10;Speaker: Grad F&#10;Content: So once it 's on tape {disfmarker}&#10;Speaker: PhD I&#10;Content: Right . Right .&#10;Speaker: Professor D&#10;Content: And we can take care of that by putting it on non - back {pause} up drives and just backing it up once onto this tape .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: I think that 's a good idea .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Oh . Yeah .&#10;Speaker: PhD I&#10;Content: OK .&#10;Speaker" />
    <node id=" Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed - up .&#10;Speaker: Grad F&#10;Content: I 'm much more concerned about the backed - up . The non - backed - up ,&#10;Speaker: PhD B&#10;Content: I haven't looked to see how much of that we have .&#10;Speaker: Grad F&#10;Content: yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .&#10;Speaker: Professor D&#10;Content: Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker}&#10;Speaker: PhD I&#10;Content: You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace .&#10;Speaker: Grad F&#10;Content: Yeah . But that 's {disf" />
    <node id="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." />
    <node id="Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But I I {disfmarker} I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it {disfmarker} it doesn't match anything that we 've described about meetings .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Whereas everything that we talked about them doing at {disfmarker} at UW and so forth really does . They 're actually talking {disfmarker}&#10;Speaker: Grad F&#10;Content: OK . So w so what does that mean for how we are gonna organize things ?&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: You can {disfmarker} you can {disfmarker} Again , as {disfmarker} as I think Andreas was saying , {vocalsound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you" />
    <node id="marker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?&#10;Speaker: Professor D&#10;Content: I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key .&#10;Speaker: Grad F&#10;Content: Well , this has two or more people conversing with each other .&#10;Speaker: Professor D&#10;Content: Nnn , well&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Grad F&#10;Content: They 're just not face to face .&#10;Speaker: PhD G&#10;Content: What if we just give it a {disfmarker} a name like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker" />
    <node id=" bit about {disfmarker} Well , we don't need to do it during this meeting .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We have a little more to discuss . But , uh , we 're {disfmarker} we 're basically ready to do it . And , uh , I have some web pages on ts {comment} more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also .&#10;Speaker: Postdoc A&#10;Content: I 'm sorry , you 've been what ? Showing them ?&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Sharing them .&#10;Speaker: Grad F&#10;Content: Sharing them with the UW folks .&#10;Speaker: Postdoc A&#10;Content: OK . OK .&#10;Speaker: Professor D&#10;Content: OK . Well , maybe uh , since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound}" />
    <node id=" like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker}&#10;Speaker: Grad F&#10;Content: I mean , that was my intention .&#10;Speaker: PhD G&#10;Content: And then later on some people will consider it a meeting and some people won't ,&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: That was my intention . So {disfmarker} so {disfmarker} s {vocalsound} so part of the reason that I wanted to bring this up is , {vocalsound} do we wanna handle it as a special case or do we wanna fold it in ,&#10;Speaker: PhD G&#10;Content: and {disfmarker} Just give it a {vocalsound} title .&#10;Speaker: Postdoc A&#10;Content: Oh .&#10;Speaker: Professor D&#10;Content: I think it is a s&#10;Speaker: Grad F&#10;Content: we give everyone who 's involved as their own user ID , give it session I D" />
    <node id="ound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you know , different directory , it 's called something different , it 's {disfmarker} you know . It is different . You can't just fold it in as if it 's {disfmarker} I mean , digits are different , too . Right ?&#10;Speaker: Grad F&#10;Content: Yeah , but those are folded in ,&#10;Speaker: PhD I&#10;Content: It might also be potentially confusing .&#10;Speaker: Grad F&#10;Content: and it 's just {disfmarker} you just mark the transcripts differently . So {disfmarker} so one option is you fold it in ,&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Grad F&#10;Content: and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .&#10;Speaker: PhD I&#10;Content: Yeah , I th&#10;Speaker: Professor D&#10;Content: Well , I don I wouldn't call reading digits &quot; meetings &quot; . Right ? I mean , we {disfmarker" />
    <node id=" Grad F&#10;Content: Synthesis system .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Um , and then , it goes to a real wizard and they 're evaluating that . And they wanted to use this equipment , and so the w question came up , is {disfmarker} well , here 's some more data . Should this be part of the corpus or not ? And my attitude was yes , because there might be people who are using this corpus for {pause} acoustics , as opposed to just for language . Um , or also for dialogue of various sorts . Um , so it 's not a meeting . Right ? Because it 's two people and they 're not face to face .&#10;Speaker: Professor D&#10;Content: Wait a minute . So , I just wanted to understand it , cuz I {disfmarker} I 'm {disfmarker} uh , hadn't quite followed this process .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Um . So , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , uh" />
    <node id="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." />
    <node id=" think it is a s&#10;Speaker: Grad F&#10;Content: we give everyone who 's involved as their own user ID , give it session I Ds , {vocalsound} let all the tools that handle Meeting Recorder handle it , or do we wanna special case it ? And if we were gonna special case it , who 's gonna do that ?&#10;Speaker: PhD E&#10;Content: So .&#10;Speaker: PhD I&#10;Content: Well , it {disfmarker} it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily .&#10;Speaker: PhD E&#10;Content: It {disfmarker} it {disfmarker} it {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I think {disfmarker}&#10;Speaker: PhD I&#10;Content: But as far as distributing it , we shouldn't label it as part of this meeting corpus .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: We should let it be its own corp&#10;Speaker: Postdoc A&#10;Content: Well it 's {disfmarker} it {disfmarker}" />
    <node id=" talked about getting something together for that , but maybe , uh {disfmarker} maybe we 'll just put that off for now , given that {disfmarker} But I think maybe we should have a {disfmarker} a sub - meeting , I think , uh , probably , uh , Adam and {disfmarker} and , uh , Chuck and me should talk about {disfmarker} should get together and talk about that sometime soon .&#10;Speaker: Grad F&#10;Content: Over a cappuccino tomorrow ?&#10;Speaker: Professor D&#10;Content: Yeah {comment} something like that . Um , uh , you know , maybe {disfmarker} maybe we 'll involve Dan Ellis at some {disfmarker} some level as well .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Um . OK . The {disfmarker} the tea is {disfmarker} is going , so , uh , I suggest we do , uh {disfmarker} uh , a unison .&#10;Speaker: Grad F&#10;Content: A unison digits ?&#10;Speaker: Postdoc A&#10;" />
    <node id="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." />
    <node id="&#10;Content: No , the {disfmarker} the question is do we save one or two far - field channels or all of them ?&#10;Speaker: PhD G&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah .&#10;Speaker: Grad F&#10;Content: I {disfmarker} I see no reason not to do all of them .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .&#10;Speaker: PhD G&#10;Content: Nnn . Yeah .&#10;Speaker: PhD I&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: So , what is the purpose of this recording ?&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: This is to get acoustic and language model training data for SmartKom. OK .&#10;Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system ." />
    <node id="Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system .&#10;Speaker: PhD E&#10;Content: The English system ? Yeah .&#10;Speaker: PhD I&#10;Content: Yeah . Right . Right .&#10;Speaker: PhD B&#10;Content: Where does this {disfmarker} ?&#10;Speaker: Professor D&#10;Content: &#10;Speaker: PhD G&#10;Content: Maybe we can have him vary the microphones , too ,&#10;Speaker: Professor D&#10;Content: Well ,&#10;Speaker: PhD E&#10;Content: B&#10;Speaker: PhD G&#10;Content: or they 're different s speakers .&#10;Speaker: Grad F&#10;Content: Right . So {disfmarker} so {disfmarker} so for their usage , they don't need anything .&#10;Speaker: Professor D&#10;Content: so why not {disfmarker} ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Right ?&#10;Speaker: PhD E&#10;Content: But {disfmarker} but I 'm not sure about the legal aspect of {disf" />
    <node id=" Grad F&#10;Content: OK . So , uh {disfmarker} uh , IBM transcription status ,&#10;Speaker: Professor D&#10;Content: IBM transcription . Uh , what else ?&#10;Speaker: Grad F&#10;Content: &#10;Speaker: Professor D&#10;Content:  What 's SmartKom ? SmartKom ?&#10;Speaker: Grad F&#10;Content: Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .&#10;Speaker: PhD E&#10;Content: The data . The data which we are collecting here .&#10;Speaker: Professor D&#10;Content: What {disfmarker} what {disfmarker} what are we collecting here ?&#10;Speaker: PhD E&#10;Content: Data ?&#10;Speaker: Grad F&#10;Content: So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ?&#10;Speaker: PhD E&#10;Content: The SmartKom data ?&#10;Speaker: Professor D&#10;Content: Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;" />
    <node id=" Right ?&#10;Speaker: PhD E&#10;Content: But {disfmarker} but I 'm not sure about the legal aspect of {disfmarker} of that . Is {disfmarker} is there some contract with SmartKom or something about the data ?&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: What they {disfmarker} or , is {disfmarker} is that our data which we are collecting here ,&#10;Speaker: Professor D&#10;Content: We 've never signed anything that said that we couldn't use anything that we did .&#10;Speaker: PhD E&#10;Content: or {disfmarker} ? OK . OK .&#10;Speaker: PhD I&#10;Content: We weren't supposed to collect any data .&#10;Speaker: PhD E&#10;Content: So . OK .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: So . Yeah , th th that was the question .&#10;Speaker: PhD I&#10;Content: This was all {disfmarker}&#10;Speaker: PhD E&#10;Content: If {disfmarker} if {disfmarker" />
    <node id="Content: and I 'd be interested to know the {disfmarker} wha if you retrain um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: do those actually go down or not ? Because {pause} of {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah . I 'll {disfmarker} can make {disfmarker} an can , like , make a c comparison of {disfmarker} of the old system to the {disfmarker} to the new one , and {pause} then {disfmarker}&#10;Speaker: PhD G&#10;Content: Yeah , just to see if by doing nothing in the modeling of {disfmarker} just having that training data wh what happens .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah . Yep .&#10;Speaker: Professor D&#10;Content: Um another one that we had on Adam 's agenda {pause} that definitely involved you was s something about SmartKom ?&#10;Speaker: Grad F&#10;Content: Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {d" />
    <node id="Speaker: Grad F&#10;Content: Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {disfmarker} Porzel {disfmarker} and the , uh , SmartKom group are collecting some dialogues .&#10;Speaker: PhD I&#10;Content: Porzel . Porzel .&#10;Speaker: Grad F&#10;Content: Basically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . And , uh , they 're doing a travel task . And , uh , it involves starting {disfmarker} I believe starting with a {disfmarker} It 's {disfmarker} it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , uh , {vocalsound} speech generation system .&#10;Speaker: PhD E&#10;Content: Yeah . Actually , it 's changed to a synthesis for {disfmarker} for the first part now .&#10;Speaker: Grad F&#10;Content: Synthesis system .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Um , and" />
    <node id="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." />
    <node id=" and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well , {vocalsound} I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've {disfmarker} {pause} uh , {pause} I , uh , uh , I 've {comment} trained the new one {disfmarker} uh , the new the newest one , {vocalsound} to , um , {vocalsound} use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation .&#10;Speaker: Grad F&#10;Content: Oh , right .&#10;Speaker: Postdoc A&#10;Content: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker}" />
    <node id=" Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: but at the same time we 're benefitting tremendously from the pre - segmentation because {vocalsound} there are huge places where there is just absolutely no activity at all . And , uh , the audio quality is so good {disfmarker}&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: So they can {disfmarker} they can , um , scroll through that pretty quick ?&#10;Speaker: Postdoc A&#10;Content: Yeah . Mm - hmm .&#10;Speaker: PhD B&#10;Content: That 's great .&#10;Speaker: Postdoc A&#10;Content: Yeah . So I think that that 's gonna , also {pause} eh , {comment} you know , speed the efficiency of this part of the process .&#10;Speaker: Professor D&#10;Content: Hmm . OK . Uh , yeah . So , uh {disfmarker} Yeah . So let 's talk about the digits , since they 're not here yet .&#10;Speaker: Grad F&#10;Content: Uh , so , we have a whole bunch of digits that we" />
    <node id=" . What about just actually doing recognition ?&#10;Speaker: Grad F&#10;Content: Well , we {disfmarker} we know what they read , because we have the forms .&#10;Speaker: Professor D&#10;Content: No , they make mistakes .&#10;Speaker: Grad F&#10;Content: Right . But , the point is that we wanna get a set of clean digits .&#10;Speaker: PhD B&#10;Content: You 're talking about as a pre - processing step .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Right , Morgan ?&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: PhD B&#10;Content: Is that what you 're {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Yeah , I 'm {disfmarker} I 'm not quite sure what I 'm talking about . I mean {disfmarker} I {disfmarker} I mean , uh , we 're talking about digits now . And {disfmarker} and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um , {" />
    <node id=": Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;Speaker: Grad F&#10;Content: Uh , reorganization status .&#10;Speaker: Professor D&#10;Content: Reorganization status .&#10;Speaker: Postdoc A&#10;Content: Oh . Files and directories ?&#10;Speaker: Professor D&#10;Content: Files and directories .&#10;Speaker: Grad F&#10;Content: Yep . Uh - huh . Absinthe , which is the multiprocessor UNIX {disfmarker} Linux . I think it was {pause} Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: And then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week .&#10;Speaker: Professor D&#10;Content: Right . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing ." />
    <node id="er}&#10;Speaker: PhD B&#10;Content: and {disfmarker}&#10;Speaker: PhD I&#10;Content: You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable&#10;Speaker: PhD B&#10;Content: Oh .&#10;Speaker: PhD I&#10;Content: because you have a different normalization constants for each model you train .&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: But , still it 's a question {disfmarker}&#10;Speaker: PhD I&#10;Content: So {disfmarker}&#10;Speaker: Professor D&#10;Content: if you have some threshold somewhere in terms of beam search or something ,&#10;Speaker: PhD B&#10;Content: Well , yeah . That 's what I was wondering .&#10;Speaker: Professor D&#10;Content: or {disfmarker} ?&#10;Speaker: PhD I&#10;Content: W yeah . I mean {disfmarker} Uh {disfmarker}&#10;Speaker: PhD B&#10;Content: I mean , if you have one threshold that works well because the range of your" />
    <node id="&#10;Content: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker} it 's interesting .&#10;Speaker: Grad F&#10;Content: I see what you mean . A backchannel , or {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Once in a while it 's a backchannel .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Postdoc A&#10;Content: Sometimes it seems to be , um , similar to the ones that are being picked up .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Postdoc A&#10;Content: And they 're rare events , but you can really go through a meeting very quickly . You just {disfmarker} you just , you know , yo you s you scroll from screen to screen , looking for blips . And , I think that we 're gonna end up with , uh {pause} better coverage of the backchannels ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: but at the same time we 're benefitting tremendously from the pre -" />
    <node id="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." />
    <node id=" , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we can do that .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: We 'll take the opportunity and get another big raft of {disfmarker} {vocalsound} of disk , I guess .&#10;Speaker: Grad F&#10;Content: Yeah . It 's really the back - up issue rather than the file server issue .&#10;Speaker: PhD I&#10;Content: Well , I think {disfmarker} {comment} I think there 's an argument for having {disfmarker} you know , you could use our old file server for {disfmarker} for disks that have data that {pause} is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed .&#10;Speaker: Grad F&#10;Content: Yeah . My understanding is , the issue isn't really the file server .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We could always put more disks on .&#10;Spe" />
    <node id=" server .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We could always put more disks on .&#10;Speaker: PhD I&#10;Content: Yeah . It 's the back it 's the back - up capaci&#10;Speaker: Grad F&#10;Content: It 's the back - up system .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} which is near saturation , apparently . So .&#10;Speaker: PhD B&#10;Content: I think {disfmarker} I think the file server could become an issue as we get a whole bunch more new compute machines .&#10;Speaker: Professor D&#10;Content: Soon .&#10;Speaker: PhD B&#10;Content: And we 've got , you know , fifty machines trying to access data off of Abbott at once .&#10;Speaker: Grad F&#10;Content: Well , we 're alright for now because the network 's so slow .&#10;Speaker: PhD I&#10;Content: I mean , I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {" />
    <node id=" one of our concerns .&#10;Speaker: PhD B&#10;Content: Are we only half ? I thought we were more than that .&#10;Speaker: Grad F&#10;Content: We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .&#10;Speaker: PhD B&#10;Content: Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: And everything else was sorta committed . Uh {disfmarker}&#10;Speaker: Grad F&#10;Content: Were those backed - up or non - backed - up ?&#10;Speaker: PhD B&#10;Content: Those were non - backed - up .&#10;Speaker: PhD E&#10;Content: Non - back - up .&#10;Speaker: Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed -" />
    <node id="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." />
    <node id="} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that we {pause} train . And then , from there we do , um {disfmarker} There 's a lot of , actually {disfmarker} {vocalsound} The way it works , you first train a phonetically - tied mixture model . Um . You do a total of {disfmarker} First you do a context - independent PTM model . Then you switch to a context {disfmarker} You do two iterations of that . Then you do two iterations of {disfmarker} of {disfmarker} of context - dependent phonetically - tied mixtures . And then from that you {disfmarker} you do the {disfmarker} you {disfmarker} you go to a state - clustered model ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: and you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm" />
    <node id=" {disfmarker} so the strategy is to first sort of treat things {pause} with fast turn - around on a smaller training set and then , {vocalsound} when you 've sort of , narrowed it down , you try it on a larger training set .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And so , we haven't done that yet .&#10;Speaker: Professor D&#10;Content: Now the other que related question , though , is {disfmarker} is , {vocalsound} uh , what 's the boot models for these things ?&#10;Speaker: PhD I&#10;Content: Th - th the boot models are trained from scratch . So we compute , um {disfmarker} So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And {disfmarker} and then we train from scratch . So we com we do a , you know , w um {disfmarker} {vocalsound} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that" />
    <node id=" {disfmarker}&#10;Speaker: PhD I&#10;Content: Mm - hmm . Mm - hmm . But there are no boot models , in fact . You {disfmarker} you 're not booting from initial models . You 're booting from initial alignments .&#10;Speaker: Professor D&#10;Content: Which you got from a different feature set .&#10;Speaker: PhD I&#10;Content: That 's correct .&#10;Speaker: Professor D&#10;Content: So , those features look at the data differently , actually .&#10;Speaker: PhD I&#10;Content: Yeah , but {disfmarker}&#10;Speaker: Professor D&#10;Content: I mean , you know , they {disfmarker} they will find boundaries a little differently , though {disfmarker} You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect ,&#10;Speaker: PhD I&#10;Content: But {disfmarker} but {disfmarker} but , what I 'm {disfmarker} what I 'm saying is {disfmarker}&#10;Speaker: Professor D&#10;Content: but {" />
    <node id="&#10;Speaker: PhD I&#10;Content: Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test set , they 're actually a little worse . But that 's beside the point . We 're looking at the discrepancy between the SRI system and the SRI system when trained with ICSI features .&#10;Speaker: PhD G&#10;Content: Right . I 'm just wondering if that {disfmarker} if {disfmarker} if you have any indication of your standard features ,&#10;Speaker: Grad F&#10;Content: What 's {disfmarker} Are the freq ?&#10;Speaker: PhD G&#10;Content: you know , if that 's also different {pause} or in the same direction or not .&#10;Speaker: Professor D&#10;Content: You 're {disfmarker} This is {disfmarker} lemme ask a q more basic que&#10;Speaker: PhD G&#10;Content: Cuz {disfmarker}&#10;Speaker: Professor D&#10;Content: I mean , is this , uh {disfmarker} uh , iterative , Baum - Welch training ?&#10;Speaker" />
    <node id="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names." />
    <node id=" uh , place names and so forth ? Is that {disfmarker} ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Exactly .&#10;Speaker: Professor D&#10;Content: Yeah , great .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: They {disfmarker} they even have a reading list .&#10;Speaker: PhD B&#10;Content: I bet that sounds good , huh ?&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: It 's pretty funny .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: You can do that if you want .&#10;Speaker: PhD B&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: I dunno if you want that .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: Professor" />
    <node id=" idea is just to read each line {pause} with a short pause between lines ,&#10;Speaker: Grad C&#10;Content: Alright .&#10;Speaker: Grad F&#10;Content: not between {disfmarker} And , uh , since we 're in a hurry , we were just gonna read everyone all at once . So , if you sorta plug your ears and read {disfmarker}&#10;Speaker: Grad C&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: So first read the transcript number , and then start reading the {pause} digits .&#10;Speaker: Grad C&#10;Content: Sure .&#10;Speaker: Grad F&#10;Content: OK ? One , two , three .&#10;Speaker: Professor D&#10;Content: OK we 're done .&#10;Speaker: Grad F&#10;Content: And {disfmarker}" />
    <node id="ll j I 'll {disfmarker} just let 's make sure everything works on the females . &quot; And the error rate {disfmarker} you know , there was a three percent difference .&#10;Speaker: Professor D&#10;Content: Oh . Uh - huh .&#10;Speaker: PhD I&#10;Content: So ,&#10;Speaker: PhD G&#10;Content: Is there less training data ?&#10;Speaker: PhD I&#10;Content: uh {disfmarker}&#10;Speaker: PhD G&#10;Content: I mean , we don&#10;Speaker: PhD I&#10;Content: No , actually there 's more training data .&#10;Speaker: PhD G&#10;Content: This is on just digits ?&#10;Speaker: Professor D&#10;Content: No .&#10;Speaker: PhD I&#10;Content: No , no .&#10;Speaker: Grad F&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Hub - five .&#10;Speaker: Grad F&#10;Content: It 's , uh , Swi&#10;Speaker: PhD G&#10;Content: Oh , sorry . OK . This is on {disfmarker}&#10;Speaker: PhD I&#10;Content: This is Hub - five .&#10;Speaker" />
    <node id="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." />
    <node id="Speaker: PhD G&#10;Content: I mean , usually they 're {disfmarker}&#10;Speaker: Grad F&#10;Content: well , not forever , they 've been finding even those degrade .&#10;Speaker: Professor D&#10;Content: Oh , I see .&#10;Speaker: Grad F&#10;Content: But , uh , the burned ones {disfmarker} I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year .&#10;Speaker: PhD G&#10;Content: That 's what I {disfmarker}&#10;Speaker: Grad F&#10;Content: On the average , it 'll probably be three or four years . But , uh {disfmarker} I {disfmarker} I {disfmarker} you don't want to per p have your only copy on a media that fails .&#10;Speaker: PhD I&#10;Content: Mmm .&#10;Speaker: Grad F&#10;Content: And they do . Um , if you have them professionally pressed , y you know , they 're good for decades .&#10;Speaker: PhD I&#10;Content: So how about {disfmarker} ? So" />
    <node id=" You can talk to the computer . &quot;&#10;Speaker: PhD B&#10;Content: It 's a lot more believable , too ,&#10;Speaker: Grad F&#10;Content: &quot; No ! &quot;&#10;Speaker: PhD B&#10;Content: if you tell them that they 're {disfmarker} the computer part is running on a Windows machine . And the whole breakdown thing kinda makes sense .&#10;Speaker: PhD I&#10;Content: O Just {disfmarker} just reboot it .&#10;Speaker: Grad F&#10;Content: Abort {disfmarker} abort , retry , fail ?&#10;Speaker: PhD G&#10;Content: So did they actually save the far - field {pause} data ?&#10;Speaker: PhD E&#10;Content: Yes .&#10;Speaker: Grad F&#10;Content: Well , this was {disfmarker} this was the question .&#10;Speaker: PhD G&#10;Content: Cuz at first they weren't {disfmarker} they weren't sa&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} so they were saying they were not going to ,&#10;Speaker: PhD E&#10;Content" />
    <node id=" , y you know , they 're good for decades .&#10;Speaker: PhD I&#10;Content: So how about {disfmarker} ? So {disfmarker} so how about putting them on that plus , like on a {disfmarker} on {disfmarker} on DAT or some other medium that isn't risky ?&#10;Speaker: Grad F&#10;Content: I think th um , we can already put them on tape . And the tape is hi is very reliable .&#10;Speaker: PhD I&#10;Content: OK . Mm - hmm .&#10;Speaker: Grad F&#10;Content: So the {disfmarker} the only issue is then {pause} if we need access to them . So that 's fine f if we don't need access to them .&#10;Speaker: PhD I&#10;Content: Right . Well , if {disfmarker} if {disfmarker} if you {disfmarker} if they last {disfmarker} Say , they actually last , like , five years , huh , in {disfmarker} in the typical case , and {disfmarker} and occasionally you might need to recreate one , and" />
    <node id="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." />
    <node id=" . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm . We have never seen big differences . Once I thought &quot; oh , I can {disfmarker} Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . &quot; Made no difference whatsoever . It 's {disfmarker} I think it 's {disfmarker} eh , i&#10;Speaker: Professor D&#10;Content: Right . Well , mis for making things better .&#10;Speaker: PhD I&#10;Content: the boot models are recur&#10;Speaker: Professor D&#10;Content: Yeah . But , this for making things worse . This it migh Th - the thought is {disfmarker} is {disfmarker} is possible {disfmarker} another possible {pause} partial cause is if the boot models {vocalsound} used a comple used a different feature set , that {disfmarker}&#10;Speaker: PhD I&#10;Content: Mm - hmm . Mm - hmm . But there are no boot" />
    <node id=" years in the system .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: And , the result in the end was no different .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: So , what I 'm saying is , the exact nature of these boot alignments is probably not {pause} a big factor in the quality of the final models .&#10;Speaker: Professor D&#10;Content: Yeah , maybe not . But {pause} it {disfmarker} it {disfmarker} I st still see it as {disfmarker} I mean , {vocalsound} there 's {disfmarker} there 's a history to this , too ,&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: but I {disfmarker} uh , I don't wanna go into ,&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: but {disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause}" />
    <node id=" I 'm {disfmarker} what I 'm saying is {disfmarker}&#10;Speaker: Professor D&#10;Content: but {disfmarker}&#10;Speaker: PhD I&#10;Content: So , we e w f w For a long time we had used boot alignments that had been trained with a {disfmarker} {vocalsound} with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD I&#10;Content: And with a dict different dictionary {disfmarker} with a considerably different dictionary , which was much less detailed and much less well - suited .&#10;Speaker: Professor D&#10;Content: Mm - hmm . Yeah .&#10;Speaker: PhD I&#10;Content: And so , {vocalsound} then we switched to new boot alignments , which {disfmarker} which now had the benefit of all these improvements that we 've made over two years in the system .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: And , the result in the end" />
    <node id="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt." />
    <node id=" , ho&#10;Speaker: Grad F&#10;Content: What {disfmarker} ?&#10;Speaker: Professor D&#10;Content: um , I 'm sorry {disfmarker} in each case how do you determine , you know , the {disfmarker} the usual {pause} fudge factors ? The , uh {disfmarker} {vocalsound} the , uh , language , uh , scaling , acoustic scaling , uh , uh {disfmarker}&#10;Speaker: PhD I&#10;Content: Um {pause} I uh {disfmarker} {comment} I 'm actually re - optimizing them . Although that hasn't shown to make {pause} a big difference .&#10;Speaker: Professor D&#10;Content: OK . And the pru the question he was asking at one point about pruning , uh {disfmarker} Remember that one ?&#10;Speaker: PhD I&#10;Content: Pruning {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Well , he was {disfmarker} he 's {disfmarker} it looked like the probabil at one point he was looking at the probabilities he was getting out {disf" />
    <node id="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks." />
    <node id=" F&#10;Content: NW archive .&#10;Speaker: Postdoc A&#10;Content: Yep {comment} {vocalsound} And if you did that during the day it would never make it to the nightly back - ups .&#10;Speaker: Grad F&#10;Content: That 's what it is .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: And then there wouldn't be this extra load .&#10;Speaker: PhD I&#10;Content: Well , it {disfmarker} if he {disfmarker} you have to put the data on a {disfmarker} on a non - backed - up disk to begin with .&#10;Speaker: Postdoc A&#10;Content: Well , but you can have it NW archive to {disfmarker} you can have , {vocalsound} uh , a non - backed - up disk NW archived ,&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: So that {disfmarker} so that {disfmarker} otherwise you don't {disfmarker} you {disfmarker}" />
    <node id="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom." />
    <node id="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings." />
    <node id="Speaker: PhD E&#10;Content: Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {disfmarker} which I 'm using , and , {vocalsound} it 's {disfmarker} {vocalsound} before it was twenty minutes of one meeting .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: So {disfmarker} should {comment} be a little bit better .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Great .&#10;Speaker: PhD I&#10;Content: That won't be perfect {disfmarker} the alignments aren't perfect ,&#10;Speaker: PhD E&#10;Content: Yeah . But {disfmarker}&#10;Speaker: PhD I&#10;Content: but , um , it 's probably still better to have all this extra data , than {disfmarker}&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah . Yep .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;" />
    <node id="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device." />
    <node id="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study." />
    <node id="disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause} that it {disfmarker} the data is being viewed in a certain way , uh , that a beginning is here rather than there and so forth ,&#10;Speaker: PhD I&#10;Content: Yeah . Right .&#10;Speaker: Professor D&#10;Content: because the actual signal - processing you 're doing is slightly different .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: But , {vocalsound} it 's {disfmarker} it 's {disfmarker} that 's probably not it .&#10;Speaker: PhD I&#10;Content: Yeah . Anyway , I {disfmarker} I {disfmarker} I should really reserve , uh , any conclusions until we 've done it on the large training set , um , and until we 've seen the results with the {disfmarker} with the VTL in training .&#10;Speaker: Professor D&#10;Content: Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast" />
    <node id=" s more if you do it on both training and test .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And so the {disfmarker} It now helps , if you do it only on the test , and I 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll {disfmarker} we 'll have , hopefully , even better results . So {disfmarker} But there 's {disfmarker} It looks like there will still be some difference , maybe between one and two percent , um , for the females .&#10;Speaker: Professor D&#10;Content: Huh .&#10;Speaker: PhD I&#10;Content: And so , um , you know , I 'm open to suggestions .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: PhD I&#10;Content: And it is true that the , uh {disfmarker} that the {disfmarker} {vocalsound} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL ,&#10;Spe" />
    <node id="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." />
    <node id=" digits , since they 're not here yet .&#10;Speaker: Grad F&#10;Content: Uh , so , we have a whole bunch of digits that we 've read and we have the forms and so on , um , but only a small number of that ha well , not a small number {disfmarker} only a subset of that has been transcribed . And so we need to decide what we wanna do . And , uh , Liz and Andreas {disfmarker} actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . And , again , I don't think we 'll be able to do with that alone , because , um , sometimes people correct themselves and things like that . But {disfmarker} so , I was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing .&#10;Speaker: Professor D&#10;Content: Well , forced alignment would be one thing . What about just actually doing recognition ?&#10;Speaker: Grad F&#10;Content: Well , we {disfmarker} we know what they read ," />
    <node id=" Grad F&#10;Content: and don't bother actually computing the di writing down the digits .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: That 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later .&#10;Speaker: Grad F&#10;Content: Yep . And then I wanted to talk about {disfmarker} but as I said I {disfmarker} we may not have time {disfmarker} what we should do about digits . We have a whole pile of digits that haven't been transcribed .&#10;Speaker: Professor D&#10;Content: Le - let 's talk about it , because that 's {disfmarker} that 's something that I {disfmarker} I know Andreas is less interested in than Liz is ,&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: so , you know . It 's good {disfmarker}&#10;Speaker: Grad F&#10;Content: Do we have anything else to say about transcription ? About IBM stuff ?&#10;Speaker: PhD B&#10;Content: Uh ," />
    <node id=" {disfmarker} uh , a unison .&#10;Speaker: Grad F&#10;Content: A unison digits ?&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Yeah . Gets our {disfmarker}&#10;Speaker: Grad F&#10;Content: Which is gonna be a little hard for a couple people because we have different digits forms .&#10;Speaker: PhD E&#10;Content: Oops .&#10;Speaker: Grad F&#10;Content: We have a {disfmarker} I found a couple of old ones .&#10;Speaker: Professor D&#10;Content: Oh .&#10;Speaker: Grad H&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: Well , that 'll be interesting . So , uh {disfmarker}&#10;Speaker: Grad F&#10;Content: Have you done digits before ?&#10;Speaker: Professor D&#10;Content: No .&#10;Speaker: Grad C&#10;Content: I haven't done it .&#10;Speaker: Grad F&#10;Content: OK . So , uh , the idea is just to read each line {pause} with a short pause between lines ,&#10;Speaker: Grad C&#10;Content: Alright .&#10;Speaker:" />
    <node id="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt." />
    <node id="aker: Grad F&#10;Content: Do we have anything else to say about transcription ? About IBM stuff ?&#10;Speaker: PhD B&#10;Content: Uh , Brian {disfmarker} I {disfmarker} I {vocalsound} sent bresset {disfmarker} {vocalsound} {vocalsound} sent Brian a message about {pause} {vocalsound} the meeting and I haven't heard back yet . So . I g hope he got it and hopefully he 's {disfmarker}&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD B&#10;Content: maybe he 's gone , I dunno . He didn't even reply to my message . So . I should probably ping him just to make sure that he got it . &#10;Speaker: Grad F&#10;Content: Alright . So , we have a whole bunch of digits , if we wanna move on to digits .&#10;Speaker: Professor D&#10;Content: Actually , maybe I {disfmarker} One {disfmarker} one relate more related thing in transcription . So that 's the IBM stuff . We 've got" />
    <node id="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation." />
    <node id="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so." />
    <node id=" are every night , you can recycle the backed - up diskspace .&#10;Speaker: Grad F&#10;Content: Yeah . But that 's {disfmarker} that 's {disfmarker} {pause} that 's risky .&#10;Speaker: Professor D&#10;Content: Yeah . You really shouldn't be saying {disfmarker}&#10;Speaker: Grad F&#10;Content: Mmm . Mmm .&#10;Speaker: PhD I&#10;Content: I didn't say that .&#10;Speaker: Grad F&#10;Content: Yeah , that 's right .&#10;Speaker: PhD I&#10;Content: I didn't say that .&#10;Speaker: Grad F&#10;Content: Beep that out .&#10;Speaker: Professor D&#10;Content: Da - we had allowed Dave to listen to these {disfmarker} {vocalsound} these , {vocalsound} uh , recordings .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Um {disfmarker} {vocalsound} Yeah , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we" />
    <node id=" @ i if you go to Dave , and {disfmarker} and {disfmarker} and ask him &quot; can I use your tape robot ? &quot; , he will say , &quot; well {pause} that 's gonna screw up our back - up operation . &quot;&#10;Speaker: Grad F&#10;Content: No , we won't . He 'll say &quot; if {disfmarker} if that means {pause} that it 's not gonna be backed - up standardly , great . &quot;&#10;Speaker: Professor D&#10;Content: He - I {disfmarker} Dave has {disfmarker} has promoted this in the past . So I don't think he 's actually against it .&#10;Speaker: Grad F&#10;Content: Yeah . It 's {disfmarker} it 's definitely no problem .&#10;Speaker: PhD I&#10;Content: Oh , OK . Alright .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Alright .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD I&#10;Content: Good .&#10;Speaker: PhD G&#10;Content: What about if the times overlap with the normal back" />
    <node id="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule." />
    <node id="aker: Professor D&#10;Content: I mean , yeah , all the L&#10;Speaker: Grad F&#10;Content: I {disfmarker} I don't know many people who do it on CD . I mean , they 're {disfmarker} the most {disfmarker} fo&#10;Speaker: Professor D&#10;Content: LDC - all the LDC distributions are on CD - ROM .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: They 're on CD , but they 're not {disfmarker} tha that 's not the only source .&#10;Speaker: PhD G&#10;Content: Like {disfmarker}&#10;Speaker: Grad F&#10;Content: They have them on disk . And they burn new ones every once in a while . But if you go {disfmarker} {vocalsound} if you go k&#10;Speaker: PhD I&#10;Content: But , you know , we have {disfmarker}&#10;Speaker: PhD G&#10;Content: But we have like thirty {pause} you know , from {pause} ten years ago ?&#10;Speaker: Professor D&#10;Content: We have all" />
    <node id="aker: Professor D&#10;Content: Well , I don I wouldn't call reading digits &quot; meetings &quot; . Right ? I mean , we {disfmarker} we {disfmarker} we were doing {disfmarker}&#10;Speaker: Grad F&#10;Content: Well , but {disfmarker} but , {vocalsound} I put it under the same directory tree .&#10;Speaker: Professor D&#10;Content: Well {disfmarker}&#10;Speaker: Grad F&#10;Content: You know , it 's in &quot; user doctor speech data MR &quot; .&#10;Speaker: PhD G&#10;Content: Can we just have a directory called , like , &quot; other stuff &quot; ?&#10;Speaker: Grad F&#10;Content: Other .&#10;Speaker: PhD G&#10;Content: And {disfmarker} Well {disfmarker} or , I dunno .&#10;Speaker: Professor D&#10;Content: I mean , I don't care what directory tree you have it under .&#10;Speaker: PhD G&#10;Content: And {disfmarker} {vocalsound} and just , um , store it there .&#10;Speaker: Professor D&#10;Content: Right ? I mean that 's" />
    <node id="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences." />
    <node id=" , sorry . OK . This is on {disfmarker}&#10;Speaker: PhD I&#10;Content: This is Hub - five .&#10;Speaker: PhD G&#10;Content: Oh , OK .&#10;Speaker: Grad F&#10;Content: Hub - five . Yeah .&#10;Speaker: PhD I&#10;Content: Yeah . Um , and the test data is CallHome and Switchboard . So , uh {disfmarker} so then {pause} um {disfmarker} Oh , and plus the {disfmarker} the vocal tract {pause} length normalization didn't {disfmarker} actually made things worse . So something 's really seriously wrong . So {disfmarker} Um {disfmarker}&#10;Speaker: Professor D&#10;Content: Aha ! OK .&#10;Speaker: PhD I&#10;Content: So {disfmarker} So {disfmarker}&#10;Speaker: Professor D&#10;Content: So {disfmarker} but you see , now , between {disfmarker} between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what" />
    <node id=" the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what you were using before was scaling factors that were just from the {disfmarker} the m the {pause} SRI front - end . And that worked {disfmarker} that worked fine .&#10;Speaker: PhD I&#10;Content: That 's true . Yeah .&#10;Speaker: Professor D&#10;Content: Uh , but now you 're looking over a larger range and it may not be so fine .&#10;Speaker: PhD I&#10;Content: Well , um {disfmarker} So {disfmarker} I just {disfmarker} d so the one thing that I then tried was to put in the low - pass filter , which we have in the {disfmarker} So , most {disfmarker} most Hub - five systems actually band - limit the {disfmarker} uh , at about , uh , thirty - seven hundred , um , hertz .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: Although , you know , normally , I mean" />
    <node id=" .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: Although , you know , normally , I mean , the channel goes to four {disfmarker} four thousand . Right ? So , um {disfmarker} And that actually helped , uh {disfmarker} uh , a little bit .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: Um {pause} and it didn't hurt on the males either . So , um {disfmarker} And I 'm now , uh , trying the {disfmarker} Oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . So , you can do vocal tract length normalization on the test data only or on both the training and the test .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content:" />
    <node id="} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL ,&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: because if you don't do VTL in both systems , uh , you know , the {disfmarker} the females are considerably worse in the {disfmarker} with the PLP features .&#10;Speaker: Professor D&#10;Content: No {disfmarker} no . I {disfmarker} I remember that .&#10;Speaker: Grad F&#10;Content: It 's much worse . Yeah .&#10;Speaker: PhD I&#10;Content: So there must be some {disfmarker} something else going on .&#10;Speaker: PhD G&#10;Content: Well , what 's the standard {disfmarker} ? Yeah , so I thought the performance was actually a little better on females than males .&#10;Speaker: Grad F&#10;Content: That 's what I thought , too .&#10;Speaker: PhD I&#10;Content: Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test" />
    <node id=": So {disfmarker} {comment} so , when {disfmarker} So I {disfmarker} I had {disfmarker} I ha&#10;Speaker: Grad F&#10;Content: That was a quick response .&#10;Speaker: PhD I&#10;Content: So , we had reached the point where {disfmarker}&#10;Speaker: PhD G&#10;Content: I 'm well rehearsed .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: we had reached the point where , {comment} um , on the male portion of the {pause} development set , the , um {disfmarker} or one of the development sets , I should say {disfmarker} {vocalsound} the , um {disfmarker} the male error rate with , uh , ICSI PLP features was pretty much identical with , uh , SRI features . which are {pause} MFCC . So , um , then I thought , &quot; Oh , great . I 'll j I 'll {disfmarker} just let 's make sure everything works on the females . &quot; And the error rate {disfmark" />
    <node id="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded." />
    <node id=" is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got {vocalsound} {vocalsound} a speedup roughly proportional to the number of processors times the clock cycle .&#10;Speaker: PhD I&#10;Content: Oh .&#10;Speaker: Grad F&#10;Content: So , that 's pretty good .&#10;Speaker: PhD I&#10;Content: Oh ! Cool .&#10;Speaker: Grad F&#10;Content: Um , I 'm in the process of doing it for Quicknet , but there 's something going wrong and it 's about half the speed that I was estimating it should be , and I 'm not sure why .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: But I 'll keep working on it . But the {disfmarker} what it means is that it 's likely that for net training and forward passes , we 'll {disfmarker} Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors .&#10;Speaker: PhD I&#10;Content: A few more processors ?" />
    <node id=" .&#10;Speaker: Professor D&#10;Content: Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast News data or something else that actually has {disfmarker} has some noisy {disfmarker} {vocalsound} noisy components , so we can see if any conclusions we come to holds {vocalsound} across {pause} different data .&#10;Speaker: PhD I&#10;Content: So . Yeah . Right .&#10;Speaker: Professor D&#10;Content: Uh {disfmarker}&#10;Speaker: PhD I&#10;Content: And , uh , with this , I have to leave .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Grad H&#10;Content: Hmm !&#10;Speaker: Professor D&#10;Content: So , is there something quick about Absinthe {pause} that you {disfmarker} ?&#10;Speaker: PhD I&#10;Content: With this said .&#10;Speaker: Grad F&#10;Content: Uh . Just what we were talking about before , which is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got" />
    <node id=" 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing .&#10;Speaker: PhD E&#10;Content: And also the SmartKom thing should b&#10;Speaker: Professor D&#10;Content: SmartKom also , Andreas . Absinthe , I think also he has sort of been involved in a lot of those things .&#10;Speaker: Grad F&#10;Content: At least ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: yeah , he 'll t he 'll probably be interested .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: But .&#10;Speaker: Professor D&#10;Content: Um So , I mean , I think they 'll be inter I 'll be interested in all this , but {disfmarker} but , uh , probably , if we had to pick something {pause} that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status , or {disfmarker} ?&#10;Speaker: Grad F&#10;Content: Yeah ." />
    <node id=" . We {disfmarker} we sorta spot - checked it .&#10;Speaker: PhD B&#10;Content: I listened to {pause} probably , uh , five or ten minutes of it from the beginning .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Oh , really ?&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: PhD B&#10;Content: And {disfmarker}&#10;Speaker: Grad F&#10;Content: I sorta spot - checked here and there and it sounded pretty good . So . I think it 'll work .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: And , uh , we 'll just hafta see what we get back from them . Uh {disfmarker}&#10;Speaker: PhD B&#10;Content: And the main thing will be if we can align what they give us with what we sent them . I mean , that 's the crucial part .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: And I think we 'll be able to do that" />
    <node id="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation." />
    <node id=": PhD I&#10;Content: Um , so , {nonvocalsound} uh , we had a discussion {disfmarker} Don and Liz and I had discussion last week about how to proceed with , uh , you know , with Don 's work ,&#10;Speaker: PhD E&#10;Content: Ch&#10;Speaker: PhD I&#10;Content: and {disfmarker} {vocalsound} and {disfmarker} and , uh , one of the obvious things that occur to us was that we 're {disfmarker} since we now have Thilo 's segmenter and it works , you know , amazingly well , {vocalsound} um , we should actually basically re - evaluate the recognition , um , results using {disfmarker} you know , without cheating on the segmentations .&#10;Speaker: PhD E&#10;Content: So {disfmarker}&#10;Speaker: PhD I&#10;Content: And , that should be fairly {disfmarker}&#10;Speaker: PhD E&#10;Content: And how do we find the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ?&#10;" />
    <node id=" for {disfmarker} for the references and for {disfmarker} for the hypothesis ,&#10;Speaker: PhD I&#10;Content: So , we ha Yeah . Right .&#10;Speaker: PhD E&#10;Content: and {disfmarker} Yeah , OK .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: PhD G&#10;Content: Maybe the {pause} start of your speech and the end of it ,&#10;Speaker: PhD I&#10;Content: So do&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: or stuff like that .&#10;Speaker: PhD I&#10;Content: Right . It does time - constrained word - alignment .&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD I&#10;Content: So . So that should be possible . I mean that shouldn't be a problem . Uh , so that was the one thing , and the other was that , um {disfmarker} What was the other problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector .&#10;Speaker:" />
    <node id=" problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Um , so that we could use , uh {disfmarker} you know there wouldn't be so much hand {vocalsound} labelling needed to , uh {disfmarker} to generate training data for {disfmarker} for the speech detector .&#10;Speaker: PhD E&#10;Content: Yeah . I 'm just in progress of {disfmarker} of doing that . So .&#10;Speaker: PhD I&#10;Content: And I think you 're in the process of doing that .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: So , you can {disfmarker} {comment} you can {disfmarker}&#10;Speaker: PhD B&#10;Content: It 'll give you a lot more data , too . Won't it ?&#10;Speaker: PhD E&#10;Content: Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {" />
    <node id=" the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ?&#10;Speaker: PhD I&#10;Content: Oh , OK . So , there 's actually {disfmarker}&#10;Speaker: PhD E&#10;Content: It 's not that {disfmarker}&#10;Speaker: PhD I&#10;Content: Why do you ask ?&#10;Speaker: Grad F&#10;Content: I could {disfmarker}&#10;Speaker: PhD I&#10;Content: No , actually , um , NIST has , um m a fairly sophisticated scoring program {vocalsound} that you can give a , um {disfmarker} {vocalsound} a time ,&#10;Speaker: Grad F&#10;Content: Hand ones .&#10;Speaker: PhD G&#10;Content: Well {disfmarker}&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD I&#10;Content: uh {disfmarker} You know , you basically just give two {pause} time - marked sequences of words , and it computes the um {disfmarker} the , {comment} uh {disfmarker}" />
    <node id="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it." />
    <node id="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." />
    <node id=" .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} I mean it {disfmarker} sure , there {disfmarker} there might be a place where it 's &quot; beep seven {pause} beep eight {pause} beep {pause} eight {pause} beep &quot; . But , you know , they {disfmarker} they 're {disfmarker} they 're gonna macros for inserting the beep marks . And so , I {disfmarker} I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem .&#10;Speaker: Professor D&#10;Content: OK . Well , I {disfmarker} I {disfmarker} I dunno , I {disfmarker} I think that that 's {disfmarker} if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is {disfmarker} needs to be much less elaborate for digits than for other stuff .&#10;Speaker:" />
    <node id=": PhD E&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Grad F&#10;Content: Well , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that ,&#10;Speaker: PhD B&#10;Content: Yeah . That 's what I thought .&#10;Speaker: Grad F&#10;Content: so .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: I it 's probably just , you know , mmm , somehow the audio {pause} device gets hung for a second ,&#10;Speaker: PhD E&#10;Content: Yeah . Some latency or something .&#10;Speaker: Grad F&#10;Content: Hiccups .&#10;Speaker: PhD E&#10;Content: Yeah ?&#10;Speaker: Postdoc A&#10;Content: As long as they have one number , and they know that there 's only one beep maximum {vocalsound} that goes with that number .&#10;Speaker: PhD B&#10;Content: or {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Right .&#10;" />
    <node id=" .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: And I think we 'll be able to do that at {disfmarker} with this new beep format .&#10;Speaker: Grad F&#10;Content: Yep . Well , I think it 's also they are much less likely to d have errors .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: I mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or {disfmarker} and they put in extraneous beeps .&#10;Speaker: PhD B&#10;Content: Right . Yeah .&#10;Speaker: Grad F&#10;Content: And with the numbers there , it 's much less likely .&#10;Speaker: PhD B&#10;Content: Yeah , one interesting note is {disfmarker} uh , or problem {disfmarker} I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @ {comment} uh , like a beep sounds like" />
    <node id=" since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh&#10;Speaker: Grad F&#10;Content: OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes &quot; beep one beep &quot; and then the phrase , and then &quot; beep two beep &quot; and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .&#10;Speaker: PhD E&#10;Content: And we have done that on the {pause} automatic segmentations .&#10;Speaker: Grad F&#10;Content: And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it .&#10;Speaker: PhD B&#10;Content: I listened to {pause} probably" />
    <node id=" or {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Right .&#10;Speaker: Grad F&#10;Content: Yeah . The only {disfmarker} the only part that might be confusing is when Chuck is reading digits .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Postdoc A&#10;Content: Well , you know , actually , are we having them {disfmarker}&#10;Speaker: PhD B&#10;Content: So {vocalsound} th&#10;Speaker: Grad F&#10;Content: &quot; Seven four eight beep seven beep {vocalsound} eight three two &quot; .&#10;Speaker: Postdoc A&#10;Content: Yeah , but are we having them do digits ?&#10;Speaker: Grad F&#10;Content: Yes . Because , uh , we don't {disfmarker} we didn't {disfmarker} In order to cut them out we 'd have to listen to it .&#10;Speaker: PhD B&#10;Content: We {disfmarker} we didn't cut those out .&#10;Speaker: PhD E&#10;Content" />
    <node id="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording." />
    <node id="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors." />
    <node id="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions." />
    <node id=" some people , or use the transcribers to do it . We could let IBM transcribe it . You know , they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . Um , or we could try some automated methods .&#10;Speaker: Professor D&#10;Content: Well {disfmarker}&#10;Speaker: Grad F&#10;Content: And my {disfmarker} my tendency right now is , well , if IBM comes back with this meeting and the transcript is good , just let them do it .&#10;Speaker: Professor D&#10;Content: Yeah , it 's {disfmarker} Y you raised a point , kind of , uh , euphemistically {disfmarker} but , I mean , m maybe it is a serious problem . Ho - what will they do when they go {disfmarker} hear &quot; beep {pause} seven {pause} beep {pause} seven three five two &quot; {disfmarker} I mean , {vocalsound} you think they 'll {disfmarker} we 'll get {disfmarker} ?&#10;Speaker: Grad F&#10;Content: It 's pretty distinct .&#10;" />
    <node id="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure." />
    <node id=" I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {disfmarker} What about putting the stuff on , like , C - CD - ROM or DVD or something ?&#10;Speaker: Grad F&#10;Content: Yeah . That was me . I was the one who said it was not reliable . The - they {disfmarker} they wear out .&#10;Speaker: PhD I&#10;Content: OK . Oh , OK .&#10;Speaker: Grad F&#10;Content: Yeah . The {disfmarker} the {disfmarker} th&#10;Speaker: PhD I&#10;Content: But they wear out just from sitting on the shelf ?&#10;Speaker: Grad F&#10;Content: Yep . Absolutely .&#10;Speaker: PhD I&#10;Content: Or from being {pause} read and read ?&#10;Speaker: Grad F&#10;Content: No . Read and write don't hurt them too much unless you scratch them .&#10;Speaker: PhD I&#10;Content: Oh , OK .&#10;Speaker: Grad F&#10;Content: But the r the write once , and the read - writes , don't last . So you don't" />
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target=" . What kind of tape drive is it ?&#10;Speaker: Grad F&#10;Content: I dunno but it 's an automatic robot so it 's very convenient .&#10;Speaker: PhD I&#10;Content: Is it {disfmarker} is {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Wh The o the one that we have ?&#10;Speaker: Grad F&#10;Content: You just run a program to restore them .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: The {disfmarker} I mean {disfmarker}&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: But it might interfere with their back - up schedule ,&#10;Speaker: PhD G&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: No , we have s we {disfmarker} Don't we have our own ?&#10;Speaker: PhD I&#10;Content: eh .&#10;Speaker: Professor D&#10;Content: Something wi th that doesn't {disfmarker} that isn't used by the back - up gang ? Don't we have something downstairs ?&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="'t you have this {disfmarker} have a {disfmarker} this conversation with Dave Johnson tha rather than with me ?&#10;Speaker: PhD I&#10;Content: No , no . Because this is {pause} maybe something that we can do without involving Dave , and {disfmarker} and , putting more burden on him . How about we buy , uh {disfmarker} uh {disfmarker} uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all {disfmarker} all , and then {disfmarker} and we don't have to bother this @ @ up ?&#10;Speaker: Grad F&#10;Content: Actually , you know , we could do that just with the tape {disfmarker} with the current tape .&#10;Speaker: PhD I&#10;Content: I dunno what the these tapes {disfmarker} uh , at some point these {disfmarker} I dunno . What kind of tape drive is it ?&#10;Speaker: Grad F&#10;Content: I dunno but it 's an automatic robot so it 's very">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Oh . Yeah .&#10;Speaker: PhD I&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Good . It 's good .&#10;Speaker: PhD G&#10;Content: So , who 's gonna do these back - ups ? The people that collect it ?&#10;Speaker: Grad F&#10;Content: Uh Well , I 'll talk to Dave , and {disfmarker} and see what th how {disfmarker} {nonvocalsound} what the best way of doing that is .&#10;Speaker: PhD B&#10;Content: It 's probably gonna n&#10;Speaker: Grad F&#10;Content: There 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .&#10;Speaker: PhD B&#10;Content: Yeah , and we should probably make that part of the procedure for recording the meetings .&#10;Speaker: PhD G&#10;Content: Well , s&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD G&#10;Content: Yeah . That 's what I 'm wondering , if {disfmarker}&#10;Speaker: Grad">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="&#10;Speaker: PhD G&#10;Content: Yeah . That 's what I 'm wondering , if {disfmarker}&#10;Speaker: Grad F&#10;Content: Well {pause} we 're g we 're gonna automate that .&#10;Speaker: PhD G&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: My intention is to {pause} do a script that 'll do everything .&#10;Speaker: PhD G&#10;Content: I mean , you don't have to physically put a tape in the drive ?&#10;Speaker: Grad F&#10;Content: No . It 's all tape robot ,&#10;Speaker: PhD G&#10;Content: Or s ? s ? {comment} Oh , OK .&#10;Speaker: Grad F&#10;Content: so you just sit down at your computer and you type a command .&#10;Speaker: PhD G&#10;Content: So it 's just {disfmarker} Oh , OK .&#10;Speaker: PhD I&#10;Content: Yeah , but then you 're effectively using the resources of the back - up system . Or is that a different tape robot ?&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: But not at">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="marker} X whatever partition .&#10;Speaker: Grad F&#10;Content: Yeah . That 's not a bad idea .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's basically what I was gonna say , is that a disk is {disfmarker} is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up {pause} issue , {vocalsound} eh , to first order .&#10;Speaker: Grad F&#10;Content: So once it 's on tape {disfmarker}&#10;Speaker: PhD I&#10;Content: Right . Right .&#10;Speaker: Professor D&#10;Content: And we can take care of that by putting it on non - back {pause} up drives and just backing it up once onto this tape .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: I think that 's a good idea .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Oh . Yeah .&#10;Speaker: PhD I&#10;Content: OK .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target=" Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed - up .&#10;Speaker: Grad F&#10;Content: I 'm much more concerned about the backed - up . The non - backed - up ,&#10;Speaker: PhD B&#10;Content: I haven't looked to see how much of that we have .&#10;Speaker: Grad F&#10;Content: yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .&#10;Speaker: Professor D&#10;Content: Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker}&#10;Speaker: PhD I&#10;Content: You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace .&#10;Speaker: Grad F&#10;Content: Yeah . But that 's {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified. They refer to it as &quot;the one that we have&quot; and &quot;it&quot; without mentioning the manufacturer or model. It is an automatic robot tape drive, the data from which can be restored by running a program, and it doesn't seem to interfere with the backup schedule or be used by the backup team. They also discuss buying a high density tape drive, but it is not clear if this is a different device or the same one. It is confirmed to be available in the professor's possession." target="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . What kind of tape drive is it ?&#10;Speaker: Grad F&#10;Content: I dunno but it 's an automatic robot so it 's very convenient .&#10;Speaker: PhD I&#10;Content: Is it {disfmarker} is {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Wh The o the one that we have ?&#10;Speaker: Grad F&#10;Content: You just run a program to restore them .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: The {disfmarker} I mean {disfmarker}&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: But it might interfere with their back - up schedule ,&#10;Speaker: PhD G&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: No , we have s we {disfmarker} Don't we have our own ?&#10;Speaker: PhD I&#10;Content: eh .&#10;Speaker: Professor D&#10;Content: Something wi th that doesn't {disfmarker} that isn't used by the back - up gang ? Don't we have something downstairs ?&#10;" target="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device.">
      <data key="d0">1</data>
    </edge>
    <edge source="'t you have this {disfmarker} have a {disfmarker} this conversation with Dave Johnson tha rather than with me ?&#10;Speaker: PhD I&#10;Content: No , no . Because this is {pause} maybe something that we can do without involving Dave , and {disfmarker} and , putting more burden on him . How about we buy , uh {disfmarker} uh {disfmarker} uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all {disfmarker} all , and then {disfmarker} and we don't have to bother this @ @ up ?&#10;Speaker: Grad F&#10;Content: Actually , you know , we could do that just with the tape {disfmarker} with the current tape .&#10;Speaker: PhD I&#10;Content: I dunno what the these tapes {disfmarker} uh , at some point these {disfmarker} I dunno . What kind of tape drive is it ?&#10;Speaker: Grad F&#10;Content: I dunno but it 's an automatic robot so it 's very" target="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Oh . Yeah .&#10;Speaker: PhD I&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Good . It 's good .&#10;Speaker: PhD G&#10;Content: So , who 's gonna do these back - ups ? The people that collect it ?&#10;Speaker: Grad F&#10;Content: Uh Well , I 'll talk to Dave , and {disfmarker} and see what th how {disfmarker} {nonvocalsound} what the best way of doing that is .&#10;Speaker: PhD B&#10;Content: It 's probably gonna n&#10;Speaker: Grad F&#10;Content: There 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .&#10;Speaker: PhD B&#10;Content: Yeah , and we should probably make that part of the procedure for recording the meetings .&#10;Speaker: PhD G&#10;Content: Well , s&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD G&#10;Content: Yeah . That 's what I 'm wondering , if {disfmarker}&#10;Speaker: Grad" target="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} X whatever partition .&#10;Speaker: Grad F&#10;Content: Yeah . That 's not a bad idea .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's basically what I was gonna say , is that a disk is {disfmarker} is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up {pause} issue , {vocalsound} eh , to first order .&#10;Speaker: Grad F&#10;Content: So once it 's on tape {disfmarker}&#10;Speaker: PhD I&#10;Content: Right . Right .&#10;Speaker: Professor D&#10;Content: And we can take care of that by putting it on non - back {pause} up drives and just backing it up once onto this tape .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: I think that 's a good idea .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Oh . Yeah .&#10;Speaker: PhD I&#10;Content: OK .&#10;Speaker" target="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed - up .&#10;Speaker: Grad F&#10;Content: I 'm much more concerned about the backed - up . The non - backed - up ,&#10;Speaker: PhD B&#10;Content: I haven't looked to see how much of that we have .&#10;Speaker: Grad F&#10;Content: yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .&#10;Speaker: Professor D&#10;Content: Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker}&#10;Speaker: PhD I&#10;Content: You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace .&#10;Speaker: Grad F&#10;Content: Yeah . But that 's {disf" target="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed - up .&#10;Speaker: Grad F&#10;Content: I 'm much more concerned about the backed - up . The non - backed - up ,&#10;Speaker: PhD B&#10;Content: I haven't looked to see how much of that we have .&#10;Speaker: Grad F&#10;Content: yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .&#10;Speaker: Professor D&#10;Content: Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker}&#10;Speaker: PhD I&#10;Content: You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace .&#10;Speaker: Grad F&#10;Content: Yeah . But that 's {disf" target="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks.">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But I I {disfmarker} I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it {disfmarker} it doesn't match anything that we 've described about meetings .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Whereas everything that we talked about them doing at {disfmarker} at UW and so forth really does . They 're actually talking {disfmarker}&#10;Speaker: Grad F&#10;Content: OK . So w so what does that mean for how we are gonna organize things ?&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: You can {disfmarker} you can {disfmarker} Again , as {disfmarker} as I think Andreas was saying , {vocalsound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="marker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?&#10;Speaker: Professor D&#10;Content: I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key .&#10;Speaker: Grad F&#10;Content: Well , this has two or more people conversing with each other .&#10;Speaker: Professor D&#10;Content: Nnn , well&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Grad F&#10;Content: They 're just not face to face .&#10;Speaker: PhD G&#10;Content: What if we just give it a {disfmarker} a name like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target=" bit about {disfmarker} Well , we don't need to do it during this meeting .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We have a little more to discuss . But , uh , we 're {disfmarker} we 're basically ready to do it . And , uh , I have some web pages on ts {comment} more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also .&#10;Speaker: Postdoc A&#10;Content: I 'm sorry , you 've been what ? Showing them ?&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Sharing them .&#10;Speaker: Grad F&#10;Content: Sharing them with the UW folks .&#10;Speaker: Postdoc A&#10;Content: OK . OK .&#10;Speaker: Professor D&#10;Content: OK . Well , maybe uh , since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound}">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target=" like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker}&#10;Speaker: Grad F&#10;Content: I mean , that was my intention .&#10;Speaker: PhD G&#10;Content: And then later on some people will consider it a meeting and some people won't ,&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: That was my intention . So {disfmarker} so {disfmarker} s {vocalsound} so part of the reason that I wanted to bring this up is , {vocalsound} do we wanna handle it as a special case or do we wanna fold it in ,&#10;Speaker: PhD G&#10;Content: and {disfmarker} Just give it a {vocalsound} title .&#10;Speaker: Postdoc A&#10;Content: Oh .&#10;Speaker: Professor D&#10;Content: I think it is a s&#10;Speaker: Grad F&#10;Content: we give everyone who 's involved as their own user ID , give it session I D">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="ound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you know , different directory , it 's called something different , it 's {disfmarker} you know . It is different . You can't just fold it in as if it 's {disfmarker} I mean , digits are different , too . Right ?&#10;Speaker: Grad F&#10;Content: Yeah , but those are folded in ,&#10;Speaker: PhD I&#10;Content: It might also be potentially confusing .&#10;Speaker: Grad F&#10;Content: and it 's just {disfmarker} you just mark the transcripts differently . So {disfmarker} so one option is you fold it in ,&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Grad F&#10;Content: and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .&#10;Speaker: PhD I&#10;Content: Yeah , I th&#10;Speaker: Professor D&#10;Content: Well , I don I wouldn't call reading digits &quot; meetings &quot; . Right ? I mean , we {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target=" Grad F&#10;Content: Synthesis system .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Um , and then , it goes to a real wizard and they 're evaluating that . And they wanted to use this equipment , and so the w question came up , is {disfmarker} well , here 's some more data . Should this be part of the corpus or not ? And my attitude was yes , because there might be people who are using this corpus for {pause} acoustics , as opposed to just for language . Um , or also for dialogue of various sorts . Um , so it 's not a meeting . Right ? Because it 's two people and they 're not face to face .&#10;Speaker: Professor D&#10;Content: Wait a minute . So , I just wanted to understand it , cuz I {disfmarker} I 'm {disfmarker} uh , hadn't quite followed this process .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Um . So , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , uh">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter.">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names.">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Prof. D's stance seems to be that using certain tools and conventions for a meeting does not match their previous descriptions, but aligns with what they discussed about activities at UW. This may imply that the group should use different tools or conventions when discussing UW-related matters, as opposed to their regular meetings. The group appears to be discussing whether or not to include certain interactions (such as two-person hallway conversations recorded at UW) in their meeting corpus. Prof. D is hesitant to label these interactions as &quot;meetings,&quot; suggesting that they should find a different way to categorize and organize them.&#10;&#10;Overall, it seems that the group needs to clarify their definitions of what constitutes a &quot;meeting&quot; and establish guidelines for organizing and categorizing different types of interactions related to their work. This may involve creating new naming conventions or directories for non-meeting related conversations, as well as clearly marking transcripts to distinguish between different types of interactions." target="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Postdoc A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But I I {disfmarker} I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it {disfmarker} it doesn't match anything that we 've described about meetings .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Whereas everything that we talked about them doing at {disfmarker} at UW and so forth really does . They 're actually talking {disfmarker}&#10;Speaker: Grad F&#10;Content: OK . So w so what does that mean for how we are gonna organize things ?&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: You can {disfmarker} you can {disfmarker} Again , as {disfmarker} as I think Andreas was saying , {vocalsound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you" target="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?&#10;Speaker: Professor D&#10;Content: I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key .&#10;Speaker: Grad F&#10;Content: Well , this has two or more people conversing with each other .&#10;Speaker: Professor D&#10;Content: Nnn , well&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Grad F&#10;Content: They 're just not face to face .&#10;Speaker: PhD G&#10;Content: What if we just give it a {disfmarker} a name like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker" target="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?&#10;Speaker: Professor D&#10;Content: I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key .&#10;Speaker: Grad F&#10;Content: Well , this has two or more people conversing with each other .&#10;Speaker: Professor D&#10;Content: Nnn , well&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Grad F&#10;Content: They 're just not face to face .&#10;Speaker: PhD G&#10;Content: What if we just give it a {disfmarker} a name like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker" target="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names.">
      <data key="d0">1</data>
    </edge>
    <edge source=" bit about {disfmarker} Well , we don't need to do it during this meeting .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We have a little more to discuss . But , uh , we 're {disfmarker} we 're basically ready to do it . And , uh , I have some web pages on ts {comment} more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also .&#10;Speaker: Postdoc A&#10;Content: I 'm sorry , you 've been what ? Showing them ?&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Sharing them .&#10;Speaker: Grad F&#10;Content: Sharing them with the UW folks .&#10;Speaker: Postdoc A&#10;Content: OK . OK .&#10;Speaker: Professor D&#10;Content: OK . Well , maybe uh , since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound}" target="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source=" like we give these meetings a name ?&#10;Speaker: Professor D&#10;Content: No , it doesn't . Right ? It has {disfmarker}&#10;Speaker: Grad F&#10;Content: I mean , that was my intention .&#10;Speaker: PhD G&#10;Content: And then later on some people will consider it a meeting and some people won't ,&#10;Speaker: Postdoc A&#10;Content: Well this {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: That was my intention . So {disfmarker} so {disfmarker} s {vocalsound} so part of the reason that I wanted to bring this up is , {vocalsound} do we wanna handle it as a special case or do we wanna fold it in ,&#10;Speaker: PhD G&#10;Content: and {disfmarker} Just give it a {vocalsound} title .&#10;Speaker: Postdoc A&#10;Content: Oh .&#10;Speaker: Professor D&#10;Content: I think it is a s&#10;Speaker: Grad F&#10;Content: we give everyone who 's involved as their own user ID , give it session I D" target="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target=" think it is a s&#10;Speaker: Grad F&#10;Content: we give everyone who 's involved as their own user ID , give it session I Ds , {vocalsound} let all the tools that handle Meeting Recorder handle it , or do we wanna special case it ? And if we were gonna special case it , who 's gonna do that ?&#10;Speaker: PhD E&#10;Content: So .&#10;Speaker: PhD I&#10;Content: Well , it {disfmarker} it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily .&#10;Speaker: PhD E&#10;Content: It {disfmarker} it {disfmarker} it {disfmarker}&#10;Speaker: Postdoc A&#10;Content: I think {disfmarker}&#10;Speaker: PhD I&#10;Content: But as far as distributing it , we shouldn't label it as part of this meeting corpus .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: We should let it be its own corp&#10;Speaker: Postdoc A&#10;Content: Well it 's {disfmarker} it {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target=" talked about getting something together for that , but maybe , uh {disfmarker} maybe we 'll just put that off for now , given that {disfmarker} But I think maybe we should have a {disfmarker} a sub - meeting , I think , uh , probably , uh , Adam and {disfmarker} and , uh , Chuck and me should talk about {disfmarker} should get together and talk about that sometime soon .&#10;Speaker: Grad F&#10;Content: Over a cappuccino tomorrow ?&#10;Speaker: Professor D&#10;Content: Yeah {comment} something like that . Um , uh , you know , maybe {disfmarker} maybe we 'll involve Dan Ellis at some {disfmarker} some level as well .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Um . OK . The {disfmarker} the tea is {disfmarker} is going , so , uh , I suggest we do , uh {disfmarker} uh , a unison .&#10;Speaker: Grad F&#10;Content: A unison digits ?&#10;Speaker: Postdoc A&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is open to giving a title or special designation to a certain event during their meetings, as evident when PhD G suggests, &quot;What if we just give it a name like we give these meetings a name?&quot; (Professor D and Grad F also don't object to this idea).&#10;2. They are considering creating individual user IDs for everyone involved in the interactions, especially after Grad F brings up the possibility of doing so by saying, &quot;we give everyone who's involved as their own user ID&quot; when discussing how to handle a specific event during their meeting. However, they have not yet made a final decision on this matter." target="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target="&#10;Content: No , the {disfmarker} the question is do we save one or two far - field channels or all of them ?&#10;Speaker: PhD G&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah .&#10;Speaker: Grad F&#10;Content: I {disfmarker} I see no reason not to do all of them .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .&#10;Speaker: PhD G&#10;Content: Nnn . Yeah .&#10;Speaker: PhD I&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: So , what is the purpose of this recording ?&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: This is to get acoustic and language model training data for SmartKom. OK .&#10;Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target="Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system .&#10;Speaker: PhD E&#10;Content: The English system ? Yeah .&#10;Speaker: PhD I&#10;Content: Yeah . Right . Right .&#10;Speaker: PhD B&#10;Content: Where does this {disfmarker} ?&#10;Speaker: Professor D&#10;Content: &#10;Speaker: PhD G&#10;Content: Maybe we can have him vary the microphones , too ,&#10;Speaker: Professor D&#10;Content: Well ,&#10;Speaker: PhD E&#10;Content: B&#10;Speaker: PhD G&#10;Content: or they 're different s speakers .&#10;Speaker: Grad F&#10;Content: Right . So {disfmarker} so {disfmarker} so for their usage , they don't need anything .&#10;Speaker: Professor D&#10;Content: so why not {disfmarker} ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Right ?&#10;Speaker: PhD E&#10;Content: But {disfmarker} but I 'm not sure about the legal aspect of {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target=" Grad F&#10;Content: OK . So , uh {disfmarker} uh , IBM transcription status ,&#10;Speaker: Professor D&#10;Content: IBM transcription . Uh , what else ?&#10;Speaker: Grad F&#10;Content: &#10;Speaker: Professor D&#10;Content:  What 's SmartKom ? SmartKom ?&#10;Speaker: Grad F&#10;Content: Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .&#10;Speaker: PhD E&#10;Content: The data . The data which we are collecting here .&#10;Speaker: Professor D&#10;Content: What {disfmarker} what {disfmarker} what are we collecting here ?&#10;Speaker: PhD E&#10;Content: Data ?&#10;Speaker: Grad F&#10;Content: So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ?&#10;Speaker: PhD E&#10;Content: The SmartKom data ?&#10;Speaker: Professor D&#10;Content: Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target=" Right ?&#10;Speaker: PhD E&#10;Content: But {disfmarker} but I 'm not sure about the legal aspect of {disfmarker} of that . Is {disfmarker} is there some contract with SmartKom or something about the data ?&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: What they {disfmarker} or , is {disfmarker} is that our data which we are collecting here ,&#10;Speaker: Professor D&#10;Content: We 've never signed anything that said that we couldn't use anything that we did .&#10;Speaker: PhD E&#10;Content: or {disfmarker} ? OK . OK .&#10;Speaker: PhD I&#10;Content: We weren't supposed to collect any data .&#10;Speaker: PhD E&#10;Content: So . OK .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: So . Yeah , th th that was the question .&#10;Speaker: PhD I&#10;Content: This was all {disfmarker}&#10;Speaker: PhD E&#10;Content: If {disfmarker} if {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target="Content: and I 'd be interested to know the {disfmarker} wha if you retrain um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: do those actually go down or not ? Because {pause} of {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah . I 'll {disfmarker} can make {disfmarker} an can , like , make a c comparison of {disfmarker} of the old system to the {disfmarker} to the new one , and {pause} then {disfmarker}&#10;Speaker: PhD G&#10;Content: Yeah , just to see if by doing nothing in the modeling of {disfmarker} just having that training data wh what happens .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah . Yep .&#10;Speaker: Professor D&#10;Content: Um another one that we had on Adam 's agenda {pause} that definitely involved you was s something about SmartKom ?&#10;Speaker: Grad F&#10;Content: Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target="Speaker: Grad F&#10;Content: Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {disfmarker} Porzel {disfmarker} and the , uh , SmartKom group are collecting some dialogues .&#10;Speaker: PhD I&#10;Content: Porzel . Porzel .&#10;Speaker: Grad F&#10;Content: Basically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . And , uh , they 're doing a travel task . And , uh , it involves starting {disfmarker} I believe starting with a {disfmarker} It 's {disfmarker} it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , uh , {vocalsound} speech generation system .&#10;Speaker: PhD E&#10;Content: Yeah . Actually , it 's changed to a synthesis for {disfmarker} for the first part now .&#10;Speaker: Grad F&#10;Content: Synthesis system .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Um , and">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Measures to vary microphones and speakers: One suggestion is to have different individuals vary the microphones used in recordings for consistency with acoustic studies. Additionally, there may be variations in speakers as well, as suggested by PhD G. However, it's not explicitly mentioned how this would be implemented.&#10;2. Legal implications: There are concerns regarding the legal aspects of data collection and usage. Specifically, PhD E raises questions about whether there is a contract with SmartKom that regulates the use of collected data. It is stated that no such contracts have been signed, but there was an understanding not to collect any data initially. To address these concerns, further discussion and clarification are required." target="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: No , the {disfmarker} the question is do we save one or two far - field channels or all of them ?&#10;Speaker: PhD G&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah .&#10;Speaker: Grad F&#10;Content: I {disfmarker} I see no reason not to do all of them .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .&#10;Speaker: PhD G&#10;Content: Nnn . Yeah .&#10;Speaker: PhD I&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: So , what is the purpose of this recording ?&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: This is to get acoustic and language model training data for SmartKom. OK .&#10;Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system ." target="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: No , the {disfmarker} the question is do we save one or two far - field channels or all of them ?&#10;Speaker: PhD G&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah .&#10;Speaker: Grad F&#10;Content: I {disfmarker} I see no reason not to do all of them .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .&#10;Speaker: PhD G&#10;Content: Nnn . Yeah .&#10;Speaker: PhD I&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: So , what is the purpose of this recording ?&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: This is to get acoustic and language model training data for SmartKom. OK .&#10;Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system ." target="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD I&#10;Content: It 's to be traini to b training data and development data for the SmartKom {pause} system .&#10;Speaker: PhD E&#10;Content: The English system ? Yeah .&#10;Speaker: PhD I&#10;Content: Yeah . Right . Right .&#10;Speaker: PhD B&#10;Content: Where does this {disfmarker} ?&#10;Speaker: Professor D&#10;Content: &#10;Speaker: PhD G&#10;Content: Maybe we can have him vary the microphones , too ,&#10;Speaker: Professor D&#10;Content: Well ,&#10;Speaker: PhD E&#10;Content: B&#10;Speaker: PhD G&#10;Content: or they 're different s speakers .&#10;Speaker: Grad F&#10;Content: Right . So {disfmarker} so {disfmarker} so for their usage , they don't need anything .&#10;Speaker: Professor D&#10;Content: so why not {disfmarker} ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Right ?&#10;Speaker: PhD E&#10;Content: But {disfmarker} but I 'm not sure about the legal aspect of {disf" target="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Grad F&#10;Content: OK . So , uh {disfmarker} uh , IBM transcription status ,&#10;Speaker: Professor D&#10;Content: IBM transcription . Uh , what else ?&#10;Speaker: Grad F&#10;Content: &#10;Speaker: Professor D&#10;Content:  What 's SmartKom ? SmartKom ?&#10;Speaker: Grad F&#10;Content: Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .&#10;Speaker: PhD E&#10;Content: The data . The data which we are collecting here .&#10;Speaker: Professor D&#10;Content: What {disfmarker} what {disfmarker} what are we collecting here ?&#10;Speaker: PhD E&#10;Content: Data ?&#10;Speaker: Grad F&#10;Content: So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ?&#10;Speaker: PhD E&#10;Content: The SmartKom data ?&#10;Speaker: Professor D&#10;Content: Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;" target="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Grad F&#10;Content: OK . So , uh {disfmarker} uh , IBM transcription status ,&#10;Speaker: Professor D&#10;Content: IBM transcription . Uh , what else ?&#10;Speaker: Grad F&#10;Content: &#10;Speaker: Professor D&#10;Content:  What 's SmartKom ? SmartKom ?&#10;Speaker: Grad F&#10;Content: Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .&#10;Speaker: PhD E&#10;Content: The data . The data which we are collecting here .&#10;Speaker: Professor D&#10;Content: What {disfmarker} what {disfmarker} what are we collecting here ?&#10;Speaker: PhD E&#10;Content: Data ?&#10;Speaker: Grad F&#10;Content: So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ?&#10;Speaker: PhD E&#10;Content: The SmartKom data ?&#10;Speaker: Professor D&#10;Content: Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;" target="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Right ?&#10;Speaker: PhD E&#10;Content: But {disfmarker} but I 'm not sure about the legal aspect of {disfmarker} of that . Is {disfmarker} is there some contract with SmartKom or something about the data ?&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: What they {disfmarker} or , is {disfmarker} is that our data which we are collecting here ,&#10;Speaker: Professor D&#10;Content: We 've never signed anything that said that we couldn't use anything that we did .&#10;Speaker: PhD E&#10;Content: or {disfmarker} ? OK . OK .&#10;Speaker: PhD I&#10;Content: We weren't supposed to collect any data .&#10;Speaker: PhD E&#10;Content: So . OK .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: So . Yeah , th th that was the question .&#10;Speaker: PhD I&#10;Content: This was all {disfmarker}&#10;Speaker: PhD E&#10;Content: If {disfmarker} if {disfmarker" target="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target=" and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well , {vocalsound} I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've {disfmarker} {pause} uh , {pause} I , uh , uh , I 've {comment} trained the new one {disfmarker} uh , the new the newest one , {vocalsound} to , um , {vocalsound} use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation .&#10;Speaker: Grad F&#10;Content: Oh , right .&#10;Speaker: Postdoc A&#10;Content: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target=" Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: but at the same time we 're benefitting tremendously from the pre - segmentation because {vocalsound} there are huge places where there is just absolutely no activity at all . And , uh , the audio quality is so good {disfmarker}&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: So they can {disfmarker} they can , um , scroll through that pretty quick ?&#10;Speaker: Postdoc A&#10;Content: Yeah . Mm - hmm .&#10;Speaker: PhD B&#10;Content: That 's great .&#10;Speaker: Postdoc A&#10;Content: Yeah . So I think that that 's gonna , also {pause} eh , {comment} you know , speed the efficiency of this part of the process .&#10;Speaker: Professor D&#10;Content: Hmm . OK . Uh , yeah . So , uh {disfmarker} Yeah . So let 's talk about the digits , since they 're not here yet .&#10;Speaker: Grad F&#10;Content: Uh , so , we have a whole bunch of digits that we">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target=" . What about just actually doing recognition ?&#10;Speaker: Grad F&#10;Content: Well , we {disfmarker} we know what they read , because we have the forms .&#10;Speaker: Professor D&#10;Content: No , they make mistakes .&#10;Speaker: Grad F&#10;Content: Right . But , the point is that we wanna get a set of clean digits .&#10;Speaker: PhD B&#10;Content: You 're talking about as a pre - processing step .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Right , Morgan ?&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: PhD B&#10;Content: Is that what you 're {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Yeah , I 'm {disfmarker} I 'm not quite sure what I 'm talking about . I mean {disfmarker} I {disfmarker} I mean , uh , we 're talking about digits now . And {disfmarker} and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um , {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target=": Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;Speaker: Grad F&#10;Content: Uh , reorganization status .&#10;Speaker: Professor D&#10;Content: Reorganization status .&#10;Speaker: Postdoc A&#10;Content: Oh . Files and directories ?&#10;Speaker: Professor D&#10;Content: Files and directories .&#10;Speaker: Grad F&#10;Content: Yep . Uh - huh . Absinthe , which is the multiprocessor UNIX {disfmarker} Linux . I think it was {pause} Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: And then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week .&#10;Speaker: Professor D&#10;Content: Right . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target="er}&#10;Speaker: PhD B&#10;Content: and {disfmarker}&#10;Speaker: PhD I&#10;Content: You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable&#10;Speaker: PhD B&#10;Content: Oh .&#10;Speaker: PhD I&#10;Content: because you have a different normalization constants for each model you train .&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: But , still it 's a question {disfmarker}&#10;Speaker: PhD I&#10;Content: So {disfmarker}&#10;Speaker: Professor D&#10;Content: if you have some threshold somewhere in terms of beam search or something ,&#10;Speaker: PhD B&#10;Content: Well , yeah . That 's what I was wondering .&#10;Speaker: Professor D&#10;Content: or {disfmarker} ?&#10;Speaker: PhD I&#10;Content: W yeah . I mean {disfmarker} Uh {disfmarker}&#10;Speaker: PhD B&#10;Content: I mean , if you have one threshold that works well because the range of your">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target="&#10;Content: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker} it 's interesting .&#10;Speaker: Grad F&#10;Content: I see what you mean . A backchannel , or {disfmarker}&#10;Speaker: Postdoc A&#10;Content: Once in a while it 's a backchannel .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Postdoc A&#10;Content: Sometimes it seems to be , um , similar to the ones that are being picked up .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Postdoc A&#10;Content: And they 're rare events , but you can really go through a meeting very quickly . You just {disfmarker} you just , you know , yo you s you scroll from screen to screen , looking for blips . And , I think that we 're gonna end up with , uh {pause} better coverage of the backchannels ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: but at the same time we 're benefitting tremendously from the pre -">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The new version of the system has been trained to use a visual representation of the channel being transcribed at any given time. This helps in identifying any &quot;blip&quot; (probably referring to important content) that might not have been included in the pre-segmented version.&#10;2. The use of pre-segmentation is still beneficial as it allows for skipping through large portions of audio with no activity, making the process more efficient. This is because the audio quality is good enough to clearly distinguish active and inactive parts." target="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well , {vocalsound} I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've {disfmarker} {pause} uh , {pause} I , uh , uh , I 've {comment} trained the new one {disfmarker} uh , the new the newest one , {vocalsound} to , um , {vocalsound} use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation .&#10;Speaker: Grad F&#10;Content: Oh , right .&#10;Speaker: Postdoc A&#10;Content: And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker}" target="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . What about just actually doing recognition ?&#10;Speaker: Grad F&#10;Content: Well , we {disfmarker} we know what they read , because we have the forms .&#10;Speaker: Professor D&#10;Content: No , they make mistakes .&#10;Speaker: Grad F&#10;Content: Right . But , the point is that we wanna get a set of clean digits .&#10;Speaker: PhD B&#10;Content: You 're talking about as a pre - processing step .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Right , Morgan ?&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: PhD B&#10;Content: Is that what you 're {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Yeah , I 'm {disfmarker} I 'm not quite sure what I 'm talking about . I mean {disfmarker} I {disfmarker} I mean , uh , we 're talking about digits now . And {disfmarker} and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um , {" target="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Yeah , right .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , right . Uh .&#10;Speaker: Grad F&#10;Content: Uh , reorganization status .&#10;Speaker: Professor D&#10;Content: Reorganization status .&#10;Speaker: Postdoc A&#10;Content: Oh . Files and directories ?&#10;Speaker: Professor D&#10;Content: Files and directories .&#10;Speaker: Grad F&#10;Content: Yep . Uh - huh . Absinthe , which is the multiprocessor UNIX {disfmarker} Linux . I think it was {pause} Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments .&#10;Speaker: Professor D&#10;Content: Um {disfmarker}&#10;Speaker: Grad F&#10;Content: And then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week .&#10;Speaker: Professor D&#10;Content: Right . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing ." target="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded.">
      <data key="d0">1</data>
    </edge>
    <edge source="er}&#10;Speaker: PhD B&#10;Content: and {disfmarker}&#10;Speaker: PhD I&#10;Content: You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable&#10;Speaker: PhD B&#10;Content: Oh .&#10;Speaker: PhD I&#10;Content: because you have a different normalization constants for each model you train .&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: But , still it 's a question {disfmarker}&#10;Speaker: PhD I&#10;Content: So {disfmarker}&#10;Speaker: Professor D&#10;Content: if you have some threshold somewhere in terms of beam search or something ,&#10;Speaker: PhD B&#10;Content: Well , yeah . That 's what I was wondering .&#10;Speaker: Professor D&#10;Content: or {disfmarker} ?&#10;Speaker: PhD I&#10;Content: W yeah . I mean {disfmarker} Uh {disfmarker}&#10;Speaker: PhD B&#10;Content: I mean , if you have one threshold that works well because the range of your" target="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained.">
      <data key="d0">1</data>
    </edge>
    <edge source="er}&#10;Speaker: PhD B&#10;Content: and {disfmarker}&#10;Speaker: PhD I&#10;Content: You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable&#10;Speaker: PhD B&#10;Content: Oh .&#10;Speaker: PhD I&#10;Content: because you have a different normalization constants for each model you train .&#10;Speaker: PhD B&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: But , still it 's a question {disfmarker}&#10;Speaker: PhD I&#10;Content: So {disfmarker}&#10;Speaker: Professor D&#10;Content: if you have some threshold somewhere in terms of beam search or something ,&#10;Speaker: PhD B&#10;Content: Well , yeah . That 's what I was wondering .&#10;Speaker: Professor D&#10;Content: or {disfmarker} ?&#10;Speaker: PhD I&#10;Content: W yeah . I mean {disfmarker} Uh {disfmarker}&#10;Speaker: PhD B&#10;Content: I mean , if you have one threshold that works well because the range of your" target="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target=" , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we can do that .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: We 'll take the opportunity and get another big raft of {disfmarker} {vocalsound} of disk , I guess .&#10;Speaker: Grad F&#10;Content: Yeah . It 's really the back - up issue rather than the file server issue .&#10;Speaker: PhD I&#10;Content: Well , I think {disfmarker} {comment} I think there 's an argument for having {disfmarker} you know , you could use our old file server for {disfmarker} for disks that have data that {pause} is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed .&#10;Speaker: Grad F&#10;Content: Yeah . My understanding is , the issue isn't really the file server .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We could always put more disks on .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target=" server .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We could always put more disks on .&#10;Speaker: PhD I&#10;Content: Yeah . It 's the back it 's the back - up capaci&#10;Speaker: Grad F&#10;Content: It 's the back - up system .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} which is near saturation , apparently . So .&#10;Speaker: PhD B&#10;Content: I think {disfmarker} I think the file server could become an issue as we get a whole bunch more new compute machines .&#10;Speaker: Professor D&#10;Content: Soon .&#10;Speaker: PhD B&#10;Content: And we 've got , you know , fifty machines trying to access data off of Abbott at once .&#10;Speaker: Grad F&#10;Content: Well , we 're alright for now because the network 's so slow .&#10;Speaker: PhD I&#10;Content: I mean , I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target=" one of our concerns .&#10;Speaker: PhD B&#10;Content: Are we only half ? I thought we were more than that .&#10;Speaker: Grad F&#10;Content: We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .&#10;Speaker: PhD B&#10;Content: Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: And everything else was sorta committed . Uh {disfmarker}&#10;Speaker: Grad F&#10;Content: Were those backed - up or non - backed - up ?&#10;Speaker: PhD B&#10;Content: Those were non - backed - up .&#10;Speaker: PhD E&#10;Content: Non - back - up .&#10;Speaker: Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed -">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the proposed solution for addressing the backup issue rather than the file server involves using the old file server to store data that is rarely accessed and investing in a new, high-density tape drive for backing up infrequently accessed data. This would free up space on the main backup system, which is near saturation, and provide a more efficient way to manage storage resources. The new tape drive would be relatively inexpensive, with the only significant cost being the backup process itself. Additionally, they plan to use non-backed up drives for storing data that doesn't need to be backed up, further optimizing their storage and backup strategy." target="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we can do that .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: We 'll take the opportunity and get another big raft of {disfmarker} {vocalsound} of disk , I guess .&#10;Speaker: Grad F&#10;Content: Yeah . It 's really the back - up issue rather than the file server issue .&#10;Speaker: PhD I&#10;Content: Well , I think {disfmarker} {comment} I think there 's an argument for having {disfmarker} you know , you could use our old file server for {disfmarker} for disks that have data that {pause} is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed .&#10;Speaker: Grad F&#10;Content: Yeah . My understanding is , the issue isn't really the file server .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: We could always put more disks on .&#10;Spe" target="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source=" one of our concerns .&#10;Speaker: PhD B&#10;Content: Are we only half ? I thought we were more than that .&#10;Speaker: Grad F&#10;Content: We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .&#10;Speaker: PhD B&#10;Content: Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: And everything else was sorta committed . Uh {disfmarker}&#10;Speaker: Grad F&#10;Content: Were those backed - up or non - backed - up ?&#10;Speaker: PhD B&#10;Content: Those were non - backed - up .&#10;Speaker: PhD E&#10;Content: Non - back - up .&#10;Speaker: Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed -" target="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks.">
      <data key="d0">1</data>
    </edge>
    <edge source=" one of our concerns .&#10;Speaker: PhD B&#10;Content: Are we only half ? I thought we were more than that .&#10;Speaker: Grad F&#10;Content: We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .&#10;Speaker: PhD B&#10;Content: Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: And everything else was sorta committed . Uh {disfmarker}&#10;Speaker: Grad F&#10;Content: Were those backed - up or non - backed - up ?&#10;Speaker: PhD B&#10;Content: Those were non - backed - up .&#10;Speaker: PhD E&#10;Content: Non - back - up .&#10;Speaker: Grad F&#10;Content: Right . So that 's different .&#10;Speaker: PhD B&#10;Content: S oh , you 're talking about backed -" target="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target="} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that we {pause} train . And then , from there we do , um {disfmarker} There 's a lot of , actually {disfmarker} {vocalsound} The way it works , you first train a phonetically - tied mixture model . Um . You do a total of {disfmarker} First you do a context - independent PTM model . Then you switch to a context {disfmarker} You do two iterations of that . Then you do two iterations of {disfmarker} of {disfmarker} of context - dependent phonetically - tied mixtures . And then from that you {disfmarker} you do the {disfmarker} you {disfmarker} you go to a state - clustered model ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: and you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target=" {disfmarker} so the strategy is to first sort of treat things {pause} with fast turn - around on a smaller training set and then , {vocalsound} when you 've sort of , narrowed it down , you try it on a larger training set .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And so , we haven't done that yet .&#10;Speaker: Professor D&#10;Content: Now the other que related question , though , is {disfmarker} is , {vocalsound} uh , what 's the boot models for these things ?&#10;Speaker: PhD I&#10;Content: Th - th the boot models are trained from scratch . So we compute , um {disfmarker} So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And {disfmarker} and then we train from scratch . So we com we do a , you know , w um {disfmarker} {vocalsound} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target=" {disfmarker}&#10;Speaker: PhD I&#10;Content: Mm - hmm . Mm - hmm . But there are no boot models , in fact . You {disfmarker} you 're not booting from initial models . You 're booting from initial alignments .&#10;Speaker: Professor D&#10;Content: Which you got from a different feature set .&#10;Speaker: PhD I&#10;Content: That 's correct .&#10;Speaker: Professor D&#10;Content: So , those features look at the data differently , actually .&#10;Speaker: PhD I&#10;Content: Yeah , but {disfmarker}&#10;Speaker: Professor D&#10;Content: I mean , you know , they {disfmarker} they will find boundaries a little differently , though {disfmarker} You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect ,&#10;Speaker: PhD I&#10;Content: But {disfmarker} but {disfmarker} but , what I 'm {disfmarker} what I 'm saying is {disfmarker}&#10;Speaker: Professor D&#10;Content: but {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target="&#10;Speaker: PhD I&#10;Content: Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test set , they 're actually a little worse . But that 's beside the point . We 're looking at the discrepancy between the SRI system and the SRI system when trained with ICSI features .&#10;Speaker: PhD G&#10;Content: Right . I 'm just wondering if that {disfmarker} if {disfmarker} if you have any indication of your standard features ,&#10;Speaker: Grad F&#10;Content: What 's {disfmarker} Are the freq ?&#10;Speaker: PhD G&#10;Content: you know , if that 's also different {pause} or in the same direction or not .&#10;Speaker: Professor D&#10;Content: You 're {disfmarker} This is {disfmarker} lemme ask a q more basic que&#10;Speaker: PhD G&#10;Content: Cuz {disfmarker}&#10;Speaker: Professor D&#10;Content: I mean , is this , uh {disfmarker} uh , iterative , Baum - Welch training ?&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. First, a context-independent Phonetically Tied Model (PTM) is trained.&#10;2. Then, two iterations of context-dependent PTM models are trained.&#10;3. After that, another two iterations of context-dependent phonetically-tied mixtures are performed.&#10;4. Finally, the process goes to a state-clustered model, which also involves four iterations.&#10;&#10;This process is used to collect observations from alignments under each feature set for extracting acoustic and language model training data for SmartKom system. It's important to note that there are no boot models involved in this process, but initial alignments are used, which were computed with the best system available. Additionally, log probabilities from different sets of models cannot be directly compared because different normalization constants are used for each model trained." target="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it.">
      <data key="d0">1</data>
    </edge>
    <edge source="} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that we {pause} train . And then , from there we do , um {disfmarker} There 's a lot of , actually {disfmarker} {vocalsound} The way it works , you first train a phonetically - tied mixture model . Um . You do a total of {disfmarker} First you do a context - independent PTM model . Then you switch to a context {disfmarker} You do two iterations of that . Then you do two iterations of {disfmarker} of {disfmarker} of context - dependent phonetically - tied mixtures . And then from that you {disfmarker} you do the {disfmarker} you {disfmarker} you go to a state - clustered model ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: and you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm" target="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} so the strategy is to first sort of treat things {pause} with fast turn - around on a smaller training set and then , {vocalsound} when you 've sort of , narrowed it down , you try it on a larger training set .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And so , we haven't done that yet .&#10;Speaker: Professor D&#10;Content: Now the other que related question , though , is {disfmarker} is , {vocalsound} uh , what 's the boot models for these things ?&#10;Speaker: PhD I&#10;Content: Th - th the boot models are trained from scratch . So we compute , um {disfmarker} So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And {disfmarker} and then we train from scratch . So we com we do a , you know , w um {disfmarker} {vocalsound} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that" target="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker}&#10;Speaker: PhD I&#10;Content: Mm - hmm . Mm - hmm . But there are no boot models , in fact . You {disfmarker} you 're not booting from initial models . You 're booting from initial alignments .&#10;Speaker: Professor D&#10;Content: Which you got from a different feature set .&#10;Speaker: PhD I&#10;Content: That 's correct .&#10;Speaker: Professor D&#10;Content: So , those features look at the data differently , actually .&#10;Speaker: PhD I&#10;Content: Yeah , but {disfmarker}&#10;Speaker: Professor D&#10;Content: I mean , you know , they {disfmarker} they will find boundaries a little differently , though {disfmarker} You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect ,&#10;Speaker: PhD I&#10;Content: But {disfmarker} but {disfmarker} but , what I 'm {disfmarker} what I 'm saying is {disfmarker}&#10;Speaker: Professor D&#10;Content: but {" target="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names." target=" uh , place names and so forth ? Is that {disfmarker} ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Exactly .&#10;Speaker: Professor D&#10;Content: Yeah , great .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Yep .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: They {disfmarker} they even have a reading list .&#10;Speaker: PhD B&#10;Content: I bet that sounds good , huh ?&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: It 's pretty funny .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: You can do that if you want .&#10;Speaker: PhD B&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: I dunno if you want that .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: Professor">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names." target=" idea is just to read each line {pause} with a short pause between lines ,&#10;Speaker: Grad C&#10;Content: Alright .&#10;Speaker: Grad F&#10;Content: not between {disfmarker} And , uh , since we 're in a hurry , we were just gonna read everyone all at once . So , if you sorta plug your ears and read {disfmarker}&#10;Speaker: Grad C&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: So first read the transcript number , and then start reading the {pause} digits .&#10;Speaker: Grad C&#10;Content: Sure .&#10;Speaker: Grad F&#10;Content: OK ? One , two , three .&#10;Speaker: Professor D&#10;Content: OK we 're done .&#10;Speaker: Grad F&#10;Content: And {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names." target="ll j I 'll {disfmarker} just let 's make sure everything works on the females . &quot; And the error rate {disfmarker} you know , there was a three percent difference .&#10;Speaker: Professor D&#10;Content: Oh . Uh - huh .&#10;Speaker: PhD I&#10;Content: So ,&#10;Speaker: PhD G&#10;Content: Is there less training data ?&#10;Speaker: PhD I&#10;Content: uh {disfmarker}&#10;Speaker: PhD G&#10;Content: I mean , we don&#10;Speaker: PhD I&#10;Content: No , actually there 's more training data .&#10;Speaker: PhD G&#10;Content: This is on just digits ?&#10;Speaker: Professor D&#10;Content: No .&#10;Speaker: PhD I&#10;Content: No , no .&#10;Speaker: Grad F&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Hub - five .&#10;Speaker: Grad F&#10;Content: It 's , uh , Swi&#10;Speaker: PhD G&#10;Content: Oh , sorry . OK . This is on {disfmarker}&#10;Speaker: PhD I&#10;Content: This is Hub - five .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Based on the transcript, it is not explicitly clear if the group has a reading list specifically for place names. However, there is a mention of a reading list when Grad F says &quot;they even have a reading list.&quot; It's possible that this reading list is a general resource for the group's discussions.&#10;2. The individuals in the conversation do not express any explicit attitudes towards a potential reading list for place names. There are no indications of approval, disapproval, or neutrality towards such an idea.&#10;3. Therefore, based on the provided transcript, there is insufficient information to make any definitive conclusions about the group's attitudes towards a reading list for place names." target="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="ll j I 'll {disfmarker} just let 's make sure everything works on the females . &quot; And the error rate {disfmarker} you know , there was a three percent difference .&#10;Speaker: Professor D&#10;Content: Oh . Uh - huh .&#10;Speaker: PhD I&#10;Content: So ,&#10;Speaker: PhD G&#10;Content: Is there less training data ?&#10;Speaker: PhD I&#10;Content: uh {disfmarker}&#10;Speaker: PhD G&#10;Content: I mean , we don&#10;Speaker: PhD I&#10;Content: No , actually there 's more training data .&#10;Speaker: PhD G&#10;Content: This is on just digits ?&#10;Speaker: Professor D&#10;Content: No .&#10;Speaker: PhD I&#10;Content: No , no .&#10;Speaker: Grad F&#10;Content: No .&#10;Speaker: PhD B&#10;Content: Hub - five .&#10;Speaker: Grad F&#10;Content: It 's , uh , Swi&#10;Speaker: PhD G&#10;Content: Oh , sorry . OK . This is on {disfmarker}&#10;Speaker: PhD I&#10;Content: This is Hub - five .&#10;Speaker" target="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." target="Speaker: PhD G&#10;Content: I mean , usually they 're {disfmarker}&#10;Speaker: Grad F&#10;Content: well , not forever , they 've been finding even those degrade .&#10;Speaker: Professor D&#10;Content: Oh , I see .&#10;Speaker: Grad F&#10;Content: But , uh , the burned ones {disfmarker} I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year .&#10;Speaker: PhD G&#10;Content: That 's what I {disfmarker}&#10;Speaker: Grad F&#10;Content: On the average , it 'll probably be three or four years . But , uh {disfmarker} I {disfmarker} I {disfmarker} you don't want to per p have your only copy on a media that fails .&#10;Speaker: PhD I&#10;Content: Mmm .&#10;Speaker: Grad F&#10;Content: And they do . Um , if you have them professionally pressed , y you know , they 're good for decades .&#10;Speaker: PhD I&#10;Content: So how about {disfmarker} ? So">
      <data key="d0">1</data>
    </edge>
    <edge source="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." target=" You can talk to the computer . &quot;&#10;Speaker: PhD B&#10;Content: It 's a lot more believable , too ,&#10;Speaker: Grad F&#10;Content: &quot; No ! &quot;&#10;Speaker: PhD B&#10;Content: if you tell them that they 're {disfmarker} the computer part is running on a Windows machine . And the whole breakdown thing kinda makes sense .&#10;Speaker: PhD I&#10;Content: O Just {disfmarker} just reboot it .&#10;Speaker: Grad F&#10;Content: Abort {disfmarker} abort , retry , fail ?&#10;Speaker: PhD G&#10;Content: So did they actually save the far - field {pause} data ?&#10;Speaker: PhD E&#10;Content: Yes .&#10;Speaker: Grad F&#10;Content: Well , this was {disfmarker} this was the question .&#10;Speaker: PhD G&#10;Content: Cuz at first they weren't {disfmarker} they weren't sa&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} so they were saying they were not going to ,&#10;Speaker: PhD E&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." target=" , y you know , they 're good for decades .&#10;Speaker: PhD I&#10;Content: So how about {disfmarker} ? So {disfmarker} so how about putting them on that plus , like on a {disfmarker} on {disfmarker} on DAT or some other medium that isn't risky ?&#10;Speaker: Grad F&#10;Content: I think th um , we can already put them on tape . And the tape is hi is very reliable .&#10;Speaker: PhD I&#10;Content: OK . Mm - hmm .&#10;Speaker: Grad F&#10;Content: So the {disfmarker} the only issue is then {pause} if we need access to them . So that 's fine f if we don't need access to them .&#10;Speaker: PhD I&#10;Content: Right . Well , if {disfmarker} if {disfmarker} if you {disfmarker} if they last {disfmarker} Say , they actually last , like , five years , huh , in {disfmarker} in the typical case , and {disfmarker} and occasionally you might need to recreate one , and">
      <data key="d0">1</data>
    </edge>
    <edge source="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." target="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks.">
      <data key="d0">1</data>
    </edge>
    <edge source="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." target="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device.">
      <data key="d0">1</data>
    </edge>
    <edge source="Computer disks, even when stored professionally, can degrade or fail within a few years, with the average being around three to four years. Therefore, it is not recommended to rely solely on computer disks as the only copy of certain data due to the risk of failure. This is because if the disk fails, there would be no other copies of the data available, leading to data loss. Other storage mediums such as tape, which are known for their reliability and longevity, can be used to create additional copies of important data to ensure its availability in case of a failure." target="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD G&#10;Content: I mean , usually they 're {disfmarker}&#10;Speaker: Grad F&#10;Content: well , not forever , they 've been finding even those degrade .&#10;Speaker: Professor D&#10;Content: Oh , I see .&#10;Speaker: Grad F&#10;Content: But , uh , the burned ones {disfmarker} I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year .&#10;Speaker: PhD G&#10;Content: That 's what I {disfmarker}&#10;Speaker: Grad F&#10;Content: On the average , it 'll probably be three or four years . But , uh {disfmarker} I {disfmarker} I {disfmarker} you don't want to per p have your only copy on a media that fails .&#10;Speaker: PhD I&#10;Content: Mmm .&#10;Speaker: Grad F&#10;Content: And they do . Um , if you have them professionally pressed , y you know , they 're good for decades .&#10;Speaker: PhD I&#10;Content: So how about {disfmarker} ? So" target="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target=" . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm . We have never seen big differences . Once I thought &quot; oh , I can {disfmarker} Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . &quot; Made no difference whatsoever . It 's {disfmarker} I think it 's {disfmarker} eh , i&#10;Speaker: Professor D&#10;Content: Right . Well , mis for making things better .&#10;Speaker: PhD I&#10;Content: the boot models are recur&#10;Speaker: Professor D&#10;Content: Yeah . But , this for making things worse . This it migh Th - the thought is {disfmarker} is {disfmarker} is possible {disfmarker} another possible {pause} partial cause is if the boot models {vocalsound} used a comple used a different feature set , that {disfmarker}&#10;Speaker: PhD I&#10;Content: Mm - hmm . Mm - hmm . But there are no boot">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target=" years in the system .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: And , the result in the end was no different .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: So , what I 'm saying is , the exact nature of these boot alignments is probably not {pause} a big factor in the quality of the final models .&#10;Speaker: Professor D&#10;Content: Yeah , maybe not . But {pause} it {disfmarker} it {disfmarker} I st still see it as {disfmarker} I mean , {vocalsound} there 's {disfmarker} there 's a history to this , too ,&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: but I {disfmarker} uh , I don't wanna go into ,&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: but {disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause}">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target=" I 'm {disfmarker} what I 'm saying is {disfmarker}&#10;Speaker: Professor D&#10;Content: but {disfmarker}&#10;Speaker: PhD I&#10;Content: So , we e w f w For a long time we had used boot alignments that had been trained with a {disfmarker} {vocalsound} with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD I&#10;Content: And with a dict different dictionary {disfmarker} with a considerably different dictionary , which was much less detailed and much less well - suited .&#10;Speaker: Professor D&#10;Content: Mm - hmm . Yeah .&#10;Speaker: PhD I&#10;Content: And so , {vocalsound} then we switched to new boot alignments , which {disfmarker} which now had the benefit of all these improvements that we 've made over two years in the system .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: And , the result in the end">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor D and PhD I discussed the role of &quot;boot alignments&quot; in developing final models. It seems that they agree that the &quot;exact nature of these boot alignments&quot; is not a significant factor in determining the quality of the final models. They mention that despite trying to improve initial alignments with better models, it made no difference in the end. They also highlight that there were no changes in features or boot models used throughout the process, and switching to new boot alignments did not affect the final results either. However, they do discuss the importance of different feature sets in affecting how boundaries are found in the data, but they expect this to have only a minor effect." target="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm . We have never seen big differences . Once I thought &quot; oh , I can {disfmarker} Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . &quot; Made no difference whatsoever . It 's {disfmarker} I think it 's {disfmarker} eh , i&#10;Speaker: Professor D&#10;Content: Right . Well , mis for making things better .&#10;Speaker: PhD I&#10;Content: the boot models are recur&#10;Speaker: Professor D&#10;Content: Yeah . But , this for making things worse . This it migh Th - the thought is {disfmarker} is {disfmarker} is possible {disfmarker} another possible {pause} partial cause is if the boot models {vocalsound} used a comple used a different feature set , that {disfmarker}&#10;Speaker: PhD I&#10;Content: Mm - hmm . Mm - hmm . But there are no boot" target="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it.">
      <data key="d0">1</data>
    </edge>
    <edge source="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt." target=" , ho&#10;Speaker: Grad F&#10;Content: What {disfmarker} ?&#10;Speaker: Professor D&#10;Content: um , I 'm sorry {disfmarker} in each case how do you determine , you know , the {disfmarker} the usual {pause} fudge factors ? The , uh {disfmarker} {vocalsound} the , uh , language , uh , scaling , acoustic scaling , uh , uh {disfmarker}&#10;Speaker: PhD I&#10;Content: Um {pause} I uh {disfmarker} {comment} I 'm actually re - optimizing them . Although that hasn't shown to make {pause} a big difference .&#10;Speaker: Professor D&#10;Content: OK . And the pru the question he was asking at one point about pruning , uh {disfmarker} Remember that one ?&#10;Speaker: PhD I&#10;Content: Pruning {disfmarker} ?&#10;Speaker: Professor D&#10;Content: Well , he was {disfmarker} he 's {disfmarker} it looked like the probabil at one point he was looking at the probabilities he was getting out {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt." target="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study.">
      <data key="d0">1</data>
    </edge>
    <edge source="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt." target="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt." target="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule.">
      <data key="d0">1</data>
    </edge>
    <edge source="In this conversation, Professor D and PhD I are discussing the process of determining and re-optimizing certain parameters, referred to as &quot;fudge factors,&quot; which affect the language scaling and acoustic scaling in their research. They mention that they are currently re-optimizing these fudge factors, but note that it has not made a significant difference in their results. Professor D also brings up the topic of pruning and the probabilities being generated by their models, suggesting that they were previously looking at the probabilities being outputted at one point. However, the specifics of how they are re-optimizing these fudge factors and determining the thresholds for beam search are not discussed in detail during this excerpt." target="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks." target=" F&#10;Content: NW archive .&#10;Speaker: Postdoc A&#10;Content: Yep {comment} {vocalsound} And if you did that during the day it would never make it to the nightly back - ups .&#10;Speaker: Grad F&#10;Content: That 's what it is .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: Postdoc A&#10;Content: And then there wouldn't be this extra load .&#10;Speaker: PhD I&#10;Content: Well , it {disfmarker} if he {disfmarker} you have to put the data on a {disfmarker} on a non - backed - up disk to begin with .&#10;Speaker: Postdoc A&#10;Content: Well , but you can have it NW archive to {disfmarker} you can have , {vocalsound} uh , a non - backed - up disk NW archived ,&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD I&#10;Content: So that {disfmarker} so that {disfmarker} otherwise you don't {disfmarker} you {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks." target="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Data on a non-backed up disk is at risk of loss if the disk fails, as there would be no other copies available. This is mentioned in the transcript as a concern.&#10;2. If data is stored on a non-backed up disk and then added to the NW archive, it can be accessed and used without interfering with the backup schedule or the backup team's resources.&#10;3. Storing data on a non-backed up disk may not cause an increase in workload during nightly backups, as the transcript suggests that this data would not be included in the backup process. However, this could also lead to data loss if the disk fails.&#10;4. The use of high-density tape drives for backing up infrequently accessed data can help address the issue of saturation on the main backup system and provide a more efficient way to manage storage resources. This would be a more reliable option than relying solely on non-backed up disks." target="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Legal Implications: There is a concern raised about the legal aspects of data collection and usage for SmartKom. PhD E asks if there is a contract with SmartKom regulating the use of collected data, to which it is replied that no such contracts have been signed. However, an understanding existed not to collect any data initially. This raises questions about ownership, consent, and permissions regarding the data collection and its usage. Further discussion and clarification are required to address these concerns.&#10;&#10;2. Data Handling Procedures: No explicit information is provided in the transcript regarding data handling procedures for SmartKom. However, it can be inferred that they plan on collecting data (as there were initial understandings against data collection) and there will be multiple microphone and speaker variations for consistency with acoustic studies. The data collected will undergo a process involving training Phonetically Tied Models (PTM), context-dependent PTMs, context-dependent phonetically-tied mixtures, and state-clustered models. These processes are used to extract acoustic and language model training data for SmartKom." target="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Clarify definitions: The group should first clarify their definitions of what constitutes a &quot;meeting&quot; to ensure everyone is on the same page. This can help distinguish between different types of interactions and how they should be categorized and organized.&#10;&#10;2. Create new naming conventions or directories: Based on Prof. D's comments, it seems appropriate for the group to create new naming conventions or directories for non-meeting related conversations. This can help keep meeting transcripts separate from other interactions, making it easier to organize and search through them later.&#10;&#10;3. Clearly mark transcripts: The group should consider implementing a system for clearly marking transcripts to distinguish between different types of interactions. This could include labels or tags indicating whether a transcript is a formal meeting, a casual conversation, or something else entirely.&#10;&#10;4. Establish guidelines for organizing and categorizing interactions: Once the group has clarified their definitions and established a system for labeling and categorizing different types of interactions, they should create clear guidelines for how to organize and store these interactions moving forward. This can help ensure consistency and ease of use over time.&#10;&#10;5. Consider individual user IDs: While the group has not yet made a final decision on this matter, creating individual user IDs for everyone involved in the interactions could be a useful way to keep track of who said what during each interaction. This can be especially helpful when analyzing meeting transcripts or other records of group discussions.&#10;&#10;6. Evaluate tools and conventions: As Prof. D suggested, the group should evaluate whether their current tools and conventions are appropriate for different types of interactions related to their work. If certain tools or conventions do not match previous descriptions of meetings, it may be necessary to use different ones for UW-related matters versus regular meetings." target="Speaker: PhD E&#10;Content: Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {disfmarker} which I 'm using , and , {vocalsound} it 's {disfmarker} {vocalsound} before it was twenty minutes of one meeting .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: So {disfmarker} should {comment} be a little bit better .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: Great .&#10;Speaker: PhD I&#10;Content: That won't be perfect {disfmarker} the alignments aren't perfect ,&#10;Speaker: PhD E&#10;Content: Yeah . But {disfmarker}&#10;Speaker: PhD I&#10;Content: but , um , it 's probably still better to have all this extra data , than {disfmarker}&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah . Yep .&#10;Speaker: PhD I&#10;Content: Yeah .&#10;Speaker: PhD E&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the exact type of tape drive is not specified and only referred to as &quot;the one that we have&quot; and &quot;it.&quot; It is an automatic robot tape drive that is convenient to use and does not interfere with the backup schedule or share the same system as the backup group. The data from this tape drive can be restored by running a program. However, it is unclear whether this is the same tape drive being considered for buying a high-density tape drive or if it is a different device." target="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study." target="disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause} that it {disfmarker} the data is being viewed in a certain way , uh , that a beginning is here rather than there and so forth ,&#10;Speaker: PhD I&#10;Content: Yeah . Right .&#10;Speaker: Professor D&#10;Content: because the actual signal - processing you 're doing is slightly different .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: But , {vocalsound} it 's {disfmarker} it 's {disfmarker} that 's probably not it .&#10;Speaker: PhD I&#10;Content: Yeah . Anyway , I {disfmarker} I {disfmarker} I should really reserve , uh , any conclusions until we 've done it on the large training set , um , and until we 've seen the results with the {disfmarker} with the VTL in training .&#10;Speaker: Professor D&#10;Content: Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study." target=" s more if you do it on both training and test .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And so the {disfmarker} It now helps , if you do it only on the test , and I 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll {disfmarker} we 'll have , hopefully , even better results . So {disfmarker} But there 's {disfmarker} It looks like there will still be some difference , maybe between one and two percent , um , for the females .&#10;Speaker: Professor D&#10;Content: Huh .&#10;Speaker: PhD I&#10;Content: And so , um , you know , I 'm open to suggestions .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: PhD I&#10;Content: And it is true that the , uh {disfmarker} that the {disfmarker} {vocalsound} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL ,&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study." target="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study." target="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential factor that could be causing a difference in the way data is being viewed might be the use of different feature sets or approaches when processing the signal. This could lead to variations in how boundaries are found within the data, even if the underlying features and boot models remain consistent throughout the process.&#10;&#10;Changing the training set by incorporating VTL (Vocal Tract Length) normalization during training might impact the conclusions since this can affect language scaling and acoustic scaling in the models being developed. However, as previously discussed, re-optimizing fudge factors related to these scalings has not made a significant difference in their results. Nonetheless, incorporating VTL into the training set could still have an effect on the final model's performance, especially when comparing male and female speakers.&#10;&#10;Retraining models using both the training and test sets with boot alignments can also help to improve the overall results. Based on their discussion, there is a potential for a slight improvement, around 1-2%, particularly for female speakers. However, this may not significantly change the way data is being viewed or the conclusions drawn from it.&#10;&#10;In summary, varying feature sets and signal processing techniques could be causing differences in how the data is being viewed. Introducing VTL normalization during training and using boot alignments in a combined training and test set might affect the final model's performance but may not have a substantial impact on the initial conclusions drawn from the study." target="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target=" digits , since they 're not here yet .&#10;Speaker: Grad F&#10;Content: Uh , so , we have a whole bunch of digits that we 've read and we have the forms and so on , um , but only a small number of that ha well , not a small number {disfmarker} only a subset of that has been transcribed . And so we need to decide what we wanna do . And , uh , Liz and Andreas {disfmarker} actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . And , again , I don't think we 'll be able to do with that alone , because , um , sometimes people correct themselves and things like that . But {disfmarker} so , I was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing .&#10;Speaker: Professor D&#10;Content: Well , forced alignment would be one thing . What about just actually doing recognition ?&#10;Speaker: Grad F&#10;Content: Well , we {disfmarker} we know what they read ,">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target=" Grad F&#10;Content: and don't bother actually computing the di writing down the digits .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: That 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later .&#10;Speaker: Grad F&#10;Content: Yep . And then I wanted to talk about {disfmarker} but as I said I {disfmarker} we may not have time {disfmarker} what we should do about digits . We have a whole pile of digits that haven't been transcribed .&#10;Speaker: Professor D&#10;Content: Le - let 's talk about it , because that 's {disfmarker} that 's something that I {disfmarker} I know Andreas is less interested in than Liz is ,&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: so , you know . It 's good {disfmarker}&#10;Speaker: Grad F&#10;Content: Do we have anything else to say about transcription ? About IBM stuff ?&#10;Speaker: PhD B&#10;Content: Uh ,">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target=" {disfmarker} uh , a unison .&#10;Speaker: Grad F&#10;Content: A unison digits ?&#10;Speaker: Postdoc A&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Yeah . Gets our {disfmarker}&#10;Speaker: Grad F&#10;Content: Which is gonna be a little hard for a couple people because we have different digits forms .&#10;Speaker: PhD E&#10;Content: Oops .&#10;Speaker: Grad F&#10;Content: We have a {disfmarker} I found a couple of old ones .&#10;Speaker: Professor D&#10;Content: Oh .&#10;Speaker: Grad H&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: Well , that 'll be interesting . So , uh {disfmarker}&#10;Speaker: Grad F&#10;Content: Have you done digits before ?&#10;Speaker: Professor D&#10;Content: No .&#10;Speaker: Grad C&#10;Content: I haven't done it .&#10;Speaker: Grad F&#10;Content: OK . So , uh , the idea is just to read each line {pause} with a short pause between lines ,&#10;Speaker: Grad C&#10;Content: Alright .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The group is discussing the use of &quot;digits&quot; in their work, which appear to be some form of transcriptions or recordings that need to be processed and categorized.&#10;2. A subset of these digits has already been transcribed, but there are many more that still need to be processed. The group is considering using automated methods, such as forced alignment and recognition, to help with this process.&#10;3. They acknowledge that automated methods may not be perfect and may require some manual cleaning or correction.&#10;4. The group also mentions the possibility of creating individual user IDs for everyone involved in the interactions, but they have not yet made a decision on this matter.&#10;5. The discussion about digits is important because they will be used as part of their meeting corpus and need to be organized and categorized properly. The group appears to be seeking ways to make the processing of these digits more efficient while also maintaining accuracy." target="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Grad F&#10;Content: and don't bother actually computing the di writing down the digits .&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Postdoc A&#10;Content: That 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later .&#10;Speaker: Grad F&#10;Content: Yep . And then I wanted to talk about {disfmarker} but as I said I {disfmarker} we may not have time {disfmarker} what we should do about digits . We have a whole pile of digits that haven't been transcribed .&#10;Speaker: Professor D&#10;Content: Le - let 's talk about it , because that 's {disfmarker} that 's something that I {disfmarker} I know Andreas is less interested in than Liz is ,&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: so , you know . It 's good {disfmarker}&#10;Speaker: Grad F&#10;Content: Do we have anything else to say about transcription ? About IBM stuff ?&#10;Speaker: PhD B&#10;Content: Uh ," target="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt." target="aker: Grad F&#10;Content: Do we have anything else to say about transcription ? About IBM stuff ?&#10;Speaker: PhD B&#10;Content: Uh , Brian {disfmarker} I {disfmarker} I {vocalsound} sent bresset {disfmarker} {vocalsound} {vocalsound} sent Brian a message about {pause} {vocalsound} the meeting and I haven't heard back yet . So . I g hope he got it and hopefully he 's {disfmarker}&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: Postdoc A&#10;Content: Hmm .&#10;Speaker: PhD B&#10;Content: maybe he 's gone , I dunno . He didn't even reply to my message . So . I should probably ping him just to make sure that he got it . &#10;Speaker: Grad F&#10;Content: Alright . So , we have a whole bunch of digits , if we wanna move on to digits .&#10;Speaker: Professor D&#10;Content: Actually , maybe I {disfmarker} One {disfmarker} one relate more related thing in transcription . So that 's the IBM stuff . We 've got">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt." target="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt." target="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The status of Brian is unclear, as PhD B mentions not receiving a response from him regarding a message about the meeting. They hope he received it and may plan to follow up with him.&#10;2. Yes, they can move on to discussing digits while they wait for Brian's response. Grad F brings up the topic of digits multiple times, indicating their importance in the conversation. Additionally, there are untranscribed digits that need processing.&#10;3. Professor D also has related transcription matters concerning IBM in mind, as she mentions wanting to discuss &quot;IBM transcription&quot; and something &quot;more related&quot; to it. However, they do not provide further details during the excerpt." target="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation." target="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The advantage of training a new model to use the visual representation from the channel being transcribed is that it helps in identifying any important content (&quot;blips&quot;) that might not have been included in the pre-segmented version. This is because the model can scan across the signal and find these blips, even if they were not distinguished in the pre-segmentation process. The visual representation provides additional context and information for the model to make more accurate predictions.&#10;2. Pre-segmentation still has its benefits, as it allows for skipping through large portions of audio with no activity, making the transcription process more efficient. This is possible because the audio quality is good enough to clearly distinguish active and inactive parts. However, using a model trained on visual representations can serve as a complementary approach to catch any important content that might have been missed during pre-segmentation." target="Based on the discussion had by Professor D and PhD I, the possible reasons for not observing any significant differences between the original and final models, despite trying to re-generate initial alignments with better models, include:&#10;&#10;1. The exact nature of boot alignments is not a significant factor in determining the quality of the final models. This means that even if they used different methods or techniques to improve the initial alignments, it may not have had a noticeable impact on the overall performance of the models.&#10;2. There were no changes in features or boot models used throughout the process. Since the same feature sets and base models were consistently applied, this could limit the potential for observing any significant improvements between iterations.&#10;3. The use of different feature sets or approaches when processing the signal might lead to variations in how boundaries are found within the data. This, in turn, may impact the performance of the models but not necessarily improve the overall quality and difference between the original and final models.&#10;4. Retraining models using both training and test sets with boot alignments has shown only a minor improvement (1-2%), particularly for female speakers, which might not be substantial enough to significantly change the way data is being viewed or the conclusions drawn from it.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so." target=" are every night , you can recycle the backed - up diskspace .&#10;Speaker: Grad F&#10;Content: Yeah . But that 's {disfmarker} that 's {disfmarker} {pause} that 's risky .&#10;Speaker: Professor D&#10;Content: Yeah . You really shouldn't be saying {disfmarker}&#10;Speaker: Grad F&#10;Content: Mmm . Mmm .&#10;Speaker: PhD I&#10;Content: I didn't say that .&#10;Speaker: Grad F&#10;Content: Yeah , that 's right .&#10;Speaker: PhD I&#10;Content: I didn't say that .&#10;Speaker: Grad F&#10;Content: Beep that out .&#10;Speaker: Professor D&#10;Content: Da - we had allowed Dave to listen to these {disfmarker} {vocalsound} these , {vocalsound} uh , recordings .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Um {disfmarker} {vocalsound} Yeah , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so." target=" @ i if you go to Dave , and {disfmarker} and {disfmarker} and ask him &quot; can I use your tape robot ? &quot; , he will say , &quot; well {pause} that 's gonna screw up our back - up operation . &quot;&#10;Speaker: Grad F&#10;Content: No , we won't . He 'll say &quot; if {disfmarker} if that means {pause} that it 's not gonna be backed - up standardly , great . &quot;&#10;Speaker: Professor D&#10;Content: He - I {disfmarker} Dave has {disfmarker} has promoted this in the past . So I don't think he 's actually against it .&#10;Speaker: Grad F&#10;Content: Yeah . It 's {disfmarker} it 's definitely no problem .&#10;Speaker: PhD I&#10;Content: Oh , OK . Alright .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Alright .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD I&#10;Content: Good .&#10;Speaker: PhD G&#10;Content: What about if the times overlap with the normal back">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so." target="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The risky behavior being discussed in relation to recycling backed-up disk space every night is not explicitly mentioned in the transcript. However, Grad F expresses concern about it being risky. The context suggests that they are discussing tape drive operations and potential interference with backup processes.&#10;2. Professor D had allowed Dave to listen to certain recordings. This is mentioned by Professor D when referring to a conversation regarding getting another file server: &quot;we had allowed Dave to listen to these recordings.&quot; It's unclear from the transcript what type of recordings Dave was listening to or why he was allowed to do so." target="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule." target="aker: Professor D&#10;Content: I mean , yeah , all the L&#10;Speaker: Grad F&#10;Content: I {disfmarker} I don't know many people who do it on CD . I mean , they 're {disfmarker} the most {disfmarker} fo&#10;Speaker: Professor D&#10;Content: LDC - all the LDC distributions are on CD - ROM .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: They 're on CD , but they 're not {disfmarker} tha that 's not the only source .&#10;Speaker: PhD G&#10;Content: Like {disfmarker}&#10;Speaker: Grad F&#10;Content: They have them on disk . And they burn new ones every once in a while . But if you go {disfmarker} {vocalsound} if you go k&#10;Speaker: PhD I&#10;Content: But , you know , we have {disfmarker}&#10;Speaker: PhD G&#10;Content: But we have like thirty {pause} you know , from {pause} ten years ago ?&#10;Speaker: Professor D&#10;Content: We have all">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule." target="aker: Professor D&#10;Content: Well , I don I wouldn't call reading digits &quot; meetings &quot; . Right ? I mean , we {disfmarker} we {disfmarker} we were doing {disfmarker}&#10;Speaker: Grad F&#10;Content: Well , but {disfmarker} but , {vocalsound} I put it under the same directory tree .&#10;Speaker: Professor D&#10;Content: Well {disfmarker}&#10;Speaker: Grad F&#10;Content: You know , it 's in &quot; user doctor speech data MR &quot; .&#10;Speaker: PhD G&#10;Content: Can we just have a directory called , like , &quot; other stuff &quot; ?&#10;Speaker: Grad F&#10;Content: Other .&#10;Speaker: PhD G&#10;Content: And {disfmarker} Well {disfmarker} or , I dunno .&#10;Speaker: Professor D&#10;Content: I mean , I don't care what directory tree you have it under .&#10;Speaker: PhD G&#10;Content: And {disfmarker} {vocalsound} and just , um , store it there .&#10;Speaker: Professor D&#10;Content: Right ? I mean that 's">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The different sources mentioned for where the LDC (Linguistic Data Consortium) distributions can be found are CD-ROM and disk. They also mention that new ones are burned every once in a while.&#10;2. The transcript does not provide specific information on how often new LDC distributions are being created. However, Grad F mentions that they &quot;have them on disk&quot; and &quot;burn new ones every once in a while,&quot; implying that it may happen periodically but not necessarily on a regular schedule." target="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences." target=" , sorry . OK . This is on {disfmarker}&#10;Speaker: PhD I&#10;Content: This is Hub - five .&#10;Speaker: PhD G&#10;Content: Oh , OK .&#10;Speaker: Grad F&#10;Content: Hub - five . Yeah .&#10;Speaker: PhD I&#10;Content: Yeah . Um , and the test data is CallHome and Switchboard . So , uh {disfmarker} so then {pause} um {disfmarker} Oh , and plus the {disfmarker} the vocal tract {pause} length normalization didn't {disfmarker} actually made things worse . So something 's really seriously wrong . So {disfmarker} Um {disfmarker}&#10;Speaker: Professor D&#10;Content: Aha ! OK .&#10;Speaker: PhD I&#10;Content: So {disfmarker} So {disfmarker}&#10;Speaker: Professor D&#10;Content: So {disfmarker} but you see , now , between {disfmarker} between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences." target=" the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what you were using before was scaling factors that were just from the {disfmarker} the m the {pause} SRI front - end . And that worked {disfmarker} that worked fine .&#10;Speaker: PhD I&#10;Content: That 's true . Yeah .&#10;Speaker: Professor D&#10;Content: Uh , but now you 're looking over a larger range and it may not be so fine .&#10;Speaker: PhD I&#10;Content: Well , um {disfmarker} So {disfmarker} I just {disfmarker} d so the one thing that I then tried was to put in the low - pass filter , which we have in the {disfmarker} So , most {disfmarker} most Hub - five systems actually band - limit the {disfmarker} uh , at about , uh , thirty - seven hundred , um , hertz .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: Although , you know , normally , I mean">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences." target=" .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: Although , you know , normally , I mean , the channel goes to four {disfmarker} four thousand . Right ? So , um {disfmarker} And that actually helped , uh {disfmarker} uh , a little bit .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: Um {pause} and it didn't hurt on the males either . So , um {disfmarker} And I 'm now , uh , trying the {disfmarker} Oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . So , you can do vocal tract length normalization on the test data only or on both the training and the test .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: And you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences." target="} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL ,&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD I&#10;Content: because if you don't do VTL in both systems , uh , you know , the {disfmarker} the females are considerably worse in the {disfmarker} with the PLP features .&#10;Speaker: Professor D&#10;Content: No {disfmarker} no . I {disfmarker} I remember that .&#10;Speaker: Grad F&#10;Content: It 's much worse . Yeah .&#10;Speaker: PhD I&#10;Content: So there must be some {disfmarker} something else going on .&#10;Speaker: PhD G&#10;Content: Well , what 's the standard {disfmarker} ? Yeah , so I thought the performance was actually a little better on females than males .&#10;Speaker: Grad F&#10;Content: That 's what I thought , too .&#10;Speaker: PhD I&#10;Content: Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with vocal tract length (VTL) normalization making things worse might be due to the specific implementation or interaction with other factors in the model. Although VTL normalization is generally beneficial for speech processing tasks, it can have negative effects if not properly integrated into the system. In this case, re-optimizing fudge factors related to language and acoustic scalings did not significantly improve the results, suggesting that there may be another issue at play.&#10;&#10;2. The difference in scaling range between males and females is likely due to physiological differences in their vocal tracts. Females typically have shorter and narrower vocal tracts than males, which can result in different acoustic properties and resonances. This difference might lead to larger scaling ranges when analyzing female speech compared to male speech, especially when using the SRI front-end or other feature sets that do not account for these differences effectively.&#10;&#10;3. The researchers mentioned that retraining models with boot alignments on both training and test sets could potentially improve results by around 1-2%, particularly for female speakers. This adjustment might help to better align and process the speech data, reducing the scaling range difference between males and females. However, it is unclear whether this improvement would significantly impact the initial conclusions drawn from the study.&#10;&#10;In summary, the negative effects of VTL normalization in this study may be due to implementation issues or interactions with other factors in the model. The larger scaling range differences between males and females are likely caused by physiological differences in their vocal tracts, which could potentially be addressed through improved feature sets or signal processing techniques that better account for these differences." target=": So {disfmarker} {comment} so , when {disfmarker} So I {disfmarker} I had {disfmarker} I ha&#10;Speaker: Grad F&#10;Content: That was a quick response .&#10;Speaker: PhD I&#10;Content: So , we had reached the point where {disfmarker}&#10;Speaker: PhD G&#10;Content: I 'm well rehearsed .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: we had reached the point where , {comment} um , on the male portion of the {pause} development set , the , um {disfmarker} or one of the development sets , I should say {disfmarker} {vocalsound} the , um {disfmarker} the male error rate with , uh , ICSI PLP features was pretty much identical with , uh , SRI features . which are {pause} MFCC . So , um , then I thought , &quot; Oh , great . I 'll j I 'll {disfmarker} just let 's make sure everything works on the females . &quot; And the error rate {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded." target=" is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got {vocalsound} {vocalsound} a speedup roughly proportional to the number of processors times the clock cycle .&#10;Speaker: PhD I&#10;Content: Oh .&#10;Speaker: Grad F&#10;Content: So , that 's pretty good .&#10;Speaker: PhD I&#10;Content: Oh ! Cool .&#10;Speaker: Grad F&#10;Content: Um , I 'm in the process of doing it for Quicknet , but there 's something going wrong and it 's about half the speed that I was estimating it should be , and I 'm not sure why .&#10;Speaker: PhD I&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: But I 'll keep working on it . But the {disfmarker} what it means is that it 's likely that for net training and forward passes , we 'll {disfmarker} Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors .&#10;Speaker: PhD I&#10;Content: A few more processors ?">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded." target=" .&#10;Speaker: Professor D&#10;Content: Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast News data or something else that actually has {disfmarker} has some noisy {disfmarker} {vocalsound} noisy components , so we can see if any conclusions we come to holds {vocalsound} across {pause} different data .&#10;Speaker: PhD I&#10;Content: So . Yeah . Right .&#10;Speaker: Professor D&#10;Content: Uh {disfmarker}&#10;Speaker: PhD I&#10;Content: And , uh , with this , I have to leave .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Grad H&#10;Content: Hmm !&#10;Speaker: Professor D&#10;Content: So , is there something quick about Absinthe {pause} that you {disfmarker} ?&#10;Speaker: PhD I&#10;Content: With this said .&#10;Speaker: Grad F&#10;Content: Uh . Just what we were talking about before , which is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded." target=" 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing .&#10;Speaker: PhD E&#10;Content: And also the SmartKom thing should b&#10;Speaker: Professor D&#10;Content: SmartKom also , Andreas . Absinthe , I think also he has sort of been involved in a lot of those things .&#10;Speaker: Grad F&#10;Content: At least ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: yeah , he 'll t he 'll probably be interested .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: But .&#10;Speaker: Professor D&#10;Content: Um So , I mean , I think they 'll be inter I 'll be interested in all this , but {disfmarker} but , uh , probably , if we had to pick something {pause} that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status , or {disfmarker} ?&#10;Speaker: Grad F&#10;Content: Yeah .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A Blass library was successfully ported to Absinthe by one of the team members.&#10;2. After porting, the Blass library was made to work with fast-forward, resulting in a significant speedup.&#10;3. The speedup achieved is roughly proportional to the number of processors times the clock cycle.&#10;4. This suggests that Absinthe will be an effective machine for net training and forward passes, especially if more processors are added or existing ones are upgraded." target=" . We {disfmarker} we sorta spot - checked it .&#10;Speaker: PhD B&#10;Content: I listened to {pause} probably , uh , five or ten minutes of it from the beginning .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: Oh , really ?&#10;Speaker: PhD B&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: OK .&#10;Speaker: PhD B&#10;Content: And {disfmarker}&#10;Speaker: Grad F&#10;Content: I sorta spot - checked here and there and it sounded pretty good . So . I think it 'll work .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Grad F&#10;Content: And , uh , we 'll just hafta see what we get back from them . Uh {disfmarker}&#10;Speaker: PhD B&#10;Content: And the main thing will be if we can align what they give us with what we sent them . I mean , that 's the crucial part .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: And I think we 'll be able to do that">
      <data key="d0">1</data>
    </edge>
    <edge source="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation." target=": PhD I&#10;Content: Um , so , {nonvocalsound} uh , we had a discussion {disfmarker} Don and Liz and I had discussion last week about how to proceed with , uh , you know , with Don 's work ,&#10;Speaker: PhD E&#10;Content: Ch&#10;Speaker: PhD I&#10;Content: and {disfmarker} {vocalsound} and {disfmarker} and , uh , one of the obvious things that occur to us was that we 're {disfmarker} since we now have Thilo 's segmenter and it works , you know , amazingly well , {vocalsound} um , we should actually basically re - evaluate the recognition , um , results using {disfmarker} you know , without cheating on the segmentations .&#10;Speaker: PhD E&#10;Content: So {disfmarker}&#10;Speaker: PhD I&#10;Content: And , that should be fairly {disfmarker}&#10;Speaker: PhD E&#10;Content: And how do we find the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ?&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation." target=" for {disfmarker} for the references and for {disfmarker} for the hypothesis ,&#10;Speaker: PhD I&#10;Content: So , we ha Yeah . Right .&#10;Speaker: PhD E&#10;Content: and {disfmarker} Yeah , OK .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Right .&#10;Speaker: PhD G&#10;Content: Maybe the {pause} start of your speech and the end of it ,&#10;Speaker: PhD I&#10;Content: So do&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: or stuff like that .&#10;Speaker: PhD I&#10;Content: Right . It does time - constrained word - alignment .&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD I&#10;Content: So . So that should be possible . I mean that shouldn't be a problem . Uh , so that was the one thing , and the other was that , um {disfmarker} What was the other problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation." target=" problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: Um , so that we could use , uh {disfmarker} you know there wouldn't be so much hand {vocalsound} labelling needed to , uh {disfmarker} to generate training data for {disfmarker} for the speech detector .&#10;Speaker: PhD E&#10;Content: Yeah . I 'm just in progress of {disfmarker} of doing that . So .&#10;Speaker: PhD I&#10;Content: And I think you 're in the process of doing that .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD I&#10;Content: So , you can {disfmarker} {comment} you can {disfmarker}&#10;Speaker: PhD B&#10;Content: It 'll give you a lot more data , too . Won't it ?&#10;Speaker: PhD E&#10;Content: Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {">
      <data key="d0">1</data>
    </edge>
    <edge source="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation." target=" the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ?&#10;Speaker: PhD I&#10;Content: Oh , OK . So , there 's actually {disfmarker}&#10;Speaker: PhD E&#10;Content: It 's not that {disfmarker}&#10;Speaker: PhD I&#10;Content: Why do you ask ?&#10;Speaker: Grad F&#10;Content: I could {disfmarker}&#10;Speaker: PhD I&#10;Content: No , actually , um , NIST has , um m a fairly sophisticated scoring program {vocalsound} that you can give a , um {disfmarker} {vocalsound} a time ,&#10;Speaker: Grad F&#10;Content: Hand ones .&#10;Speaker: PhD G&#10;Content: Well {disfmarker}&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD I&#10;Content: uh {disfmarker} You know , you basically just give two {pause} time - marked sequences of words , and it computes the um {disfmarker} the , {comment} uh {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The proposed way to locate the transcripts for the evaluated recognition results without using privileged segmentations is to use the newly trained model that has been trained to utilize a visual representation of the channel being transcribed at any given time. This approach aims to identify any &quot;blips&quot; or important content that might not have been included in the pre-segmented version, providing more accurate transcription results. While pre-segmentation still offers benefits such as skipping through large portions of audio with no activity, using a model trained on visual representations can serve as a complementary approach to ensure important content is not missed during pre-segmentation." target="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target=" .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} I mean it {disfmarker} sure , there {disfmarker} there might be a place where it 's &quot; beep seven {pause} beep eight {pause} beep {pause} eight {pause} beep &quot; . But , you know , they {disfmarker} they 're {disfmarker} they 're gonna macros for inserting the beep marks . And so , I {disfmarker} I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem .&#10;Speaker: Professor D&#10;Content: OK . Well , I {disfmarker} I {disfmarker} I dunno , I {disfmarker} I think that that 's {disfmarker} if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is {disfmarker} needs to be much less elaborate for digits than for other stuff .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target=": PhD E&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Grad F&#10;Content: Well , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that ,&#10;Speaker: PhD B&#10;Content: Yeah . That 's what I thought .&#10;Speaker: Grad F&#10;Content: so .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: I it 's probably just , you know , mmm , somehow the audio {pause} device gets hung for a second ,&#10;Speaker: PhD E&#10;Content: Yeah . Some latency or something .&#10;Speaker: Grad F&#10;Content: Hiccups .&#10;Speaker: PhD E&#10;Content: Yeah ?&#10;Speaker: Postdoc A&#10;Content: As long as they have one number , and they know that there 's only one beep maximum {vocalsound} that goes with that number .&#10;Speaker: PhD B&#10;Content: or {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Right .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target=" .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: And I think we 'll be able to do that at {disfmarker} with this new beep format .&#10;Speaker: Grad F&#10;Content: Yep . Well , I think it 's also they are much less likely to d have errors .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: I mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or {disfmarker} and they put in extraneous beeps .&#10;Speaker: PhD B&#10;Content: Right . Yeah .&#10;Speaker: Grad F&#10;Content: And with the numbers there , it 's much less likely .&#10;Speaker: PhD B&#10;Content: Yeah , one interesting note is {disfmarker} uh , or problem {disfmarker} I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @ {comment} uh , like a beep sounds like">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target=" since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh&#10;Speaker: Grad F&#10;Content: OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes &quot; beep one beep &quot; and then the phrase , and then &quot; beep two beep &quot; and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .&#10;Speaker: PhD E&#10;Content: And we have done that on the {pause} automatic segmentations .&#10;Speaker: Grad F&#10;Content: And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it .&#10;Speaker: PhD B&#10;Content: I listened to {pause} probably">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target=" or {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Right .&#10;Speaker: Grad F&#10;Content: Yeah . The only {disfmarker} the only part that might be confusing is when Chuck is reading digits .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Postdoc A&#10;Content: Well , you know , actually , are we having them {disfmarker}&#10;Speaker: PhD B&#10;Content: So {vocalsound} th&#10;Speaker: Grad F&#10;Content: &quot; Seven four eight beep seven beep {vocalsound} eight three two &quot; .&#10;Speaker: Postdoc A&#10;Content: Yeah , but are we having them do digits ?&#10;Speaker: Grad F&#10;Content: Yes . Because , uh , we don't {disfmarker} we didn't {disfmarker} In order to cut them out we 'd have to listen to it .&#10;Speaker: PhD B&#10;Content: We {disfmarker} we didn't cut those out .&#10;Speaker: PhD E&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. One possibility is that the audio device or software experiences latency or brief interruptions, causing it to add extra beeps. This can potentially be resolved by improving the stability and performance of the audio recording equipment or software.&#10;2. Another reason could be human error, where the settings for the number of beeps per number have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. A third possibility is that there are inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.&#10;4. To ensure only one beep per number, the group could consider using a different method for marking numbers, such as spoken digits or unique identifiers, which would reduce the likelihood of errors and make it easier to keep track of where they are in the file. This new format has already been tested and seems promising.&#10;5. Regularly spot-checking and listening to the processed files can help identify any issues early on and ensure that the automated methods are working as intended. If errors are found, adjustments can be made to improve the accuracy of the processing." target="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: So {disfmarker} I mean it {disfmarker} sure , there {disfmarker} there might be a place where it 's &quot; beep seven {pause} beep eight {pause} beep {pause} eight {pause} beep &quot; . But , you know , they {disfmarker} they 're {disfmarker} they 're gonna macros for inserting the beep marks . And so , I {disfmarker} I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem .&#10;Speaker: Professor D&#10;Content: OK . Well , I {disfmarker} I {disfmarker} I dunno , I {disfmarker} I think that that 's {disfmarker} if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is {disfmarker} needs to be much less elaborate for digits than for other stuff .&#10;Speaker:" target="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.">
      <data key="d0">1</data>
    </edge>
    <edge source=": PhD E&#10;Content: Yep .&#10;Speaker: PhD B&#10;Content: So .&#10;Speaker: Grad F&#10;Content: Well , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that ,&#10;Speaker: PhD B&#10;Content: Yeah . That 's what I thought .&#10;Speaker: Grad F&#10;Content: so .&#10;Speaker: Postdoc A&#10;Content: Mm - hmm .&#10;Speaker: PhD B&#10;Content: I it 's probably just , you know , mmm , somehow the audio {pause} device gets hung for a second ,&#10;Speaker: PhD E&#10;Content: Yeah . Some latency or something .&#10;Speaker: Grad F&#10;Content: Hiccups .&#10;Speaker: PhD E&#10;Content: Yeah ?&#10;Speaker: Postdoc A&#10;Content: As long as they have one number , and they know that there 's only one beep maximum {vocalsound} that goes with that number .&#10;Speaker: PhD B&#10;Content: or {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Right .&#10;" target="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Grad F&#10;Content: Right .&#10;Speaker: PhD B&#10;Content: And I think we 'll be able to do that at {disfmarker} with this new beep format .&#10;Speaker: Grad F&#10;Content: Yep . Well , I think it 's also they are much less likely to d have errors .&#10;Speaker: PhD B&#10;Content: Mm - hmm .&#10;Speaker: Grad F&#10;Content: I mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or {disfmarker} and they put in extraneous beeps .&#10;Speaker: PhD B&#10;Content: Right . Yeah .&#10;Speaker: Grad F&#10;Content: And with the numbers there , it 's much less likely .&#10;Speaker: PhD B&#10;Content: Yeah , one interesting note is {disfmarker} uh , or problem {disfmarker} I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @ {comment} uh , like a beep sounds like" target="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.">
      <data key="d0">1</data>
    </edge>
    <edge source=" since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh&#10;Speaker: Grad F&#10;Content: OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes &quot; beep one beep &quot; and then the phrase , and then &quot; beep two beep &quot; and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .&#10;Speaker: PhD E&#10;Content: And we have done that on the {pause} automatic segmentations .&#10;Speaker: Grad F&#10;Content: And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it .&#10;Speaker: PhD B&#10;Content: I listened to {pause} probably" target="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording.">
      <data key="d0">1</data>
    </edge>
    <edge source=" since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh&#10;Speaker: Grad F&#10;Content: OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes &quot; beep one beep &quot; and then the phrase , and then &quot; beep two beep &quot; and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .&#10;Speaker: PhD E&#10;Content: And we have done that on the {pause} automatic segmentations .&#10;Speaker: Grad F&#10;Content: And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it .&#10;Speaker: PhD B&#10;Content: I listened to {pause} probably" target="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.">
      <data key="d0">1</data>
    </edge>
    <edge source=" or {disfmarker}&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD B&#10;Content: Yeah . Right .&#10;Speaker: Grad F&#10;Content: Yeah . The only {disfmarker} the only part that might be confusing is when Chuck is reading digits .&#10;Speaker: PhD B&#10;Content: Right .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Postdoc A&#10;Content: Well , you know , actually , are we having them {disfmarker}&#10;Speaker: PhD B&#10;Content: So {vocalsound} th&#10;Speaker: Grad F&#10;Content: &quot; Seven four eight beep seven beep {vocalsound} eight three two &quot; .&#10;Speaker: Postdoc A&#10;Content: Yeah , but are we having them do digits ?&#10;Speaker: Grad F&#10;Content: Yes . Because , uh , we don't {disfmarker} we didn't {disfmarker} In order to cut them out we 'd have to listen to it .&#10;Speaker: PhD B&#10;Content: We {disfmarker} we didn't cut those out .&#10;Speaker: PhD E&#10;Content" target="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, based on the transcript, the digits read by Chuck were not edited out in the final version of the audio recording that is being discussed. This was stated explicitly by PhD B when they said &quot;We didn't cut those out.&quot; Additionally, Grad F mentioned that separating each beep with a spoken digit, including those recorded by Chuck, seemed pretty good and made it easier to keep track of where they are in the file. Therefore, it can be concluded that the digits read by Chuck were not edited out in the final version of the audio recording." target="1. Audio device latency or brief interruptions: PhD B suggests that the audio device or software may be experiencing latency or brief interruptions, causing it to add extra beeps. Improving the stability and performance of the audio recording equipment or software could resolve this issue.&#10;2. Human error in settings configuration: Grad F mentions the possibility of human error, where the settings for the number of beeps per number may have been misconfigured in the software. Checking and adjusting the settings accordingly should resolve this issue.&#10;3. Inconsistencies in manual processing: Postdoc A points out that there could be inconsistencies in the way beeps are inserted during manual processing. Implementing standardized procedures and training for beep insertion can help minimize these errors.">
      <data key="d0">1</data>
    </edge>
    <edge source="If an automated transcription service like IBM transcribes sensitive information such as a phone number during a meeting, there is a risk of exposing this confidential data. This could potentially lead to privacy issues or unauthorized access to the mentioned resources. To prevent this, it's essential to configure the transcription settings appropriately and consider using alternative methods for marking important information, like spoken digits or unique identifiers, which would reduce the likelihood of errors and maintain data security. Regularly monitoring and adjusting the processing methods can also help ensure accurate and secure transcriptions." target=" some people , or use the transcribers to do it . We could let IBM transcribe it . You know , they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . Um , or we could try some automated methods .&#10;Speaker: Professor D&#10;Content: Well {disfmarker}&#10;Speaker: Grad F&#10;Content: And my {disfmarker} my tendency right now is , well , if IBM comes back with this meeting and the transcript is good , just let them do it .&#10;Speaker: Professor D&#10;Content: Yeah , it 's {disfmarker} Y you raised a point , kind of , uh , euphemistically {disfmarker} but , I mean , m maybe it is a serious problem . Ho - what will they do when they go {disfmarker} hear &quot; beep {pause} seven {pause} beep {pause} seven three five two &quot; {disfmarker} I mean , {vocalsound} you think they 'll {disfmarker} we 'll get {disfmarker} ?&#10;Speaker: Grad F&#10;Content: It 's pretty distinct .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. CD-ROMs and DVDs can degrade or fail over time, even when stored professionally. The average lifespan of these storage mediums is around three to four years, but they have been known to fail in as little as one year. This is due to the gradual breakdown of the materials used to store data on the disks.&#10;2. When a disk fails, any data stored on it will be lost unless there are other copies available. Relying solely on CD-ROMs or DVDs for storage therefore presents a risk of data loss.&#10;3. Although read and write operations do not significantly contribute to the degradation of these disks, they can still wear out from simply sitting on a shelf. This is because the materials used to store data naturally degrade over time.&#10;4. To mitigate the risk of data loss, it is recommended to use other storage mediums such as tape, which are known for their reliability and longevity. Creating additional copies of important data on these mediums can ensure its availability in case of a failure." target=" I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {disfmarker} What about putting the stuff on , like , C - CD - ROM or DVD or something ?&#10;Speaker: Grad F&#10;Content: Yeah . That was me . I was the one who said it was not reliable . The - they {disfmarker} they wear out .&#10;Speaker: PhD I&#10;Content: OK . Oh , OK .&#10;Speaker: Grad F&#10;Content: Yeah . The {disfmarker} the {disfmarker} th&#10;Speaker: PhD I&#10;Content: But they wear out just from sitting on the shelf ?&#10;Speaker: Grad F&#10;Content: Yep . Absolutely .&#10;Speaker: PhD I&#10;Content: Or from being {pause} read and read ?&#10;Speaker: Grad F&#10;Content: No . Read and write don't hurt them too much unless you scratch them .&#10;Speaker: PhD I&#10;Content: Oh , OK .&#10;Speaker: Grad F&#10;Content: But the r the write once , and the read - writes , don't last . So you don't">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
