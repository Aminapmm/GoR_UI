<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." />
    <node id=" our {disfmarker}&#10;Speaker: PhD F&#10;Content: Maybe the sections that are not right afte you know , after lunch when everybody 's still munching and {disfmarker}&#10;Speaker: PhD A&#10;Content: So can you send out a schedule once you know it , jus ?&#10;Speaker: Professor B&#10;Content: OK . Well {disfmarker}&#10;Speaker: PhD A&#10;Content: Is {disfmarker} is there a r ?&#10;Speaker: Professor B&#10;Content: OK . Yeah . I guess I sent it around a little bit .&#10;Speaker: PhD A&#10;Content: There 's a res Is it changed now , or {disfmarker} ?&#10;Speaker: Professor B&#10;Content: But {disfmarker} I hadn't heard back from Mari after I {disfmarker} I u u uh , brought up the point abou about Andreas 's schedule . So , {vocalsound} um , maybe when I get back there 'll be {pause} some {disfmarker} some mail from her .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor B" />
    <node id="mm !&#10;Speaker: Professor B&#10;Content: And Andreas has the last word .&#10;Speaker: Grad E&#10;Content: Did you read it twice or what ?&#10;Speaker: PhD A&#10;Content: He 's try No , he 's trying to get good recognition performance .&#10;Speaker: Postdoc C&#10;Content: He had the h&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: He had the {disfmarker} the long form .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: And we 're off .&#10;Speaker: PhD F&#10;Content: No ." />
    <node id="Speaker: Grad E&#10;Content: OK , we 're on .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: Grad E&#10;Content: So , I mean , everyone who 's on the wireless check that they 're on .&#10;Speaker: PhD F&#10;Content: C we {disfmarker}&#10;Speaker: Grad G&#10;Content: Alright .&#10;Speaker: Postdoc C&#10;Content: I see . Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: OK , our agenda was quite short .&#10;Speaker: Professor B&#10;Content: Oh , could you {pause} close the door , maybe ? Yeah .&#10;Speaker: Grad E&#10;Content: Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,&#10;Speaker: Professor B&#10;Content: &#10;Speaker: Grad E&#10;Content: but they didn't ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for" />
    <node id=" Yeah .&#10;Speaker: Grad E&#10;Content: Have them all read them at once .&#10;Speaker: PhD A&#10;Content: Well , different digits&#10;Speaker: PhD D&#10;Content: Eh {disfmarker}&#10;Speaker: PhD A&#10;Content: but same groupings .&#10;Speaker: Grad E&#10;Content: Or {disfmarker} or just same digits .&#10;Speaker: PhD A&#10;Content: So they would all be {disfmarker} Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah . That 'd be good .&#10;Speaker: Grad E&#10;Content: See if anyone notices .&#10;Speaker: Professor B&#10;Content: There 's so many possibilities .&#10;Speaker: Postdoc C&#10;Content: And then {disfmarker} then we can sing them next time .&#10;Speaker: Professor B&#10;Content: Uh . OK , why don't we go ? Uh , one two three {disfmarker} Go !&#10;Speaker: Postdoc C&#10;Content: OK . Mmm !&#10;Speaker: Professor B&#10;Content: And Andreas has the last word .&#10;Speaker: Grad E&#10;Content: Did you read it twice" />
    <node id="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for which I {disfmarker}&#10;Speaker: Grad E&#10;Content: so .&#10;Speaker: PhD F&#10;Content: We should do that second , because Liz might join us in time for that .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Um . OK , so there 's digits , alignments , and , um , I guess the other thing , {vocalsound} which I came unprepared for , uh , {vocalsound} is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: So . Any {disfmarker} I mean , maybe not .&#10;Speaker: Grad E&#10;Content: Digits and alignments . But {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh .&#10;Speaker: PhD F&#10;Content: Talk about aligning people 's schedules .&#10;Speaker: Professor B&#10;Content: Yeah" />
    <node id="&#10;Content: Are we meeting in here probably or {disfmarker} ? OK .&#10;Speaker: Professor B&#10;Content: Yeah . That was my thought .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I think this is {disfmarker}&#10;Speaker: PhD F&#10;Content: Are we recording it ?&#10;Speaker: PhD A&#10;Content: We won't have enough microphones ,&#10;Speaker: Professor B&#10;Content: &#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Professor B&#10;Content: u No . I {disfmarker} I hadn't in intended to .&#10;Speaker: PhD A&#10;Content: There 's no way .&#10;Speaker: Professor B&#10;Content: We won we wanna {disfmarker} I mean , they 're {disfmarker} there 's gonna be , uh , Jeff , Katrin , Mari and two students .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: So there 's five {pause} from there .&#10;Speaker: Grad E&#10;Content: And Brian .&#10;Spe" />
    <node id="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." />
    <node id="er} it won't leave this room .&#10;Speaker: Professor B&#10;Content: Alright , so in the interest of getting to the {disfmarker}&#10;Speaker: PhD A&#10;Content: We could do digits while other people eat .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So it 's background crunching .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: We don't have background chewing .&#10;Speaker: Postdoc C&#10;Content: Nice .&#10;Speaker: PhD H&#10;Content: Is , eh , a {disfmarker} another acoustic event .&#10;Speaker: PhD D&#10;Content: Background crunch . Yeah .&#10;Speaker: PhD A&#10;Content: No , we don't have any data with background eating .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I 'm serious . You&#10;Speaker: Professor B&#10;Content: She 's {disfmarker" />
    <node id=" That 's nice .&#10;Speaker: PhD H&#10;Content: But , eh {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Oh , thanks , Jose .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: Postdoc C&#10;Content: Wow .&#10;Speaker: PhD H&#10;Content: To Andreas , the idea is {disfmarker} is good . {vocalsound} s To eat here .&#10;Speaker: Professor B&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Postdoc C&#10;Content: Wow . Very nice .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD A&#10;Content: Oh , wow .&#10;Speaker: Professor B&#10;Content: Tha - that 's {disfmarker} that looks great .&#10;Speaker: PhD F&#10;Content: Oh , yeah . Th - it doesn't {disfmarker} it won't leave this room .&#10;Speaker: Professor B&#10;Content: Alright , so in the interest of getting to the {disfmark" />
    <node id=" A&#10;Content: I the first time is {pause} traumatic ,&#10;Speaker: Professor B&#10;Content: We&#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Professor B&#10;Content: Y {vocalsound} Yeah , bu&#10;Speaker: Postdoc C&#10;Content: Oh , and the groupings are important ,&#10;Speaker: PhD H&#10;Content: Mmm .&#10;Speaker: Postdoc C&#10;Content: so yo you 're supposed to pause between the groupings .&#10;Speaker: PhD H&#10;Content: The grouping .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK . So , uh {disfmarker}&#10;Speaker: PhD F&#10;Content: You mean that the {disfmarker} the grouping is supposed to be synchronized ?&#10;Speaker: Professor B&#10;Content: No , no .&#10;Speaker: Postdoc C&#10;Content: No .&#10;Speaker: Grad E&#10;Content: Yeah , sure .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: That 'd be good" />
    <node id="&#10;Speaker: Grad E&#10;Content: And then it {disfmarker}&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: I already {pause} tried to get it close .&#10;Speaker: Postdoc C&#10;Content: Good .&#10;Speaker: Grad E&#10;Content: So if it doesn't bounce around too much , that 's actually good placement .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc C&#10;Content: That looks good .&#10;Speaker: Grad E&#10;Content: But it looks like it 's gonna bounce a lot .&#10;Speaker: Professor B&#10;Content: So , where were we ? Uh {disfmarker} {vocalsound} Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Digits . Adaptation .&#10;Speaker: Professor B&#10;Content: Uh , adaptation , non - adaptation , um , factor of two , um {disfmarker} Oh , yeah . I know what I was go w&#10;Speaker: PhD F&#10;Content: What k u By the way" />
    <node id=" Postdoc C&#10;Content: I think we can ha&#10;Speaker: PhD F&#10;Content: bec b {vocalsound} Nah {disfmarker}&#10;Speaker: PhD A&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: Postdoc C&#10;Content: Nah .&#10;Speaker: PhD F&#10;Content: i Because these {disfmarker} the conference organizers actually have an interest in getting lots of submissions .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I mean , a {disfmarker} a monetary interest .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: So {disfmarker} {vocalsound} Um .&#10;Speaker: Professor B&#10;Content: Th - that 's {disfmarker} that 's true .&#10;Speaker: Postdoc C&#10;Content: And good ones , good ones , which sometimes means {pause} a little extra time .&#10;Speaker: PhD F&#10;Content:" />
    <node id="&#10;Speaker: PhD A&#10;Content: I 'm serious . You&#10;Speaker: Professor B&#10;Content: She 's {disfmarker} she 's serious .&#10;Speaker: PhD A&#10;Content: I am serious .&#10;Speaker: Grad E&#10;Content: It 's just the rest of the digits {disfmarker} the rest of the digits are very clean ,&#10;Speaker: Professor B&#10;Content: She is serious .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: Well {disfmarker} ?&#10;Speaker: PhD H&#10;Content: Are you {disfmarker} ? Oh , they 're clean .&#10;Speaker: PhD D&#10;Content: Yeah !&#10;Speaker: Grad E&#10;Content: um , without a lot of background noise ,&#10;Speaker: PhD A&#10;Content: And it {disfmarker} You have to write down , like , while y what you 're {disfmarker} what ch chocolate you 're eating&#10;Speaker: Grad E&#10;Content: so I 'm just not sure {disfmarker}&#10;Speaker: PhD A&#10;Content: c" />
    <node id="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." />
    <node id=" a verb now .&#10;Speaker: Postdoc C&#10;Content: I know {disfmarker} I know Ch - Chafe dealt with {disfmarker}&#10;Speaker: PhD F&#10;Content: So s&#10;Speaker: Grad G&#10;Content: That 's cool .&#10;Speaker: PhD F&#10;Content: W uh , w&#10;Speaker: Postdoc C&#10;Content: Chafe speaks about intonation units .&#10;Speaker: PhD A&#10;Content: Yes . Right .&#10;Speaker: Postdoc C&#10;Content: But maybe he speaks about spurts as well&#10;Speaker: PhD F&#10;Content: We&#10;Speaker: Postdoc C&#10;Content: and I just don't know . Yeah , go ahead .&#10;Speaker: Grad E&#10;Content: I 've heard &quot; burst &quot; also .&#10;Speaker: PhD F&#10;Content: So what we 're doing {disfmarker} uh , this {disfmarker} this is just {disfmarker} maybe someone has s some {disfmarker} some ideas about how to do it better ,&#10;Speaker: Grad G&#10;Content: Mmm .&#10;Speaker: PhD F&#10;Content: but" />
    <node id=": Well , see , I know S Sue wrote about spurts of development .&#10;Speaker: PhD F&#10;Content: So maybe we should talk {disfmarker}&#10;Speaker: PhD A&#10;Content: Maybe it was Sue {disfmarker} ? Y&#10;Speaker: Postdoc C&#10;Content: But , in any case , I think it 's a good term ,&#10;Speaker: PhD A&#10;Content: So we have spurts and we have spurt - ify dot shell and spurt - ify&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: and , uh {disfmarker}&#10;Speaker: Grad E&#10;Content: Hmm !&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: And ma maybe {disfmarker} maybe Chafe did .&#10;Speaker: PhD F&#10;Content: Uh .&#10;Speaker: PhD A&#10;Content: And then it 's got all {disfmarker} it 's a verb now .&#10;Speaker: Postdoc C&#10;Content: I know {disfmarker} I know Ch - Chafe dealt with {d" />
    <node id=" also ?&#10;Speaker: PhD A&#10;Content: so {disfmarker}&#10;Speaker: Grad E&#10;Content: Spurt has the horrible name overloading with other {disfmarker} with hardware at ICSI .&#10;Speaker: Professor B&#10;Content: Here . Just very locally , yeah .&#10;Speaker: PhD A&#10;Content: Well , well , Chafe had this wor I think it was Chafe , or somebody had a {disfmarker} the word &quot; spurt &quot; originally ,&#10;Speaker: Professor B&#10;Content: But {disfmarker} but that just {disfmarker}&#10;Speaker: PhD H&#10;Content: Here @ @ {disfmarker}&#10;Speaker: PhD A&#10;Content: and so I {disfmarker} But tha that 's good to know .&#10;Speaker: Postdoc C&#10;Content: Actually {disfmarker}&#10;Speaker: PhD A&#10;Content: Was thi it 's Chafe ?&#10;Speaker: Postdoc C&#10;Content: Well , see , I know S Sue wrote about spurts of development .&#10;Speaker: PhD F&#10;Content: So maybe we should talk {d" />
    <node id=" {pause} pauses around it ?&#10;Speaker: Postdoc C&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: Yeah . I know that th the Telecom people use {disfmarker} use &quot; spurt &quot; for that .&#10;Speaker: Postdoc C&#10;Content: Good .&#10;Speaker: PhD A&#10;Content: They do ? Oh !&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: Professor B&#10;Content: And that 's {disfmarker} I mean , I {disfmarker} I was using that for a while when I was doing the rate of speech stuff ,&#10;Speaker: PhD A&#10;Content: I would jus&#10;Speaker: Professor B&#10;Content: because I {disfmarker} because I looked up in some books and I found {disfmarker} OK , I wanna find a spurt {vocalsound} in which {disfmarker}&#10;Speaker: PhD A&#10;Content: Ah , right ! It 's just , like , defined by the acoustics .&#10;Speaker: Professor" />
    <node id="&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: and {disfmarker} and how many speakers per utterance .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker}&#10;Speaker: PhD F&#10;Content: Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker}&#10;Speaker: Grad E&#10;Content: I strongly suspect that they have more speakers than we do . So , uh {disfmark" />
    <node id=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content" />
    <node id="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." />
    <node id="marker} that were correctable .&#10;Speaker: Professor B&#10;Content: Mmm . Yeah .&#10;Speaker: Grad E&#10;Content: So that , if someone just read the wrong digit , I corrected it .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: And then there was another one where Jose couldn't tell whether {disfmarker} I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either .&#10;Speaker: Grad I&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: So I just cut it out .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: You know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially {disfmarker} I think TI - digits is all {pause} American English .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Right ? So it" />
    <node id="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So , {vocalsound} one {disfmarker} so there were a number of things we noted from this .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: One is , yeah , the SRI system is a lot better than the HTK {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: this , you know , very limited training HTK system .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for" />
    <node id=" tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No .&#10;Speaker: Professor B&#10;Content: It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker}&#10;Speaker: PhD F&#10;Content: But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits .&#10;Speaker: Grad E&#10;Content: I bet it would do even slightly better .&#10;Speaker: PhD F&#10;Content: I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: and I could ask them what they get {pause} on TI - digits .&#10;Spe" />
    <node id="&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: That would be the , sort of {disfmarker} probably the safest way to do {disfmarker}&#10;Speaker: Grad E&#10;Content: I might have to do that anyway to {disfmarker} to do {disfmarker} because we may have to do an extract to get the {pause} amount of data per speaker about right .&#10;Speaker: PhD F&#10;Content: Uh - huh .&#10;Speaker: Grad E&#10;Content: The other thing is , isn't TI - digits isolated digits ?&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Or is that another one ? I 'm {disfmarker} I looked through a bunch of the digits t corp corpora , and now they 're all blurring .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cuz one of them was literally people reading a single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think" />
    <node id=" and , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or {disfmarker}&#10;Speaker: Grad E&#10;Content: Wha - what 's TI - digits ? I thought t&#10;Speaker: Professor B&#10;Content: It 's wide - band , yeah . It 's {disfmarker} in {disfmarker} in fact , we looked it up&#10;Speaker: Grad E&#10;Content: It is wide - band . OK .&#10;Speaker: Professor B&#10;Content: and it was actually twenty kilohertz sampling .&#10;Speaker: Grad E&#10;Content: Oh , that 's right . I {disfmarker} I did look that up .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: I couldn't remember whether that was TI - digits or one of the other digit tasks .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right . But {disf" />
    <node id="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" />
    <node id="&#10;Content: Yeah , sure .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: That 'd be good .&#10;Speaker: Professor B&#10;Content: Synchronized digits .&#10;Speaker: Postdoc C&#10;Content: No .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: We - we 'll give everybody the same sheet&#10;Speaker: PhD F&#10;Content: It 's like a {disfmarker} like a Greek {disfmarker} like a Greek choir ?&#10;Speaker: PhD A&#10;Content: but they say different {disfmarker}&#10;Speaker: PhD F&#10;Content: You know ?&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: Grad E&#10;Content: Hey , what a good idea .&#10;Speaker: PhD F&#10;Content: Like {disfmarker}&#10;Speaker: Grad E&#10;Content: We could do the same sheet for everyone .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Have them all read them at once .&#10;Speaker: PhD A&#10;Content: Well , different digits" />
    <node id="m - hmm .&#10;Speaker: PhD F&#10;Content: and I could ask them what they get {pause} on TI - digits .&#10;Speaker: Professor B&#10;Content: Yeah , bu although I 'd be {disfmarker} I think it 'd be interesting to just take this exact actual system so that these numbers were comparable&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: and try it out on TI - digits .&#10;Speaker: PhD F&#10;Content: Well , Adam knows how to run it ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah . No problem .&#10;Speaker: PhD F&#10;Content: so you just make a f&#10;Speaker: Professor B&#10;Content: Yeah . Yeah . Cuz our sense from the other {disfmarker} from the Aurora , uh , task is that {disfmarker}&#10;Speaker: Grad E&#10;Content: And try it with TI - digits ?&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , cuz we were getting sub one" />
    <node id="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." />
    <node id=" {pause} some {disfmarker} some mail from her .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: So , I 'll make a {disfmarker}&#10;Speaker: Postdoc C&#10;Content: I 'm looking forward to seeing your representation . That 'd be , uh {disfmarker}&#10;Speaker: PhD A&#10;Content: And w we should get {pause} the two meetings from y&#10;Speaker: Postdoc C&#10;Content: I 'd like to see that . Yeah .&#10;Speaker: PhD A&#10;Content: I mean , I know about the first meeting , um , but the other one that you did , the NSA one , which we {pause} hadn't done cuz we weren't running recognition on it , because the non - native speaker {disfmarker}&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: there were five non - native speakers .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm . I see . Mm - hmm .&#10;Speaker: PhD A&#10;Content: But , it would" />
    <node id=" confuse somebody who looks at these later .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: I mean , this is {disfmarker} we we 're recording secret NSA meetings ?&#10;Speaker: PhD F&#10;Content: Um . Not the {disfmarker}&#10;Speaker: Professor B&#10;Content: I mean , it 's {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah . Not that NSA .&#10;Speaker: PhD F&#10;Content: Uh . The {disfmarker} th the {disfmarker}&#10;Speaker: PhD A&#10;Content: They are hard to understand .&#10;Speaker: Professor B&#10;Content: It 's network services and applications .&#10;Speaker: PhD F&#10;Content: Wait .&#10;Speaker: PhD A&#10;Content: They 're very , uh , out there .&#10;Speaker: PhD F&#10;Content: The {disfmarker}&#10;Speaker: PhD A&#10;Content: I have no idea what they 're talking about .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F" />
    <node id=" try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: and we don't know what people are doing . Try to create a paper out of that .&#10;Speaker: Professor B&#10;Content: Yeah . I mean , y y you folks have probably {pause} already told me , but were {disfmarker} were you intending to do a Eurospeech submission , or {disfmarker} ?&#10;Speaker: PhD A&#10;Content: Um , you mean the one due tomorrow ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Yeah . Well , we 're still , like , writing the scripts for doing the research , and we will {disfmarker} Yes , we 're gonna try .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And I was telling Don , do not {" />
    <node id=" find in common {disfmarker} roughly in common , was on a Saturday .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Ugh .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: It 's pretty sad .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Have {disfmarker} Have we thought about having a conference call to include him in more of {disfmarker} {vocalsound} in more of the meeting ? I {disfmarker} I mean , I don't know , if we had the {disfmarker} if we had the telephone on the table {disfmarker}&#10;Speaker: Professor B&#10;Content: No . But , h I mean , he probably has to go do something .&#10;Speaker: PhD F&#10;Content: No , actually I {disfmarker} I have to {disfmarker} I have to shuttle {pause} kids from various places to various other places .&#10;Speaker: Professor B&#10;Content: Right ?" />
    <node id="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." />
    <node id="aker: PhD A&#10;Content: Well , yeah . You could look at , I guess , that PZM or something .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: Professor B&#10;Content: But the other is , it 's very , uh {disfmarker} I mean , even though there 's {disfmarker} I 'm sure the f f the {disfmarker} the SRI , uh , front - end has some kind of pre - emphasis , it 's {disfmarker} it 's , uh {disfmarker} {vocalsound} still , th it 's picking up lots of low - frequency energy .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So , even discriminating against it , I 'm sure some of it 's getting through . Um . But , yeah , you 're right . Prob - a part of it is just the distance .&#10;Speaker: PhD A&#10;Content: And aren't these pretty bad microphones ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean {disfmark" />
    <node id="'t these pretty bad microphones ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean {disfmarker}&#10;Speaker: Professor B&#10;Content: Well , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah .&#10;Speaker: Grad E&#10;Content: Yeah . When you listen to it , uh , the PZM and the PDA {disfmarker} Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty {disfmarker} uh , pretty much the same .&#10;Speaker: PhD A&#10;Content: I just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So .&#10;Speaker: Professor B&#10;Content: Well , they 're {pause} twenty - five cents or so .&#10;Speaker: Grad E&#10;Content: Th - we wanted them to be {disfmarker} to be typical of what would be in a PDA .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Spe" />
    <node id=" single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .&#10;Speaker: Grad E&#10;Content: Maybe it 's the Bell Gram . Bell Digits . Alright .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that" />
    <node id="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios." />
    <node id=" a PDA .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: So they are {disfmarker} they 're not the PZM three hundred dollar type . They 're the twenty - five cent ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: buy them in packs of thousand type .&#10;Speaker: PhD A&#10;Content: I see .&#10;Speaker: Professor B&#10;Content: But , I mean , the thing is people use those little mikes for everything because they 're really not bad .&#10;Speaker: Grad E&#10;Content: Everything .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , if you 're not {vocalsound} doing something ridiculous like feeding it to a speech recognizer , they {disfmarker} they {disfmarker} {vocalsound} they {disfmarker} you know , you can hear the sou hear the sounds just fine .&#10;Speaker: PhD A&#10;Content: Right .&#10;Spe" />
    <node id=" .&#10;Speaker: PhD F&#10;Content: I 'll let {disfmarker} I 'd let {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I let , uh , my five - year - old have a try at the digits , eh .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So , anyway , I can talk about digits . Um , did everyone get the results or shall I go over them again ? I mean that it was basically {disfmarker} the only thing that was even slightly surprising was that the lapel did so well . Um , and in retrospect that 's not as surprising as maybe i it shouldn't have been as surprising as I {disfmarker} as {disfmarker} as I felt it was . The lapel mike is a very high - quality microphone . And as Morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling {pause} if no one else is talking .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Exactly .&#10;Spe" />
    <node id="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation." />
    <node id="ound} there was a significant , um , loss or win {comment} from adaptation {disfmarker} with {disfmarker} with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small {disfmarker} like point one percent on the natives {disfmarker} uh , win from doing , um , you know , adaptation to {pause} the recognition hypotheses . And {pause} I tried both means adaptation and means and variances , and the variances added another {disfmarker} or subtracted another point one percent . So , {vocalsound} it 's , um {disfmarker} that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: But I think one thing is that , uh , I would presume {disfmarker} Hav - Have you ever t {vocalsound} Have you ever tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No" />
    <node id=" of the other digit tasks .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right . But {disfmarker} but , I would {disfmarker} Yeah . It 's {disfmarker} it 's easy enough to try , just run it on {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: See w&#10;Speaker: Grad E&#10;Content: So , Morgan , you 're getting a little breath noise .&#10;Speaker: PhD F&#10;Content: Now , eh , does {disfmarker}&#10;Speaker: Grad E&#10;Content: You might wanna move the mike down a little bit .&#10;Speaker: PhD F&#10;Content: one {disfmarker} one issue {disfmarker} one issue with {disfmarker} with that is that {vocalsound} um , the system has this , uh , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and" />
    <node id="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." />
    <node id=" . Yeah . Yeah .&#10;Speaker: Grad G&#10;Content: I don't think that was the new version .&#10;Speaker: PhD A&#10;Content: Um {disfmarker} That {disfmarker} Yeah , actually it wasn't the new new , it was the medium new .&#10;Speaker: Postdoc C&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: But {disfmarker} but we would {disfmarker} we should do the {disfmarker} the latest version .&#10;Speaker: Postdoc C&#10;Content: OK .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It was the one from last week .&#10;Speaker: Grad G&#10;Content: You {disfmarker} did you adjust the {disfmarker} the utterance times , um , for each channel ?&#10;Speaker: Postdoc C&#10;Content: Yes . Yes , I did . And furthermore , I found that there were a certain number where {disfmarker} {vocalsound} not {disfmarker} not a lot , but several times I actually {vocalsound} moved an utterance" />
    <node id=" {disfmarker} like , the beginning of the first word , the end of the last word {disfmarker} and then we could , you know , do some adjustments .&#10;Speaker: Postdoc C&#10;Content: Yeah . I {disfmarker} OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts , {comment} that would help .&#10;Speaker: PhD F&#10;Content: No .&#10;Speaker: Postdoc C&#10;Content: And then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: but {disfmarker} but in terms {disfmarker}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: So I {disf" />
    <node id=" this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and then that 's the {disfmarker} that 's what the {disfmarker}&#10;Speaker: Grad E&#10;Content: I think Transcriber , uh , outputs CTM .&#10;Speaker: Postdoc C&#10;Content: If it {disfmarker} ? OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: So you would know this more than I would .&#10;Speaker: Grad E&#10;Content: I think so .&#10;Speaker: PhD A&#10;Content: So , I mean {disfmarker}&#10;Speaker: Postdoc C&#10;Content: It seems like she {disfmarker} if she 's g if she 's moving time marks around ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: since our representation in Transcriber uses time marks , it seems like there should be some way of {disfmarker} of using that {disfmarker} benefitting from that .&#10;Spe" />
    <node id="er}&#10;Speaker: Postdoc C&#10;Content: Well , I th I 'm thinking just ch e e incorporating it into the representation .&#10;Speaker: PhD A&#10;Content: Um .&#10;Speaker: Postdoc C&#10;Content: I mean , if it 's {disfmarker} if it 's {disfmarker}&#10;Speaker: PhD A&#10;Content: You mean like {disfmarker} Yeah , word start insights .&#10;Speaker: Postdoc C&#10;Content: if you have start points , if you have , like , time tags ,&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: which is what I assume . Isn't that what {disfmarker} what you {disfmarker} ? Well , see , Adam would be {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah , whatever you use .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and" />
    <node id="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files." />
    <node id=" do that anyway .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Grad E&#10;Content: Oh . So , although you {disfmarker} you can pipe it as well , we tend to do it that way because that way you can concentrate on one block and not keep re - doing it over and over .&#10;Speaker: PhD F&#10;Content: Oh , OK .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Alright .&#10;Speaker: Professor B&#10;Content: Yeah . So I 've {disfmarker} I {disfmarker}&#10;Speaker: Grad E&#10;Content: So tha that 's exactly what the P - file {pause} is for .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Yeah , the {disfmarker} the {disfmarker} the cumbersome thing is {disfmarker} is , um {disfmarker} is that you actually have to dump out little {disfmarker} little files .&#10;Speaker: PhD A&#10;Content: Uh {disfmarker}&#10;Speaker: PhD F&#10;Content" />
    <node id=" {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors {pause} that were occurring and um , some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a um , I think was both a {disfmarker} a pruning {pause} problem and possibly a problem with needing constraints on word locations . And so we tried both of these st things . We tried saying {disfmarker} I don't know , I got this {vocalsound} whacky idea that {disfmarker} just from looking at the data , that when people talk {pause} their words are usually chunked together . It 's not that they say one word and then there 's a bunch of words together . They 're {comment} might say one word and then another word far away if they were doing just backchannels ? But in general , if there 's , like , five or six words and one word 's far away from it , that 's probably wrong on average . So , um {disfmark" />
    <node id="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group." />
    <node id=" need , eh , something , eh , from us in the future , I {disfmarker} I will be at Spain , {vocalsound} to you help , uh .&#10;Speaker: Professor B&#10;Content: Well .&#10;Speaker: Grad E&#10;Content: Great .&#10;Speaker: Postdoc C&#10;Content: Great .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: Thank you , Jose .&#10;Speaker: Postdoc C&#10;Content: Thank you .&#10;Speaker: PhD H&#10;Content: And , thank you very much .&#10;Speaker: PhD F&#10;Content: Have a good trip .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Keep in touch .&#10;Speaker: PhD H&#10;Content: Thank you .&#10;Speaker: Professor B&#10;Content: Yeah . OK . I guess , uh , unless somebody has something else , we 'll read {disfmarker} read our digits&#10;Speaker: Grad E&#10;Content: Digits ?&#10;Speaker: Professor B&#10;Content: and we 'll get our {disfmark" />
    <node id="&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The last meeting meeting ?&#10;Speaker: PhD H&#10;Content: Because , eh , I leave , eh , the next Sunday .&#10;Speaker: Grad E&#10;Content: It 's off .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD H&#10;Content: I will come back to home {disfmarker} to Spain .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: Professor B&#10;Content: I d so I {disfmarker} I jus&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD H&#10;Content: And I {disfmarker} I would like to {disfmarker} to {disfmarker} to say thank you very much , eh , to all people {pause} in the group and at ICSI ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Yeah . It was" />
    <node id="} I will try to recommend , eh , at , eh , {vocalsound} the Spanish government but , eh , the following @ @ scholarship , eh , eh , {vocalsound} eh , will be here {pause} more time , because eh , i in my opinion is {disfmarker} is better , {vocalsound} eh , for us {pause} to {disfmarker} to spend more time here and to work more time i i in a topic .&#10;Speaker: Professor B&#10;Content: Yeah , it 's a very short time .&#10;Speaker: PhD H&#10;Content: No ? But , uh {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , six months is hard .&#10;Speaker: PhD H&#10;Content: Yeah . It is .&#10;Speaker: Grad E&#10;Content: I think a year is a lot better .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: It 's difficult . You {disfmarker} e you have , eh {disfmarker" />
    <node id="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." />
    <node id="Speaker: Professor B&#10;Content: Mm - hmm . Right . I understand . But doing the same kind of limited thing {disfmarker}&#10;Speaker: PhD A&#10;Content: Or {disfmarker} or some high number .&#10;Speaker: Professor B&#10;Content: Yeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing {vocalsound} as people have done in Switchboard evaluations or as {disfmarker} a&#10;Speaker: PhD A&#10;Content: Yeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ?&#10;Speaker: Professor B&#10;Content: Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ?&#10;Speaker: Grad E&#10;Content: Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ?&#10;Speaker: Professor B&#10;Content: Yeah , do it with one of {disfmarker} on&#10;Speaker: Grad E&#10;Content: Cuz we extract the times from the near - field mike , but you use" />
    <node id="Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Uh , I mean , I think that 's actually really u useful also&#10;Speaker: PhD F&#10;Content: And {disfmarker}&#10;Speaker: PhD A&#10;Content: because even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to {pause} get a transcript like {disfmarker} like this anyway , just for doing far - field recognition . So , you know , it 's {disfmarker} it 's sort of {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway .&#10;Speaker: Postdoc C&#10;Content: That 's wonderful .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: PhD A&#10;Content: I mean , i I never thought about it before ," />
    <node id="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes." />
    <node id="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." />
    <node id=" {disfmarker} Oh , yeah . I know what I was go w&#10;Speaker: PhD F&#10;Content: What k u By the way , wh what factor of two did you {disfmarker} ?&#10;Speaker: Professor B&#10;Content: Oh , no , no .&#10;Speaker: PhD F&#10;Content: I mean {disfmarker}&#10;Speaker: Professor B&#10;Content: It 's tha that {disfmarker} that we were saying , you know , well is {disfmarker} how much worse is far than near , you know .&#10;Speaker: PhD F&#10;Content: Oh , th OK .&#10;Speaker: Professor B&#10;Content: And I mean it depends on which one you 're looking at ,&#10;Speaker: PhD F&#10;Content: That factor of two .&#10;Speaker: Professor B&#10;Content: but for the everybody , it 's {vocalsound} little under a factor or two .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Yeah . I {disfmarker} I know what I was thinking was that maybe , uh , i i we could actually" />
    <node id="aker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: But if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: It 's just {disfmarker} it 'll just require more {disfmarker}&#10;Speaker: PhD A&#10;Content: Just {pause} sort of huge .&#10;Speaker: PhD F&#10;Content: you know , slightly different {disfmarker}&#10;Speaker: Postdoc C&#10;Content: What 's interesting is it 's exactly what , um , i in discussing with , um , Sue about this ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: um , she , um , i i i indicated that that {disfmarker} you know , that 's very important for overlap analysis .&#10;Speaker: PhD A&#10;Content: Yeah . It 's {disfmarker} it 's nice to know ,&#10;Speaker: PhD F&#10;Content: Right" />
    <node id=" an important data point , if you 're {disfmarker} if {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: Um . The other thing that {disfmarker} that , uh {disfmarker} of course , what Barry was looking at was {disfmarker} was just that , the near versus far . And , yeah , the adaptation would get {vocalsound} th some of that .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: But , I think even {disfmarker} even if there was , uh , only a factor of two or something , like I was saying in the email , I think that 's {disfmarker} {vocalsound} that 's a big factor . So {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: N&#10;Speaker: Grad E&#10;Content: Liz , you could also just use the other mike if you 're having problems with that one .&#10;Speaker: Postdoc" />
    <node id="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions." />
    <node id=" or period or , {vocalsound} um , you know , comma and things like that , and we kept the {disfmarker} and disfluency dashes {disfmarker} uh , kept those in because we sort of wanna know where those are relative to the spurt overlaps {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm . Right .&#10;Speaker: PhD A&#10;Content: sp overlaps ,&#10;Speaker: PhD F&#10;Content: So {disfmarker} so those are actually sort of retro - fitted into the time alignment .&#10;Speaker: PhD A&#10;Content: or {disfmarker}&#10;Speaker: PhD F&#10;Content: And then we merge all the alignments from the various channels and we sort them by time . And then there 's a {disfmarker} then there 's a process where you now determine the spurts . That is {disfmarker} Actually , no , you do that before you merge the various channels . So you {disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts" />
    <node id="disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then {vocalsound} you extract the individual channels again , but this time you know where the other people start and end talking {disfmarker} you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end {pause} tags for overlaps . So , you {disfmarker} you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Uh , I mean , I think that 's actually really u" />
    <node id="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;" />
    <node id=": &quot; And then she said , and then he said . &quot;&#10;Speaker: Grad G&#10;Content: Yeah , I know it by heart . So , um , {vocalsound} there 's one point when you 're running down the stairs .&#10;Speaker: Postdoc C&#10;Content: Uh - oh .&#10;Speaker: Grad G&#10;Content: Right ? And , like , there 's an interruption . You interrupt somebody , but then there 's no line after that . For example , there 's no speaker identification after that line .&#10;Speaker: Postdoc C&#10;Content: Uh - huh .&#10;Speaker: Grad G&#10;Content: Is that what you 're talking about ? Or were there mislabellings as far as , like , the a Adam was {disfmarker} ?&#10;Speaker: Postdoc C&#10;Content: That was fixed , um , before {disfmarker} i i i I think I I think I understood that pretty {disfmarker}&#10;Speaker: Grad G&#10;Content: Yeah . Cuz I thought I let you know about that .&#10;Speaker: Postdoc C&#10;Content: Thank you for mentioning . Yeah , no , tha that {" />
    <node id=" on my {disfmarker} on my machine cuz I didn't have a headphone .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: So it @ @ , like , I mean {disfmarker} Yeah , I {disfmarker} I mean , i in retrospect {vocalsound} it would 've been good to ha {vocalsound} have got I should 've gotten a headphone . But in any case , um , thi this is {disfmarker} this was transcribed in a {disfmarker} in a , {vocalsound} uh , less optimal way than {disfmarker} than the ones that came after it , and I was able to {disfmarker} you know , an and this meant that there were some speaker identif identifications which were changes .&#10;Speaker: Grad G&#10;Content: Well , I know there were some speaker labelling problems , um , after interruptions .&#10;Speaker: Postdoc C&#10;Content: Yeah . Fixed that .&#10;Speaker: Grad G&#10;Content: Is that what you 're referring to ? I mean , cuz there 's this" />
    <node id=" mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for that , uh , might be that there 's still {disfmarker} even though it 's close - talking , there still is some noise and some room acoustics .&#10;Speaker: PhD F&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: And another might be that , uh , I 'd {disfmarker} I would presume that in the studio , uh , uh , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little {disfmarker} that they didn't include it ,&#10;Speaker: Grad E&#10;Content: They didn't include it .&#10;Speaker: Professor B&#10;Content: they made them do it again .&#10;Speaker: Grad E&#10;Content: Whereas , I took out {pause} the ones that I noticed that were blatant {disfmarker} that were correctable .&#10;Speaker: Professor B&#10;Content: Mmm . Yeah .&#10;Speaker: Grad E&#10;Content: So" />
    <node id="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript." />
    <node id="marker} you know , it doesn't take weeks to train it .&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Um . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates {pause} go from {disfmarker} I don't know , in very noisy environment , like from , uh , uh {disfmarker} I for now I {disfmarker} OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to {vocalsound} eight percent or from e e you know , point {disfmarker} you know , from one percent to point eight percent ?&#10;Speaker: Professor B&#10;Content: H i it got {disfmarker} it got better .&#10;Speaker: PhD F&#10;Content: I mean , it 's a {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah , yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: It got better" />
    <node id="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level." />
    <node id="er}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: So I {disfmarker} so for {disfmarker} for one of the N S A groups . And also I went back to the original one that I first transcribed and {disfmarker} and did it w uh , w uh , utterance by utterance for that particular one . So I think you do have {disfmarker} if that 's a sufficient unit , I think that you do have hand - marking for that . But it 'd be wonderful to be able to {vocalsound} benefit from your Waves stuff .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: We don't care what {disfmarker} what tool you use .&#10;Speaker: PhD A&#10;Content: Yeah . I mean , if {disfmarker} if you can , um {disfmarker} if you wanna {disfmarker}&#10;Speaker: Postdoc C&#10;Content: OK . I used it in Transcriber&#10;Speaker: PhD F&#10;Content: U uh" />
    <node id="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons." />
    <node id="Speaker: PhD D&#10;Content: Other way .&#10;Speaker: Grad E&#10;Content: Other way . Liz {disfmarker}&#10;Speaker: PhD A&#10;Content: Now you 're all watching me .&#10;Speaker: Grad E&#10;Content: It f it clips over your ears .&#10;Speaker: PhD A&#10;Content: Alright . This way .&#10;Speaker: Grad E&#10;Content: There you go .&#10;Speaker: Postdoc C&#10;Content: If you have a strong fe if you have a strong preference , you could use this .&#10;Speaker: PhD A&#10;Content: You 're all watching . This is terrible .&#10;Speaker: Postdoc C&#10;Content: It 's just we {disfmarker} we think it has some spikes . So , uh , we {disfmarker} we didn't use that one .&#10;Speaker: PhD A&#10;Content: I 'll get it .&#10;Speaker: Postdoc C&#10;Content: But you could if you want .&#10;Speaker: Professor B&#10;Content: Yeah . At any rate , I don't know if w&#10;Speaker: Postdoc C&#10;Content: I don't know . And Andre - Andreas" />
    <node id="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance." />
    <node id=" , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause} all the participants in Aurora , {vocalsound} was so much worse {vocalsound} than the {disfmarker} than the S R&#10;Speaker: Grad E&#10;Content: Everybody .&#10;Speaker: Professor B&#10;Content: And the interesting thing is that even though , {vocalsound} yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , {vocalsound} it 's just not as good as having a {disfmarker} a l very large amount of data and training up a {disfmarker} a {disfmarker} a nice good big {vocalsound} HMM . Um , also you had the adaptation in the SRI system , which we didn't have in this . Um . So . Um .&#10;Speaker: PhD F&#10;Content: And we know {disfmarker} Di - did I send you some results without adaptation ?&#10;Speaker: Grad E&#10;Content: No .&#10;Spe" />
    <node id="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription." />
    <node id=" PhD F&#10;Content: So {disfmarker}&#10;Speaker: PhD A&#10;Content: I mean , i I never thought about it before ,&#10;Speaker: Grad E&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: And {disfmarker} and we {disfmarker}&#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Grad E&#10;Content: Y yes .&#10;Speaker: PhD F&#10;Content: In {disfmarker}&#10;Speaker: Grad E&#10;Content: I mean , s when I came up with the original data {disfmarker} suggested data format based on the transcription graph , there 's capability of doing that sort of thing in there .&#10;Speaker: PhD A&#10;Content: Right . But you can't get it directly from the transcription .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm . Yeah , that 's right .&#10;Speaker: PhD F&#10;Content: Right . Well , this is {disfmarker} this is just {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , this is like a poor" />
    <node id="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." />
    <node id="m - hmm .&#10;Speaker: Postdoc C&#10;Content: and the most natural way is for you to have initiated the topic by asking a question .&#10;Speaker: PhD F&#10;Content: Well ,&#10;Speaker: PhD A&#10;Content: That 's interesting .&#10;Speaker: PhD F&#10;Content: I think {disfmarker} No . I think it 's {disfmarker} actually I think what 's going on is backchannelling is something that happens in two - party conversations .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And if you ask someone a question , you essentially initiating a little two - party conversation .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Well , actu Yeah , when we looked at this {disfmarker}&#10;Speaker: Postdoc C&#10;Content: Exactly .&#10;Speaker: PhD F&#10;Content: So then you 're {disfmarker} so and then you 're expected to backchannel because the person is addressing you directly and not everybody .&#10;Speaker: Postdoc C&#10;Content: Exactly ." />
    <node id="disfmarker} w well , I won't say &quot; usually &quot; {disfmarker} but anyway , very often , I picked them up in a channel {vocalsound} w which was the person who had asked a question . S so , like , someone says &quot; an and have you done the so - and - so ? &quot; And then there would be backchannels , but it would be the person who asked the question . Other people weren't really doing much backchannelling . And , you know , sometimes you have the {disfmarker} Yeah , uh - huh .&#10;Speaker: PhD A&#10;Content: Well , that 's interesting . Yeah .&#10;Speaker: Postdoc C&#10;Content: I mean , i it wouldn't be perfect , but {disfmarker} but it does seem more natural to give a backchannel when {disfmarker} when you 're somehow involved in the topic ,&#10;Speaker: PhD A&#10;Content: No , that 's really interesting .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: and the most natural way is for you to have initiated the topic by asking a question" />
    <node id=" and then you 're expected to backchannel because the person is addressing you directly and not everybody .&#10;Speaker: Postdoc C&#10;Content: Exactly . Exactly my point . An - and so this is the expectation thing that {disfmarker} uh , uh ,&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: just the dyadic {disfmarker}&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: But in addition , you know , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what {disfmarker} what the answer is that this {disfmarker} that the {disfmarker} the answerer 's given {disfmarker}&#10;Speaker: Professor B&#10;Content: H&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: I tell you , I say {disfmarker} I say &quot; uh - huh" />
    <node id=" is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {disfmarker} and these {disfmarker}&#10;Speaker: PhD A&#10;Content: Right . There 's just probably less backchannelling in general ,&#10;Speaker: Postdoc C&#10;Content: Mm - hmm . So that 's good news , really .&#10;Speaker: PhD A&#10;Content: even if you consider every other person altogether one person in the meeting , but we 'll find out anyway . We were {disfmarker} I guess the other thing we 're {disfmarker} we 're {disfmarker} I should say is that we 're gonna , um try {disfmarker} compare this type of overlap analysis to Switchboard , where {disfmarker}&#10;Speaker: PhD F&#10;Content: And&#10;Speaker: PhD A&#10;Content: and CallHome , where we have both sides , so that we can try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the" />
    <node id=" words .&#10;Speaker: Postdoc C&#10;Content: Oh , yeah .&#10;Speaker: PhD A&#10;Content: And &quot; uh - huh &quot; is not as frequent as it sort of would be in Switchboard , if you looked at just a word frequency list of one - word short utterances . And &quot; yeah &quot; is way up there , but not &quot; uh - huh &quot; . And so I was thinking thi it 's not like {pause} you 're being encouraged by everybody else to keep {pause} talking in the meeting . And uh , that 's all , I I 'll stop there , cuz I I think what you say makes a lot of sense .&#10;Speaker: Postdoc C&#10;Content: Well , that 's right . And that would {disfmarker}&#10;Speaker: PhD A&#10;Content: But it was sort of {disfmarker}&#10;Speaker: Postdoc C&#10;Content: Well , an And what you say is the {disfmarker} is the re uh , o other side of this , which is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {" />
    <node id="&#10;Content: We don't even have enough channel {disfmarker}&#10;Speaker: Professor B&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: Because it would be a different kind of meeting ,&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: that 's what I 'm {disfmarker}&#10;Speaker: Professor B&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: But {disfmarker}&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I hadn't {pause} really thought of it ,&#10;Speaker: PhD F&#10;Content: Maybe just {disfmarker} maybe not the whole day&#10;Speaker: Professor B&#10;Content: but {disfmarker}&#10;Speaker: PhD F&#10;Content: but just , you know , maybe some {disfmarker} I mean ,&#10;Speaker: Professor B&#10;Content: Maybe part of it .&#10;Speaker: PhD F&#10;Content: part of it ?&#10;Speaker: Professor B&#10;Content: Maybe part of it .&#10;Speaker:" />
    <node id="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks." />
    <node id=" over the telephone you don't actually want to put a whole lot of effort into adaptation&#10;Speaker: PhD F&#10;Content: Well , I don't know .&#10;Speaker: Professor B&#10;Content: because {vocalsound} somebody {pause} gets on the phone and says a number and then you just want it . You don't {disfmarker} don't , uh {disfmarker}&#10;Speaker: Postdoc C&#10;Content: This is {disfmarker} this {disfmarker} that one 's better .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um , but , you know , I {disfmarker} uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to {disfmarker} you want to {disfmarker} That 's the obvious thing to try .&#10;Speaker: Postdoc C&#10;Content: Oh . Oh .&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Right ?" />
    <node id="Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted {disfmarker}&#10;Speaker: Grad E&#10;Content: Channel adapted .&#10;Speaker: PhD F&#10;Content: use that as the starting models for your speaker adaptation .&#10;Speaker: Professor B&#10;Content: Yeah . {vocalsound} But the thing is , uh {disfmarker} I mean , w when you {disfmarker} it depends whether you 're ju were just using this as a {disfmarker} {vocalsound} a starter task for {disfmarker} you know , to get things going for conversational or if we 're really interested i in connected digits . And I {disfmarker} I think the answer is both . And for {disfmarker} for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation&#10;Speaker: PhD F&#10;Content: Well , I don't know" />
    <node id="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation." />
    <node id="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information." />
    <node id=" 's {disfmarker} and because you don't know how people are gonna put them on , you know .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Right . So , also , Andreas , on that one the {disfmarker} the back part of it should be right against your head . And that will he keep it from flopping aro up and down as much .&#10;Speaker: PhD F&#10;Content: It is against my head .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Yeah . Um . Yeah , we actually talked about this in the , uh , front - end meeting this morning , too . Much the same thing ,&#10;Speaker: Grad E&#10;Content: Uh - huh .&#10;Speaker: Professor B&#10;Content: and {disfmarker} and it was {disfmarker} uh , I mean , there the point of interest to the group was primarily that , um , {vocalsound} the , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause" />
    <node id="disfmarker} little files .&#10;Speaker: PhD A&#10;Content: Uh {disfmarker}&#10;Speaker: PhD F&#10;Content: So for each segment that you want to recognize {vocalsound} you have to {pause} dump out {pause} a separate file .&#10;Speaker: Grad E&#10;Content: Uh - huh .&#10;Speaker: PhD F&#10;Content: Just like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know {disfmarker} So .&#10;Speaker: Professor B&#10;Content: Cool . OK . So the s the {disfmarker} the next thing we had on the agenda was something about alignments ?&#10;Speaker: PhD A&#10;Content: Oh . Yes , we have {disfmarker} I don't know , did you wanna talk about it , or {disfmarker} ? I can give a {disfmarker} I was just telling this to Jane and {disfmarker} and {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first" />
    <node id="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information." />
    <node id=" D&#10;Content: No , no .&#10;Speaker: Grad E&#10;Content: So are we gonna do digits simultaneously&#10;Speaker: PhD A&#10;Content: You {disfmarker} This is our reward if we {pause} do our digi&#10;Speaker: Professor B&#10;Content: Well ? Yeah .&#10;Speaker: Postdoc C&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: or what ?&#10;Speaker: PhD D&#10;Content: Simultaneous digit chocolate task .&#10;Speaker: PhD H&#10;Content: I {disfmarker} I think , eh , it 's enough , eh , for more peopl for more people {pause} after .&#10;Speaker: Professor B&#10;Content: We 're gonna {disfmarker} we 're gonna do digits at the same {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: PhD F&#10;Content: Mmm !&#10;Speaker: Postdoc C&#10;Content: That 's nice .&#10;Speaker: PhD H&#10;Content: But , eh {disfmarker}&#10;Speaker: PhD F&#10;Content:" />
    <node id="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones." />
    <node id="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text." />
    <node id="marker}&#10;Speaker: PhD F&#10;Content: um . So .&#10;Speaker: PhD A&#10;Content: Anyway .&#10;Speaker: PhD F&#10;Content: I don't know .&#10;Speaker: PhD A&#10;Content: But the good thing is this does {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , I I don't know . I mean , you could {disfmarker} you could do a paper on {pause} what 's wrong with the Aurora task by comparing it to {pause} other ways of doing it .&#10;Speaker: PhD F&#10;Content: How well does an Aurora system do on {disfmarker} on {disfmarker} you know , on digits collected in a {disfmarker} in this environment ?&#10;Speaker: PhD H&#10;Content: &#10;Speaker: Grad E&#10;Content: Different way . Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Maybe .&#10;Speaker: PhD F&#10;Content: Maybe .&#10;Speaker: Grad E&#10;Content: Pretty hokey .&#10;Speaker: Professor B&#10;Content: I think it 's a l" />
    <node id=" D&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Oh , I thought you meant this was just the digits section . I didn't know you meant it was Aurora digits .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Well , no . If you {disfmarker} if you have {disfmarker} it 's to {disfmarker} if you discuss some relation to the Aurora task , like if you use the same {disfmarker}&#10;Speaker: Professor B&#10;Content: This is not the Aurora task . So they just do a little grep for {disfmarker}&#10;Speaker: PhD A&#10;Content: Do {disfmarker} uh , d d Do not {disfmarker} do not {disfmarker} we are not setting a good example .&#10;Speaker: PhD F&#10;Content: Um . Well , a relation other than negation , maybe ,&#10;Speaker: PhD A&#10;Content: This is not a {disfmarker}&#10;Speaker: PhD F&#10;Content: um . So .&#10;Speaker: PhD A&#10;Content: Anyway .&#10;Speaker: PhD" />
    <node id="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI." />
    <node id=" ICSI ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Yeah . It was good having you .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: because I {disfmarker} I enjoyed @ @ very much ,&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD H&#10;Content: uh . And I 'm sorry by the result of overlapping , because , eh , {vocalsound} I haven't good results , eh , yet but , eh , {vocalsound} I {disfmarker} {vocalsound} I pretend {comment} to {disfmarker} to continuing out to Spain , eh , during the {disfmarker} the following months ,&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD H&#10;Content: eh , because I have , eh , another ideas but , eh , I haven't enough time to {disfmarker} to {disfmarker} {vocalsound} with six months it 's not enough" />
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target=" our {disfmarker}&#10;Speaker: PhD F&#10;Content: Maybe the sections that are not right afte you know , after lunch when everybody 's still munching and {disfmarker}&#10;Speaker: PhD A&#10;Content: So can you send out a schedule once you know it , jus ?&#10;Speaker: Professor B&#10;Content: OK . Well {disfmarker}&#10;Speaker: PhD A&#10;Content: Is {disfmarker} is there a r ?&#10;Speaker: Professor B&#10;Content: OK . Yeah . I guess I sent it around a little bit .&#10;Speaker: PhD A&#10;Content: There 's a res Is it changed now , or {disfmarker} ?&#10;Speaker: Professor B&#10;Content: But {disfmarker} I hadn't heard back from Mari after I {disfmarker} I u u uh , brought up the point abou about Andreas 's schedule . So , {vocalsound} um , maybe when I get back there 'll be {pause} some {disfmarker} some mail from her .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor B">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="mm !&#10;Speaker: Professor B&#10;Content: And Andreas has the last word .&#10;Speaker: Grad E&#10;Content: Did you read it twice or what ?&#10;Speaker: PhD A&#10;Content: He 's try No , he 's trying to get good recognition performance .&#10;Speaker: Postdoc C&#10;Content: He had the h&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: He had the {disfmarker} the long form .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: And we 're off .&#10;Speaker: PhD F&#10;Content: No .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="Speaker: Grad E&#10;Content: OK , we 're on .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: Grad E&#10;Content: So , I mean , everyone who 's on the wireless check that they 're on .&#10;Speaker: PhD F&#10;Content: C we {disfmarker}&#10;Speaker: Grad G&#10;Content: Alright .&#10;Speaker: Postdoc C&#10;Content: I see . Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: OK , our agenda was quite short .&#10;Speaker: Professor B&#10;Content: Oh , could you {pause} close the door , maybe ? Yeah .&#10;Speaker: Grad E&#10;Content: Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,&#10;Speaker: Professor B&#10;Content: &#10;Speaker: Grad E&#10;Content: but they didn't ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target=" Yeah .&#10;Speaker: Grad E&#10;Content: Have them all read them at once .&#10;Speaker: PhD A&#10;Content: Well , different digits&#10;Speaker: PhD D&#10;Content: Eh {disfmarker}&#10;Speaker: PhD A&#10;Content: but same groupings .&#10;Speaker: Grad E&#10;Content: Or {disfmarker} or just same digits .&#10;Speaker: PhD A&#10;Content: So they would all be {disfmarker} Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah . That 'd be good .&#10;Speaker: Grad E&#10;Content: See if anyone notices .&#10;Speaker: Professor B&#10;Content: There 's so many possibilities .&#10;Speaker: Postdoc C&#10;Content: And then {disfmarker} then we can sing them next time .&#10;Speaker: Professor B&#10;Content: Uh . OK , why don't we go ? Uh , one two three {disfmarker} Go !&#10;Speaker: Postdoc C&#10;Content: OK . Mmm !&#10;Speaker: Professor B&#10;Content: And Andreas has the last word .&#10;Speaker: Grad E&#10;Content: Did you read it twice">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for which I {disfmarker}&#10;Speaker: Grad E&#10;Content: so .&#10;Speaker: PhD F&#10;Content: We should do that second , because Liz might join us in time for that .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Um . OK , so there 's digits , alignments , and , um , I guess the other thing , {vocalsound} which I came unprepared for , uh , {vocalsound} is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: So . Any {disfmarker} I mean , maybe not .&#10;Speaker: Grad E&#10;Content: Digits and alignments . But {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh .&#10;Speaker: PhD F&#10;Content: Talk about aligning people 's schedules .&#10;Speaker: Professor B&#10;Content: Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="&#10;Content: Are we meeting in here probably or {disfmarker} ? OK .&#10;Speaker: Professor B&#10;Content: Yeah . That was my thought .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I think this is {disfmarker}&#10;Speaker: PhD F&#10;Content: Are we recording it ?&#10;Speaker: PhD A&#10;Content: We won't have enough microphones ,&#10;Speaker: Professor B&#10;Content: &#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Professor B&#10;Content: u No . I {disfmarker} I hadn't in intended to .&#10;Speaker: PhD A&#10;Content: There 's no way .&#10;Speaker: Professor B&#10;Content: We won we wanna {disfmarker} I mean , they 're {disfmarker} there 's gonna be , uh , Jeff , Katrin , Mari and two students .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: So there 's five {pause} from there .&#10;Speaker: Grad E&#10;Content: And Brian .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that there was some discussion about Andreas' schedule, but no clear answer was given regarding its current status or whether there is a revised version. Professor B mentioned that they had brought up the point about Andreas' schedule and that they hadn't heard back from Mari yet. They expressed hope that there might be an update via email upon their return. Therefore, it seems that the status of Andreas' schedule is still uncertain and may depend on further communication with Mari." target="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Grad E&#10;Content: OK , we 're on .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: Grad E&#10;Content: So , I mean , everyone who 's on the wireless check that they 're on .&#10;Speaker: PhD F&#10;Content: C we {disfmarker}&#10;Speaker: Grad G&#10;Content: Alright .&#10;Speaker: Postdoc C&#10;Content: I see . Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: OK , our agenda was quite short .&#10;Speaker: Professor B&#10;Content: Oh , could you {pause} close the door , maybe ? Yeah .&#10;Speaker: Grad E&#10;Content: Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,&#10;Speaker: Professor B&#10;Content: &#10;Speaker: Grad E&#10;Content: but they didn't ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for" target="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Grad E&#10;Content: OK , we 're on .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: Grad E&#10;Content: So , I mean , everyone who 's on the wireless check that they 're on .&#10;Speaker: PhD F&#10;Content: C we {disfmarker}&#10;Speaker: Grad G&#10;Content: Alright .&#10;Speaker: Postdoc C&#10;Content: I see . Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: OK , our agenda was quite short .&#10;Speaker: Professor B&#10;Content: Oh , could you {pause} close the door , maybe ? Yeah .&#10;Speaker: Grad E&#10;Content: Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,&#10;Speaker: Professor B&#10;Content: &#10;Speaker: Grad E&#10;Content: but they didn't ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for" target="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: Grad E&#10;Content: Have them all read them at once .&#10;Speaker: PhD A&#10;Content: Well , different digits&#10;Speaker: PhD D&#10;Content: Eh {disfmarker}&#10;Speaker: PhD A&#10;Content: but same groupings .&#10;Speaker: Grad E&#10;Content: Or {disfmarker} or just same digits .&#10;Speaker: PhD A&#10;Content: So they would all be {disfmarker} Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah . That 'd be good .&#10;Speaker: Grad E&#10;Content: See if anyone notices .&#10;Speaker: Professor B&#10;Content: There 's so many possibilities .&#10;Speaker: Postdoc C&#10;Content: And then {disfmarker} then we can sing them next time .&#10;Speaker: Professor B&#10;Content: Uh . OK , why don't we go ? Uh , one two three {disfmarker} Go !&#10;Speaker: Postdoc C&#10;Content: OK . Mmm !&#10;Speaker: Professor B&#10;Content: And Andreas has the last word .&#10;Speaker: Grad E&#10;Content: Did you read it twice" target="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I guess the only other thing , uh , for which I {disfmarker}&#10;Speaker: Grad E&#10;Content: so .&#10;Speaker: PhD F&#10;Content: We should do that second , because Liz might join us in time for that .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Um . OK , so there 's digits , alignments , and , um , I guess the other thing , {vocalsound} which I came unprepared for , uh , {vocalsound} is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: So . Any {disfmarker} I mean , maybe not .&#10;Speaker: Grad E&#10;Content: Digits and alignments . But {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh .&#10;Speaker: PhD F&#10;Content: Talk about aligning people 's schedules .&#10;Speaker: Professor B&#10;Content: Yeah" target="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target="er} it won't leave this room .&#10;Speaker: Professor B&#10;Content: Alright , so in the interest of getting to the {disfmarker}&#10;Speaker: PhD A&#10;Content: We could do digits while other people eat .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So it 's background crunching .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: We don't have background chewing .&#10;Speaker: Postdoc C&#10;Content: Nice .&#10;Speaker: PhD H&#10;Content: Is , eh , a {disfmarker} another acoustic event .&#10;Speaker: PhD D&#10;Content: Background crunch . Yeah .&#10;Speaker: PhD A&#10;Content: No , we don't have any data with background eating .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I 'm serious . You&#10;Speaker: Professor B&#10;Content: She 's {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target=" That 's nice .&#10;Speaker: PhD H&#10;Content: But , eh {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Oh , thanks , Jose .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: Postdoc C&#10;Content: Wow .&#10;Speaker: PhD H&#10;Content: To Andreas , the idea is {disfmarker} is good . {vocalsound} s To eat here .&#10;Speaker: Professor B&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Postdoc C&#10;Content: Wow . Very nice .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD A&#10;Content: Oh , wow .&#10;Speaker: Professor B&#10;Content: Tha - that 's {disfmarker} that looks great .&#10;Speaker: PhD F&#10;Content: Oh , yeah . Th - it doesn't {disfmarker} it won't leave this room .&#10;Speaker: Professor B&#10;Content: Alright , so in the interest of getting to the {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target=" A&#10;Content: I the first time is {pause} traumatic ,&#10;Speaker: Professor B&#10;Content: We&#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Professor B&#10;Content: Y {vocalsound} Yeah , bu&#10;Speaker: Postdoc C&#10;Content: Oh , and the groupings are important ,&#10;Speaker: PhD H&#10;Content: Mmm .&#10;Speaker: Postdoc C&#10;Content: so yo you 're supposed to pause between the groupings .&#10;Speaker: PhD H&#10;Content: The grouping .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK . So , uh {disfmarker}&#10;Speaker: PhD F&#10;Content: You mean that the {disfmarker} the grouping is supposed to be synchronized ?&#10;Speaker: Professor B&#10;Content: No , no .&#10;Speaker: Postdoc C&#10;Content: No .&#10;Speaker: Grad E&#10;Content: Yeah , sure .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: That 'd be good">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target="&#10;Speaker: Grad E&#10;Content: And then it {disfmarker}&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: I already {pause} tried to get it close .&#10;Speaker: Postdoc C&#10;Content: Good .&#10;Speaker: Grad E&#10;Content: So if it doesn't bounce around too much , that 's actually good placement .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc C&#10;Content: That looks good .&#10;Speaker: Grad E&#10;Content: But it looks like it 's gonna bounce a lot .&#10;Speaker: Professor B&#10;Content: So , where were we ? Uh {disfmarker} {vocalsound} Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Digits . Adaptation .&#10;Speaker: Professor B&#10;Content: Uh , adaptation , non - adaptation , um , factor of two , um {disfmarker} Oh , yeah . I know what I was go w&#10;Speaker: PhD F&#10;Content: What k u By the way">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target=" Postdoc C&#10;Content: I think we can ha&#10;Speaker: PhD F&#10;Content: bec b {vocalsound} Nah {disfmarker}&#10;Speaker: PhD A&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: Postdoc C&#10;Content: Nah .&#10;Speaker: PhD F&#10;Content: i Because these {disfmarker} the conference organizers actually have an interest in getting lots of submissions .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I mean , a {disfmarker} a monetary interest .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: So {disfmarker} {vocalsound} Um .&#10;Speaker: Professor B&#10;Content: Th - that 's {disfmarker} that 's true .&#10;Speaker: Postdoc C&#10;Content: And good ones , good ones , which sometimes means {pause} a little extra time .&#10;Speaker: PhD F&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target="&#10;Speaker: PhD A&#10;Content: I 'm serious . You&#10;Speaker: Professor B&#10;Content: She 's {disfmarker} she 's serious .&#10;Speaker: PhD A&#10;Content: I am serious .&#10;Speaker: Grad E&#10;Content: It 's just the rest of the digits {disfmarker} the rest of the digits are very clean ,&#10;Speaker: Professor B&#10;Content: She is serious .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: Well {disfmarker} ?&#10;Speaker: PhD H&#10;Content: Are you {disfmarker} ? Oh , they 're clean .&#10;Speaker: PhD D&#10;Content: Yeah !&#10;Speaker: Grad E&#10;Content: um , without a lot of background noise ,&#10;Speaker: PhD A&#10;Content: And it {disfmarker} You have to write down , like , while y what you 're {disfmarker} what ch chocolate you 're eating&#10;Speaker: Grad E&#10;Content: so I 'm just not sure {disfmarker}&#10;Speaker: PhD A&#10;Content: c">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group of individuals, including Ph.D. speakers H, F, A, Professor B, and Postdoc C, respond positively to the idea of eating at a certain place. They express their agreement with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; There are also expressions of excitement, such as &quot;wow&quot; and &quot;that looks great.&quot; Additionally, they admire the appearance of the food, with comments like &quot;it doesn't leave this room&quot; and &quot;it won't bounce around too much.&quot; Overall, the group appears to be in favor of eating at the suggested location." target="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source=" A&#10;Content: I the first time is {pause} traumatic ,&#10;Speaker: Professor B&#10;Content: We&#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Professor B&#10;Content: Y {vocalsound} Yeah , bu&#10;Speaker: Postdoc C&#10;Content: Oh , and the groupings are important ,&#10;Speaker: PhD H&#10;Content: Mmm .&#10;Speaker: Postdoc C&#10;Content: so yo you 're supposed to pause between the groupings .&#10;Speaker: PhD H&#10;Content: The grouping .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK . So , uh {disfmarker}&#10;Speaker: PhD F&#10;Content: You mean that the {disfmarker} the grouping is supposed to be synchronized ?&#10;Speaker: Professor B&#10;Content: No , no .&#10;Speaker: Postdoc C&#10;Content: No .&#10;Speaker: Grad E&#10;Content: Yeah , sure .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: That 'd be good" target="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Grad E&#10;Content: And then it {disfmarker}&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: I already {pause} tried to get it close .&#10;Speaker: Postdoc C&#10;Content: Good .&#10;Speaker: Grad E&#10;Content: So if it doesn't bounce around too much , that 's actually good placement .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc C&#10;Content: That looks good .&#10;Speaker: Grad E&#10;Content: But it looks like it 's gonna bounce a lot .&#10;Speaker: Professor B&#10;Content: So , where were we ? Uh {disfmarker} {vocalsound} Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Digits . Adaptation .&#10;Speaker: Professor B&#10;Content: Uh , adaptation , non - adaptation , um , factor of two , um {disfmarker} Oh , yeah . I know what I was go w&#10;Speaker: PhD F&#10;Content: What k u By the way" target="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Postdoc C&#10;Content: I think we can ha&#10;Speaker: PhD F&#10;Content: bec b {vocalsound} Nah {disfmarker}&#10;Speaker: PhD A&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: No .&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: Postdoc C&#10;Content: Nah .&#10;Speaker: PhD F&#10;Content: i Because these {disfmarker} the conference organizers actually have an interest in getting lots of submissions .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: I mean , a {disfmarker} a monetary interest .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: So {disfmarker} {vocalsound} Um .&#10;Speaker: Professor B&#10;Content: Th - that 's {disfmarker} that 's true .&#10;Speaker: Postdoc C&#10;Content: And good ones , good ones , which sometimes means {pause} a little extra time .&#10;Speaker: PhD F&#10;Content:" target="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target=" a verb now .&#10;Speaker: Postdoc C&#10;Content: I know {disfmarker} I know Ch - Chafe dealt with {disfmarker}&#10;Speaker: PhD F&#10;Content: So s&#10;Speaker: Grad G&#10;Content: That 's cool .&#10;Speaker: PhD F&#10;Content: W uh , w&#10;Speaker: Postdoc C&#10;Content: Chafe speaks about intonation units .&#10;Speaker: PhD A&#10;Content: Yes . Right .&#10;Speaker: Postdoc C&#10;Content: But maybe he speaks about spurts as well&#10;Speaker: PhD F&#10;Content: We&#10;Speaker: Postdoc C&#10;Content: and I just don't know . Yeah , go ahead .&#10;Speaker: Grad E&#10;Content: I 've heard &quot; burst &quot; also .&#10;Speaker: PhD F&#10;Content: So what we 're doing {disfmarker} uh , this {disfmarker} this is just {disfmarker} maybe someone has s some {disfmarker} some ideas about how to do it better ,&#10;Speaker: Grad G&#10;Content: Mmm .&#10;Speaker: PhD F&#10;Content: but">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target=": Well , see , I know S Sue wrote about spurts of development .&#10;Speaker: PhD F&#10;Content: So maybe we should talk {disfmarker}&#10;Speaker: PhD A&#10;Content: Maybe it was Sue {disfmarker} ? Y&#10;Speaker: Postdoc C&#10;Content: But , in any case , I think it 's a good term ,&#10;Speaker: PhD A&#10;Content: So we have spurts and we have spurt - ify dot shell and spurt - ify&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: and , uh {disfmarker}&#10;Speaker: Grad E&#10;Content: Hmm !&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: And ma maybe {disfmarker} maybe Chafe did .&#10;Speaker: PhD F&#10;Content: Uh .&#10;Speaker: PhD A&#10;Content: And then it 's got all {disfmarker} it 's a verb now .&#10;Speaker: Postdoc C&#10;Content: I know {disfmarker} I know Ch - Chafe dealt with {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target=" also ?&#10;Speaker: PhD A&#10;Content: so {disfmarker}&#10;Speaker: Grad E&#10;Content: Spurt has the horrible name overloading with other {disfmarker} with hardware at ICSI .&#10;Speaker: Professor B&#10;Content: Here . Just very locally , yeah .&#10;Speaker: PhD A&#10;Content: Well , well , Chafe had this wor I think it was Chafe , or somebody had a {disfmarker} the word &quot; spurt &quot; originally ,&#10;Speaker: Professor B&#10;Content: But {disfmarker} but that just {disfmarker}&#10;Speaker: PhD H&#10;Content: Here @ @ {disfmarker}&#10;Speaker: PhD A&#10;Content: and so I {disfmarker} But tha that 's good to know .&#10;Speaker: Postdoc C&#10;Content: Actually {disfmarker}&#10;Speaker: PhD A&#10;Content: Was thi it 's Chafe ?&#10;Speaker: Postdoc C&#10;Content: Well , see , I know S Sue wrote about spurts of development .&#10;Speaker: PhD F&#10;Content: So maybe we should talk {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target=" {pause} pauses around it ?&#10;Speaker: Postdoc C&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: Yeah . I know that th the Telecom people use {disfmarker} use &quot; spurt &quot; for that .&#10;Speaker: Postdoc C&#10;Content: Good .&#10;Speaker: PhD A&#10;Content: They do ? Oh !&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD F&#10;Content: Oh .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: Professor B&#10;Content: And that 's {disfmarker} I mean , I {disfmarker} I was using that for a while when I was doing the rate of speech stuff ,&#10;Speaker: PhD A&#10;Content: I would jus&#10;Speaker: Professor B&#10;Content: because I {disfmarker} because I looked up in some books and I found {disfmarker} OK , I wanna find a spurt {vocalsound} in which {disfmarker}&#10;Speaker: PhD A&#10;Content: Ah , right ! It 's just , like , defined by the acoustics .&#10;Speaker: Professor">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target="&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: and {disfmarker} and how many speakers per utterance .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker}&#10;Speaker: PhD F&#10;Content: Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker}&#10;Speaker: Grad E&#10;Content: I strongly suspect that they have more speakers than we do . So , uh {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Use of the term &quot;spurt&quot;: Some participants suggest using the term &quot;spurt&quot; to refer to intonation units or spurts in speech, as introduced by Wallace Chafe. However, there is a concern about the name overloading with other meanings, particularly in hardware at ICSI.&#10;2. Pauses around the term &quot;spurt&quot;: Postdoc C raises the possibility of examining pauses around the term &quot;spurt&quot; to better understand its usage and significance in speech.&#10;3. Consideration of Sue's work on spurts of development: PhD F brings up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech.&#10;4. Using &quot;spurt&quot; in telecom for acoustic purposes: Professor B mentions that telecom professionals use &quot;spurt&quot; to describe a specific acoustic phenomenon. This could potentially be explored as a method for dealing with intonation units or spurts in speech.&#10;5. Examining the TI-digits database: PhD F suggests investigating the TI-digits database, which has known speakers and may provide a comparable amount of data to what is available in their current recordings. This could help establish more accurate VTL estimation and variance norm methods for intonation units or spurts analysis." target="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI.">
      <data key="d0">1</data>
    </edge>
    <edge source=" a verb now .&#10;Speaker: Postdoc C&#10;Content: I know {disfmarker} I know Ch - Chafe dealt with {disfmarker}&#10;Speaker: PhD F&#10;Content: So s&#10;Speaker: Grad G&#10;Content: That 's cool .&#10;Speaker: PhD F&#10;Content: W uh , w&#10;Speaker: Postdoc C&#10;Content: Chafe speaks about intonation units .&#10;Speaker: PhD A&#10;Content: Yes . Right .&#10;Speaker: Postdoc C&#10;Content: But maybe he speaks about spurts as well&#10;Speaker: PhD F&#10;Content: We&#10;Speaker: Postdoc C&#10;Content: and I just don't know . Yeah , go ahead .&#10;Speaker: Grad E&#10;Content: I 've heard &quot; burst &quot; also .&#10;Speaker: PhD F&#10;Content: So what we 're doing {disfmarker} uh , this {disfmarker} this is just {disfmarker} maybe someone has s some {disfmarker} some ideas about how to do it better ,&#10;Speaker: Grad G&#10;Content: Mmm .&#10;Speaker: PhD F&#10;Content: but" target="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons.">
      <data key="d0">1</data>
    </edge>
    <edge source=" also ?&#10;Speaker: PhD A&#10;Content: so {disfmarker}&#10;Speaker: Grad E&#10;Content: Spurt has the horrible name overloading with other {disfmarker} with hardware at ICSI .&#10;Speaker: Professor B&#10;Content: Here . Just very locally , yeah .&#10;Speaker: PhD A&#10;Content: Well , well , Chafe had this wor I think it was Chafe , or somebody had a {disfmarker} the word &quot; spurt &quot; originally ,&#10;Speaker: Professor B&#10;Content: But {disfmarker} but that just {disfmarker}&#10;Speaker: PhD H&#10;Content: Here @ @ {disfmarker}&#10;Speaker: PhD A&#10;Content: and so I {disfmarker} But tha that 's good to know .&#10;Speaker: Postdoc C&#10;Content: Actually {disfmarker}&#10;Speaker: PhD A&#10;Content: Was thi it 's Chafe ?&#10;Speaker: Postdoc C&#10;Content: Well , see , I know S Sue wrote about spurts of development .&#10;Speaker: PhD F&#10;Content: So maybe we should talk {d" target="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: and {disfmarker} and how many speakers per utterance .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker}&#10;Speaker: PhD F&#10;Content: Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker}&#10;Speaker: Grad E&#10;Content: I strongly suspect that they have more speakers than we do . So , uh {disfmark" target="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: and {disfmarker} and how many speakers per utterance .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker}&#10;Speaker: PhD F&#10;Content: Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker}&#10;Speaker: Grad E&#10;Content: I strongly suspect that they have more speakers than we do . So , uh {disfmark" target="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content" target="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content" target="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content" target="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content" target="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: Grad E&#10;Content: Yeah , I noticed the script that extracted it .&#10;Speaker: PhD F&#10;Content: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ?&#10;Speaker: Grad E&#10;Content: Yep . Yep .&#10;Speaker: PhD F&#10;Content: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ?&#10;Speaker: Grad E&#10;Content: That I don't know . I don't know . I don't know how many speakers there are ,&#10;Speaker: Professor B&#10;Content" target="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="marker} that were correctable .&#10;Speaker: Professor B&#10;Content: Mmm . Yeah .&#10;Speaker: Grad E&#10;Content: So that , if someone just read the wrong digit , I corrected it .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: And then there was another one where Jose couldn't tell whether {disfmarker} I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either .&#10;Speaker: Grad I&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: So I just cut it out .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: You know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially {disfmarker} I think TI - digits is all {pause} American English .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Right ? So it">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So , {vocalsound} one {disfmarker} so there were a number of things we noted from this .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: One is , yeah , the SRI system is a lot better than the HTK {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: this , you know , very limited training HTK system .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target=" tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No .&#10;Speaker: Professor B&#10;Content: It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker}&#10;Speaker: PhD F&#10;Content: But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits .&#10;Speaker: Grad E&#10;Content: I bet it would do even slightly better .&#10;Speaker: PhD F&#10;Content: I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: and I could ask them what they get {pause} on TI - digits .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: That would be the , sort of {disfmarker} probably the safest way to do {disfmarker}&#10;Speaker: Grad E&#10;Content: I might have to do that anyway to {disfmarker} to do {disfmarker} because we may have to do an extract to get the {pause} amount of data per speaker about right .&#10;Speaker: PhD F&#10;Content: Uh - huh .&#10;Speaker: Grad E&#10;Content: The other thing is , isn't TI - digits isolated digits ?&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Or is that another one ? I 'm {disfmarker} I looked through a bunch of the digits t corp corpora , and now they 're all blurring .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cuz one of them was literally people reading a single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target=" and , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or {disfmarker}&#10;Speaker: Grad E&#10;Content: Wha - what 's TI - digits ? I thought t&#10;Speaker: Professor B&#10;Content: It 's wide - band , yeah . It 's {disfmarker} in {disfmarker} in fact , we looked it up&#10;Speaker: Grad E&#10;Content: It is wide - band . OK .&#10;Speaker: Professor B&#10;Content: and it was actually twenty kilohertz sampling .&#10;Speaker: Grad E&#10;Content: Oh , that 's right . I {disfmarker} I did look that up .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: I couldn't remember whether that was TI - digits or one of the other digit tasks .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right . But {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. While editing the recording, the speaker made corrections such as fixing misread digits and removing uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot; The speaker also edited out the first word of an utterance to improve its cleanliness.&#10;2. The speaker's expectations for the cleanliness of TI-digits are that it would be very clean, especially since they perceive it to be American English. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation." target="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} that were correctable .&#10;Speaker: Professor B&#10;Content: Mmm . Yeah .&#10;Speaker: Grad E&#10;Content: So that , if someone just read the wrong digit , I corrected it .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: And then there was another one where Jose couldn't tell whether {disfmarker} I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either .&#10;Speaker: Grad I&#10;Content: Hmm .&#10;Speaker: Grad E&#10;Content: So I just cut it out .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: You know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially {disfmarker} I think TI - digits is all {pause} American English .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Right ? So it" target="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So , {vocalsound} one {disfmarker} so there were a number of things we noted from this .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: One is , yeah , the SRI system is a lot better than the HTK {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: this , you know , very limited training HTK system .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for" target="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So , {vocalsound} one {disfmarker} so there were a number of things we noted from this .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: One is , yeah , the SRI system is a lot better than the HTK {disfmarker}&#10;Speaker: PhD F&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: this , you know , very limited training HTK system .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for" target="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source=" tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No .&#10;Speaker: Professor B&#10;Content: It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker}&#10;Speaker: PhD F&#10;Content: But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits .&#10;Speaker: Grad E&#10;Content: I bet it would do even slightly better .&#10;Speaker: PhD F&#10;Content: I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: and I could ask them what they get {pause} on TI - digits .&#10;Spe" target="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)">
      <data key="d0">1</data>
    </edge>
    <edge source=" tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No .&#10;Speaker: Professor B&#10;Content: It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker}&#10;Speaker: PhD F&#10;Content: But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits .&#10;Speaker: Grad E&#10;Content: I bet it would do even slightly better .&#10;Speaker: PhD F&#10;Content: I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: and I could ask them what they get {pause} on TI - digits .&#10;Spe" target="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: That would be the , sort of {disfmarker} probably the safest way to do {disfmarker}&#10;Speaker: Grad E&#10;Content: I might have to do that anyway to {disfmarker} to do {disfmarker} because we may have to do an extract to get the {pause} amount of data per speaker about right .&#10;Speaker: PhD F&#10;Content: Uh - huh .&#10;Speaker: Grad E&#10;Content: The other thing is , isn't TI - digits isolated digits ?&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad E&#10;Content: Or is that another one ? I 'm {disfmarker} I looked through a bunch of the digits t corp corpora , and now they 're all blurring .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Cuz one of them was literally people reading a single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think" target="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="&#10;Content: Yeah , sure .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: That 'd be good .&#10;Speaker: Professor B&#10;Content: Synchronized digits .&#10;Speaker: Postdoc C&#10;Content: No .&#10;Speaker: PhD F&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: We - we 'll give everybody the same sheet&#10;Speaker: PhD F&#10;Content: It 's like a {disfmarker} like a Greek {disfmarker} like a Greek choir ?&#10;Speaker: PhD A&#10;Content: but they say different {disfmarker}&#10;Speaker: PhD F&#10;Content: You know ?&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: Grad E&#10;Content: Hey , what a good idea .&#10;Speaker: PhD F&#10;Content: Like {disfmarker}&#10;Speaker: Grad E&#10;Content: We could do the same sheet for everyone .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Have them all read them at once .&#10;Speaker: PhD A&#10;Content: Well , different digits">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="m - hmm .&#10;Speaker: PhD F&#10;Content: and I could ask them what they get {pause} on TI - digits .&#10;Speaker: Professor B&#10;Content: Yeah , bu although I 'd be {disfmarker} I think it 'd be interesting to just take this exact actual system so that these numbers were comparable&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: and try it out on TI - digits .&#10;Speaker: PhD F&#10;Content: Well , Adam knows how to run it ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Yeah . No problem .&#10;Speaker: PhD F&#10;Content: so you just make a f&#10;Speaker: Professor B&#10;Content: Yeah . Yeah . Cuz our sense from the other {disfmarker} from the Aurora , uh , task is that {disfmarker}&#10;Speaker: Grad E&#10;Content: And try it with TI - digits ?&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , cuz we were getting sub one">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Have all participants read the same set of digits at once, with the expectation that they will be grouped differently. This is to test if any differences in reading can be noticed and to explore the various possibilities. (Grad E, PhD A, Postdoc C, Professor B)&#10;2. Consider using a TI-digits database for speaker normalization, variance normization, and VTL estimation during editing. The expectation is that this will result in very clean recordings, especially since TI-digits are perceived to be American English. (Grad E)&#10;3. It was also suggested that the same system should be used for all comparisons, including trying out the system on TI-digits, to ensure accurate and consistent results. (Professor B, PhD F)" target="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target=" {pause} some {disfmarker} some mail from her .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: So , I 'll make a {disfmarker}&#10;Speaker: Postdoc C&#10;Content: I 'm looking forward to seeing your representation . That 'd be , uh {disfmarker}&#10;Speaker: PhD A&#10;Content: And w we should get {pause} the two meetings from y&#10;Speaker: Postdoc C&#10;Content: I 'd like to see that . Yeah .&#10;Speaker: PhD A&#10;Content: I mean , I know about the first meeting , um , but the other one that you did , the NSA one , which we {pause} hadn't done cuz we weren't running recognition on it , because the non - native speaker {disfmarker}&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: there were five non - native speakers .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm . I see . Mm - hmm .&#10;Speaker: PhD A&#10;Content: But , it would">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target=" confuse somebody who looks at these later .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: I mean , this is {disfmarker} we we 're recording secret NSA meetings ?&#10;Speaker: PhD F&#10;Content: Um . Not the {disfmarker}&#10;Speaker: Professor B&#10;Content: I mean , it 's {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah . Not that NSA .&#10;Speaker: PhD F&#10;Content: Uh . The {disfmarker} th the {disfmarker}&#10;Speaker: PhD A&#10;Content: They are hard to understand .&#10;Speaker: Professor B&#10;Content: It 's network services and applications .&#10;Speaker: PhD F&#10;Content: Wait .&#10;Speaker: PhD A&#10;Content: They 're very , uh , out there .&#10;Speaker: PhD F&#10;Content: The {disfmarker}&#10;Speaker: PhD A&#10;Content: I have no idea what they 're talking about .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target=" try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: and we don't know what people are doing . Try to create a paper out of that .&#10;Speaker: Professor B&#10;Content: Yeah . I mean , y y you folks have probably {pause} already told me , but were {disfmarker} were you intending to do a Eurospeech submission , or {disfmarker} ?&#10;Speaker: PhD A&#10;Content: Um , you mean the one due tomorrow ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Yeah . Well , we 're still , like , writing the scripts for doing the research , and we will {disfmarker} Yes , we 're gonna try .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And I was telling Don , do not {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target=" find in common {disfmarker} roughly in common , was on a Saturday .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Ugh .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: It 's pretty sad .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Have {disfmarker} Have we thought about having a conference call to include him in more of {disfmarker} {vocalsound} in more of the meeting ? I {disfmarker} I mean , I don't know , if we had the {disfmarker} if we had the telephone on the table {disfmarker}&#10;Speaker: Professor B&#10;Content: No . But , h I mean , he probably has to go do something .&#10;Speaker: PhD F&#10;Content: No , actually I {disfmarker} I have to {disfmarker} I have to shuttle {pause} kids from various places to various other places .&#10;Speaker: Professor B&#10;Content: Right ?">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, it appears that PhD A and Postdoc C briefly discussed a meeting that took place with five non-native speakers, which may have been referred to as the &quot;NSA&quot; meeting. However, there was no clear update or decision made about the status of this meeting in the conversation. It is possible that further details were discussed after the excerpt provided or that it will be addressed in future communications. Without additional context or information, it is difficult to provide a definitive answer regarding the current status or outcome of the meeting." target="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information.">
      <data key="d0">1</data>
    </edge>
    <edge source=" confuse somebody who looks at these later .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: I mean , this is {disfmarker} we we 're recording secret NSA meetings ?&#10;Speaker: PhD F&#10;Content: Um . Not the {disfmarker}&#10;Speaker: Professor B&#10;Content: I mean , it 's {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah . Not that NSA .&#10;Speaker: PhD F&#10;Content: Uh . The {disfmarker} th the {disfmarker}&#10;Speaker: PhD A&#10;Content: They are hard to understand .&#10;Speaker: Professor B&#10;Content: It 's network services and applications .&#10;Speaker: PhD F&#10;Content: Wait .&#10;Speaker: PhD A&#10;Content: They 're very , uh , out there .&#10;Speaker: PhD F&#10;Content: The {disfmarker}&#10;Speaker: PhD A&#10;Content: I have no idea what they 're talking about .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F" target="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI.">
      <data key="d0">1</data>
    </edge>
    <edge source=" try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: and we don't know what people are doing . Try to create a paper out of that .&#10;Speaker: Professor B&#10;Content: Yeah . I mean , y y you folks have probably {pause} already told me , but were {disfmarker} were you intending to do a Eurospeech submission , or {disfmarker} ?&#10;Speaker: PhD A&#10;Content: Um , you mean the one due tomorrow ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Yeah . Well , we 're still , like , writing the scripts for doing the research , and we will {disfmarker} Yes , we 're gonna try .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And I was telling Don , do not {" target="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="aker: PhD A&#10;Content: Well , yeah . You could look at , I guess , that PZM or something .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: Professor B&#10;Content: But the other is , it 's very , uh {disfmarker} I mean , even though there 's {disfmarker} I 'm sure the f f the {disfmarker} the SRI , uh , front - end has some kind of pre - emphasis , it 's {disfmarker} it 's , uh {disfmarker} {vocalsound} still , th it 's picking up lots of low - frequency energy .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So , even discriminating against it , I 'm sure some of it 's getting through . Um . But , yeah , you 're right . Prob - a part of it is just the distance .&#10;Speaker: PhD A&#10;Content: And aren't these pretty bad microphones ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="'t these pretty bad microphones ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean {disfmarker}&#10;Speaker: Professor B&#10;Content: Well , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah .&#10;Speaker: Grad E&#10;Content: Yeah . When you listen to it , uh , the PZM and the PDA {disfmarker} Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty {disfmarker} uh , pretty much the same .&#10;Speaker: PhD A&#10;Content: I just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So .&#10;Speaker: Professor B&#10;Content: Well , they 're {pause} twenty - five cents or so .&#10;Speaker: Grad E&#10;Content: Th - we wanted them to be {disfmarker} to be typical of what would be in a PDA .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target=" single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .&#10;Speaker: Grad E&#10;Content: Maybe it 's the Bell Gram . Bell Digits . Alright .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones being used are of poor quality, as mentioned by PhD A and Grad E. This can significantly affect the recording quality.&#10;2. There is an issue with low-frequency energy capture, as pointed out by Professor B. Despite possible pre-emphasis in the front-end, the system is still picking up a lot of low-frequency energy, which could be negatively impacting the recordings.&#10;3. The distance between the speakers and the microphones may also affect recording quality, as suggested by Professor B. Even if lower-quality microphones are used, bringing them closer to the speakers can improve the recordings.&#10;4. There might be room acoustics affecting the sound quality, as mentioned by PhD F. Adapting the models to the specific room acoustics could potentially improve the recording quality.&#10;5. Background noise could also contribute to lower recording quality, and it would be addressed by adapting the models to the specific noise present in the recording environment, as suggested by PhD F." target="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones.">
      <data key="d0">1</data>
    </edge>
    <edge source="'t these pretty bad microphones ?&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean {disfmarker}&#10;Speaker: Professor B&#10;Content: Well , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah .&#10;Speaker: Grad E&#10;Content: Yeah . When you listen to it , uh , the PZM and the PDA {disfmarker} Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty {disfmarker} uh , pretty much the same .&#10;Speaker: PhD A&#10;Content: I just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So .&#10;Speaker: Professor B&#10;Content: Well , they 're {pause} twenty - five cents or so .&#10;Speaker: Grad E&#10;Content: Th - we wanted them to be {disfmarker} to be typical of what would be in a PDA .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Spe" target="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios.">
      <data key="d0">1</data>
    </edge>
    <edge source=" single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .&#10;Speaker: Grad E&#10;Content: Maybe it 's the Bell Gram . Bell Digits . Alright .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that" target="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios.">
      <data key="d0">1</data>
    </edge>
    <edge source=" single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .&#10;Speaker: Grad E&#10;Content: Maybe it 's the Bell Gram . Bell Digits . Alright .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that" target="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .&#10;Speaker: Grad E&#10;Content: Maybe it 's the Bell Gram . Bell Digits . Alright .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that" target="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" single digit . And then others were connected digits .&#10;Speaker: Professor B&#10;Content: Yeah . Most of TI - digits is connected digits , I think .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits .&#10;Speaker: Grad E&#10;Content: Maybe it 's the Bell Gram . Bell Digits . Alright .&#10;Speaker: Professor B&#10;Content: Um .&#10;Speaker: PhD F&#10;Content: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .&#10;Speaker: Grad E&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that" target="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios." target=" a PDA .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: So they are {disfmarker} they 're not the PZM three hundred dollar type . They 're the twenty - five cent ,&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: buy them in packs of thousand type .&#10;Speaker: PhD A&#10;Content: I see .&#10;Speaker: Professor B&#10;Content: But , I mean , the thing is people use those little mikes for everything because they 're really not bad .&#10;Speaker: Grad E&#10;Content: Everything .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I mean , if you 're not {vocalsound} doing something ridiculous like feeding it to a speech recognizer , they {disfmarker} they {disfmarker} {vocalsound} they {disfmarker} you know , you can hear the sou hear the sounds just fine .&#10;Speaker: PhD A&#10;Content: Right .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios." target=" .&#10;Speaker: PhD F&#10;Content: I 'll let {disfmarker} I 'd let {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I let , uh , my five - year - old have a try at the digits , eh .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: So , anyway , I can talk about digits . Um , did everyone get the results or shall I go over them again ? I mean that it was basically {disfmarker} the only thing that was even slightly surprising was that the lapel did so well . Um , and in retrospect that 's not as surprising as maybe i it shouldn't have been as surprising as I {disfmarker} as {disfmarker} as I felt it was . The lapel mike is a very high - quality microphone . And as Morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling {pause} if no one else is talking .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Exactly .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The microphones were purchased intentionally cheap, as mentioned by PhD A and Grad E, primarily for the purpose of being affordable. They cost around twenty-five cents each and are bought in bulk packages of thousands.&#10;2. Despite being inexpensive, these microphones are still functional and serve their purpose well in many situations, as noted by Professor B. As long as they are not used for critical applications like feeding into a speech recognizer, their sound quality is adequate.&#10;3. The microphones' sound quality is comparable to typical microphones found in a Personal Digital Assistant (PDA), as stated by Grad E and Professor B. They were intentionally chosen to be similar in quality to those commonly found in PDAs to maintain consistency and better represent real-world usage scenarios." target="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation." target="ound} there was a significant , um , loss or win {comment} from adaptation {disfmarker} with {disfmarker} with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small {disfmarker} like point one percent on the natives {disfmarker} uh , win from doing , um , you know , adaptation to {pause} the recognition hypotheses . And {pause} I tried both means adaptation and means and variances , and the variances added another {disfmarker} or subtracted another point one percent . So , {vocalsound} it 's , um {disfmarker} that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: But I think one thing is that , uh , I would presume {disfmarker} Hav - Have you ever t {vocalsound} Have you ever tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No">
      <data key="d0">1</data>
    </edge>
    <edge source="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation." target=" of the other digit tasks .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right . But {disfmarker} but , I would {disfmarker} Yeah . It 's {disfmarker} it 's easy enough to try , just run it on {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: See w&#10;Speaker: Grad E&#10;Content: So , Morgan , you 're getting a little breath noise .&#10;Speaker: PhD F&#10;Content: Now , eh , does {disfmarker}&#10;Speaker: Grad E&#10;Content: You might wanna move the mike down a little bit .&#10;Speaker: PhD F&#10;Content: one {disfmarker} one issue {disfmarker} one issue with {disfmarker} with that is that {vocalsound} um , the system has this , uh , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and">
      <data key="d0">1</data>
    </edge>
    <edge source="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation." target="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes.">
      <data key="d0">1</data>
    </edge>
    <edge source="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation." target="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions.">
      <data key="d0">1</data>
    </edge>
    <edge source="The issue with the system's use of a speaker model for adaptation and variance norm in mean and mean in the context of speech is that if there is only one utterance per speaker, it may negatively affect the estimation of the warping factor. This could potentially lead to inaccurate results in speech processing tasks such as VTL (vocal tract length) estimation." target="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="ound} there was a significant , um , loss or win {comment} from adaptation {disfmarker} with {disfmarker} with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small {disfmarker} like point one percent on the natives {disfmarker} uh , win from doing , um , you know , adaptation to {pause} the recognition hypotheses . And {pause} I tried both means adaptation and means and variances , and the variances added another {disfmarker} or subtracted another point one percent . So , {vocalsound} it 's , um {disfmarker} that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: But I think one thing is that , uh , I would presume {disfmarker} Hav - Have you ever t {vocalsound} Have you ever tried this exact same recognizer out on the actual TI - digits test set ?&#10;Speaker: PhD F&#10;Content: This exact same recognizer ? No" target="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance.">
      <data key="d0">1</data>
    </edge>
    <edge source=" of the other digit tasks .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right . But {disfmarker} but , I would {disfmarker} Yeah . It 's {disfmarker} it 's easy enough to try , just run it on {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: See w&#10;Speaker: Grad E&#10;Content: So , Morgan , you 're getting a little breath noise .&#10;Speaker: PhD F&#10;Content: Now , eh , does {disfmarker}&#10;Speaker: Grad E&#10;Content: You might wanna move the mike down a little bit .&#10;Speaker: PhD F&#10;Content: one {disfmarker} one issue {disfmarker} one issue with {disfmarker} with that is that {vocalsound} um , the system has this , uh , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and" target="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." target=" . Yeah . Yeah .&#10;Speaker: Grad G&#10;Content: I don't think that was the new version .&#10;Speaker: PhD A&#10;Content: Um {disfmarker} That {disfmarker} Yeah , actually it wasn't the new new , it was the medium new .&#10;Speaker: Postdoc C&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: But {disfmarker} but we would {disfmarker} we should do the {disfmarker} the latest version .&#10;Speaker: Postdoc C&#10;Content: OK .&#10;Speaker: Grad G&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It was the one from last week .&#10;Speaker: Grad G&#10;Content: You {disfmarker} did you adjust the {disfmarker} the utterance times , um , for each channel ?&#10;Speaker: Postdoc C&#10;Content: Yes . Yes , I did . And furthermore , I found that there were a certain number where {disfmarker} {vocalsound} not {disfmarker} not a lot , but several times I actually {vocalsound} moved an utterance">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." target=" {disfmarker} like , the beginning of the first word , the end of the last word {disfmarker} and then we could , you know , do some adjustments .&#10;Speaker: Postdoc C&#10;Content: Yeah . I {disfmarker} OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts , {comment} that would help .&#10;Speaker: PhD F&#10;Content: No .&#10;Speaker: Postdoc C&#10;Content: And then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: but {disfmarker} but in terms {disfmarker}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: So I {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." target=" this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and then that 's the {disfmarker} that 's what the {disfmarker}&#10;Speaker: Grad E&#10;Content: I think Transcriber , uh , outputs CTM .&#10;Speaker: Postdoc C&#10;Content: If it {disfmarker} ? OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: So you would know this more than I would .&#10;Speaker: Grad E&#10;Content: I think so .&#10;Speaker: PhD A&#10;Content: So , I mean {disfmarker}&#10;Speaker: Postdoc C&#10;Content: It seems like she {disfmarker} if she 's g if she 's moving time marks around ,&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: since our representation in Transcriber uses time marks , it seems like there should be some way of {disfmarker} of using that {disfmarker} benefitting from that .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." target="er}&#10;Speaker: Postdoc C&#10;Content: Well , I th I 'm thinking just ch e e incorporating it into the representation .&#10;Speaker: PhD A&#10;Content: Um .&#10;Speaker: Postdoc C&#10;Content: I mean , if it 's {disfmarker} if it 's {disfmarker}&#10;Speaker: PhD A&#10;Content: You mean like {disfmarker} Yeah , word start insights .&#10;Speaker: Postdoc C&#10;Content: if you have start points , if you have , like , time tags ,&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: which is what I assume . Isn't that what {disfmarker} what you {disfmarker} ? Well , see , Adam would be {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah , whatever you use .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: I mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." target="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Postdoc C mentioned that they adjusted the utterance times for each channel in the medium new version of the project from last week. They also moved the beginning and end of some utterances and found several instances where this was necessary. However, the transcript does not provide specific details about the extent or nature of these adjustments. It is possible that further information was discussed during the meeting, but the relevant portions were not included in the excerpt provided. Without additional context or information, it is difficult to answer this question definitively." target="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} like , the beginning of the first word , the end of the last word {disfmarker} and then we could , you know , do some adjustments .&#10;Speaker: Postdoc C&#10;Content: Yeah . I {disfmarker} OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts , {comment} that would help .&#10;Speaker: PhD F&#10;Content: No .&#10;Speaker: Postdoc C&#10;Content: And then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: but {disfmarker} but in terms {disfmarker}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: So I {disf" target="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files." target=" do that anyway .&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Grad E&#10;Content: Oh . So , although you {disfmarker} you can pipe it as well , we tend to do it that way because that way you can concentrate on one block and not keep re - doing it over and over .&#10;Speaker: PhD F&#10;Content: Oh , OK .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Alright .&#10;Speaker: Professor B&#10;Content: Yeah . So I 've {disfmarker} I {disfmarker}&#10;Speaker: Grad E&#10;Content: So tha that 's exactly what the P - file {pause} is for .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Yeah , the {disfmarker} the {disfmarker} the cumbersome thing is {disfmarker} is , um {disfmarker} is that you actually have to dump out little {disfmarker} little files .&#10;Speaker: PhD A&#10;Content: Uh {disfmarker}&#10;Speaker: PhD F&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for tending to concentrate on one block and not repeatedly doing it over when piping is that this method allows the speaker to focus on a single section of the content without interruption. This can help improve the flow and coherence of the spoken material.&#10;2. Creating separate files is considered cumbersome because, in this context, handling multiple files requires additional effort for managing, organizing, and keeping track of them. The process can become tedious and time-consuming, especially when dealing with a large number of small files." target=" {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors {pause} that were occurring and um , some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a um , I think was both a {disfmarker} a pruning {pause} problem and possibly a problem with needing constraints on word locations . And so we tried both of these st things . We tried saying {disfmarker} I don't know , I got this {vocalsound} whacky idea that {disfmarker} just from looking at the data , that when people talk {pause} their words are usually chunked together . It 's not that they say one word and then there 's a bunch of words together . They 're {comment} might say one word and then another word far away if they were doing just backchannels ? But in general , if there 's , like , five or six words and one word 's far away from it , that 's probably wrong on average . So , um {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group." target=" need , eh , something , eh , from us in the future , I {disfmarker} I will be at Spain , {vocalsound} to you help , uh .&#10;Speaker: Professor B&#10;Content: Well .&#10;Speaker: Grad E&#10;Content: Great .&#10;Speaker: Postdoc C&#10;Content: Great .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: Thank you , Jose .&#10;Speaker: Postdoc C&#10;Content: Thank you .&#10;Speaker: PhD H&#10;Content: And , thank you very much .&#10;Speaker: PhD F&#10;Content: Have a good trip .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Keep in touch .&#10;Speaker: PhD H&#10;Content: Thank you .&#10;Speaker: Professor B&#10;Content: Yeah . OK . I guess , uh , unless somebody has something else , we 'll read {disfmarker} read our digits&#10;Speaker: Grad E&#10;Content: Digits ?&#10;Speaker: Professor B&#10;Content: and we 'll get our {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group." target="&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The last meeting meeting ?&#10;Speaker: PhD H&#10;Content: Because , eh , I leave , eh , the next Sunday .&#10;Speaker: Grad E&#10;Content: It 's off .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD H&#10;Content: I will come back to home {disfmarker} to Spain .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: Professor B&#10;Content: I d so I {disfmarker} I jus&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD H&#10;Content: And I {disfmarker} I would like to {disfmarker} to {disfmarker} to say thank you very much , eh , to all people {pause} in the group and at ICSI ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Yeah . It was">
      <data key="d0">1</data>
    </edge>
    <edge source="The difficulty discussed by PhD H is likely related to their upcoming departure, as they mention leaving soon and wanting to say thank you to everyone in the group and at ICSI. They may be facing challenges with time constraints or other issues related to their departure.&#10;&#10;PhD H suggests being contacted in the future by saying &quot;I will be at Spain, I will try to recommend at the Spanish government but the following scholarship will be here more time, I think a year is a lot better.&quot; This suggests that they may be seeking a way to extend their stay or make arrangements to return to the group in the future. They may also be interested in exploring funding opportunities through the Spanish government or other sources to support their continued involvement with the group." target="} I will try to recommend , eh , at , eh , {vocalsound} the Spanish government but , eh , the following @ @ scholarship , eh , eh , {vocalsound} eh , will be here {pause} more time , because eh , i in my opinion is {disfmarker} is better , {vocalsound} eh , for us {pause} to {disfmarker} to spend more time here and to work more time i i in a topic .&#10;Speaker: Professor B&#10;Content: Yeah , it 's a very short time .&#10;Speaker: PhD H&#10;Content: No ? But , uh {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah . Yeah .&#10;Speaker: Grad E&#10;Content: Yeah , six months is hard .&#10;Speaker: PhD H&#10;Content: Yeah . It is .&#10;Speaker: Grad E&#10;Content: I think a year is a lot better .&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: It 's difficult . You {disfmarker} e you have , eh {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The last meeting meeting ?&#10;Speaker: PhD H&#10;Content: Because , eh , I leave , eh , the next Sunday .&#10;Speaker: Grad E&#10;Content: It 's off .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD H&#10;Content: I will come back to home {disfmarker} to Spain .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: Professor B&#10;Content: I d so I {disfmarker} I jus&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: PhD H&#10;Content: And I {disfmarker} I would like to {disfmarker} to {disfmarker} to say thank you very much , eh , to all people {pause} in the group and at ICSI ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Yeah . It was" target="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="Speaker: Professor B&#10;Content: Mm - hmm . Right . I understand . But doing the same kind of limited thing {disfmarker}&#10;Speaker: PhD A&#10;Content: Or {disfmarker} or some high number .&#10;Speaker: Professor B&#10;Content: Yeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing {vocalsound} as people have done in Switchboard evaluations or as {disfmarker} a&#10;Speaker: PhD A&#10;Content: Yeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ?&#10;Speaker: Professor B&#10;Content: Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ?&#10;Speaker: Grad E&#10;Content: Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ?&#10;Speaker: Professor B&#10;Content: Yeah , do it with one of {disfmarker} on&#10;Speaker: Grad E&#10;Content: Cuz we extract the times from the near - field mike , but you use">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Uh , I mean , I think that 's actually really u useful also&#10;Speaker: PhD F&#10;Content: And {disfmarker}&#10;Speaker: PhD A&#10;Content: because even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to {pause} get a transcript like {disfmarker} like this anyway , just for doing far - field recognition . So , you know , it 's {disfmarker} it 's sort of {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway .&#10;Speaker: Postdoc C&#10;Content: That 's wonderful .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: PhD A&#10;Content: I mean , i I never thought about it before ,">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, it is possible to perform the current task using a far-field microphone, as suggested by Grad E. This approach would involve placing the microphone at a distance from the speakers and extracting the time information from the near-field microphone. However, this method should ensure that the speaker is known and there is no overlap, and it should only use the far-field for those regions. This is similar to how it was done in Switchboard evaluations where the same type of limited approach was taken with known speakers and disjoint speech regions." target="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Professor B&#10;Content: Mm - hmm . Right . I understand . But doing the same kind of limited thing {disfmarker}&#10;Speaker: PhD A&#10;Content: Or {disfmarker} or some high number .&#10;Speaker: Professor B&#10;Content: Yeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing {vocalsound} as people have done in Switchboard evaluations or as {disfmarker} a&#10;Speaker: PhD A&#10;Content: Yeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ?&#10;Speaker: Professor B&#10;Content: Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ?&#10;Speaker: Grad E&#10;Content: Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ?&#10;Speaker: Professor B&#10;Content: Yeah , do it with one of {disfmarker} on&#10;Speaker: Grad E&#10;Content: Cuz we extract the times from the near - field mike , but you use" target="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Uh , I mean , I think that 's actually really u useful also&#10;Speaker: PhD F&#10;Content: And {disfmarker}&#10;Speaker: PhD A&#10;Content: because even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to {pause} get a transcript like {disfmarker} like this anyway , just for doing far - field recognition . So , you know , it 's {disfmarker} it 's sort of {disfmarker}&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway .&#10;Speaker: Postdoc C&#10;Content: That 's wonderful .&#10;Speaker: PhD F&#10;Content: So {disfmarker}&#10;Speaker: PhD A&#10;Content: I mean , i I never thought about it before ," target="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes." target="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that the TI-digits database may have a sufficient number of known speakers, but the exact number is not specified. Grad E mentions that they don't know how many speakers there are in the database. However, PhD F raises the concern that if there is only one utterance per speaker, it might negatively affect the estimation of the warping factor used in VTL (vocal tract length) estimation. Therefore, it is important to consider whether the TI-digits database has a sufficient number of utterances per speaker for accurate VTL estimation and normalization processes." target="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." target=" {disfmarker} Oh , yeah . I know what I was go w&#10;Speaker: PhD F&#10;Content: What k u By the way , wh what factor of two did you {disfmarker} ?&#10;Speaker: Professor B&#10;Content: Oh , no , no .&#10;Speaker: PhD F&#10;Content: I mean {disfmarker}&#10;Speaker: Professor B&#10;Content: It 's tha that {disfmarker} that we were saying , you know , well is {disfmarker} how much worse is far than near , you know .&#10;Speaker: PhD F&#10;Content: Oh , th OK .&#10;Speaker: Professor B&#10;Content: And I mean it depends on which one you 're looking at ,&#10;Speaker: PhD F&#10;Content: That factor of two .&#10;Speaker: Professor B&#10;Content: but for the everybody , it 's {vocalsound} little under a factor or two .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Yeah . I {disfmarker} I know what I was thinking was that maybe , uh , i i we could actually">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." target="aker: Grad E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: But if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: It 's just {disfmarker} it 'll just require more {disfmarker}&#10;Speaker: PhD A&#10;Content: Just {pause} sort of huge .&#10;Speaker: PhD F&#10;Content: you know , slightly different {disfmarker}&#10;Speaker: Postdoc C&#10;Content: What 's interesting is it 's exactly what , um , i in discussing with , um , Sue about this ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Postdoc C&#10;Content: um , she , um , i i i indicated that that {disfmarker} you know , that 's very important for overlap analysis .&#10;Speaker: PhD A&#10;Content: Yeah . It 's {disfmarker} it 's nice to know ,&#10;Speaker: PhD F&#10;Content: Right">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." target=" an important data point , if you 're {disfmarker} if {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: Um . The other thing that {disfmarker} that , uh {disfmarker} of course , what Barry was looking at was {disfmarker} was just that , the near versus far . And , yeah , the adaptation would get {vocalsound} th some of that .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: But , I think even {disfmarker} even if there was , uh , only a factor of two or something , like I was saying in the email , I think that 's {disfmarker} {vocalsound} that 's a big factor . So {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: N&#10;Speaker: Grad E&#10;Content: Liz , you could also just use the other mike if you 're having problems with that one .&#10;Speaker: Postdoc">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." target="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." target="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript discusses the comparison between far-field and near-field microphones for a specific task. At one point in the conversation, Professor B mentions that &quot;for everybody, it's a little under a factor of two&quot; when comparing the negative impact of far actions to near actions. This implies that using far-field microphones results in degraded performance compared to near-field microphones, with the difference being around a factor of two.&#10;&#10;However, the reason for this dependence on which action is being considered is not explicitly explained in the transcript. It can be inferred that the impact may vary depending on the specific scenario, task constraints, or other factors related to the implementation. The speakers do not delve deeper into the reasons behind this difference in the provided text." target="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions." target=" or period or , {vocalsound} um , you know , comma and things like that , and we kept the {disfmarker} and disfluency dashes {disfmarker} uh , kept those in because we sort of wanna know where those are relative to the spurt overlaps {disfmarker}&#10;Speaker: PhD F&#10;Content: Mm - hmm . Right .&#10;Speaker: PhD A&#10;Content: sp overlaps ,&#10;Speaker: PhD F&#10;Content: So {disfmarker} so those are actually sort of retro - fitted into the time alignment .&#10;Speaker: PhD A&#10;Content: or {disfmarker}&#10;Speaker: PhD F&#10;Content: And then we merge all the alignments from the various channels and we sort them by time . And then there 's a {disfmarker} then there 's a process where you now determine the spurts . That is {disfmarker} Actually , no , you do that before you merge the various channels . So you {disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Identification of spurt boundaries: The process involves identifying the beginnings and ends of speech spurts based on a pause length criterion. A pause is defined as a period of silence between words or intonation units in speech. By setting a threshold for pause length, it is possible to determine where one spurt ends and another begins.&#10;&#10;2. Tagging spurt beginnings and ends: Once the spurt boundaries have been identified, tags are added to mark these points in the time alignment. This allows for easy identification of the spurts during subsequent analysis steps.&#10;&#10;3. Pre-merging channel determination: Before merging the various channels (i.e., different speakers or microphones), it is necessary to determine which channel corresponds to each speaker. This step is critical for accurately aligning and analyzing speech from multiple sources.&#10;&#10;4. Merging channels based on time marks: After determining the individual channels, they are merged into a single alignment based on time marks. This linearization process creates a combined timeline for all speakers, allowing for easy comparison and analysis of their speech patterns.&#10;&#10;5. Extracting individual channels with spurt information: With the merged alignment, it is possible to extract each speaker's channel individually, now marked with spurt beginnings and ends. This allows for further analysis of how each speaker's speech relates to the others in terms of overlaps, pauses, and other factors.&#10;&#10;6. Adding overlap tags: Inside words or between them, begin and end tags are added for overlaps, which helps identify regions where multiple speakers may be talking simultaneously. This information can be used to refine the analysis and better understand the dynamics of group speech interactions." target="disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then {vocalsound} you extract the individual channels again , but this time you know where the other people start and end talking {disfmarker} you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end {pause} tags for overlaps . So , you {disfmarker} you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech .&#10;Speaker: Grad E&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Uh , I mean , I think that 's actually really u">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;" target=": &quot; And then she said , and then he said . &quot;&#10;Speaker: Grad G&#10;Content: Yeah , I know it by heart . So , um , {vocalsound} there 's one point when you 're running down the stairs .&#10;Speaker: Postdoc C&#10;Content: Uh - oh .&#10;Speaker: Grad G&#10;Content: Right ? And , like , there 's an interruption . You interrupt somebody , but then there 's no line after that . For example , there 's no speaker identification after that line .&#10;Speaker: Postdoc C&#10;Content: Uh - huh .&#10;Speaker: Grad G&#10;Content: Is that what you 're talking about ? Or were there mislabellings as far as , like , the a Adam was {disfmarker} ?&#10;Speaker: Postdoc C&#10;Content: That was fixed , um , before {disfmarker} i i i I think I I think I understood that pretty {disfmarker}&#10;Speaker: Grad G&#10;Content: Yeah . Cuz I thought I let you know about that .&#10;Speaker: Postdoc C&#10;Content: Thank you for mentioning . Yeah , no , tha that {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;" target=" on my {disfmarker} on my machine cuz I didn't have a headphone .&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: So it @ @ , like , I mean {disfmarker} Yeah , I {disfmarker} I mean , i in retrospect {vocalsound} it would 've been good to ha {vocalsound} have got I should 've gotten a headphone . But in any case , um , thi this is {disfmarker} this was transcribed in a {disfmarker} in a , {vocalsound} uh , less optimal way than {disfmarker} than the ones that came after it , and I was able to {disfmarker} you know , an and this meant that there were some speaker identif identifications which were changes .&#10;Speaker: Grad G&#10;Content: Well , I know there were some speaker labelling problems , um , after interruptions .&#10;Speaker: Postdoc C&#10;Content: Yeah . Fixed that .&#10;Speaker: Grad G&#10;Content: Is that what you 're referring to ? I mean , cuz there 's this">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;" target=" mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for that , uh , might be that there 's still {disfmarker} even though it 's close - talking , there still is some noise and some room acoustics .&#10;Speaker: PhD F&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: And another might be that , uh , I 'd {disfmarker} I would presume that in the studio , uh , uh , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little {disfmarker} that they didn't include it ,&#10;Speaker: Grad E&#10;Content: They didn't include it .&#10;Speaker: Professor B&#10;Content: they made them do it again .&#10;Speaker: Grad E&#10;Content: Whereas , I took out {pause} the ones that I noticed that were blatant {disfmarker} that were correctable .&#10;Speaker: Professor B&#10;Content: Mmm . Yeah .&#10;Speaker: Grad E&#10;Content: So">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;" target="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there were issues with speaker identification in the conversation between 'she' and 'he.' There were some speaker labeling problems, particularly after interruptions. However, Postdoc C mentioned that they have already fixed those issues.&#10;2. The speakers also discussed the notion of a &quot;speaker model&quot; which is used in adaptation, variance normization, and VTL (voice tempo length) estimation. They believe that using a TI-digits database would help in speaker normalization and variance normization, as well as VTL estimation. The TI-digits database has speakers that are known, but it is unclear if there is enough data or a comparable amount of data to what they have in their recordings.&#10;3. There were also instances where the first word of an utterance was edited out to improve its cleanliness and correct mistakes such as misread digits or uncertain portions where there was confusion over whether the speaker said &quot;zero&quot; or &quot;six.&quot;" target="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript." target="marker} you know , it doesn't take weeks to train it .&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Um . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates {pause} go from {disfmarker} I don't know , in very noisy environment , like from , uh , uh {disfmarker} I for now I {disfmarker} OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to {vocalsound} eight percent or from e e you know , point {disfmarker} you know , from one percent to point eight percent ?&#10;Speaker: Professor B&#10;Content: H i it got {disfmarker} it got better .&#10;Speaker: PhD F&#10;Content: I mean , it 's a {disfmarker}&#10;Speaker: Professor B&#10;Content: Yeah , yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: It got better">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript." target="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript." target="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, PhD F mentioned that there were &quot;very impressive results&quot; with discriminative Gaussian training in a noisy environment, where error rates went from &quot;ten percent to eight percent or from one percent to point eight percent.&quot; However, Professor B was not certain about the order of magnitude. Therefore, the specific order of magnitude for this decrease in error rates is not explicitly stated in the transcript." target="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level." target="er}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: So I {disfmarker} so for {disfmarker} for one of the N S A groups . And also I went back to the original one that I first transcribed and {disfmarker} and did it w uh , w uh , utterance by utterance for that particular one . So I think you do have {disfmarker} if that 's a sufficient unit , I think that you do have hand - marking for that . But it 'd be wonderful to be able to {vocalsound} benefit from your Waves stuff .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: We don't care what {disfmarker} what tool you use .&#10;Speaker: PhD A&#10;Content: Yeah . I mean , if {disfmarker} if you can , um {disfmarker} if you wanna {disfmarker}&#10;Speaker: Postdoc C&#10;Content: OK . I used it in Transcriber&#10;Speaker: PhD F&#10;Content: U uh">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level." target="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level." target="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Yes, there was a discussion about using 'Waves' during the meeting. Postdoc C asked PhD F if it would be possible to incorporate what they did with Waves into the present transcripts, to which PhD F responded that the tool used didn't matter. Later, Postdoc C confirmed that they had used Waves in Transcriber.&#10;2. Yes, there is a hand-marked transcript with individual utterances that could be used for adjustments in the transcription process. Postdoc C mentioned that one of the transcripts was gone over by a transcriber and then hand-marked by them, so they do have the beginning and ending of individual utterances, although not at a word level." target="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons." target="Speaker: PhD D&#10;Content: Other way .&#10;Speaker: Grad E&#10;Content: Other way . Liz {disfmarker}&#10;Speaker: PhD A&#10;Content: Now you 're all watching me .&#10;Speaker: Grad E&#10;Content: It f it clips over your ears .&#10;Speaker: PhD A&#10;Content: Alright . This way .&#10;Speaker: Grad E&#10;Content: There you go .&#10;Speaker: Postdoc C&#10;Content: If you have a strong fe if you have a strong preference , you could use this .&#10;Speaker: PhD A&#10;Content: You 're all watching . This is terrible .&#10;Speaker: Postdoc C&#10;Content: It 's just we {disfmarker} we think it has some spikes . So , uh , we {disfmarker} we didn't use that one .&#10;Speaker: PhD A&#10;Content: I 'll get it .&#10;Speaker: Postdoc C&#10;Content: But you could if you want .&#10;Speaker: Professor B&#10;Content: Yeah . At any rate , I don't know if w&#10;Speaker: Postdoc C&#10;Content: I don't know . And Andre - Andreas">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific information about the object in question, but based on the context, it seems that the group is discussing the use of different tools or methods for transcribing audio data. Specifically, Postdoc C brings up the idea of using 'Waves' and mentions that there are some spikes in one of the transcripts, which they did not use. However, the reason for rejecting it is not explicitly stated in the transcript.&#10;&#10;Overall, the speakers express positive opinions about a certain place or experience, with words such as &quot;yeah,&quot; &quot;nice,&quot; and &quot;very nice.&quot; They also express excitement and admiration for the appearance of the food.&#10;&#10;Regarding the tool or method for transcribing audio data, Postdoc C mentions Chafe's work on intonation units and spurts, and there is discussion about how to do it better. However, PhD F notes that the conference organizers have a monetary interest in getting lots of submissions, which sometimes means a little extra time.&#10;&#10;Therefore, while the speakers generally express positive opinions about the object or experience being discussed, Postdoc C rejects using 'Waves' for unspecified reasons." target="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance." target=" , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause} all the participants in Aurora , {vocalsound} was so much worse {vocalsound} than the {disfmarker} than the S R&#10;Speaker: Grad E&#10;Content: Everybody .&#10;Speaker: Professor B&#10;Content: And the interesting thing is that even though , {vocalsound} yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , {vocalsound} it 's just not as good as having a {disfmarker} a l very large amount of data and training up a {disfmarker} a {disfmarker} a nice good big {vocalsound} HMM . Um , also you had the adaptation in the SRI system , which we didn't have in this . Um . So . Um .&#10;Speaker: PhD F&#10;Content: And we know {disfmarker} Di - did I send you some results without adaptation ?&#10;Speaker: Grad E&#10;Content: No .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance." target="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The question asks about trying out the current recognizer on the actual TI-digits test set. Based on the discussion, none of the participants have tried this exact recognizer on TI-digits yet. However, PhD F mentions that people at SRI are working on digits and using a system trained on digits, which performs better than their previous system based on HTK.&#10;2. The SRI system, when trained on digits, outperforms the limited training HTK system used by the participants in the Aurora project. This is true even though the digits task involves a smaller number of words and has more training data available. Additionally, the SRI system incorporates adaptation, which further improves its performance compared to the other systems not using adaptation.&#10;&#10;In summary, trying out the recognizer on the TI-digits test set is expected to yield better results than the previous HTK-based system. The SRI system, when trained on digits and utilizing adaptation techniques, compares favorably against other digit recognition systems in terms of performance." target="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The original data format proposed by PhD F, based on the transcription graph, is not explicitly stated in the transcript. However, it seems that this format has the capability of incorporating certain information, such as Waves, which can't be obtained directly from the transcription.&#10;2. It is not possible to obtain the desired information directly from the transcription because, as PhD A mentioned, there might be issues with the quality of microphones, low-frequency energy capture, distance between speakers and microphones, room acoustics, or background noise. These factors could affect the recording quality and make it difficult to extract the required data directly from the transcription." target=" PhD F&#10;Content: So {disfmarker}&#10;Speaker: PhD A&#10;Content: I mean , i I never thought about it before ,&#10;Speaker: Grad E&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: And {disfmarker} and we {disfmarker}&#10;Speaker: PhD A&#10;Content: but {disfmarker}&#10;Speaker: Grad E&#10;Content: Y yes .&#10;Speaker: PhD F&#10;Content: In {disfmarker}&#10;Speaker: Grad E&#10;Content: I mean , s when I came up with the original data {disfmarker} suggested data format based on the transcription graph , there 's capability of doing that sort of thing in there .&#10;Speaker: PhD A&#10;Content: Right . But you can't get it directly from the transcription .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm . Yeah , that 's right .&#10;Speaker: PhD F&#10;Content: Right . Well , this is {disfmarker} this is just {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , this is like a poor">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target="m - hmm .&#10;Speaker: Postdoc C&#10;Content: and the most natural way is for you to have initiated the topic by asking a question .&#10;Speaker: PhD F&#10;Content: Well ,&#10;Speaker: PhD A&#10;Content: That 's interesting .&#10;Speaker: PhD F&#10;Content: I think {disfmarker} No . I think it 's {disfmarker} actually I think what 's going on is backchannelling is something that happens in two - party conversations .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: And if you ask someone a question , you essentially initiating a little two - party conversation .&#10;Speaker: Postdoc C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Well , actu Yeah , when we looked at this {disfmarker}&#10;Speaker: Postdoc C&#10;Content: Exactly .&#10;Speaker: PhD F&#10;Content: So then you 're {disfmarker} so and then you 're expected to backchannel because the person is addressing you directly and not everybody .&#10;Speaker: Postdoc C&#10;Content: Exactly .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target="disfmarker} w well , I won't say &quot; usually &quot; {disfmarker} but anyway , very often , I picked them up in a channel {vocalsound} w which was the person who had asked a question . S so , like , someone says &quot; an and have you done the so - and - so ? &quot; And then there would be backchannels , but it would be the person who asked the question . Other people weren't really doing much backchannelling . And , you know , sometimes you have the {disfmarker} Yeah , uh - huh .&#10;Speaker: PhD A&#10;Content: Well , that 's interesting . Yeah .&#10;Speaker: Postdoc C&#10;Content: I mean , i it wouldn't be perfect , but {disfmarker} but it does seem more natural to give a backchannel when {disfmarker} when you 're somehow involved in the topic ,&#10;Speaker: PhD A&#10;Content: No , that 's really interesting .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc C&#10;Content: and the most natural way is for you to have initiated the topic by asking a question">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target=" and then you 're expected to backchannel because the person is addressing you directly and not everybody .&#10;Speaker: Postdoc C&#10;Content: Exactly . Exactly my point . An - and so this is the expectation thing that {disfmarker} uh , uh ,&#10;Speaker: PhD F&#10;Content: Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: just the dyadic {disfmarker}&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: But in addition , you know , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what {disfmarker} what the answer is that this {disfmarker} that the {disfmarker} the answerer 's given {disfmarker}&#10;Speaker: Professor B&#10;Content: H&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Professor B&#10;Content: I tell you , I say {disfmarker} I say &quot; uh - huh">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target=" is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {disfmarker} and these {disfmarker}&#10;Speaker: PhD A&#10;Content: Right . There 's just probably less backchannelling in general ,&#10;Speaker: Postdoc C&#10;Content: Mm - hmm . So that 's good news , really .&#10;Speaker: PhD A&#10;Content: even if you consider every other person altogether one person in the meeting , but we 'll find out anyway . We were {disfmarker} I guess the other thing we 're {disfmarker} we 're {disfmarker} I should say is that we 're gonna , um try {disfmarker} compare this type of overlap analysis to Switchboard , where {disfmarker}&#10;Speaker: PhD F&#10;Content: And&#10;Speaker: PhD A&#10;Content: and CallHome , where we have both sides , so that we can try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target=" words .&#10;Speaker: Postdoc C&#10;Content: Oh , yeah .&#10;Speaker: PhD A&#10;Content: And &quot; uh - huh &quot; is not as frequent as it sort of would be in Switchboard , if you looked at just a word frequency list of one - word short utterances . And &quot; yeah &quot; is way up there , but not &quot; uh - huh &quot; . And so I was thinking thi it 's not like {pause} you 're being encouraged by everybody else to keep {pause} talking in the meeting . And uh , that 's all , I I 'll stop there , cuz I I think what you say makes a lot of sense .&#10;Speaker: Postdoc C&#10;Content: Well , that 's right . And that would {disfmarker}&#10;Speaker: PhD A&#10;Content: But it was sort of {disfmarker}&#10;Speaker: Postdoc C&#10;Content: Well , an And what you say is the {disfmarker} is the re uh , o other side of this , which is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target="&#10;Content: We don't even have enough channel {disfmarker}&#10;Speaker: Professor B&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: Because it would be a different kind of meeting ,&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: that 's what I 'm {disfmarker}&#10;Speaker: Professor B&#10;Content: Well {disfmarker}&#10;Speaker: PhD F&#10;Content: But {disfmarker}&#10;Speaker: PhD H&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I hadn't {pause} really thought of it ,&#10;Speaker: PhD F&#10;Content: Maybe just {disfmarker} maybe not the whole day&#10;Speaker: Professor B&#10;Content: but {disfmarker}&#10;Speaker: PhD F&#10;Content: but just , you know , maybe some {disfmarker} I mean ,&#10;Speaker: Professor B&#10;Content: Maybe part of it .&#10;Speaker: PhD F&#10;Content: part of it ?&#10;Speaker: Professor B&#10;Content: Maybe part of it .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, backchanneling in a two-party conversation occurs when one participant responds with brief utterances such as &quot;mm-hmm,&quot; &quot;uh-huh,&quot; or &quot;yeah&quot; to indicate active listening and engagement with the speaker. In this context, it is related to initiating a conversation because when a question is asked, it typically marks the beginning of a two-party conversation. The person who is addressed directly in the question is then expected to backchannel, acknowledging that they are involved in the topic and following the conversation closely. This dynamic reinforces the interaction between the two parties and fosters effective communication." target="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks." target=" over the telephone you don't actually want to put a whole lot of effort into adaptation&#10;Speaker: PhD F&#10;Content: Well , I don't know .&#10;Speaker: Professor B&#10;Content: because {vocalsound} somebody {pause} gets on the phone and says a number and then you just want it . You don't {disfmarker} don't , uh {disfmarker}&#10;Speaker: Postdoc C&#10;Content: This is {disfmarker} this {disfmarker} that one 's better .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Postdoc C&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um , but , you know , I {disfmarker} uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to {disfmarker} you want to {disfmarker} That 's the obvious thing to try .&#10;Speaker: Postdoc C&#10;Content: Oh . Oh .&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: Right ?">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks." target="Content: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted {disfmarker}&#10;Speaker: Grad E&#10;Content: Channel adapted .&#10;Speaker: PhD F&#10;Content: use that as the starting models for your speaker adaptation .&#10;Speaker: Professor B&#10;Content: Yeah . {vocalsound} But the thing is , uh {disfmarker} I mean , w when you {disfmarker} it depends whether you 're ju were just using this as a {disfmarker} {vocalsound} a starter task for {disfmarker} you know , to get things going for conversational or if we 're really interested i in connected digits . And I {disfmarker} I think the answer is both . And for {disfmarker} for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation&#10;Speaker: PhD F&#10;Content: Well , I don't know">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks." target="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks." target="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the potential benefits and drawbacks of investing effort in adapting to far-field microphone issues for telephone conversations. Professor B mentions that for tasks involving connected digits over the telephone, there might not be a need to put in much effort to adapt to these issues, as the impact on performance may only result in a &quot;single digit&quot; difference. PhD F agrees with this perspective but suggests that adapting the models to room acoustics and noise specific to the recording environment could still improve the results. Overall, there seems to be some disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks." target="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing small, inexpensive microphones that cost around twenty-five cents each and can be bought in bulk packages of thousands. These microphones were intentionally chosen to be similar in quality to those commonly found in Personal Digital Assistants (PDAs) for consistency and real-world representation. Although their sound quality is adequate for many situations, they may not be suitable for critical applications like feeding into a speech recognizer due to their low quality.&#10;2. The speakers mention the possibility of using these far-field microphones for the current task by placing them at a distance from the speakers and extracting time information from a near-field microphone. This approach would require knowing the speaker and ensuring no overlap, using the far-field microphone only for specific regions where it is necessary.&#10;3. The conversation also touches on potential issues affecting recording quality, such as low-frequency energy capture, distance between speakers and microphones, room acoustics, and background noise. Adapting models to these specific factors could potentially improve the recording quality.&#10;4. The speakers compare far-field and near-field microphones, noting that there is a negative impact when using far-field microphones, with the difference being around a factor of two. This comparison's reasons and context are not explicitly explained in the transcript.&#10;5. Lastly, they discuss speaker identification issues and mention a &quot;speaker model&quot; used for adaptation, variance normization, and VTL estimation. They consider using a TI-digits database to help with speaker normalization, variance normization, and VTL estimation, but there is uncertainty about whether the available data in the TI-digits database is comparable to their recordings.&#10;&#10;In summary, the speakers are discussing the suitability of small, inexpensive microphones for various applications beyond speech recognition, particularly focusing on their potential use in specific tasks while considering factors that may affect recording quality. They also touch upon speaker identification issues and the possibility of using a TI-digits database to improve their implementation." target="Yes, it is possible to perform the current study using a far-field microphone while keeping other conditions the same as in the near-field mike setup. This would allow for a comparison of the results obtained with each type of microphone. However, there are some factors to consider:&#10;&#10;1. Microphone quality: The low-quality microphones being used may not provide optimal results, especially when using far-field microphones. Although these microphones are suitable for many situations, they might not be adequate for critical applications like feeding into a speech recognizer.&#10;2. Low-frequency energy capture: If the system is picking up a lot of low-frequency energy, it could negatively impact the recordings, particularly with far-field microphones. Pre-emphasis in the front-end may help, but it might not completely solve the issue.&#10;3. Distance between speakers and microphones: Bringing the microphones closer to the speakers can improve the recordings. This is especially important when using lower-quality microphones.&#10;4. Room acoustics and background noise: Adapting the models to these specific factors could potentially improve the recording quality, even when using far-field microphones.&#10;&#10;Regarding the observed decrease in error rates with discriminative Gaussian training in a noisy environment, the transcript does not provide a specific order of magnitude for this decrease (e.g., from 10% to 8%, or from 1% to 0.8%). Nevertheless, this method could potentially help improve performance when using far-field microphones.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information." target=" 's {disfmarker} and because you don't know how people are gonna put them on , you know .&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Right . So , also , Andreas , on that one the {disfmarker} the back part of it should be right against your head . And that will he keep it from flopping aro up and down as much .&#10;Speaker: PhD F&#10;Content: It is against my head .&#10;Speaker: Grad E&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: Yeah . Um . Yeah , we actually talked about this in the , uh , front - end meeting this morning , too . Much the same thing ,&#10;Speaker: Grad E&#10;Content: Uh - huh .&#10;Speaker: Professor B&#10;Content: and {disfmarker} and it was {disfmarker} uh , I mean , there the point of interest to the group was primarily that , um , {vocalsound} the , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Digits: The first item on the agenda was discussing digits, but there is no further information provided about what specifically this referred to or what was discussed.&#10;2. Forced Alignment: The second item on the agenda was forced alignment. It appears that Liz and Andreas were expected to have information on this topic, but did not. The transcript does not provide an explanation for why they did not have the necessary information." target="disfmarker} little files .&#10;Speaker: PhD A&#10;Content: Uh {disfmarker}&#10;Speaker: PhD F&#10;Content: So for each segment that you want to recognize {vocalsound} you have to {pause} dump out {pause} a separate file .&#10;Speaker: Grad E&#10;Content: Uh - huh .&#10;Speaker: PhD F&#10;Content: Just like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know {disfmarker} So .&#10;Speaker: Professor B&#10;Content: Cool . OK . So the s the {disfmarker} the next thing we had on the agenda was something about alignments ?&#10;Speaker: PhD A&#10;Content: Oh . Yes , we have {disfmarker} I don't know , did you wanna talk about it , or {disfmarker} ? I can give a {disfmarker} I was just telling this to Jane and {disfmarker} and {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information." target=" D&#10;Content: No , no .&#10;Speaker: Grad E&#10;Content: So are we gonna do digits simultaneously&#10;Speaker: PhD A&#10;Content: You {disfmarker} This is our reward if we {pause} do our digi&#10;Speaker: Professor B&#10;Content: Well ? Yeah .&#10;Speaker: Postdoc C&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: or what ?&#10;Speaker: PhD D&#10;Content: Simultaneous digit chocolate task .&#10;Speaker: PhD H&#10;Content: I {disfmarker} I think , eh , it 's enough , eh , for more peopl for more people {pause} after .&#10;Speaker: Professor B&#10;Content: We 're gonna {disfmarker} we 're gonna do digits at the same {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh .&#10;Speaker: PhD F&#10;Content: Mmm !&#10;Speaker: Postdoc C&#10;Content: That 's nice .&#10;Speaker: PhD H&#10;Content: But , eh {disfmarker}&#10;Speaker: PhD F&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the group plans to perform a &quot;simultaneous digit chocolate task.&quot; However, the exact nature of this activity is not explicitly explained in the given text. It appears to be a task where participants will perform some action related to both digits and chocolate simultaneously, but the specifics are not provided. Therefore, it's not possible to answer this question without additional context or information." target="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text.">
      <data key="d0">1</data>
    </edge>
    <edge source="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text." target="marker}&#10;Speaker: PhD F&#10;Content: um . So .&#10;Speaker: PhD A&#10;Content: Anyway .&#10;Speaker: PhD F&#10;Content: I don't know .&#10;Speaker: PhD A&#10;Content: But the good thing is this does {disfmarker}&#10;Speaker: Grad E&#10;Content: Well , I I don't know . I mean , you could {disfmarker} you could do a paper on {pause} what 's wrong with the Aurora task by comparing it to {pause} other ways of doing it .&#10;Speaker: PhD F&#10;Content: How well does an Aurora system do on {disfmarker} on {disfmarker} you know , on digits collected in a {disfmarker} in this environment ?&#10;Speaker: PhD H&#10;Content: &#10;Speaker: Grad E&#10;Content: Different way . Yeah .&#10;Speaker: PhD F&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Maybe .&#10;Speaker: PhD F&#10;Content: Maybe .&#10;Speaker: Grad E&#10;Content: Pretty hokey .&#10;Speaker: Professor B&#10;Content: I think it 's a l">
      <data key="d0">1</data>
    </edge>
    <edge source="The Aurora system, when specifically trained on digits and utilizing adaptation techniques, performs better than other digit recognition systems. This is true even though the digits task involves a smaller number of words and has more training data available. However, it's important to note that there might not be a significant need to adapt to far-field microphone issues for connected digit tasks over the telephone, as the impact on performance may only result in a &quot;single digit&quot; difference. The exact drawbacks of using the Aurora task for digit recognition are not explicitly mentioned in the transcript; however, some discussion revolves around the disagreement regarding the extent to which it is worthwhile to invest effort in addressing far-field microphone problems for telephone conversations, particularly when focusing on connected digit tasks.&#10;&#10;As a side note, the transcript mentions that the group plans to perform a &quot;simultaneous digit chocolate task,&quot; but the specifics of this activity are not provided in the text." target=" D&#10;Content: Yeah .&#10;Speaker: Grad E&#10;Content: Oh , I thought you meant this was just the digits section . I didn't know you meant it was Aurora digits .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Well , no . If you {disfmarker} if you have {disfmarker} it 's to {disfmarker} if you discuss some relation to the Aurora task , like if you use the same {disfmarker}&#10;Speaker: Professor B&#10;Content: This is not the Aurora task . So they just do a little grep for {disfmarker}&#10;Speaker: PhD A&#10;Content: Do {disfmarker} uh , d d Do not {disfmarker} do not {disfmarker} we are not setting a good example .&#10;Speaker: PhD F&#10;Content: Um . Well , a relation other than negation , maybe ,&#10;Speaker: PhD A&#10;Content: This is not a {disfmarker}&#10;Speaker: PhD F&#10;Content: um . So .&#10;Speaker: PhD A&#10;Content: Anyway .&#10;Speaker: PhD">
      <data key="d0">1</data>
    </edge>
    <edge source="3. PhD F brought up S. Sue's writings on spurts of development, suggesting that the group should discuss her work further to gain insights into the concept of spurts in speech. However, they did not specifically mention any connection between spurts of development and overloading hardware names at ICSI." target=" ICSI ,&#10;Speaker: PhD F&#10;Content: Mm - hmm .&#10;Speaker: Grad E&#10;Content: Yeah . It was good having you .&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD H&#10;Content: because I {disfmarker} I enjoyed @ @ very much ,&#10;Speaker: PhD F&#10;Content: Mmm .&#10;Speaker: PhD H&#10;Content: uh . And I 'm sorry by the result of overlapping , because , eh , {vocalsound} I haven't good results , eh , yet but , eh , {vocalsound} I {disfmarker} {vocalsound} I pretend {comment} to {disfmarker} to continuing out to Spain , eh , during the {disfmarker} the following months ,&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD H&#10;Content: eh , because I have , eh , another ideas but , eh , I haven't enough time to {disfmarker} to {disfmarker} {vocalsound} with six months it 's not enough">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
