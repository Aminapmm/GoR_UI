<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." />
    <node id=" Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disfmarker} I think they are still working well .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and {disfmarker} but well hmm For the moment they have this large delay on the {disfmarker} the feature computation and so we don't&#10;Speaker: Professor B&#10;Content: OK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it {disfmarker} but it looks like it you know maybe could help in a couple places .&#10;Speaker: PhD C&#10;Content: I th&#10;Speaker: Professor B&#10;Content: Uh little bit .&#10;Speaker: PhD" />
    <node id=" great .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Um {vocalsound} what else is there here ? Um see the second {disfmarker} second from the bottom it says SIL , but this is some different kind of silence or thing or {disfmarker} what was that ?&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: It the {disfmarker} the output silence of the MLP .&#10;Speaker: PhD C&#10;Content: Oh yeah I see .&#10;Speaker: PhD D&#10;Content: It 's only one small experiment to know what happened . To apply also to in include also the {disfmarker} the silence of the MLP we have the fifty - six form and the silence to pick up the silence and we include those .&#10;Speaker: Professor B&#10;Content: Yes . Uh - huh , uh - huh . The silence plus the KLT output ? Oh so you 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we" />
    <node id=" For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt , yeah&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well&#10;Speaker: Professor B&#10;Content: Oh we can't do it . Oh OK .&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD D&#10;Content: For that {disfmarker} for that we {disfmarker}&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Too bad . Good idea , but can't do it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disf" />
    <node id=" 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we apply the KLT&#10;Speaker: PhD C&#10;Content: No they 're {disfmarker} I think there is this silence in addition to the um KLT outputs&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: PhD D&#10;Content: in addition , yes .&#10;Speaker: PhD C&#10;Content: it is because we {disfmarker} we {disfmarker} we just keep uh we don't keep all the dimensions after the KLT&#10;Speaker: PhD D&#10;Content: In addition t&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: PhD D&#10;Content: and we not s we are not sure if we pick {disfmarker} we have the silence .&#10;Speaker: PhD C&#10;Content: So we try to add the silence also in addition to the {disfmarker} these twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's O" />
    <node id="&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only .&#10;Speaker: PhD C&#10;Content: Yeah . For TI - digits .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD C&#10;Content: Yeah , actually yeah . For the TI - digits they want to train on clean and on noisy&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: So we 're doing that also , I guess .&#10;Speaker: PhD C&#10;Content: Uh yeah . But uh we actually {disfmarker} do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Well anyway , sounds like there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next" />
    <node id=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I" />
    <node id="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet." />
    <node id=" is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;Speaker: PhD C&#10;Content: Yeah there is something funny happening here because {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: But there are thirty - six and then sometimes we are {disfmarker} we are {disfmarker} we are around forty - two and&#10;Speaker: Professor B&#10;Content: Now up&#10;Speaker: PhD C&#10;Content: but&#10;Speaker: Professor B&#10;Content: Uh so one of the ideas that you had mentioned last time was having a {disfmarker} a second um silence detection .&#10;Speaker: PhD C&#10;Content: Yeah . So there are some results here&#10;Speaker: PhD D&#10;Content: For the Italian .&#10;Speaker: PhD C&#10;Content: uh so the third and the fifth line of the table&#10;Speaker: PhD D&#10;Content: For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt" />
    <node id="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." />
    <node id=" um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features go through a contextualized KLT . Then these features also uh get um low - pass filtered&#10;Speaker: PhD C&#10;Content: Yeah . Yeah so yeah I could perhaps draw this on the blackboard&#10;Speaker: Professor B&#10;Content: Sure . Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The graph , yeah another one .&#10;Speaker: Professor B&#10;Content: Yeah , that 's good .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor B&#10;Content: So&#10;Speaker: PhD C&#10;Content: So we have these features from OGI that goes through the three paths .&#10;Speaker: Professor B&#10;Content: Yeah . Three , OK .&#10;Speaker: PhD C&#10;Content: The first is a KLT using several frames of the features .&#10;Speaker: Professor B&#10;Content: Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features" />
    <node id="Speaker: Professor B&#10;Content: OK So uh today we 're looking at a number of uh things we 're trying and uh fortunately for listeners to this uh we lost some of it 's visual but um got tables in front of us . Um what is {disfmarker} what does combo mean ?&#10;Speaker: PhD C&#10;Content: So combo is um a system where we have these features that go through a network and then this same string of features but low - pass filtered with the low - pass filter used in the MSG features . And so these low - pass filtered goes through M eh {disfmarker} another MLP and then the linear output of these two MLP 's are combined just by adding the values and then there is this KLT . Um the output is used as uh features as well .&#10;Speaker: Professor B&#10;Content: Um so let me try to restate this and see if I have it right . There is uh {disfmarker} there is the features uh there 's the OGI features and then um those features um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features" />
    <node id=" twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's OGI forty - five ? The bottom one there ?&#10;Speaker: PhD C&#10;Content: Uh it 's o it 's OGI two , it 's {disfmarker} so the {disfmarker} th it 's the features from the first line&#10;Speaker: PhD D&#10;Content: It 's in fact OGI two .&#10;Speaker: Professor B&#10;Content: S&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Right , but I mean what 's the {disfmarker} what does the last row mean ?&#10;Speaker: PhD C&#10;Content: So it 's uh basically this but without the KLT on the {disfmarker} from the left path .&#10;Speaker: Professor B&#10;Content: I thought that was the one {disfmarker} I thought that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have" />
    <node id=" Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features&#10;Speaker: Professor B&#10;Content: Yeah . Uh - huh .&#10;Speaker: PhD C&#10;Content: The third path is this low - pass filter .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh , MLP&#10;Speaker: Professor B&#10;Content: Aha ! aha !&#10;Speaker: PhD C&#10;Content: Adding the outputs just like in the second propose the {disfmarker} the proposal from {disfmarker} for the first evaluation .&#10;Speaker: Professor B&#10;Content: Yeah ? Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: And then the KLT and then the two together again .&#10;Speaker: Professor B&#10;Content: No , the KLT . And those two together . That 's it .&#10;Speaker: PhD D&#10;Content: Two HTK .&#10;Speaker: Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content:" />
    <node id="Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker} top row ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: So yeah to {disfmarker} actually OGI two is the {disfmarker} the baseline with the OGI features but this is not exactly the result that they have because they 've {disfmarker} they 're still made some changes in the features&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: and {disfmarker} well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Uh OK so the one {disfmarker} one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;" />
    <node id="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence." />
    <node id="&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: I 'm not sure these are great ideas .&#10;Speaker: Professor B&#10;Content: But they 're ideas . Yeah ? Oh , that was good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And {disfmarker} and uh also it 's still true that uh I think it 's true that {disfmarker} that we {disfmarker} we at least got fairly consistent i improved results by running uh the uh neural net transformation in parallel with the features&#10;Speaker: PhD C&#10;Content: But&#10;Speaker: Professor B&#10;Content: rather than uh in sequence which was {disfmarker} was your suggestion and that {disfmarker} that {disfmarker} that seems to have been borne out .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: The fact that none of these are {disfmarker} are {disfmarker" />
    <node id="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." />
    <node id=" you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {disfmarker} we could {disfmarker} we could start soon , yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Write up something .&#10;Speaker: Professor B&#10;Content: Yeah , and {disfmarker} and I {disfmarker} I would {disfmarker} you know , I would {disfmarker} I 'd kind of like to see it&#10;Speaker: PhD C&#10;Content: Um yeah . Mm - hmm .&#10;Speaker: Professor B&#10;Content: maybe I can {disfmarker} I can edit it a bit uh sure . The {disfmarker} my {disfmarker} what in this si i in this situation is my forte which is English .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh so&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh H yeah . Have y have you seen" />
    <node id="&#10;Content: it d&#10;Speaker: Professor B&#10;Content: I {disfmarker} Yeah , OK except that we do have to write it up .&#10;Speaker: PhD C&#10;Content: I think we fixed on Tuesday , yeah . Yeah . Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: Also , so&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: Um&#10;Speaker: PhD C&#10;Content: Uh yeah well . Well basically it 's this with perhaps some kind of printing and some {disfmarker} some other @ @ .&#10;Speaker: Professor B&#10;Content: Right so maybe what we do is we {disfmarker} we {disfmarker} we uh as soon as we get the data from them we start the training and so forth&#10;Speaker: PhD C&#10;Content: Yeah but Mm - hmm .&#10;Speaker: Professor B&#10;Content: but we start the write - up right away because as you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {d" />
    <node id=": Professor B&#10;Content: K , uh if nobody has anything else maybe we should go around do {disfmarker} do our digits {disfmarker} do our digits duty . OK . OK I 'll start . Uh , let me say that again . OK . I guess we 're done ." />
    <node id=" B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker} well {disfmarker} the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .&#10;Speaker: PhD D&#10;Content: Ye But words {disfmarker} well word {disfmarker} I don't know .&#10;Speaker: PhD C&#10;Content: Hmm ? The words , yeah . S sentences .&#10;Speaker: PhD D&#10;Content: Sentences .&#10;Speaker: PhD C&#10;Content: Some sets have five hundred sentences , so .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So the {disfmarker} so the sets {disfmarker} so the test sets are between five hundred and two thousand sentences , let 's say&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: and each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content" />
    <node id=" {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah , well . Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: was like {disfmarker} I thought it was five PM or something , I didn't think it was midnight . I thought they said they wanted everything by&#10;Speaker: PhD D&#10;Content: Yeah , five PM .&#10;Speaker: Professor B&#10;Content: well , so five PM their time is {disfmarker} is {disfmarker} if&#10;Speaker: PhD D&#10;Content: Not five PM , three PM .&#10;Speaker: Professor B&#10;Content: three PM .&#10;Speaker: PhD D&#10;Content: Three PM .&#10;Speaker: Professor B&#10;Content: Alright , that 's six in the morning here .&#10;Speaker: PhD C&#10;Content: It 's d no .&#10;Speaker: PhD D&#10;Content: Uh no three {disfmarker} three A - three PM ?&#10;Speaker: PhD C&#10;Content: No , we are wondering about the {disfmarker} the" />
    <node id="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." />
    <node id=" of {disfmarker} end of the month , the TI - digits are there also ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . It 's included , yeah .&#10;Speaker: Professor B&#10;Content: Oh OK . OK . And see what else there is here . Um Oh I see {disfmarker} the one {disfmarker} I was looking down here at the {disfmarker} the o the row below the lower yellowed one . Uh that 's uh that 's with the reduced uh KLT size {disfmarker} reduced dimensionality .&#10;Speaker: PhD C&#10;Content: Mm - hmm ? Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: What happens there is it 's around the same and so you could reduce the dimension as you were saying before a bit perhaps .&#10;Speaker: PhD C&#10;Content: Yeah , it 's {disfmarker} it 's significantly worse well but {disfmarker} Mm - hmm .&#10;Speaker: Professor B&#10;Content: It 's significantly worse {disfmarker} it 's {disfmarker} it 's uh it" />
    <node id=" - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: But yeah . Generally what you observe with TI - digits is that the result are very close whatever the {disfmarker} the system .&#10;Speaker: Professor B&#10;Content: OK . And so have you put all these numbers together into a single number representing that ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean not {disfmarker}&#10;Speaker: PhD C&#10;Content: Uh not yet .&#10;Speaker: Professor B&#10;Content: OK so that should be pretty easy to do and that would be good {disfmarker}&#10;Speaker: PhD C&#10;Content: No . Mmm yeah , yeah .&#10;Speaker: Professor B&#10;Content: then we could compare the two and say what was better .&#10;Speaker: PhD C&#10;Content: Mmm . Yeah .&#10;Speaker: Professor B&#10;Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker}" />
    <node id=": PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no low {disfmarker} low - pass processing used as additional feature stream .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Do you e um they mentioned {disfmarker} made some {disfmarker} uh when I was on the phone with Sunil they {disfmarker} they mentioned some weighting scheme that was used to evaluate all of these numbers .&#10;Speaker: PhD C&#10;Content: Yeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .&#10;Speaker: Professor B&#10;Content: Um and we don't have the TI - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker" />
    <node id="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." />
    <node id=" delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look at&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but I just would add the {disfmarker} the {disfmarker} the second row one&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and then um if we can um&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: oh yeah also when {disfmarker} when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?&#10;Speaker: PhD C&#10;Content: Uh {vocalsound} I guess , yeah .&#10;Speaker: Professor B&#10;Content: Yeah OK .&#10;Speaker: PhD C&#10;Content: I guess , yeah . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;" />
    <node id=" each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah for the Italian even seven digits y more or less&#10;Speaker: PhD C&#10;Content: It {disfmarker} it d Seven digits .&#10;Speaker: PhD D&#10;Content: but sometime the sentence have only one digit and sometime uh like uh the number of uh credit cards , something like that .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Right , so between one and sixteen . See the {disfmarker} I mean the reason I 'm asking is {disfmarker} is {disfmarker} is we have all these small differences and I don't know how seriously to take them , right ?&#10;Speaker: PhD C&#10;Content: Mm - hmm ?&#10;Speaker: Professor B&#10;Content: So uh i if {disfmarker} if you had uh just you know {disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth" />
    <node id="disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth of a percent would just be one word ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: right ? So {disfmarker} so it wouldn't mean anything .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Oh&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: um so um yeah it be kind of {disfmarker} I 'd kind of like to know what the sizes of these test sets were actually .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The size that we have ?&#10;Speaker: PhD C&#10;Content: We could {disfmarker} we could run {disfmarker} run some kind of significance tests&#10;Speaker: Professor B&#10;Content: Yeah since these {disfmarker} well also just to know the numbers ,&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: PhD D&#10;Content: Yeah .&#10;" />
    <node id="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." />
    <node id="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system." />
    <node id=": Oh that 's probably the {disfmarker}&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: Professor B&#10;Content: this is probably channel error stuff&#10;Speaker: PhD C&#10;Content: well , you {disfmarker}&#10;Speaker: Professor B&#10;Content: huh ? Oh this is i right , it says right above here channel {disfmarker} channel error resilience ,&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: yeah . So recognition performance is just the top part , actually . Uh and they have {disfmarker} yes , split between seen databases and non - seen so basically between development and {disfmarker} and evaluation .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And {vocalsound} so {disfmarker} right , it 's presumed there 's all sorts of tuning that 's gone on on the see what they call seen databases and there won't be tuning for the uh unseen . Multi - condition {disfmarker} multi - condition . So they have {disfmarker} looks like they have uh uh" />
    <node id="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision." />
    <node id=" that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have this combo stuff so you just&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: uh&#10;Speaker: Professor B&#10;Content: So this is like the second line but with {disfmarker} with the combo stuff .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD D&#10;Content: And with the {disfmarker} all the output of the combo .&#10;Speaker: Professor B&#10;Content: OK . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: OK , so {disfmarker} alright so it looks to me {disfmarker} I guess the same {disfmarker} given that we have to take the filt ones out of the {disfmarker} the running because of this delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look" />
    <node id="'t want to do several and {disfmarker} and take the best&#10;Speaker: PhD C&#10;Content: Yeah . Mmm .&#10;Speaker: Professor B&#10;Content: that 's {disfmarker} that 's {disfmarker} that 's not proper but if this is development data we could still look at a couple .&#10;Speaker: PhD C&#10;Content: Yeah . We can {disfmarker} yeah . Sure . But we have to decide {disfmarker} I mean we have to fix the system on this d on this data , to choose the best&#10;Speaker: Professor B&#10;Content: Yeah . I Right .&#10;Speaker: PhD C&#10;Content: and these&#10;Speaker: Professor B&#10;Content: But the question is when {disfmarker} when do we fix the system ,&#10;Speaker: PhD C&#10;Content: But we could&#10;Speaker: Professor B&#10;Content: do we fix the system uh tomorrow or do we fix the system on Tuesday ?&#10;Speaker: PhD C&#10;Content: it d&#10;Speaker: Professor B&#10;Content: I {disfmarker} Yeah , OK except that we do have to write it" />
    <node id="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet." />
    <node id="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." />
    <node id=" . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;Speaker: Professor B&#10;Content: OK . Maybe {disfmarker} maybe they 'll argue about it . Um OK so if we can know what {disfmarker} how many words are in each and then um Dave uh Dave promised to get us something tomorrow which will be there as far as they 've gotten {vocalsound} Friday&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: and then we 'll operate with that&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and uh how long did it I guess if we 're not doing all these things {disfmarker} if we 're only doing um um I guess since this is development data it 's legitimate to do more than one , right ? I mean ordinarily if {disfmarker} in final test data you don't want to do several and {disfmarker} and take the best&#10;Speaker: PhD C&#10;Content: Yeah . Mmm .&#10;Spe" />
    <node id="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing." />
    <node id=" Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content: Um . So this is {disfmarker} yeah&#10;Speaker: Professor B&#10;Content: And so uh and then the {disfmarker} the {disfmarker} the one at the top {disfmarker} and I presume these things that uh are in yellow are in yellow because overall they 're the best ?&#10;Speaker: PhD C&#10;Content: Yeah that 's the reason , yeah .&#10;Speaker: Professor B&#10;Content: Oh let 's focus on them then so what 's the block diagram for the one above it ?&#10;Speaker: PhD C&#10;Content: For the f the f first yellow line you mean ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah so it 's uh basically s the same except that we don't have this uh low - pass filtering so we have only two streams .&#10;Speaker: PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no" />
    <node id=" PhD D&#10;Content: Mmm yeah .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD C&#10;Content: Actually the {disfmarker} yeah the second line is uh pretty much like the first line in yellow except that we don't have this KLT on the first {disfmarker} on the left part of the diagram . We just have the features as they are .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Yeah . Yeah so when we do this weighted measure we should compare the two cuz it might even come out better . And it 's {disfmarker} it 's {disfmarker} it 's a little {disfmarker} slightly simpler .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor B&#10;Content: So {disfmarker} so there 's {disfmarker} so I {disfmarker} I would put that one also as a {disfmarker} as a maybe . Uh and it {disfmarker} yeah and" />
    <node id="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems." />
    <node id="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers)." />
    <node id="aker: Professor B&#10;Content: It 's significantly worse {disfmarker} it 's {disfmarker} it 's uh it 's {disfmarker} it 's mostly worse .&#10;Speaker: PhD C&#10;Content: Exc - except for the HM&#10;Speaker: PhD D&#10;Content: For many a mismatch it 's worse .&#10;Speaker: PhD C&#10;Content: but&#10;Speaker: Professor B&#10;Content: Yeah . But it is little . I mean not {disfmarker} not by a huge amount , I don't know . What are {disfmarker} what are the sizes of any of these sets , I {disfmarker} I 'm {disfmarker} I 'm sure you told me before , but I 've forgotten . So {disfmarker} you know how many words are in uh one of these test sets ?&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: I don't remember .&#10;Speaker: Professor B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker" />
    <node id="er} well also just to know the numbers ,&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: right . So these {disfmarker} these are word error rates&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: so this is on how many words .&#10;Speaker: PhD C&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Yeah we have the result that the output of the HTK&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The number of {disfmarker} of sentences , no it 's the number isn't .&#10;Speaker: PhD C&#10;Content: Yeah sure {disfmarker} sure . Yeah sure .&#10;Speaker: Professor B&#10;Content: Yeah so anyway if you could just mail out what those numbers are and then {disfmarker} then {disfmarker} that {disfmarker} that be great .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content" />
    <node id="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output." />
    <node id="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." />
    <node id="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month." />
    <node id=" the uh unseen . Multi - condition {disfmarker} multi - condition . So they have {disfmarker} looks like they have uh uh&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so they splitting up between the TI - digits and everything else , I see . So the everything else is the SpeechDat - Car , that 's the multi multilingual&#10;Speaker: PhD C&#10;Content: Yeah , so it 's not divided between languages you mean or {disfmarker}&#10;Speaker: Professor B&#10;Content: Well , it is .&#10;Speaker: PhD C&#10;Content: it just&#10;Speaker: Professor B&#10;Content: It is , but there 's also {disfmarker} there 's these tables over here for the {disfmarker} for the TI - digits and these tables over here for the car data which is {disfmarker} which is I guess all the multilingual stuff&#10;Speaker: PhD C&#10;Content: Oh yeah .&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only" />
    <node id="marker} I would put that one also as a {disfmarker} as a maybe . Uh and it {disfmarker} yeah and it 's actually {vocalsound} does {disfmarker} does significantly better on the uh uh highly mismatched Italian , so s and little worse on the mis on the MM case , but uh Well yeah it 's worse than a few things&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so uh let 's see how that c that c c see how that comes out on their {disfmarker} their measure and {disfmarker} are {disfmarker} are we running this uh for TI - digits or uh&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Now is TI di {disfmarker} is is that part of the result that they get for the uh development {disfmarker} th the results that they 're supposed to get at the end of {disfmarker} end of the month , the TI - digits are there also ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah" />
    <node id="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission." />
    <node id=" {disfmarker} uh well we should look but my assumption is that we basically have to be done Tuesday . Um so then next Thursday we can sort of have a little aftermath&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: but then {disfmarker} then we 'll actually have the new data which is the German and the Danish&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: but that really will be much less work because uh the system will be fixed&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: so all we 'll do is take whatever {vocalsound} they have and {disfmarker} and uh and run it through the process .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh we won't be changing the training on anything&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so there 'll be no new training , there 'll just be new HTK runs , so that 's means in some sense we can kind of relax from this" />
    <node id=" there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next uh next few days&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Yes .&#10;Speaker: Professor B&#10;Content: I guess they have to send it out {disfmarker} let 's see the thirty - first is uh uh Wednesday and I think the {disfmarker} it has to be there by some hour uh European time on Wednesday&#10;Speaker: PhD C&#10;Content: Hmm - hmm .&#10;Speaker: Professor B&#10;Content: so {vocalsound} I think basically&#10;Speaker: PhD D&#10;Content: We lost time uh Wednesday maybe because {vocalsound} that the difference in the time may be {disfmarker} is a long different of the time .&#10;Speaker: Professor B&#10;Content: E excuse me ?&#10;Speaker: PhD D&#10;Content: Maybe the Thursday the twelfth of the night of the Thurs - thirty - one is {disfmarker} is not valid in Europe .&#10;Speaker: PhD C&#10;Content: Yeah" />
    <node id="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work." />
    <node id="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." />
    <node id="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results." />
    <node id="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on." />
    <node id="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP." />
    <node id="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information." />
    <node id="disfmarker} wanna run them he 's {disfmarker} he 's offering it .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So . It 's uh when he was here eh uh he {disfmarker} he used i not only every machine here but every machine on campus as far as I could tell , so {disfmarker} so in some ways he just got his payback , but uh again I {disfmarker} I don't know if we 'll end up with {disfmarker} if we 're gonna be CPU limited on anything that we 're doing in this group&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but {disfmarker} but if {disfmarker} if we are that 's an offer . OK well uh you guys doing great stuff so that 's {disfmarker} that {disfmarker} that 's really neat and uh we 'll uh uh g don't think we need to uh um Oh well the other thing I guess that I will say is that" />
    <node id="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion." />
    <node id="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed." />
    <node id="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration." />
    <node id=" the night of the Thurs - thirty - one is {disfmarker} is not valid in Europe .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: We don't know is happening .&#10;Speaker: Professor B&#10;Content: Yes , so I mean {disfmarker} I think we have to actually get it done Tuesday&#10;Speaker: PhD D&#10;Content: Tuesday .&#10;Speaker: Professor B&#10;Content: right because I {disfmarker} I think&#10;Speaker: PhD C&#10;Content: Yeah , well .&#10;Speaker: Professor B&#10;Content: uh Uh&#10;Speaker: PhD C&#10;Content: Except if {disfmarker} if it 's the thirty - one at midnight or I don't know {disfmarker} we can {vocalsound} still do some work on Wednesday morning .&#10;Speaker: Professor B&#10;Content: yeah well . W i is but is {disfmarker} is it midni I thought it was actually something like five PM on {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah , well . Yeah .&#10;Speaker: PhD D&#10;Content: Yeah ." />
    <node id="marker} three A - three PM ?&#10;Speaker: PhD C&#10;Content: No , we are wondering about the {disfmarker} the {disfmarker} the hour that we have to eh I don't know if it 's three PM {disfmarker} it 's&#10;Speaker: PhD D&#10;Content: Oh yeah , yeah , yeah , yeah . Three PM here is in Europe midnight .&#10;Speaker: PhD C&#10;Content: Yeah , it 's {disfmarker} it 's midnight but&#10;Speaker: Professor B&#10;Content: Yes , yes , but I didn't think it was midnight that it was due , I thought it was due at some hour during the day like five PM or something .&#10;Speaker: PhD D&#10;Content: Oh OK . Mm - hmm . Mm - hmm , &#10;Speaker: Professor B&#10;Content: In which case&#10;Speaker: PhD D&#10;Content: maybe .&#10;Speaker: Professor B&#10;Content: so I {disfmarker} I {disfmarker} uh well we should look but my assumption is that we basically have to be done Tuesday . Um so then next Thursday we can sort" />
    <node id="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation." />
    <node id="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation." />
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target=" Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disfmarker} I think they are still working well .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and {disfmarker} but well hmm For the moment they have this large delay on the {disfmarker} the feature computation and so we don't&#10;Speaker: Professor B&#10;Content: OK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it {disfmarker} but it looks like it you know maybe could help in a couple places .&#10;Speaker: PhD C&#10;Content: I th&#10;Speaker: Professor B&#10;Content: Uh little bit .&#10;Speaker: PhD">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target=" great .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Um {vocalsound} what else is there here ? Um see the second {disfmarker} second from the bottom it says SIL , but this is some different kind of silence or thing or {disfmarker} what was that ?&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: It the {disfmarker} the output silence of the MLP .&#10;Speaker: PhD C&#10;Content: Oh yeah I see .&#10;Speaker: PhD D&#10;Content: It 's only one small experiment to know what happened . To apply also to in include also the {disfmarker} the silence of the MLP we have the fifty - six form and the silence to pick up the silence and we include those .&#10;Speaker: Professor B&#10;Content: Yes . Uh - huh , uh - huh . The silence plus the KLT output ? Oh so you 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target=" For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt , yeah&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well&#10;Speaker: Professor B&#10;Content: Oh we can't do it . Oh OK .&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD D&#10;Content: For that {disfmarker} for that we {disfmarker}&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Too bad . Good idea , but can't do it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target=" 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we apply the KLT&#10;Speaker: PhD C&#10;Content: No they 're {disfmarker} I think there is this silence in addition to the um KLT outputs&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: PhD D&#10;Content: in addition , yes .&#10;Speaker: PhD C&#10;Content: it is because we {disfmarker} we {disfmarker} we just keep uh we don't keep all the dimensions after the KLT&#10;Speaker: PhD D&#10;Content: In addition t&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: PhD D&#10;Content: and we not s we are not sure if we pick {disfmarker} we have the silence .&#10;Speaker: PhD C&#10;Content: So we try to add the silence also in addition to the {disfmarker} these twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's O">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target="&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only .&#10;Speaker: PhD C&#10;Content: Yeah . For TI - digits .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD C&#10;Content: Yeah , actually yeah . For the TI - digits they want to train on clean and on noisy&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: So we 're doing that also , I guess .&#10;Speaker: PhD C&#10;Content: Uh yeah . But uh we actually {disfmarker} do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Well anyway , sounds like there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;2. Potential benefits of using a low-pass filter cepstrum: Professor B mentioned that they have observed some results with a low-pass filter cepstrum, and it appears to have a small positive impact in certain places. While it may not drastically improve the situation, it could help fine-tune some aspects of their work.&#10;&#10;3. Limitations of using a low-pass filter cepstrum: Although there might be some benefits, it is unclear if implementing a low-pass filter cepstrum would significantly address the main issues being faced by the team, such as reducing delays in the silence detector." target="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disfmarker} I think they are still working well .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and {disfmarker} but well hmm For the moment they have this large delay on the {disfmarker} the feature computation and so we don't&#10;Speaker: Professor B&#10;Content: OK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it {disfmarker} but it looks like it you know maybe could help in a couple places .&#10;Speaker: PhD C&#10;Content: I th&#10;Speaker: Professor B&#10;Content: Uh little bit .&#10;Speaker: PhD" target="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disfmarker} I think they are still working well .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and {disfmarker} but well hmm For the moment they have this large delay on the {disfmarker} the feature computation and so we don't&#10;Speaker: Professor B&#10;Content: OK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it {disfmarker} but it looks like it you know maybe could help in a couple places .&#10;Speaker: PhD C&#10;Content: I th&#10;Speaker: Professor B&#10;Content: Uh little bit .&#10;Speaker: PhD" target="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disfmarker} I think they are still working well .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and {disfmarker} but well hmm For the moment they have this large delay on the {disfmarker} the feature computation and so we don't&#10;Speaker: Professor B&#10;Content: OK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it {disfmarker} but it looks like it you know maybe could help in a couple places .&#10;Speaker: PhD C&#10;Content: I th&#10;Speaker: Professor B&#10;Content: Uh little bit .&#10;Speaker: PhD" target="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" great .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Um {vocalsound} what else is there here ? Um see the second {disfmarker} second from the bottom it says SIL , but this is some different kind of silence or thing or {disfmarker} what was that ?&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: It the {disfmarker} the output silence of the MLP .&#10;Speaker: PhD C&#10;Content: Oh yeah I see .&#10;Speaker: PhD D&#10;Content: It 's only one small experiment to know what happened . To apply also to in include also the {disfmarker} the silence of the MLP we have the fifty - six form and the silence to pick up the silence and we include those .&#10;Speaker: Professor B&#10;Content: Yes . Uh - huh , uh - huh . The silence plus the KLT output ? Oh so you 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we" target="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt , yeah&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well&#10;Speaker: Professor B&#10;Content: Oh we can't do it . Oh OK .&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD D&#10;Content: For that {disfmarker} for that we {disfmarker}&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Too bad . Good idea , but can't do it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disf" target="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt , yeah&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well&#10;Speaker: Professor B&#10;Content: Oh we can't do it . Oh OK .&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD D&#10;Content: For that {disfmarker} for that we {disfmarker}&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Too bad . Good idea , but can't do it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disf" target="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt , yeah&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well&#10;Speaker: Professor B&#10;Content: Oh we can't do it . Oh OK .&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD D&#10;Content: For that {disfmarker} for that we {disfmarker}&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Too bad . Good idea , but can't do it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disf" target="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt , yeah&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Um yeah so it seems f for the {disfmarker} the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are {disfmarker} there 's no room left for any silence detector at the server side because of the delay . Uh well&#10;Speaker: Professor B&#10;Content: Oh we can't do it . Oh OK .&#10;Speaker: PhD C&#10;Content: No .&#10;Speaker: PhD D&#10;Content: For that {disfmarker} for that we {disfmarker}&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Too bad . Good idea , but can't do it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Except I don't know because they {disf" target="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we apply the KLT&#10;Speaker: PhD C&#10;Content: No they 're {disfmarker} I think there is this silence in addition to the um KLT outputs&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: PhD D&#10;Content: in addition , yes .&#10;Speaker: PhD C&#10;Content: it is because we {disfmarker} we {disfmarker} we just keep uh we don't keep all the dimensions after the KLT&#10;Speaker: PhD D&#10;Content: In addition t&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: PhD D&#10;Content: and we not s we are not sure if we pick {disfmarker} we have the silence .&#10;Speaker: PhD C&#10;Content: So we try to add the silence also in addition to the {disfmarker} these twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's O" target="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" 're only using the silence .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah , because when we apply the KLT&#10;Speaker: PhD C&#10;Content: No they 're {disfmarker} I think there is this silence in addition to the um KLT outputs&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: PhD D&#10;Content: in addition , yes .&#10;Speaker: PhD C&#10;Content: it is because we {disfmarker} we {disfmarker} we just keep uh we don't keep all the dimensions after the KLT&#10;Speaker: PhD D&#10;Content: In addition t&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: PhD D&#10;Content: and we not s we are not sure if we pick {disfmarker} we have the silence .&#10;Speaker: PhD C&#10;Content: So we try to add the silence also in addition to the {disfmarker} these twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's O" target="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only .&#10;Speaker: PhD C&#10;Content: Yeah . For TI - digits .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD C&#10;Content: Yeah , actually yeah . For the TI - digits they want to train on clean and on noisy&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: So we 're doing that also , I guess .&#10;Speaker: PhD C&#10;Content: Uh yeah . But uh we actually {disfmarker} do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Well anyway , sounds like there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next" target="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only .&#10;Speaker: PhD C&#10;Content: Yeah . For TI - digits .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD C&#10;Content: Yeah , actually yeah . For the TI - digits they want to train on clean and on noisy&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: So we 're doing that also , I guess .&#10;Speaker: PhD C&#10;Content: Uh yeah . But uh we actually {disfmarker} do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Well anyway , sounds like there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next" target="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only .&#10;Speaker: PhD C&#10;Content: Yeah . For TI - digits .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD C&#10;Content: Yeah , actually yeah . For the TI - digits they want to train on clean and on noisy&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: So we 're doing that also , I guess .&#10;Speaker: PhD C&#10;Content: Uh yeah . But uh we actually {disfmarker} do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Well anyway , sounds like there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next" target="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I" target="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I" target="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I" target="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I" target="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is there anything else we should talk about or {disfmarker} or {disfmarker} are we done ?&#10;Speaker: PhD C&#10;Content: Mm - hmm . I think it 's OK um . We so basically we will {disfmarker} I think we 'll try to {disfmarker} to focus on these three architectures and {disfmarker} and perhaps I was thinking also a fourth one with just {disfmarker} just a single KLT because we did not really test that {disfmarker}&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: removing all these KLT 's and putting one single KLT at the end .&#10;Speaker: Professor B&#10;Content: Yeah , I mean that would be pretty low maintenance to try it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh if you can fit it in .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Oh I have {disfmarker} yeah I do have one other piece of information which uh I" target="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet." target=" is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;Speaker: PhD C&#10;Content: Yeah there is something funny happening here because {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: But there are thirty - six and then sometimes we are {disfmarker} we are {disfmarker} we are around forty - two and&#10;Speaker: Professor B&#10;Content: Now up&#10;Speaker: PhD C&#10;Content: but&#10;Speaker: Professor B&#10;Content: Uh so one of the ideas that you had mentioned last time was having a {disfmarker} a second um silence detection .&#10;Speaker: PhD C&#10;Content: Yeah . So there are some results here&#10;Speaker: PhD D&#10;Content: For the Italian .&#10;Speaker: PhD C&#10;Content: uh so the third and the fifth line of the table&#10;Speaker: PhD D&#10;Content: For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet." target="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet." target="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, there are indications that implementing a silence detector at the server side for the &quot;filt&quot; system is not feasible due to existing delays. These delays do not allow for the integration of a silence detector at the server side. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. They seem to be exploring other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, but these may not have been implemented or tested yet." target="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;Speaker: PhD C&#10;Content: Yeah there is something funny happening here because {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: But there are thirty - six and then sometimes we are {disfmarker} we are {disfmarker} we are around forty - two and&#10;Speaker: Professor B&#10;Content: Now up&#10;Speaker: PhD C&#10;Content: but&#10;Speaker: Professor B&#10;Content: Uh so one of the ideas that you had mentioned last time was having a {disfmarker} a second um silence detection .&#10;Speaker: PhD C&#10;Content: Yeah . So there are some results here&#10;Speaker: PhD D&#10;Content: For the Italian .&#10;Speaker: PhD C&#10;Content: uh so the third and the fifth line of the table&#10;Speaker: PhD D&#10;Content: For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt" target="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;Speaker: PhD C&#10;Content: Yeah there is something funny happening here because {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: But there are thirty - six and then sometimes we are {disfmarker} we are {disfmarker} we are around forty - two and&#10;Speaker: Professor B&#10;Content: Now up&#10;Speaker: PhD C&#10;Content: but&#10;Speaker: Professor B&#10;Content: Uh so one of the ideas that you had mentioned last time was having a {disfmarker} a second um silence detection .&#10;Speaker: PhD C&#10;Content: Yeah . So there are some results here&#10;Speaker: PhD D&#10;Content: For the Italian .&#10;Speaker: PhD C&#10;Content: uh so the third and the fifth line of the table&#10;Speaker: PhD D&#10;Content: For this one .&#10;Speaker: Professor B&#10;Content: So filt is what that is ?&#10;Speaker: PhD C&#10;Content: Filt" target="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target=" um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features go through a contextualized KLT . Then these features also uh get um low - pass filtered&#10;Speaker: PhD C&#10;Content: Yeah . Yeah so yeah I could perhaps draw this on the blackboard&#10;Speaker: Professor B&#10;Content: Sure . Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The graph , yeah another one .&#10;Speaker: Professor B&#10;Content: Yeah , that 's good .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor B&#10;Content: So&#10;Speaker: PhD C&#10;Content: So we have these features from OGI that goes through the three paths .&#10;Speaker: Professor B&#10;Content: Yeah . Three , OK .&#10;Speaker: PhD C&#10;Content: The first is a KLT using several frames of the features .&#10;Speaker: Professor B&#10;Content: Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target="Speaker: Professor B&#10;Content: OK So uh today we 're looking at a number of uh things we 're trying and uh fortunately for listeners to this uh we lost some of it 's visual but um got tables in front of us . Um what is {disfmarker} what does combo mean ?&#10;Speaker: PhD C&#10;Content: So combo is um a system where we have these features that go through a network and then this same string of features but low - pass filtered with the low - pass filter used in the MSG features . And so these low - pass filtered goes through M eh {disfmarker} another MLP and then the linear output of these two MLP 's are combined just by adding the values and then there is this KLT . Um the output is used as uh features as well .&#10;Speaker: Professor B&#10;Content: Um so let me try to restate this and see if I have it right . There is uh {disfmarker} there is the features uh there 's the OGI features and then um those features um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target=" twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's OGI forty - five ? The bottom one there ?&#10;Speaker: PhD C&#10;Content: Uh it 's o it 's OGI two , it 's {disfmarker} so the {disfmarker} th it 's the features from the first line&#10;Speaker: PhD D&#10;Content: It 's in fact OGI two .&#10;Speaker: Professor B&#10;Content: S&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Right , but I mean what 's the {disfmarker} what does the last row mean ?&#10;Speaker: PhD C&#10;Content: So it 's uh basically this but without the KLT on the {disfmarker} from the left path .&#10;Speaker: Professor B&#10;Content: I thought that was the one {disfmarker} I thought that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target=" Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features&#10;Speaker: Professor B&#10;Content: Yeah . Uh - huh .&#10;Speaker: PhD C&#10;Content: The third path is this low - pass filter .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh , MLP&#10;Speaker: Professor B&#10;Content: Aha ! aha !&#10;Speaker: PhD C&#10;Content: Adding the outputs just like in the second propose the {disfmarker} the proposal from {disfmarker} for the first evaluation .&#10;Speaker: Professor B&#10;Content: Yeah ? Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: And then the KLT and then the two together again .&#10;Speaker: Professor B&#10;Content: No , the KLT . And those two together . That 's it .&#10;Speaker: PhD D&#10;Content: Two HTK .&#10;Speaker: Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target="Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker} top row ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: So yeah to {disfmarker} actually OGI two is the {disfmarker} the baseline with the OGI features but this is not exactly the result that they have because they 've {disfmarker} they 're still made some changes in the features&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: and {disfmarker} well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Uh OK so the one {disfmarker} one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first path: A KLT (Karhunen-LoÃ¨ve Transform) using multiple frames of the features.&#10;2. The second path: An MLP (Multi-Layer Perceptron) also using several frames of features.&#10;3. The third path: A low-pass filter, followed by another MLP and then combined with the output of the first two paths. Finally, a KLT is applied to the combined output." target="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP.">
      <data key="d0">1</data>
    </edge>
    <edge source=" um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features go through a contextualized KLT . Then these features also uh get um low - pass filtered&#10;Speaker: PhD C&#10;Content: Yeah . Yeah so yeah I could perhaps draw this on the blackboard&#10;Speaker: Professor B&#10;Content: Sure . Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The graph , yeah another one .&#10;Speaker: Professor B&#10;Content: Yeah , that 's good .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor B&#10;Content: So&#10;Speaker: PhD C&#10;Content: So we have these features from OGI that goes through the three paths .&#10;Speaker: Professor B&#10;Content: Yeah . Three , OK .&#10;Speaker: PhD C&#10;Content: The first is a KLT using several frames of the features .&#10;Speaker: Professor B&#10;Content: Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features" target="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence.">
      <data key="d0">1</data>
    </edge>
    <edge source=" um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features go through a contextualized KLT . Then these features also uh get um low - pass filtered&#10;Speaker: PhD C&#10;Content: Yeah . Yeah so yeah I could perhaps draw this on the blackboard&#10;Speaker: Professor B&#10;Content: Sure . Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The graph , yeah another one .&#10;Speaker: Professor B&#10;Content: Yeah , that 's good .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor B&#10;Content: So&#10;Speaker: PhD C&#10;Content: So we have these features from OGI that goes through the three paths .&#10;Speaker: Professor B&#10;Content: Yeah . Three , OK .&#10;Speaker: PhD C&#10;Content: The first is a KLT using several frames of the features .&#10;Speaker: Professor B&#10;Content: Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features" target="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Professor B&#10;Content: OK So uh today we 're looking at a number of uh things we 're trying and uh fortunately for listeners to this uh we lost some of it 's visual but um got tables in front of us . Um what is {disfmarker} what does combo mean ?&#10;Speaker: PhD C&#10;Content: So combo is um a system where we have these features that go through a network and then this same string of features but low - pass filtered with the low - pass filter used in the MSG features . And so these low - pass filtered goes through M eh {disfmarker} another MLP and then the linear output of these two MLP 's are combined just by adding the values and then there is this KLT . Um the output is used as uh features as well .&#10;Speaker: Professor B&#10;Content: Um so let me try to restate this and see if I have it right . There is uh {disfmarker} there is the features uh there 's the OGI features and then um those features um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features" target="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Professor B&#10;Content: OK So uh today we 're looking at a number of uh things we 're trying and uh fortunately for listeners to this uh we lost some of it 's visual but um got tables in front of us . Um what is {disfmarker} what does combo mean ?&#10;Speaker: PhD C&#10;Content: So combo is um a system where we have these features that go through a network and then this same string of features but low - pass filtered with the low - pass filter used in the MSG features . And so these low - pass filtered goes through M eh {disfmarker} another MLP and then the linear output of these two MLP 's are combined just by adding the values and then there is this KLT . Um the output is used as uh features as well .&#10;Speaker: Professor B&#10;Content: Um so let me try to restate this and see if I have it right . There is uh {disfmarker} there is the features uh there 's the OGI features and then um those features um go through a contextual {disfmarker} uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features" target="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing.">
      <data key="d0">1</data>
    </edge>
    <edge source=" twenty - eight dimensions .&#10;Speaker: Professor B&#10;Content: I see . OK . And what {disfmarker} and what 's OGI forty - five ? The bottom one there ?&#10;Speaker: PhD C&#10;Content: Uh it 's o it 's OGI two , it 's {disfmarker} so the {disfmarker} th it 's the features from the first line&#10;Speaker: PhD D&#10;Content: It 's in fact OGI two .&#10;Speaker: Professor B&#10;Content: S&#10;Speaker: PhD C&#10;Content: and {disfmarker} yeah .&#10;Speaker: Professor B&#10;Content: Right , but I mean what 's the {disfmarker} what does the last row mean ?&#10;Speaker: PhD C&#10;Content: So it 's uh basically this but without the KLT on the {disfmarker} from the left path .&#10;Speaker: Professor B&#10;Content: I thought that was the one {disfmarker} I thought that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have" target="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features&#10;Speaker: Professor B&#10;Content: Yeah . Uh - huh .&#10;Speaker: PhD C&#10;Content: The third path is this low - pass filter .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh , MLP&#10;Speaker: Professor B&#10;Content: Aha ! aha !&#10;Speaker: PhD C&#10;Content: Adding the outputs just like in the second propose the {disfmarker} the proposal from {disfmarker} for the first evaluation .&#10;Speaker: Professor B&#10;Content: Yeah ? Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: And then the KLT and then the two together again .&#10;Speaker: Professor B&#10;Content: No , the KLT . And those two together . That 's it .&#10;Speaker: PhD D&#10;Content: Two HTK .&#10;Speaker: Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content:" target="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features&#10;Speaker: Professor B&#10;Content: Yeah . Uh - huh .&#10;Speaker: PhD C&#10;Content: The third path is this low - pass filter .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh , MLP&#10;Speaker: Professor B&#10;Content: Aha ! aha !&#10;Speaker: PhD C&#10;Content: Adding the outputs just like in the second propose the {disfmarker} the proposal from {disfmarker} for the first evaluation .&#10;Speaker: Professor B&#10;Content: Yeah ? Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: And then the KLT and then the two together again .&#10;Speaker: Professor B&#10;Content: No , the KLT . And those two together . That 's it .&#10;Speaker: PhD D&#10;Content: Two HTK .&#10;Speaker: Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content:" target="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: PhD C&#10;Content: The second path is uh MLP also using nine frames {disfmarker} several frames of features&#10;Speaker: Professor B&#10;Content: Yeah . Uh - huh .&#10;Speaker: PhD C&#10;Content: The third path is this low - pass filter .&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Uh , MLP&#10;Speaker: Professor B&#10;Content: Aha ! aha !&#10;Speaker: PhD C&#10;Content: Adding the outputs just like in the second propose the {disfmarker} the proposal from {disfmarker} for the first evaluation .&#10;Speaker: Professor B&#10;Content: Yeah ? Yeah . Yeah .&#10;Speaker: PhD C&#10;Content: And then the KLT and then the two together again .&#10;Speaker: Professor B&#10;Content: No , the KLT . And those two together . That 's it .&#10;Speaker: PhD D&#10;Content: Two HTK .&#10;Speaker: Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content:" target="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker} top row ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: So yeah to {disfmarker} actually OGI two is the {disfmarker} the baseline with the OGI features but this is not exactly the result that they have because they 've {disfmarker} they 're still made some changes in the features&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: and {disfmarker} well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Uh OK so the one {disfmarker} one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;" target="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker} top row ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: So yeah to {disfmarker} actually OGI two is the {disfmarker} the baseline with the OGI features but this is not exactly the result that they have because they 've {disfmarker} they 're still made some changes in the features&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: and {disfmarker} well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Uh OK so the one {disfmarker} one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;" target="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker} top row ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: So yeah to {disfmarker} actually OGI two is the {disfmarker} the baseline with the OGI features but this is not exactly the result that they have because they 've {disfmarker} they 're still made some changes in the features&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: and {disfmarker} well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: Uh OK so the one {disfmarker} one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: An&#10;" target="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output.">
      <data key="d0">1</data>
    </edge>
    <edge source="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence." target="&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: I 'm not sure these are great ideas .&#10;Speaker: Professor B&#10;Content: But they 're ideas . Yeah ? Oh , that was good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And {disfmarker} and uh also it 's still true that uh I think it 's true that {disfmarker} that we {disfmarker} we at least got fairly consistent i improved results by running uh the uh neural net transformation in parallel with the features&#10;Speaker: PhD C&#10;Content: But&#10;Speaker: Professor B&#10;Content: rather than uh in sequence which was {disfmarker} was your suggestion and that {disfmarker} that {disfmarker} that seems to have been borne out .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: The fact that none of these are {disfmarker} are {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="The improvement in results comes from the ability to extract more relevant information and capture dependencies between frames when running the neural net transformation in parallel with the features. When run in sequence, each frame is processed independently, which may not fully exploit the relationships between consecutive frames. By processing them in parallel, the model can consider the context of multiple frames simultaneously, leading to improved performance. This was PhD C's suggested approach, and the results indicate that it has been more effective than running the neural net transformation in sequence." target="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: I 'm not sure these are great ideas .&#10;Speaker: Professor B&#10;Content: But they 're ideas . Yeah ? Oh , that was good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And {disfmarker} and uh also it 's still true that uh I think it 's true that {disfmarker} that we {disfmarker} we at least got fairly consistent i improved results by running uh the uh neural net transformation in parallel with the features&#10;Speaker: PhD C&#10;Content: But&#10;Speaker: Professor B&#10;Content: rather than uh in sequence which was {disfmarker} was your suggestion and that {disfmarker} that {disfmarker} that seems to have been borne out .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: The fact that none of these are {disfmarker} are {disfmarker" target="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target=" you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {disfmarker} we could {disfmarker} we could start soon , yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Write up something .&#10;Speaker: Professor B&#10;Content: Yeah , and {disfmarker} and I {disfmarker} I would {disfmarker} you know , I would {disfmarker} I 'd kind of like to see it&#10;Speaker: PhD C&#10;Content: Um yeah . Mm - hmm .&#10;Speaker: Professor B&#10;Content: maybe I can {disfmarker} I can edit it a bit uh sure . The {disfmarker} my {disfmarker} what in this si i in this situation is my forte which is English .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh so&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh H yeah . Have y have you seen">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="&#10;Content: it d&#10;Speaker: Professor B&#10;Content: I {disfmarker} Yeah , OK except that we do have to write it up .&#10;Speaker: PhD C&#10;Content: I think we fixed on Tuesday , yeah . Yeah . Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: Also , so&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: Um&#10;Speaker: PhD C&#10;Content: Uh yeah well . Well basically it 's this with perhaps some kind of printing and some {disfmarker} some other @ @ .&#10;Speaker: Professor B&#10;Content: Right so maybe what we do is we {disfmarker} we {disfmarker} we uh as soon as we get the data from them we start the training and so forth&#10;Speaker: PhD C&#10;Content: Yeah but Mm - hmm .&#10;Speaker: Professor B&#10;Content: but we start the write - up right away because as you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {d">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target=": Professor B&#10;Content: K , uh if nobody has anything else maybe we should go around do {disfmarker} do our digits {disfmarker} do our digits duty . OK . OK I 'll start . Uh , let me say that again . OK . I guess we 're done .">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target=" B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker} well {disfmarker} the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .&#10;Speaker: PhD D&#10;Content: Ye But words {disfmarker} well word {disfmarker} I don't know .&#10;Speaker: PhD C&#10;Content: Hmm ? The words , yeah . S sentences .&#10;Speaker: PhD D&#10;Content: Sentences .&#10;Speaker: PhD C&#10;Content: Some sets have five hundred sentences , so .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So the {disfmarker} so the sets {disfmarker} so the test sets are between five hundred and two thousand sentences , let 's say&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: and each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target=" {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah , well . Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: was like {disfmarker} I thought it was five PM or something , I didn't think it was midnight . I thought they said they wanted everything by&#10;Speaker: PhD D&#10;Content: Yeah , five PM .&#10;Speaker: Professor B&#10;Content: well , so five PM their time is {disfmarker} is {disfmarker} if&#10;Speaker: PhD D&#10;Content: Not five PM , three PM .&#10;Speaker: Professor B&#10;Content: three PM .&#10;Speaker: PhD D&#10;Content: Three PM .&#10;Speaker: Professor B&#10;Content: Alright , that 's six in the morning here .&#10;Speaker: PhD C&#10;Content: It 's d no .&#10;Speaker: PhD D&#10;Content: Uh no three {disfmarker} three A - three PM ?&#10;Speaker: PhD C&#10;Content: No , we are wondering about the {disfmarker} the">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, PhD C and Professor B discussed plans to start working soon and write up something. Specifically, Professor B mentioned her proficiency in English and offered to edit the work, stating that it would be her contribution to the task at hand. She appears confident in this area, as she notes that &quot;my forte which is English&quot; can be helpful in improving the writing. PhD C agreed with this suggestion, showing agreement throughout the conversation." target="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {disfmarker} we could {disfmarker} we could start soon , yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Write up something .&#10;Speaker: Professor B&#10;Content: Yeah , and {disfmarker} and I {disfmarker} I would {disfmarker} you know , I would {disfmarker} I 'd kind of like to see it&#10;Speaker: PhD C&#10;Content: Um yeah . Mm - hmm .&#10;Speaker: Professor B&#10;Content: maybe I can {disfmarker} I can edit it a bit uh sure . The {disfmarker} my {disfmarker} what in this si i in this situation is my forte which is English .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh so&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh H yeah . Have y have you seen" target="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {disfmarker} we could {disfmarker} we could start soon , yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Write up something .&#10;Speaker: Professor B&#10;Content: Yeah , and {disfmarker} and I {disfmarker} I would {disfmarker} you know , I would {disfmarker} I 'd kind of like to see it&#10;Speaker: PhD C&#10;Content: Um yeah . Mm - hmm .&#10;Speaker: Professor B&#10;Content: maybe I can {disfmarker} I can edit it a bit uh sure . The {disfmarker} my {disfmarker} what in this si i in this situation is my forte which is English .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh so&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh H yeah . Have y have you seen" target="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: it d&#10;Speaker: Professor B&#10;Content: I {disfmarker} Yeah , OK except that we do have to write it up .&#10;Speaker: PhD C&#10;Content: I think we fixed on Tuesday , yeah . Yeah . Mm - hmm . Mm - hmm .&#10;Speaker: Professor B&#10;Content: Also , so&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: Um&#10;Speaker: PhD C&#10;Content: Uh yeah well . Well basically it 's this with perhaps some kind of printing and some {disfmarker} some other @ @ .&#10;Speaker: Professor B&#10;Content: Right so maybe what we do is we {disfmarker} we {disfmarker} we uh as soon as we get the data from them we start the training and so forth&#10;Speaker: PhD C&#10;Content: Yeah but Mm - hmm .&#10;Speaker: Professor B&#10;Content: but we start the write - up right away because as you say there {disfmarker} there 's only minor differences between these .&#10;Speaker: PhD C&#10;Content: I think you {d" target="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor B&#10;Content: K , uh if nobody has anything else maybe we should go around do {disfmarker} do our digits {disfmarker} do our digits duty . OK . OK I 'll start . Uh , let me say that again . OK . I guess we 're done ." target="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=" B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker} well {disfmarker} the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .&#10;Speaker: PhD D&#10;Content: Ye But words {disfmarker} well word {disfmarker} I don't know .&#10;Speaker: PhD C&#10;Content: Hmm ? The words , yeah . S sentences .&#10;Speaker: PhD D&#10;Content: Sentences .&#10;Speaker: PhD C&#10;Content: Some sets have five hundred sentences , so .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So the {disfmarker} so the sets {disfmarker} so the test sets are between five hundred and two thousand sentences , let 's say&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: and each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content" target="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=" B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker} well {disfmarker} the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .&#10;Speaker: PhD D&#10;Content: Ye But words {disfmarker} well word {disfmarker} I don't know .&#10;Speaker: PhD C&#10;Content: Hmm ? The words , yeah . S sentences .&#10;Speaker: PhD D&#10;Content: Sentences .&#10;Speaker: PhD C&#10;Content: Some sets have five hundred sentences , so .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So the {disfmarker} so the sets {disfmarker} so the test sets are between five hundred and two thousand sentences , let 's say&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: and each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content" target="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision.">
      <data key="d0">1</data>
    </edge>
    <edge source=" B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker} well {disfmarker} the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .&#10;Speaker: PhD D&#10;Content: Ye But words {disfmarker} well word {disfmarker} I don't know .&#10;Speaker: PhD C&#10;Content: Hmm ? The words , yeah . S sentences .&#10;Speaker: PhD D&#10;Content: Sentences .&#10;Speaker: PhD C&#10;Content: Some sets have five hundred sentences , so .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So the {disfmarker} so the sets {disfmarker} so the test sets are between five hundred and two thousand sentences , let 's say&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: and each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content" target="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers).">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah , well . Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: was like {disfmarker} I thought it was five PM or something , I didn't think it was midnight . I thought they said they wanted everything by&#10;Speaker: PhD D&#10;Content: Yeah , five PM .&#10;Speaker: Professor B&#10;Content: well , so five PM their time is {disfmarker} is {disfmarker} if&#10;Speaker: PhD D&#10;Content: Not five PM , three PM .&#10;Speaker: Professor B&#10;Content: three PM .&#10;Speaker: PhD D&#10;Content: Three PM .&#10;Speaker: Professor B&#10;Content: Alright , that 's six in the morning here .&#10;Speaker: PhD C&#10;Content: It 's d no .&#10;Speaker: PhD D&#10;Content: Uh no three {disfmarker} three A - three PM ?&#10;Speaker: PhD C&#10;Content: No , we are wondering about the {disfmarker} the" target="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." target=" of {disfmarker} end of the month , the TI - digits are there also ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . It 's included , yeah .&#10;Speaker: Professor B&#10;Content: Oh OK . OK . And see what else there is here . Um Oh I see {disfmarker} the one {disfmarker} I was looking down here at the {disfmarker} the o the row below the lower yellowed one . Uh that 's uh that 's with the reduced uh KLT size {disfmarker} reduced dimensionality .&#10;Speaker: PhD C&#10;Content: Mm - hmm ? Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: What happens there is it 's around the same and so you could reduce the dimension as you were saying before a bit perhaps .&#10;Speaker: PhD C&#10;Content: Yeah , it 's {disfmarker} it 's significantly worse well but {disfmarker} Mm - hmm .&#10;Speaker: Professor B&#10;Content: It 's significantly worse {disfmarker} it 's {disfmarker} it 's uh it">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." target=" - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: But yeah . Generally what you observe with TI - digits is that the result are very close whatever the {disfmarker} the system .&#10;Speaker: Professor B&#10;Content: OK . And so have you put all these numbers together into a single number representing that ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean not {disfmarker}&#10;Speaker: PhD C&#10;Content: Uh not yet .&#10;Speaker: Professor B&#10;Content: OK so that should be pretty easy to do and that would be good {disfmarker}&#10;Speaker: PhD C&#10;Content: No . Mmm yeah , yeah .&#10;Speaker: Professor B&#10;Content: then we could compare the two and say what was better .&#10;Speaker: PhD C&#10;Content: Mmm . Yeah .&#10;Speaker: Professor B&#10;Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." target=": PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no low {disfmarker} low - pass processing used as additional feature stream .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Do you e um they mentioned {disfmarker} made some {disfmarker} uh when I was on the phone with Sunil they {disfmarker} they mentioned some weighting scheme that was used to evaluate all of these numbers .&#10;Speaker: PhD C&#10;Content: Yeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .&#10;Speaker: Professor B&#10;Content: Um and we don't have the TI - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." target="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." target="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits refer to a specific set of data or test conditions in the conversation. They are mentioned several times throughout the discussion, and it seems that they are related to the evaluation or testing of different systems or methods.&#10;&#10;The reduced KLT size with slightly worse performance is a comparison point for the TI-digits. It appears that the speakers were discussing different dimensionality reduction techniques, including one that involves reducing the KLT (Karhunen-LoÃ¨ve Transform) size. This reduction in KLT size results in slightly worse performance compared to the original KLT size, but it is still a viable option for comparison with the TI-digits.&#10;&#10;In summary, the TI-digits are a specific set of data or test conditions, and they are being compared to a reduced KLT size technique that has slightly worse performance. The speakers are discussing how these two options compare and how they might be used in their evaluation or analysis." target="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: But yeah . Generally what you observe with TI - digits is that the result are very close whatever the {disfmarker} the system .&#10;Speaker: Professor B&#10;Content: OK . And so have you put all these numbers together into a single number representing that ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean not {disfmarker}&#10;Speaker: PhD C&#10;Content: Uh not yet .&#10;Speaker: Professor B&#10;Content: OK so that should be pretty easy to do and that would be good {disfmarker}&#10;Speaker: PhD C&#10;Content: No . Mmm yeah , yeah .&#10;Speaker: Professor B&#10;Content: then we could compare the two and say what was better .&#10;Speaker: PhD C&#10;Content: Mmm . Yeah .&#10;Speaker: Professor B&#10;Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker}" target="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month.">
      <data key="d0">1</data>
    </edge>
    <edge source=" - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: But yeah . Generally what you observe with TI - digits is that the result are very close whatever the {disfmarker} the system .&#10;Speaker: Professor B&#10;Content: OK . And so have you put all these numbers together into a single number representing that ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean not {disfmarker}&#10;Speaker: PhD C&#10;Content: Uh not yet .&#10;Speaker: Professor B&#10;Content: OK so that should be pretty easy to do and that would be good {disfmarker}&#10;Speaker: PhD C&#10;Content: No . Mmm yeah , yeah .&#10;Speaker: Professor B&#10;Content: then we could compare the two and say what was better .&#10;Speaker: PhD C&#10;Content: Mmm . Yeah .&#10;Speaker: Professor B&#10;Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker}" target="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results.">
      <data key="d0">1</data>
    </edge>
    <edge source=" - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: But yeah . Generally what you observe with TI - digits is that the result are very close whatever the {disfmarker} the system .&#10;Speaker: Professor B&#10;Content: OK . And so have you put all these numbers together into a single number representing that ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean not {disfmarker}&#10;Speaker: PhD C&#10;Content: Uh not yet .&#10;Speaker: Professor B&#10;Content: OK so that should be pretty easy to do and that would be good {disfmarker}&#10;Speaker: PhD C&#10;Content: No . Mmm yeah , yeah .&#10;Speaker: Professor B&#10;Content: then we could compare the two and say what was better .&#10;Speaker: PhD C&#10;Content: Mmm . Yeah .&#10;Speaker: Professor B&#10;Content: Um and how does this compare to the numbers {disfmarker} oh so OGI two is just the top {disfmarker}" target="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=": PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no low {disfmarker} low - pass processing used as additional feature stream .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Do you e um they mentioned {disfmarker} made some {disfmarker} uh when I was on the phone with Sunil they {disfmarker} they mentioned some weighting scheme that was used to evaluate all of these numbers .&#10;Speaker: PhD C&#10;Content: Yeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .&#10;Speaker: Professor B&#10;Content: Um and we don't have the TI - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker" target="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=": PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no low {disfmarker} low - pass processing used as additional feature stream .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Do you e um they mentioned {disfmarker} made some {disfmarker} uh when I was on the phone with Sunil they {disfmarker} they mentioned some weighting scheme that was used to evaluate all of these numbers .&#10;Speaker: PhD C&#10;Content: Yeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .&#10;Speaker: Professor B&#10;Content: Um and we don't have the TI - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker" target="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month.">
      <data key="d0">1</data>
    </edge>
    <edge source=": PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no low {disfmarker} low - pass processing used as additional feature stream .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Do you e um they mentioned {disfmarker} made some {disfmarker} uh when I was on the phone with Sunil they {disfmarker} they mentioned some weighting scheme that was used to evaluate all of these numbers .&#10;Speaker: PhD C&#10;Content: Yeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .&#10;Speaker: Professor B&#10;Content: Um and we don't have the TI - digits part yet ?&#10;Speaker: PhD C&#10;Content: Uh , no .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker" target="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed.">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target=" delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look at&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but I just would add the {disfmarker} the {disfmarker} the second row one&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and then um if we can um&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: oh yeah also when {disfmarker} when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?&#10;Speaker: PhD C&#10;Content: Uh {vocalsound} I guess , yeah .&#10;Speaker: Professor B&#10;Content: Yeah OK .&#10;Speaker: PhD C&#10;Content: I guess , yeah . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target=" each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah for the Italian even seven digits y more or less&#10;Speaker: PhD C&#10;Content: It {disfmarker} it d Seven digits .&#10;Speaker: PhD D&#10;Content: but sometime the sentence have only one digit and sometime uh like uh the number of uh credit cards , something like that .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Right , so between one and sixteen . See the {disfmarker} I mean the reason I 'm asking is {disfmarker} is {disfmarker} is we have all these small differences and I don't know how seriously to take them , right ?&#10;Speaker: PhD C&#10;Content: Mm - hmm ?&#10;Speaker: Professor B&#10;Content: So uh i if {disfmarker} if you had uh just you know {disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth of a percent would just be one word ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: right ? So {disfmarker} so it wouldn't mean anything .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Oh&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: um so um yeah it be kind of {disfmarker} I 'd kind of like to know what the sizes of these test sets were actually .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The size that we have ?&#10;Speaker: PhD C&#10;Content: We could {disfmarker} we could run {disfmarker} run some kind of significance tests&#10;Speaker: Professor B&#10;Content: Yeah since these {disfmarker} well also just to know the numbers ,&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: PhD D&#10;Content: Yeah .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently.">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers).">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results.">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="The text indicates that there is uncertainty regarding whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the numbers. This was brought up by Professor B, but it is not clear from the transcript if there was a definitive answer provided." target="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed.">
      <data key="d0">1</data>
    </edge>
    <edge source=" delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look at&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but I just would add the {disfmarker} the {disfmarker} the second row one&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and then um if we can um&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: oh yeah also when {disfmarker} when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?&#10;Speaker: PhD C&#10;Content: Uh {vocalsound} I guess , yeah .&#10;Speaker: Professor B&#10;Content: Yeah OK .&#10;Speaker: PhD C&#10;Content: I guess , yeah . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;" target="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision.">
      <data key="d0">1</data>
    </edge>
    <edge source=" delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look at&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but I just would add the {disfmarker} the {disfmarker} the second row one&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and then um if we can um&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: oh yeah also when {disfmarker} when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?&#10;Speaker: PhD C&#10;Content: Uh {vocalsound} I guess , yeah .&#10;Speaker: Professor B&#10;Content: Yeah OK .&#10;Speaker: PhD C&#10;Content: I guess , yeah . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;" target="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look at&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but I just would add the {disfmarker} the {disfmarker} the second row one&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and then um if we can um&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: oh yeah also when {disfmarker} when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?&#10;Speaker: PhD C&#10;Content: Uh {vocalsound} I guess , yeah .&#10;Speaker: Professor B&#10;Content: Yeah OK .&#10;Speaker: PhD C&#10;Content: I guess , yeah . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;" target="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers.">
      <data key="d0">1</data>
    </edge>
    <edge source=" each sentence on the average has four or five digits or is it {disfmarker} most of them longer or&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah for the Italian even seven digits y more or less&#10;Speaker: PhD C&#10;Content: It {disfmarker} it d Seven digits .&#10;Speaker: PhD D&#10;Content: but sometime the sentence have only one digit and sometime uh like uh the number of uh credit cards , something like that .&#10;Speaker: Professor B&#10;Content: Mm - hmm . Right , so between one and sixteen . See the {disfmarker} I mean the reason I 'm asking is {disfmarker} is {disfmarker} is we have all these small differences and I don't know how seriously to take them , right ?&#10;Speaker: PhD C&#10;Content: Mm - hmm ?&#10;Speaker: Professor B&#10;Content: So uh i if {disfmarker} if you had uh just you know {disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth" target="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers).">
      <data key="d0">1</data>
    </edge>
    <edge source="disfmarker} to give an example , if you had uh um if you had a thousand words then uh a {disfmarker} a tenth of a percent would just be one word ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: right ? So {disfmarker} so it wouldn't mean anything .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Oh&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: um so um yeah it be kind of {disfmarker} I 'd kind of like to know what the sizes of these test sets were actually .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The size that we have ?&#10;Speaker: PhD C&#10;Content: We could {disfmarker} we could run {disfmarker} run some kind of significance tests&#10;Speaker: Professor B&#10;Content: Yeah since these {disfmarker} well also just to know the numbers ,&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: PhD D&#10;Content: Yeah .&#10;" target="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers).">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. According to Professor B, the change that led to improved and consistent results was running the neural net transformation in parallel with the features, instead of in sequence as initially suggested by PhD C. This approach allows for the exploration of relationships between consecutive frames, which can lead to better performance compared to processing each frame independently." target="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system." target=": Oh that 's probably the {disfmarker}&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: Professor B&#10;Content: this is probably channel error stuff&#10;Speaker: PhD C&#10;Content: well , you {disfmarker}&#10;Speaker: Professor B&#10;Content: huh ? Oh this is i right , it says right above here channel {disfmarker} channel error resilience ,&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: yeah . So recognition performance is just the top part , actually . Uh and they have {disfmarker} yes , split between seen databases and non - seen so basically between development and {disfmarker} and evaluation .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And {vocalsound} so {disfmarker} right , it 's presumed there 's all sorts of tuning that 's gone on on the see what they call seen databases and there won't be tuning for the uh unseen . Multi - condition {disfmarker} multi - condition . So they have {disfmarker} looks like they have uh uh">
      <data key="d0">1</data>
    </edge>
    <edge source="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system." target="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system." target="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system." target="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work.">
      <data key="d0">1</data>
    </edge>
    <edge source="The topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. They are discussing the performance of the system, specifically how it has been optimized for &quot;seen&quot; databases but may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning. The speakers also mention running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better performance. They consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory results. Additionally, they briefly touch upon the topic of silence detection in their neural network system." target="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Oh that 's probably the {disfmarker}&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: Professor B&#10;Content: this is probably channel error stuff&#10;Speaker: PhD C&#10;Content: well , you {disfmarker}&#10;Speaker: Professor B&#10;Content: huh ? Oh this is i right , it says right above here channel {disfmarker} channel error resilience ,&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor B&#10;Content: yeah . So recognition performance is just the top part , actually . Uh and they have {disfmarker} yes , split between seen databases and non - seen so basically between development and {disfmarker} and evaluation .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And {vocalsound} so {disfmarker} right , it 's presumed there 's all sorts of tuning that 's gone on on the see what they call seen databases and there won't be tuning for the uh unseen . Multi - condition {disfmarker} multi - condition . So they have {disfmarker} looks like they have uh uh" target="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on.">
      <data key="d0">1</data>
    </edge>
    <edge source="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision." target=" that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have this combo stuff so you just&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: uh&#10;Speaker: Professor B&#10;Content: So this is like the second line but with {disfmarker} with the combo stuff .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD D&#10;Content: And with the {disfmarker} all the output of the combo .&#10;Speaker: Professor B&#10;Content: OK . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: OK , so {disfmarker} alright so it looks to me {disfmarker} I guess the same {disfmarker} given that we have to take the filt ones out of the {disfmarker} the running because of this delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look">
      <data key="d0">1</data>
    </edge>
    <edge source="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision." target="'t want to do several and {disfmarker} and take the best&#10;Speaker: PhD C&#10;Content: Yeah . Mmm .&#10;Speaker: Professor B&#10;Content: that 's {disfmarker} that 's {disfmarker} that 's not proper but if this is development data we could still look at a couple .&#10;Speaker: PhD C&#10;Content: Yeah . We can {disfmarker} yeah . Sure . But we have to decide {disfmarker} I mean we have to fix the system on this d on this data , to choose the best&#10;Speaker: Professor B&#10;Content: Yeah . I Right .&#10;Speaker: PhD C&#10;Content: and these&#10;Speaker: Professor B&#10;Content: But the question is when {disfmarker} when do we fix the system ,&#10;Speaker: PhD C&#10;Content: But we could&#10;Speaker: Professor B&#10;Content: do we fix the system uh tomorrow or do we fix the system on Tuesday ?&#10;Speaker: PhD C&#10;Content: it d&#10;Speaker: Professor B&#10;Content: I {disfmarker} Yeah , OK except that we do have to write it">
      <data key="d0">1</data>
    </edge>
    <edge source="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision." target="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results.">
      <data key="d0">1</data>
    </edge>
    <edge source="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision." target="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Ph.D C and Professor B are reviewing several options and discussing details about them. They seem to be trying to decide which options to select. Professor B brings up the second row option and suggests adding it to their considerations. Ph.D C agrees with this suggestion.&#10;&#10;Later in the conversation, Ph.D C expresses a preference for not choosing several options and then taking the best one, to which Professor B responds that they could still look at a couple of options even if they are development data.&#10;&#10;Ph.D C also mentions three different paths they could take, including MLP with nine frames of features, a low-pass filter, and adding outputs using the proposal from the first evaluation. Professor B seems to understand and agrees with these options.&#10;&#10;Overall, Ph.D C and Professor B appear to be having a productive conversation as they review their options and come to a decision." target="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP.">
      <data key="d0">1</data>
    </edge>
    <edge source=" that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have this combo stuff so you just&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: uh&#10;Speaker: Professor B&#10;Content: So this is like the second line but with {disfmarker} with the combo stuff .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD D&#10;Content: And with the {disfmarker} all the output of the combo .&#10;Speaker: Professor B&#10;Content: OK . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: OK , so {disfmarker} alright so it looks to me {disfmarker} I guess the same {disfmarker} given that we have to take the filt ones out of the {disfmarker} the running because of this delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look" target="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" that was the second row . So what 's the difference between the second&#10;Speaker: PhD C&#10;Content: Uh the second line you don't have this combo stuff so you just&#10;Speaker: Professor B&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: uh&#10;Speaker: Professor B&#10;Content: So this is like the second line but with {disfmarker} with the combo stuff .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD D&#10;Content: And with the {disfmarker} all the output of the combo .&#10;Speaker: Professor B&#10;Content: OK . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Uh&#10;Speaker: Professor B&#10;Content: OK , so {disfmarker} alright so it looks to me {disfmarker} I guess the same {disfmarker} given that we have to take the filt ones out of the {disfmarker} the running because of this delay problem {disfmarker} so it looks to me like the ones you said I agree are {disfmarker} are the ones to look" target="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output.">
      <data key="d0">1</data>
    </edge>
    <edge source="'t want to do several and {disfmarker} and take the best&#10;Speaker: PhD C&#10;Content: Yeah . Mmm .&#10;Speaker: Professor B&#10;Content: that 's {disfmarker} that 's {disfmarker} that 's not proper but if this is development data we could still look at a couple .&#10;Speaker: PhD C&#10;Content: Yeah . We can {disfmarker} yeah . Sure . But we have to decide {disfmarker} I mean we have to fix the system on this d on this data , to choose the best&#10;Speaker: Professor B&#10;Content: Yeah . I Right .&#10;Speaker: PhD C&#10;Content: and these&#10;Speaker: Professor B&#10;Content: But the question is when {disfmarker} when do we fix the system ,&#10;Speaker: PhD C&#10;Content: But we could&#10;Speaker: Professor B&#10;Content: do we fix the system uh tomorrow or do we fix the system on Tuesday ?&#10;Speaker: PhD C&#10;Content: it d&#10;Speaker: Professor B&#10;Content: I {disfmarker} Yeah , OK except that we do have to write it" target="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Current status of reducing delay in the silence detector: Based on the conversation, it appears that PhD C and their team are still working on reducing the delay of the silence detector. They had been working on this issue two days prior to the meeting. However, there seems to be a constraint in implementing a silence detector on the server side due to delays.&#10;&#10;The reason for not being able to implement a silence detector at the server side for the filt system is primarily due to existing delays that do not allow for its integration. The team has been working on reducing the delay related to the silence detector, but it appears to be a challenging constraint they are facing. While there may be potential benefits to using a low-pass filter cepstrum, as mentioned by Professor B, it seems unlikely that this would significantly address the main issue of reducing delays in the silence detector.&#10;&#10;At the time of the conversation, PhD C mentions that their team has been working on reducing delay issues for the silence detector within the past two days, but implementing a silence detector at the server side remains unfeasible due to the existing delays. Other possibilities, such as reducing delay on the handset side or finding a compromise between delays on both sides, are being explored but have not been implemented or tested yet." target="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." target=" . Mmm .&#10;Speaker: Professor B&#10;Content: Alright .&#10;Speaker: PhD C&#10;Content: It 's not clear here .&#10;Speaker: Professor B&#10;Content: OK . Maybe {disfmarker} maybe they 'll argue about it . Um OK so if we can know what {disfmarker} how many words are in each and then um Dave uh Dave promised to get us something tomorrow which will be there as far as they 've gotten {vocalsound} Friday&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: and then we 'll operate with that&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and uh how long did it I guess if we 're not doing all these things {disfmarker} if we 're only doing um um I guess since this is development data it 's legitimate to do more than one , right ? I mean ordinarily if {disfmarker} in final test data you don't want to do several and {disfmarker} and take the best&#10;Speaker: PhD C&#10;Content: Yeah . Mmm .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." target="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." target="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." target="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." target="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B and PhD C discussed the number of words in a project and whether it's appropriate to perform more than one development data process. At one point, PhD C mentions that &quot;it's not clear here&quot; regarding the word count, and later on, Professor B brings up the issue again saying, &quot;I guess if we're only doing um um I guess since this is development data it's legitimate to do more than one, right?&quot; This implies that they are considering using a larger number of words for their project and are debating whether it's acceptable to do so in the context of development data. They ultimately agree that it's reasonable to do more than one process for development data, as long as they keep track of which approach they use and its corresponding results." target="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing." target=" Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content: Um . So this is {disfmarker} yeah&#10;Speaker: Professor B&#10;Content: And so uh and then the {disfmarker} the {disfmarker} the one at the top {disfmarker} and I presume these things that uh are in yellow are in yellow because overall they 're the best ?&#10;Speaker: PhD C&#10;Content: Yeah that 's the reason , yeah .&#10;Speaker: Professor B&#10;Content: Oh let 's focus on them then so what 's the block diagram for the one above it ?&#10;Speaker: PhD C&#10;Content: For the f the f first yellow line you mean ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah so it 's uh basically s the same except that we don't have this uh low - pass filtering so we have only two streams .&#10;Speaker: PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing." target=" PhD D&#10;Content: Mmm yeah .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD C&#10;Content: Actually the {disfmarker} yeah the second line is uh pretty much like the first line in yellow except that we don't have this KLT on the first {disfmarker} on the left part of the diagram . We just have the features as they are .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Um&#10;Speaker: Professor B&#10;Content: Yeah . Yeah so when we do this weighted measure we should compare the two cuz it might even come out better . And it 's {disfmarker} it 's {disfmarker} it 's a little {disfmarker} slightly simpler .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor B&#10;Content: So {disfmarker} so there 's {disfmarker} so I {disfmarker} I would put that one also as a {disfmarker} as a maybe . Uh and it {disfmarker} yeah and">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing." target="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing." target="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Block Diagram for the Third Path (Yellow Line with Low-Pass Filtering):&#10;&#10;The third path, referred to as &quot;combo,&quot; consists of the following stages:&#10;&#10;a. Features go through a network (possibly an MLP or other processing)&#10;b. The same string of features but low-pass filtered with the low-pass filter used in the MSG features&#10;c. Both streams of original and low-pass filtered features are processed using another MLP&#10;d. The linear output of these two MLPs is combined by adding their values&#10;e. A Karhunen-LoÃ¨ve Transform (KLT) is applied to the combined output, and the resulting output serves as features for further processing." target="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content: Um . So this is {disfmarker} yeah&#10;Speaker: Professor B&#10;Content: And so uh and then the {disfmarker} the {disfmarker} the one at the top {disfmarker} and I presume these things that uh are in yellow are in yellow because overall they 're the best ?&#10;Speaker: PhD C&#10;Content: Yeah that 's the reason , yeah .&#10;Speaker: Professor B&#10;Content: Oh let 's focus on them then so what 's the block diagram for the one above it ?&#10;Speaker: PhD C&#10;Content: For the f the f first yellow line you mean ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah so it 's uh basically s the same except that we don't have this uh low - pass filtering so we have only two streams .&#10;Speaker: PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no" target="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor B&#10;Content: OK so that 's {disfmarker} that 's this bottom one .&#10;Speaker: PhD C&#10;Content: Um . So this is {disfmarker} yeah&#10;Speaker: Professor B&#10;Content: And so uh and then the {disfmarker} the {disfmarker} the one at the top {disfmarker} and I presume these things that uh are in yellow are in yellow because overall they 're the best ?&#10;Speaker: PhD C&#10;Content: Yeah that 's the reason , yeah .&#10;Speaker: Professor B&#10;Content: Oh let 's focus on them then so what 's the block diagram for the one above it ?&#10;Speaker: PhD C&#10;Content: For the f the f first yellow line you mean ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah so it 's uh basically s the same except that we don't have this uh low - pass filtering so we have only two streams .&#10;Speaker: PhD D&#10;Content: Step .&#10;Speaker: PhD C&#10;Content: Well . There 's {disfmarker} there 's no" target="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The difference between the second line of content with and without the &quot;combo stuff&quot; refers to the inclusion or exclusion of additional processing steps in the feature extraction pipeline. In this context, the &quot;combo stuff&quot; likely includes the low-pass filtering and the combination of the linear output from two MLPs before applying the Karhunen-LoÃ¨ve Transform (KLT).&#10;2. Based on the discussion about a delay problem, the relevant lines to consider are those that have been processed while taking the &quot;filt&quot; ones out due to the delay issue. The transcript mentions that the &quot;second line&quot; and the &quot;ones you said I agree are the ones to look at&quot; should be considered, but it is not explicitly clear which lines these refer to. It seems that the speakers are referring to specific lines in their visual aids or documents, which might not be included in the transcript provided.&#10;&#10;Without further context or information about the specific lines being referred to, it's challenging to provide a precise answer. Nonetheless, based on the conversation, it can be inferred that the difference between processing with and without the &quot;combo stuff&quot; is significant, and there are some filtering constraints due to delay problems." target="Based on the given transcript, I infer that the &quot;second line of content&quot; refers to a processing pipeline without the additional steps including low-pass filtering and combining linear outputs from two MLPs before applying Karhunen-LoÃ¨ve Transform (KLT). The &quot;combo stuff&quot; likely refers to these extra processes.&#10;&#10;The main differences between the second line with and without &quot;combo stuff&quot; are:&#10;1. Additional low-pass filtering of features stream in the &quot;combo&quot; path.&#10;2. Combining linear outputs from two MLPs in the &quot;combo&quot; path.&#10;3. Applying Karhunen-LoÃ¨ve Transform (KLT) on the combined output in the &quot;combo&quot; path.&#10;&#10;The inclusion of all the output of the &quot;combo&quot; does not seem to affect the selection of lines directly. However, considering the discussion about a delay problem, some specific lines are excluded from the analysis due to filtering constraints. The transcript does not provide enough context for explicit line references; nevertheless, it implies that the focus is on comparing the second line with and without &quot;combo stuff&quot; while taking into account the delay problem's impact on the selection of lines.&#10;&#10;In summary, the differences between processing pipelines with and without &quot;combo stuff&quot; lie in low-pass filtering, combining MLP outputs, and applying KLT, which are not explicitly specified in the provided transcript. The selection of lines to consider is influenced by a delay problem rather than the inclusion of &quot;combo&quot; output.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers)." target="aker: Professor B&#10;Content: It 's significantly worse {disfmarker} it 's {disfmarker} it 's uh it 's {disfmarker} it 's mostly worse .&#10;Speaker: PhD C&#10;Content: Exc - except for the HM&#10;Speaker: PhD D&#10;Content: For many a mismatch it 's worse .&#10;Speaker: PhD C&#10;Content: but&#10;Speaker: Professor B&#10;Content: Yeah . But it is little . I mean not {disfmarker} not by a huge amount , I don't know . What are {disfmarker} what are the sizes of any of these sets , I {disfmarker} I 'm {disfmarker} I 'm sure you told me before , but I 've forgotten . So {disfmarker} you know how many words are in uh one of these test sets ?&#10;Speaker: PhD C&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: I don't remember .&#10;Speaker: Professor B&#10;Content: About ?&#10;Speaker: PhD C&#10;Content: Um it 's {disfmarker} it depends {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers)." target="er} well also just to know the numbers ,&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: right . So these {disfmarker} these are word error rates&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: so this is on how many words .&#10;Speaker: PhD C&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Yeah we have the result that the output of the HTK&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The number of {disfmarker} of sentences , no it 's the number isn't .&#10;Speaker: PhD C&#10;Content: Yeah sure {disfmarker} sure . Yeah sure .&#10;Speaker: Professor B&#10;Content: Yeah so anyway if you could just mail out what those numbers are and then {disfmarker} then {disfmarker} that {disfmarker} that be great .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers)." target="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The typical size of the well-matched set is around two thousand or three thousand words. Some sets have five hundred sentences.&#10;2. Test sets, which are the sets being evaluated, have sizes between five hundred and two thousand sentences, with each sentence having an average of four or five digits. However, sentence length can vary, ranging from one digit to as many as sixteen digits (including numbers like credit card numbers)." target="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} well also just to know the numbers ,&#10;Speaker: PhD C&#10;Content: or&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: right . So these {disfmarker} these are word error rates&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: so this is on how many words .&#10;Speaker: PhD C&#10;Content: Yep .&#10;Speaker: PhD D&#10;Content: Yeah we have the result that the output of the HTK&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: The number of {disfmarker} of sentences , no it 's the number isn't .&#10;Speaker: PhD C&#10;Content: Yeah sure {disfmarker} sure . Yeah sure .&#10;Speaker: Professor B&#10;Content: Yeah so anyway if you could just mail out what those numbers are and then {disfmarker} then {disfmarker} that {disfmarker} that be great .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content" target="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." target="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." target="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." target="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." target="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." target="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the given transcript, Professor B mentioned an additional piece of information related to their discussion on focusing on three architectures and considering a fourth one with a single KLT. However, the specifics of this new information were not provided in the text. The conversation continues with other topics, and there is no further context given about any new details regarding the architectures. Therefore, I'm unable to answer this question without more context or information." target="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month." target=" the uh unseen . Multi - condition {disfmarker} multi - condition . So they have {disfmarker} looks like they have uh uh&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so they splitting up between the TI - digits and everything else , I see . So the everything else is the SpeechDat - Car , that 's the multi multilingual&#10;Speaker: PhD C&#10;Content: Yeah , so it 's not divided between languages you mean or {disfmarker}&#10;Speaker: Professor B&#10;Content: Well , it is .&#10;Speaker: PhD C&#10;Content: it just&#10;Speaker: Professor B&#10;Content: It is , but there 's also {disfmarker} there 's these tables over here for the {disfmarker} for the TI - digits and these tables over here for the car data which is {disfmarker} which is I guess all the multilingual stuff&#10;Speaker: PhD C&#10;Content: Oh yeah .&#10;Speaker: Professor B&#10;Content: and then uh there 's {disfmarker} they also split up between multi - condition and clean only">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month." target="marker} I would put that one also as a {disfmarker} as a maybe . Uh and it {disfmarker} yeah and it 's actually {vocalsound} does {disfmarker} does significantly better on the uh uh highly mismatched Italian , so s and little worse on the mis on the MM case , but uh Well yeah it 's worse than a few things&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so uh let 's see how that c that c c see how that comes out on their {disfmarker} their measure and {disfmarker} are {disfmarker} are we running this uh for TI - digits or uh&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Now is TI di {disfmarker} is is that part of the result that they get for the uh development {disfmarker} th the results that they 're supposed to get at the end of {disfmarker} end of the month , the TI - digits are there also ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month." target="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month." target="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits and other data are divided and categorized in the multi-condition, multilingual SpeechDat-Car dataset based on the testing conditions (TI-digits) and all other data. The &quot;everything else&quot; refers to the SpeechDat-Car, which is a multilingual dataset. There are separate tables for the TI-digits and the car data, with the car data representing the multilingual portion of the dataset. Additionally, the data is also divided between multi-condition and clean only. For the TI-digits specifically, there is a desire to train on both clean and noisy conditions. The clean training features for the TI-digits have been extracted but not yet tested. The SpeechDat-Car dataset likely contains results for the TI-digits as well, as it is expected that they will be included in the results delivered at the end of the month." target="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} I would put that one also as a {disfmarker} as a maybe . Uh and it {disfmarker} yeah and it 's actually {vocalsound} does {disfmarker} does significantly better on the uh uh highly mismatched Italian , so s and little worse on the mis on the MM case , but uh Well yeah it 's worse than a few things&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so uh let 's see how that c that c c see how that comes out on their {disfmarker} their measure and {disfmarker} are {disfmarker} are we running this uh for TI - digits or uh&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Now is TI di {disfmarker} is is that part of the result that they get for the uh development {disfmarker} th the results that they 're supposed to get at the end of {disfmarker} end of the month , the TI - digits are there also ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah" target="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission." target=" {disfmarker} uh well we should look but my assumption is that we basically have to be done Tuesday . Um so then next Thursday we can sort of have a little aftermath&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: but then {disfmarker} then we 'll actually have the new data which is the German and the Danish&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: but that really will be much less work because uh the system will be fixed&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: so all we 'll do is take whatever {vocalsound} they have and {disfmarker} and uh and run it through the process .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh we won't be changing the training on anything&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: so there 'll be no new training , there 'll just be new HTK runs , so that 's means in some sense we can kind of relax from this">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission." target=" there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next uh next few days&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Yes .&#10;Speaker: Professor B&#10;Content: I guess they have to send it out {disfmarker} let 's see the thirty - first is uh uh Wednesday and I think the {disfmarker} it has to be there by some hour uh European time on Wednesday&#10;Speaker: PhD C&#10;Content: Hmm - hmm .&#10;Speaker: Professor B&#10;Content: so {vocalsound} I think basically&#10;Speaker: PhD D&#10;Content: We lost time uh Wednesday maybe because {vocalsound} that the difference in the time may be {disfmarker} is a long different of the time .&#10;Speaker: Professor B&#10;Content: E excuse me ?&#10;Speaker: PhD D&#10;Content: Maybe the Thursday the twelfth of the night of the Thurs - thirty - one is {disfmarker} is not valid in Europe .&#10;Speaker: PhD C&#10;Content: Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission." target="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, the primary tasks for the team next Thursday, after the fixing of the system, will include:&#10;&#10;1. Processing new data from Germany and Denmark by taking whatever is available and running it through the fixed system. This process won't involve any new training but rather new HTK runs.&#10;2. Working with partners to fill out tables in the days leading up to Wednesday (the 31st), as mentioned by PhD C. There seems to be a need to finalize these tables by a specific hour in European time on that day, and there might be some concerns about potential differences in time zones or valid workdays between regions.&#10;&#10;The exact details of the tasks may depend on further information not provided in the transcript, but the primary focus will be on processing the new data from Germany and Denmark using the fixed system and collaborating with partners on completing tables for submission." target="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration.">
      <data key="d0">1</data>
    </edge>
    <edge source=" there 'll be a lot to do just to {vocalsound} work with our partners to fill out the tables {vocalsound} over the next uh next few days&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Yes .&#10;Speaker: Professor B&#10;Content: I guess they have to send it out {disfmarker} let 's see the thirty - first is uh uh Wednesday and I think the {disfmarker} it has to be there by some hour uh European time on Wednesday&#10;Speaker: PhD C&#10;Content: Hmm - hmm .&#10;Speaker: Professor B&#10;Content: so {vocalsound} I think basically&#10;Speaker: PhD D&#10;Content: We lost time uh Wednesday maybe because {vocalsound} that the difference in the time may be {disfmarker} is a long different of the time .&#10;Speaker: Professor B&#10;Content: E excuse me ?&#10;Speaker: PhD D&#10;Content: Maybe the Thursday the twelfth of the night of the Thurs - thirty - one is {disfmarker} is not valid in Europe .&#10;Speaker: PhD C&#10;Content: Yeah" target="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work." target="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work." target="1. The first path, referred to as &quot;KLT,&quot; involves using a Karhunen-LoÃ¨ve Transform (KLT) with multiple frames of the features.&#10;2. The second path is also an MLP (Multi-Layer Perceptron) that uses several frames of features, similar to the first path but with different processing.&#10;3. The third path, referred to as &quot;combo,&quot; consists of a low-pass filter, another MLP for processing both the original and low-pass filtered features, and a Karhunen-LoÃ¨ve Transform (KLT) applied to the combined output. This KLT output serves as features for further processing.&#10;&#10;The third path involves more stages than the first two paths, combining the outputs of the first and second proposals with additional processing using a low-pass filter and another MLP.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B and PhD C have not explicitly discussed the significance of improvements and bug fixes in their work. While they talk about various aspects of their project, such as reducing delay in the silence detector, implementing a low-pass filter cepstrum, and optimizing performance for unseen databases, they do not directly address how these changes impact the overall importance or implications of their work." target="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." target="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." target="1. The main topic of discussion between Speakers PhD C and Professor B is related to a neural network system with a focus on channel error resilience. Channel error resilience refers to the system's ability to maintain performance even when there are errors in the communication channels, such as those caused by interference or noise.&#10;&#10;2. The performance of the neural network has been optimized for &quot;seen&quot; databases, which are databases used during the development and tuning phase of the model. However, they mention that it may not perform as well for &quot;unseen&quot; or new databases due to multi-condition tuning, indicating that the system might be overfitted to the seen databases.&#10;&#10;3. Speakers PhD C and Professor B have implemented changes to improve the performance of their neural network system, such as running the neural net transformation in parallel with features and exploring relationships between consecutive frames for better results. They also consider testing a new architecture with a single KLT (Karhunen-LoÃ¨ve Transform) at the end, aiming for lower maintenance while maintaining satisfactory performance.&#10;&#10;4. Professor B briefly touched upon the topic of silence detection in their neural network system and mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK (Hidden Markov Model Toolkit) system. However, specific values for these metrics were not provided in the transcript.&#10;&#10;5. The speakers discussed a split between seen and unseen databases, where the system has been tuned for better performance on seen databases but may struggle with unseen databases due to the lack of tuning for those conditions. This difference highlights the importance of ensuring that neural network systems can generalize well to new data and not just perform well on the data they have been trained on.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." target="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." target="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." target="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the conversation, Professor B mentioned that they have results related to &quot;word error rates&quot; and the number of sentences recognized by the HTK system. However, the specific values for these metrics were not provided in the transcript. Therefore, I'm unable to answer this question without those specific numbers." target="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results." target="1. The transcript indicates that a weighting scheme of forty percent (40%) was used for evaluating the TI-digits, while sixty percent (60%) was used for all SpeechDat languages. However, the specifics of how this weighting scheme was applied (whether to percentages or raw errors) is not clarified in the conversation.&#10;2. The mismatch between the testing and training data is handled by categorizing the data into different mismatch levels: well-matched (40% weight), medium mismatch (35% weight), and high mismatch (25% weight). However, the transcript does not provide information on how these categories were determined or applied in the evaluation process.&#10;3. It is important to note that there may have been variations in sentence length within the test sets, with some sentences having as few as one digit and others having up to sixteen digits (including credit card numbers). This variation could potentially affect the weighting scheme and should be taken into account when interpreting the results.&#10;4. Unfortunately, the transcript does not provide specific values for word error rates or the number of sentences recognized by the HTK system, so a more detailed analysis cannot be performed.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results." target="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration.">
      <data key="d0">1</data>
    </edge>
    <edge source="The TI-digits are a specific set of data or test conditions that are being evaluated and compared to a reduced KLT size technique. They are a part of the SpeechDat-Car dataset, which is a multilingual dataset divided into categories based on testing conditions. The speakers are discussing how the TI-digits compare to other methods and how they might be used in their evaluation or analysis.&#10;&#10;Yes, the TI-digits are expected to be included in the results delivered at the end of the month as part of the SpeechDat-Car dataset. However, the transcript does not provide specific information on whether the weighting scheme of forty, thirty-five, and twenty-five is applied to percentages or raw errors when evaluating the TI-digits results." target="1. Plans for training and testing on both clean and noisy TI-digits: The team has expressed their intention to train on both clean and noisy TI-digits for the SpeechDat-Car dataset. This is because they want to compare the performance of systems under different conditions (clean vs. noisy).&#10;2. Features for clean TI-digits obtained for testing: PhD C mentions that they have already extracted features for the clean TI-digits but haven't tested them yet. This indicates that, while they have the necessary data to proceed with testing on clean TI-digits, it has not been executed at the time of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professor B does not express a strong personal opinion about an individual who used every machine in the campus. She mentions it as an observation, stating that the person &quot;got his payback&quot; and later brings up the possibility of the group being CPU limited in their work. In response to this, Professor B acknowledges an offer made in such a situation, but the transcript does not provide further context or specifics about the offer. Therefore, it is difficult to determine Professor B's opinion on the matter without additional information." target="disfmarker} wanna run them he 's {disfmarker} he 's offering it .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So . It 's uh when he was here eh uh he {disfmarker} he used i not only every machine here but every machine on campus as far as I could tell , so {disfmarker} so in some ways he just got his payback , but uh again I {disfmarker} I don't know if we 'll end up with {disfmarker} if we 're gonna be CPU limited on anything that we 're doing in this group&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but {disfmarker} but if {disfmarker} if we are that 's an offer . OK well uh you guys doing great stuff so that 's {disfmarker} that {disfmarker} that 's really neat and uh we 'll uh uh g don't think we need to uh um Oh well the other thing I guess that I will say is that">
      <data key="d0">1</data>
    </edge>
    <edge source="In the course of their conversation, Professors B and C discuss the number of words in their project's development data. At one point, PhD C mentions that it's &quot;not clear here&quot; regarding the word count, indicating some uncertainty about this aspect. Later on, Professor B brings up the issue again, asking if it's appropriate to perform more than one development data process. They ultimately agree that it is reasonable to do so, as long as they keep track of which approach they use and its corresponding results.&#10;&#10;However, it's important to note that while they discuss the number of words and the legitimacy of using multiple processes for development data, they do not explicitly state the exact word count or provide a clear answer regarding whether it's appropriate in this specific context. Therefore, while we know they are discussing these topics, we don't have all the details or a definitive conclusion to their discussion." target="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration." target=" the night of the Thurs - thirty - one is {disfmarker} is not valid in Europe .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: We don't know is happening .&#10;Speaker: Professor B&#10;Content: Yes , so I mean {disfmarker} I think we have to actually get it done Tuesday&#10;Speaker: PhD D&#10;Content: Tuesday .&#10;Speaker: Professor B&#10;Content: right because I {disfmarker} I think&#10;Speaker: PhD C&#10;Content: Yeah , well .&#10;Speaker: Professor B&#10;Content: uh Uh&#10;Speaker: PhD C&#10;Content: Except if {disfmarker} if it 's the thirty - one at midnight or I don't know {disfmarker} we can {vocalsound} still do some work on Wednesday morning .&#10;Speaker: Professor B&#10;Content: yeah well . W i is but is {disfmarker} is it midni I thought it was actually something like five PM on {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah , well . Yeah .&#10;Speaker: PhD D&#10;Content: Yeah .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration." target="marker} three A - three PM ?&#10;Speaker: PhD C&#10;Content: No , we are wondering about the {disfmarker} the {disfmarker} the hour that we have to eh I don't know if it 's three PM {disfmarker} it 's&#10;Speaker: PhD D&#10;Content: Oh yeah , yeah , yeah , yeah . Three PM here is in Europe midnight .&#10;Speaker: PhD C&#10;Content: Yeah , it 's {disfmarker} it 's midnight but&#10;Speaker: Professor B&#10;Content: Yes , yes , but I didn't think it was midnight that it was due , I thought it was due at some hour during the day like five PM or something .&#10;Speaker: PhD D&#10;Content: Oh OK . Mm - hmm . Mm - hmm , &#10;Speaker: Professor B&#10;Content: In which case&#10;Speaker: PhD D&#10;Content: maybe .&#10;Speaker: Professor B&#10;Content: so I {disfmarker} I {disfmarker} uh well we should look but my assumption is that we basically have to be done Tuesday . Um so then next Thursday we can sort">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the conversation, it seems that there is some confusion regarding the exact deadline for completing the task, specifically the validity of &quot;the night of the Thurs-thirty-one&quot; (presumably referring to the evening of January 31st) in Europe and whether work can still be done on Wednesday morning. However, the speakers do agree that there is a deadline on Wednesday, with potential concerns about time zone differences.&#10;&#10;When clarifying the deadline, PhD D mentions that &quot;three PM here is in Europe midnight,&quot; to which Professor B responds by saying, &quot;three PM . . . six in the morning here.&quot; This implies that the speakers are considering three PM Eastern Standard Time (EST) as their deadline, which would be six in the morning on January 31st in Central European Time (CET).&#10;&#10;Given this information, the speakers should aim to complete the task by the morning of Wednesday, January 31st, CET. It is essential to confirm time zone differences and clarify any ambiguity regarding deadlines to ensure all parties are aligned and prepared for successful collaboration." target="Speakers A and B (PhD C and Professor B) discussed starting to work on a task together and writing something up. Professor B offered to use her proficiency in English to edit the work, stating that it would be her contribution to the project. She expressed confidence in this area, referring to her language skills as her &quot;forte.&quot; PhD C agreed with this suggestion and showed agreement throughout the conversation.">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
