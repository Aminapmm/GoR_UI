<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." />
    <node id=" , the {disfmarker} the instantaneous frequency ,&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: it probably too , you can find , {vocalsound} eh , that the instantaneous frequency {vocalsound} for the continuous , eh , {vocalsound} eh {disfmarker} the output of the continuous filters are very near . And in {pause} my case {disfmarker} i in {disfmarker} equal with our signal , {vocalsound} it doesn't happened .&#10;Speaker: Professor A&#10;Content: Yeah . I 'd hafta look at that and think about it .&#10;Speaker: PhD C&#10;Content: And {disfmarker}&#10;Speaker: Professor A&#10;Content: It 's {disfmarker} it 's {disfmarker} it 's {disfmarker} I haven't worked with that either so I 'm not sure {disfmarker} The way {disfmarker} {vocalsound} the simple - minded way I suggested was what Chuck was just saying , is that you could make a {disf" />
    <node id=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." />
    <node id=" {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {disfmarker} I use these {disfmarker} these frequency , eh , the range is different , and the resolution is different .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And I observe more {disfmarker} more or less , thing like this . And the paper said that , eh , these frequencies are probably , eh , harmonics .&#10;Speaker: Professor A&#10;Content: I see . Huh .&#10;Speaker: PhD C&#10;Content: But , eh , they used , eh , a rule , eh , based in the {disfmarker} in the {disfmarker} because to {disfmarker} to calculate the instantaneous frequency , they use a Hanning window .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And , they said that , eh , if {pause} these {pause} peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh {disfmarker} w eh eh" />
    <node id=" but {disfmarker} but then , given those guesses , try , um , uh , only looking at the energy at multiples of the {disfmarker} of that frequency , and {disfmarker} and see how much of the {disfmarker} take the one that 's maximum . Call that the {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But {disfmarker}&#10;Speaker: PhD C&#10;Content: Using the energy of the {disfmarker} of the multiple of the frequency .&#10;Speaker: Professor A&#10;Content: Of all the harmonics of that . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: Do you hafta do some kind of , uh , low - pass filter before you do that ?&#10;Speaker: PhD C&#10;Content: I don't use .&#10;Speaker: PhD G&#10;Content: Or {disfmarker}&#10;Speaker: PhD C&#10;Content: But , I {disfmarker} I know many people use , eh , low - pass filter to {disfmarker" />
    <node id=" .&#10;Speaker: PhD C&#10;Content: I get the {disfmarker} {pause} the spectrum ,&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and I represent all the frequency .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And {disfmarker} when ou I obtained the instantaneous frequency . And I change {vocalsound} the {disfmarker} the {disfmarker} the @ @ , using the instantaneous frequency , here .&#10;Speaker: Professor A&#10;Content: Oh , so you scale {disfmarker} you s you do a {disfmarker} a scaling along that axis according to instantaneous {disfmarker}&#10;Speaker: PhD C&#10;Content: I use {disfmarker} Yeah .&#10;Speaker: Professor A&#10;Content: It 's a kinda normalization .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . Because when {disfmarker} when {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {" />
    <node id=" PhD C&#10;Content: But , I {disfmarker} I know many people use , eh , low - pass filter to {disfmarker} to {disfmarker} to get , eh , the pitch .&#10;Speaker: Professor A&#10;Content: No . To get the pitch , yes .&#10;Speaker: PhD C&#10;Content: I don't use . To get the pitch , yes .&#10;Speaker: PhD E&#10;Content: To get the pitch , yeah .&#10;Speaker: PhD C&#10;Content: But the harmonic , no .&#10;Speaker: PhD G&#10;Content: But i But the harmonics are gonna be , uh , uh , I don't know what the right word is . Um , they 're gonna be dampened by the uh , vocal tract , right ? The response of the vocal tract .&#10;Speaker: Professor A&#10;Content: Yeah ?&#10;Speaker: PhD C&#10;Content: Yeah ?&#10;Speaker: PhD G&#10;Content: And so {disfmarker} just looking at the energy on those {disfmarker} at the harmonics , is that gonna {disfmarker} ?&#10;Speaker: Professor A&#10;Content: Well so the thing" />
    <node id="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." />
    <node id="isfmarker} eh , FTT . to FFT to {disfmarker} to obtain the {disfmarker} or to study the harmonics from {disfmarker} from the spectrum directly ,&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and to study the energy and the multiples of&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: frequency . And another {disfmarker} another algorithm I have is the {disfmarker} in the {pause} instantaneous frequency , based on {disfmarker} on {disfmarker} on the FFT to {disfmarker} to {disfmarker} to calculate the {disfmarker} the phase derivate in the time . Eh , uh n the d I mean I {disfmarker} I have two {disfmarker} two algorithms .&#10;Speaker: Professor A&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: But , eh , in m {pause} i in my opinion the {disfmarker} the {disfmarker} the instantaneous frequency , the {" />
    <node id="} No {disfmarker} No . No .&#10;Speaker: PhD G&#10;Content: And then hypothesize a new fundamental and get the energy {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah , that 's wh&#10;Speaker: PhD C&#10;Content: No . I {disfmarker} I {disfmarker} I {disfmarker} I don't proth process the {disfmarker} the fundamental . I {disfmarker} {vocalsound} I , ehm {disfmarker} I calculate the {disfmarker} the phase derivate using the FFT .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And {disfmarker} The algorithm said that , eh , {vocalsound} if you {disfmarker} if you change the {disfmarker} the {disfmarker} {vocalsound} the , eh , nnn {disfmarker} the X - the frequency &quot; X &quot; , eh , using the in the instantaneous frequency , you can find , eh , how , eh , in several frequencies that proba" />
    <node id=" this is in {disfmarker} in {disfmarker} in {disfmarker} in bands ? Or {disfmarker} or {disfmarker}&#10;Speaker: PhD C&#10;Content: No , no , no .&#10;Speaker: Professor A&#10;Content: Just {disfmarker} just overall {disfmarker}&#10;Speaker: PhD C&#10;Content: It 's a {disfmarker} it 's a {disfmarker} o i w the band {disfmarker} the band is , eh , from zero to {disfmarker} to four kilohertz . And I {disfmarker} I ot I {disfmarker}&#10;Speaker: Professor A&#10;Content: And you just take the instantaneous frequency ?&#10;Speaker: PhD C&#10;Content: Yeah . I u m t I {disfmarker} I used two m two method {disfmarker} two methods . Eh , one , eh , based on the F {disfmarker} eh , FTT . to FFT to {disfmarker} to obtain the {disfmarker} or to study the" />
    <node id="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." />
    <node id=": Postdoc F&#10;Content: That 's what they 've been doing . So , within an overlap segment , they {disfmarker} they do this .&#10;Speaker: PhD G&#10;Content: Right . But {disfmarker} Right . But if there 's a big hunk of speech , let 's say on Morgan 's mike where he 's not talking at all , um , don't {disfmarker} don't worry about that .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: So what we 're saying is , there 's no guarantee that , um {disfmarker} So for the chunks that are transcribed , everything 's transcribed . But outside of those boundaries , there could have been stuff that wasn't transcribed . So you just {disfmarker} somebody can't rely on that data and say &quot; that 's perfectly clean data &quot; . Uh {disfmarker} do you see what I 'm saying ?&#10;Speaker: Postdoc F&#10;Content: Yeah , you 're saying it 's {disfmarker} uncharted territory .&#10;Speaker: PhD G&#10;Content" />
    <node id="} this is actual stuff that we {disfmarker} we wanna work with .&#10;Speaker: Postdoc F&#10;Content: Well this is in very interesting&#10;Speaker: Professor A&#10;Content: So .&#10;Speaker: Postdoc F&#10;Content: because i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in {disfmarker} in discourse and linguistic research , what counts is what 's communit communicative .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: And {disfmarker} breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: and the idea is that the transcripts will {disfmarker} that {disfmarker} get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses .&#10;Speaker" />
    <node id=" are the transcriptions going ? Yeah .&#10;Speaker: Postdoc F&#10;Content: The {disfmarker} the news is that I 've {disfmarker} I uh {disfmarker} s So {disfmarker} in s um {disfmarker} So I 've switched to {disfmarker} Start my new sentence . I {disfmarker} I switched to doing the channel - by - channel transcriptions to provide , uh , the {disfmarker} uh , tighter time bins for {disfmarker} partly for use in Thilo 's work and also it 's of relevance to other people in the project . And , um , I discovered in the process a couple of {disfmarker} of interesting things , which , um , one of them is that , um , it seems that there are time lags involved in doing this , uh , uh , using an interface that has so much more complexity to it . And I {disfmarker} and I wanted to maybe ask , uh , Chuck to help me with some of the questions of efficiency . Maybe {disfmarker} I was thinking maybe the best way to do this in" />
    <node id="disfmarker} let 's think about the practicalities of how we get to that master copy with reference to breaths . So what I would {disfmarker} r r what I would wonder is would it be possible to encode those automatically ? Could we get a breath detector ?&#10;Speaker: Grad B&#10;Content: Oh , just to save the transcribers time .&#10;Speaker: Postdoc F&#10;Content: Well , I mean , you just have no idea . I mean , if you 're getting a breath several times every minute ,&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: and just simply the keystrokes it takes to negotiate , to put the boundaries in , to {disfmarker} to type it in , i it 's just a huge amount of time .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: Oops .&#10;Speaker: Professor A&#10;Content: Wh - what {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: And you wanna be sure it 's used ," />
    <node id=" Postdoc F&#10;Content: just so that they 're {disfmarker} they 're not being overlooked because of that , and count on accuracy during the sparser phases .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Cuz there are large s spaces of the {disfmarker} That 's a good point . There are large spaces where there 's no overlap at all . Someone 's giving a presentation ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: or whatever . That 's {disfmarker} that 's a good {disfmarker} that 's a good thought . And , um , let 's see , there was one other thing I was gonna say . I {disfmarker} I think it 's really interesting data to work with , I have to say , it 's very enjoyable . I really , not {disfmarker} not a problem spending time with these data . Really interesting . And not just because I 'm in there . No , it 's real interesting .&#10;Speaker: Professor A&#10;Content: Uh , well I think it" />
    <node id="}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: And you wanna be sure it 's used , and you wanna be sure it 's done as efficiently as possible , and if it can be done automatically , that would be ideal .&#10;Speaker: Professor A&#10;Content: what if you put it in but didn't put the boundaries ?&#10;Speaker: Postdoc F&#10;Content: Well , but {disfmarker}&#10;Speaker: Professor A&#10;Content: So you just know it 's between these other things ,&#10;Speaker: Postdoc F&#10;Content: Well , OK . So now there 's {disfmarker} there 's another {disfmarker} another possibility&#10;Speaker: Professor A&#10;Content: right ?&#10;Speaker: Postdoc F&#10;Content: which is , um , the time boundaries could mark off words {comment} from nonwords . And that would be extremely time - effective , if that 's sufficient .&#10;Speaker: Professor A&#10;Content: Yeah I mean I 'm think if it 's too {disfmarker} if it 's too hard for us to annotate the breaths per se ," />
    <node id="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." />
    <node id="Speaker: Professor A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: OK we 're on and we seem to be working .&#10;Speaker: PhD C&#10;Content: Yes .&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: We didn't crash {disfmarker} we 're not crashing anymore&#10;Speaker: PhD C&#10;Content: One , two , three , four , f&#10;Speaker: Grad B&#10;Content: and it really bothers me .&#10;Speaker: Professor A&#10;Content: Yeah ?&#10;Speaker: PhD C&#10;Content: No crashing .&#10;Speaker: PhD G&#10;Content: I do . I crashed when I started this morning .&#10;Speaker: Grad B&#10;Content: You crashed {disfmarker} crashed this morning ? I did not crash this morning .&#10;Speaker: PhD C&#10;Content: Yeah ?&#10;Speaker: Professor A&#10;Content: Oh ! Well maybe it 's just , you know , how many t u u u u how many times you crash in a day .&#10;Speaker: PhD G&#10;Content: Really ? Yeah . Maybe , yeah .&#10;Speaker: Professor A&#10;Content:" />
    <node id=" you crash in a day .&#10;Speaker: PhD G&#10;Content: Really ? Yeah . Maybe , yeah .&#10;Speaker: Professor A&#10;Content: First time {disfmarker} first time in the day , you know .&#10;Speaker: PhD G&#10;Content: Or maybe it 's once you 've {pause} done enough meetings {comment} it won't crash on you anymore .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: No ?&#10;Speaker: Postdoc F&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: It 's a matter of experience .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Self - learning , yeah .&#10;Speaker: Professor A&#10;Content: That 's {disfmarker} that 's great .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Uh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Do we have an agenda ? Liz {disfmarker} Liz and Andreas can't" />
    <node id="&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Do we have an agenda ? Liz {disfmarker} Liz and Andreas can't sh can't {disfmarker} uh , can't come .&#10;Speaker: Grad B&#10;Content: I do .&#10;Speaker: Professor A&#10;Content: So , they won't be here .&#10;Speaker: Grad B&#10;Content: I have agenda and it 's all me .&#10;Speaker: PhD G&#10;Content: Did {disfmarker}&#10;Speaker: Grad B&#10;Content: Cuz no one sent me anything else .&#10;Speaker: PhD G&#10;Content: Did they send , uh , the messages to you about the meeting today ?&#10;Speaker: Grad B&#10;Content: I have no idea but I just got it a few minutes ago .&#10;Speaker: PhD G&#10;Content: Oh .&#10;Speaker: Grad B&#10;Content: Right when you were in my office it arrived .&#10;Speaker: PhD G&#10;Content: Oh . OK , cuz I checked my mail . I didn't have anything .&#10;Speaker: Grad B&#10;Content: So , does anyone have any a agenda items other than me ? I actually" />
    <node id="Speaker: PhD G&#10;Content: Tomorrow .&#10;Speaker: Professor A&#10;Content: Tomorrow . March second , I said .&#10;Speaker: PhD E&#10;Content: Tomorrow ?&#10;Speaker: Grad B&#10;Content: I 've been a day off all week .&#10;Speaker: PhD C&#10;Content: Tomorrow .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: I guess that 's a good thing cuz that way I got my papers done early .&#10;Speaker: PhD G&#10;Content: It would be interesting {disfmarker}&#10;Speaker: Professor A&#10;Content: So that 's amazing you showed up at this meeting !&#10;Speaker: Grad B&#10;Content: It is . It is actually quite amazing .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: It 'll be interesting to see the reviewer 's comments .&#10;Speaker: Professor A&#10;Content: Yeah . Yeah . My favorite is was when {disfmarker} when {disfmarker} when one reviewer says , uh , &quot; you know , this should be far more detailed &quot; , and the nex the next reviewer says" />
    <node id=" they didn't reject a lot of the pre - proposals ?&#10;Speaker: Professor A&#10;Content: Do you know anything about the numbers ?&#10;Speaker: Grad B&#10;Content: No . Just {disfmarker} just th&#10;Speaker: PhD G&#10;Content: It 's just from his message it sounded like that .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah . I said something , yeah .&#10;Speaker: PhD G&#10;Content: Gary Strong 's {disfmarker}&#10;Speaker: Professor A&#10;Content: I&#10;Speaker: PhD G&#10;Content: there was a sentence at the end of one of his paragraphs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: I {disfmarker}&#10;Speaker: Professor A&#10;Content: I should go back and look . I didn't {disfmarker} I don't think that 's true .&#10;Speaker: Grad B&#10;Content: Yeah , OK .&#10;Speaker: PhD G&#10;Content: Mmm . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Spe" />
    <node id="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." />
    <node id="isfmarker} at the harmonics , is that gonna {disfmarker} ?&#10;Speaker: Professor A&#10;Content: Well so the thing is that the {disfmarker} This is for , uh , a , um {disfmarker}&#10;Speaker: PhD G&#10;Content: I m what you 'd like to do is get rid of the effect of the vocal tract . Right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: And just look at the {disfmarker} at {disfmarker} at the signal coming out of the glottis .&#10;Speaker: Professor A&#10;Content: Yeah . Uh , well , yeah that 'd be good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But , uh {disfmarker} but I {disfmarker} but {disfmarker} {vocalsound} but I don't know that you need to {disfmarker}&#10;Speaker: Grad B&#10;Content: Open wide !&#10;Speaker: Professor A&#10;Content: but I don't need you {disfmarker} know" />
    <node id=" {vocalsound} I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be {pause} primarily a low frequency phenomenon . And if you looked at the low frequencies , yes the higher frequencies are gonna {disfmarker} there 's gonna be a spectral slope . The higher frequencies will be lower energy . But so what . I mean {disfmarker} {vocalsound} that 's {disfmarker} that 's w&#10;Speaker: PhD C&#10;Content: I will prepare for the next week eh , all my results about the harmonicity and {pause} will {disfmarker} will try to come in and to discuss here , because , eh , I haven't enough feeling to {disfmarker} {vocalsound} to u {vocalsound} many time to {disfmarker} {vocalsound} to understand what happened with the {disfmarker} with , eh , so many peaks , eh , eh , and {vocalsound} I {disfmarker} I see the harmonics there many time but , eh , {vocalsound} there are a lot of peaks" />
    <node id=" {disfmarker} the {disfmarker} the reason we still complain about it is because is {disfmarker} when {disfmarker} when you have more realistic conditions then {disfmarker} then things fall apart .&#10;Speaker: Postdoc F&#10;Content: OK , fair enough . I guess , um , I {disfmarker} uh , what I was wondering is what {disfmarker} what {disfmarker} at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to {disfmarker}&#10;Speaker: Professor A&#10;Content: But that 's a research question , you know ? And so {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Yeah , well , see and that 's" />
    <node id="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is." />
    <node id=" errors and have them re - read , just to finish out the test set .&#10;Speaker: Postdoc F&#10;Content: Oh ! By {disfmarker} throw them out completely ?&#10;Speaker: Grad B&#10;Content: Um , the other thing you could do is change the transcript to match what they really said . So those are {disfmarker} those are the two options .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: But there 's often things where people do false starts . I know I 've done it , where I say {disfmarker} say a {disfmarker}&#10;Speaker: Grad B&#10;Content: What the transcribers did with that is if they did a correction , and they eventually did read the right string , {comment} you extract the right string .&#10;Speaker: PhD G&#10;Content: Oh , you 're talking about where they completely read the wrong string and didn't correct it ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yeah . And didn't notice . Which happens" />
    <node id=" correct it ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yeah . And didn't notice . Which happens in a few places .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: Ah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So {disfmarker} so {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Well , and s and you 're talking string - wise , you 're not talking about the entire page ?&#10;Speaker: Grad B&#10;Content: Correct .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: I get it .&#10;Speaker: Grad B&#10;Content: And so the {disfmarker} the two options are change the transcript to match what they really said , but then {disfmarker} but then the transcript isn't the Aurora test set anymore . I don't think that really matters because the conditions are so different . And that would be a little easier .&#10;Speaker: PhD G&#10;Content: Well how many are {disfmarker} how" />
    <node id=" are so different . And that would be a little easier .&#10;Speaker: PhD G&#10;Content: Well how many are {disfmarker} how {disfmarker} how often does that happen ?&#10;Speaker: Grad B&#10;Content: Mmm , five or six times .&#10;Speaker: PhD G&#10;Content: Oh , so it 's not very much .&#10;Speaker: Grad B&#10;Content: No , it 's not much at all .&#10;Speaker: PhD G&#10;Content: Seems like we should just change the transcripts&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: to match .&#10;Speaker: Professor A&#10;Content: Yeah , it 's five or six times out of {pause} thousands ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Four thousand .&#10;Speaker: Professor A&#10;Content: Four thousand ?&#10;Speaker: PhD C&#10;Content: Four thous Ah ! Four thousand .&#10;Speaker: PhD G&#10;Content: Yeah , it 's {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah" />
    <node id="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." />
    <node id="vocalsound} my impression was that the best way to do it was however you {disfmarker} You 've used instantaneous frequency , whatever . {comment} However you 've come up {disfmarker} you {disfmarker} with your candidates , you wanna see how much of the energy is in that&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor A&#10;Content: as coppo as opposed to all of the {disfmarker} all {disfmarker} the total energy . And , um , if it 's voiced , I guess {disfmarker} so {disfmarker} so y I think maybe you do need a voiced - unvoiced determination too . But if it 's voiced ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: um , and the , uh {disfmarker} e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be {disfmarker} then it 's more likely to be an overlap .&#10;Speaker: PhD C&#10;Content: Is height . Yeah ." />
    <node id=" um {disfmarker} yeah I guess you could {disfmarker} I guess {disfmarker} yeah you 're {disfmarker} so you 're not distinguished between voiced and unvoiced , so {disfmarker} so , i if you don't {disfmarker} if you don't care about that {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: See , if you also wanna {vocalsound} just determine {disfmarker} if you also wanna determine whether it 's unvoiced , {vocalsound} then I think you want to {pause} look {disfmarker} look at high frequencies also , because the f the fact that there 's more energy in the high frequencies is gonna be an ob sort of obvious cue that it 's unvoiced .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But , i i uh {disfmarker} {vocalsound} I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be {" />
    <node id="doc F&#10;Content: Yeah , you 're saying it 's {disfmarker} uncharted territory .&#10;Speaker: PhD G&#10;Content: So I would say don't tell them to transcribe anything that 's outside of a grouping of words .&#10;Speaker: Professor A&#10;Content: That sounds like a reasonable {disfmarker} reasonable compromise .&#10;Speaker: PhD E&#10;Content: Yeah , and that 's {disfmarker} that {disfmarker} that quite co corresponds to the way I {disfmarker} I try to train the speech - nonspeech detector , as I really try to {disfmarker} not to detect those breaths which are not within a speech chunk but with {disfmarker} which are just in {disfmarker} in a silence region .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: And they {disfmarker} so they hopefully won't be marked in {disfmarker} in those channel - specific files .&#10;Speaker: Professor A&#10;Content: u I {disfmarker} I wanted to comment a little more just for clarification about this" />
    <node id=" be {disfmarker} then it 's more likely to be an overlap .&#10;Speaker: PhD C&#10;Content: Is height . Yeah . This {disfmarker} this is the idea {disfmarker} the idea I {disfmarker} I {disfmarker} I had to {disfmarker} to compare the {disfmarker} the ratio of the {disfmarker} {vocalsound} the energy of the harmonics with the {disfmarker} eh , with the , eh , total energy in the spectrum and try to get a ratio to {disfmarker} to distinguish between overlapping and speech . Mmm .&#10;Speaker: Professor A&#10;Content: But you 're looking a y you 're looking at {disfmarker} Let 's take a second with this . Uh , uh , you 're looking at f at the phase derivative , um , in {disfmarker} in , uh , what domain ? I mean this is {disfmarker} this is in {disfmarker} in {disfmarker} in {disfmarker} in bands ? Or {disfmarker" />
    <node id="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." />
    <node id="marker} it {disfmarker} it 's a different problem . I mean it 's a {disfmarker} it 's a {disfmarker} it 's an interesting problem {disfmarker} I mean , we 've done stuff with numbers before , and yeah sometimes people {disfmarker} If you say s &quot; three nine eight one &quot; sometimes people will say &quot; thirty - nine eighty - one &quot; or &quot; three hundred {disfmarker} three hundred eighty - nine one &quot; , or {disfmarker} I don't think they 'd say that ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: but {disfmarker} but th&#10;Speaker: Grad B&#10;Content: Not very frequently&#10;Speaker: Professor A&#10;Content: no {disfmarker}&#10;Speaker: Grad B&#10;Content: but , {vocalsound} they certainly could .&#10;Speaker: Professor A&#10;Content: But {disfmarker} Yeah . Uh , th thirty - eight ninety - one is probably how they 'd do it .&#10;Speaker: Grad B&#10;Content: So . I mean" />
    <node id=" .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I mean if you saw a telephone number you would never see it this way .&#10;Speaker: Grad B&#10;Content: The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" />
    <node id="Speaker: PhD G&#10;Content: So you {disfmarker} um , how many digits have been transcribed now ?&#10;Speaker: Grad B&#10;Content: Four thousand lines . And each line is between one and about ten digits .&#10;Speaker: PhD G&#10;Content: Four thousand lines ?&#10;Speaker: Grad B&#10;Content: I didn't {disfmarker} I didn't compute the average . I think the average was around four or five .&#10;Speaker: Professor A&#10;Content: So that 's a couple hours of {disfmarker} of , uh , speech , probably .&#10;Speaker: PhD G&#10;Content: Wow .&#10;Speaker: Grad B&#10;Content: Yep . Yep .&#10;Speaker: Professor A&#10;Content: Which is a yeah reasonable {disfmarker} reasonable test set .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And , Jane , I do have a set of forms which I think you have copies of somewhere .&#10;Speaker: Postdoc F&#10;Content: Mm - hmm . Yeah , true" />
    <node id="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files." />
    <node id="er} for m the meetings we were thinking about three letters and three numbers for meeting I Ds . Uh , for speakers , M or F and then three numbers , For , uh {disfmarker} and , uh , that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent . Um , and then , uh , the microphone issues . We want some way of specifying , more than looking in the &quot; key &quot; file , what channel and what mike . What channel , what mike , and what broadcaster . Or {disfmarker} I don't know how to s say it . So I mean with this one it 's this particular headset with this particular transmitter w {pause} as a wireless .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Grad B&#10;Content: And you know that one is a different headset and different channel . And so we just need some naming conventions on that .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And , uh ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;" />
    <node id=" we can also rationalize some of the naming .&#10;Speaker: Postdoc F&#10;Content: I {disfmarker} I would think though that the transcribe {disfmarker} the transcripts themselves wouldn't need to have such lengthy names .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Postdoc F&#10;Content: So , I mean , you 're dealing with a different domain there , and with start and end times and all that , and channels and stuff ,&#10;Speaker: Grad B&#10;Content: Right . So the only thing that would change with that is just the directory names ,&#10;Speaker: Postdoc F&#10;Content: so , it 's a different {pause} set .&#10;Speaker: Grad B&#10;Content: I would change them to match . So instead of being MR one it would be MRM zero zero one . But I don't think that 's a big deal .&#10;Speaker: Postdoc F&#10;Content: Fine . Fine .&#10;Speaker: Grad B&#10;Content: So for {disfmarker} for m the meetings we were thinking about three letters and three numbers for meeting I Ds . Uh , for speakers , M or F and then three" />
    <node id="&#10;Speaker: Postdoc F&#10;Content: i&#10;Speaker: Grad B&#10;Content: And so if each one of those is a fixed length , the sorting becomes a lot easier .&#10;Speaker: Postdoc F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: She wanted to keep them {vocalsound} the same lengths across different meetings also . So like , the NSA meeting lengths , {comment} all filenames are gonna be the same length as the Meeting Recorder meeting names ?&#10;Speaker: Grad B&#10;Content: Yep . And as I said , the it 's {disfmarker} we just don't have that many that that 's a big deal .&#10;Speaker: PhD G&#10;Content: Cuz of digits .&#10;Speaker: Grad B&#10;Content: And so , uh , um , at some point we have to sort of take a few days off , let the transcribers have a few days off , make sure no one 's touching the data and reorganize the file structures . And when we do that we can also rationalize some of the naming .&#10;Speaker: Postdoc F&#10;Content: I {disfmarker} I would think though that" />
    <node id=" conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the people who {disfmarker} for whom it 's relevant .&#10;Speaker: Professor A&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: I could always say something about transcription . I 've been {disfmarker} {vocalsound} but {disfmarker} but {disfmarker} uh , well {disfmarker}&#10;Speaker: Professor A&#10;Content: Well if we {disfmarker} Yeah , we shouldn't add things in just to add things in . I 'm actually pretty busy today ,&#10;Speaker: Postdoc F&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: so if we can {disfmarker} {comment} {vocalsound} we {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: Professor A&#10;Content: a short meeting would be fine .&#10;Speaker: Postdoc F&#10;Content: This does sound" />
    <node id="&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And , uh ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: that 's gonna become especially important once we start changing the microphone set - up . We have some new microphones that I 'd like to start trying out , um , once I test them . And then we 'll {disfmarker} we 'll need to specify that somewhere . So I was just gonna do a fixed list of , uh , microphones and types .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So , as I said {disfmarker}&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: That sounds good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Um , {pause} {vocalsound} since we have such a short agenda list I guess I wi I will ask how {disfmarker} how are the transcriptions going ? Yeah .&#10;Speaker: Postdoc F&#10;Content: The {disfmarker} the news is that I 've" />
    <node id="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers." />
    <node id=" like training the speech - nonspeech segmentation thing .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Th - it 's necessary to have it more tightly tuned than that .&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: Postdoc F&#10;Content: And w and w and , you know , is a It would be wonderful if , uh , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , um , you know , I 've {disfmarker} th the {disfmarker} So , I I don't know exactly where that 's going at this point . But m I was experimenting with doing this by hand and I really do think that it 's wise that we 've had them start the way we have with , uh , m y working off the mixed signal , um , having the interface that doesn't require them to do the ti uh , the time bins for every single channel at a t uh , through the entire interaction .&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: Um , I did discover a couple" />
    <node id="er} that one of the reason we thought we were so much faster than {disfmarker} than , uh , the {disfmarker} the other transcription , uh , thing was that {disfmarker} that we were using the mixed {pause} file .&#10;Speaker: Postdoc F&#10;Content: Oh , yes . OK . But , um , with the mixed , when you have an overlap , you only have a {disfmarker} a choice of one start and end time for that entire overlap , which means that you 're not tightly , uh , tuning the individual parts th of that overlap by different speakers .&#10;Speaker: Professor A&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Postdoc F&#10;Content: So someone may have only said two words in that entire big chunk of overlap .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: And for purposes of {disfmarker} of , uh , things like {disfmarker} well , so things like training the speech - nonspeech segmentation thing .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content" />
    <node id="&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: Um , I did discover a couple other things by doing this though , and one of them is that , um , um , once in a while a backchannel will be overlooked by the transcriber .&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: As you might expect ,&#10;Speaker: Professor A&#10;Content: Sure .&#10;Speaker: Postdoc F&#10;Content: because when it 's a b backchannel could well happen in a very densely populated overlap . And if we 're gonna study types of overlaps , which is what I wanna do , an analysis of that , then that really does require listening {comment} to every single channel all the way through the entire {comment} length for all the different speakers . Now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . So it 's li you know , kind of wondering {disfmarker} And I think again it 's like this {disfmarker} it 's" />
    <node id="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day." />
    <node id="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." />
    <node id="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." />
    <node id=": Yeah .&#10;Speaker: Grad B&#10;Content: I thought it was smaller , that it was like four or five , wasn't it ?&#10;Speaker: Professor A&#10;Content: Well they fund {disfmarker}&#10;Speaker: PhD G&#10;Content: I {disfmarker} I 'm {disfmarker}&#10;Speaker: Professor A&#10;Content: they {disfmarker}&#10;Speaker: PhD G&#10;Content: I don't remember .&#10;Speaker: Professor A&#10;Content: yeah . I mean {disfmarker}&#10;Speaker: Grad B&#10;Content: Uh it doesn't matter , we 'll find out one way or another .&#10;Speaker: Professor A&#10;Content: Yeah . I mean last time I think they just had two categories , small and big ,&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: and this time they came up with a middle one , so it 'll {disfmarker} there 'll be more of them that they fund than {disfmarker} of the big .&#10;Speaker: PhD G&#10;Content: If we end up getting this ," />
    <node id=" . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Speaker: PhD G&#10;Content: because we didn't want to weed out much in the first phase .&#10;Speaker: PhD E&#10;Content: yeah . Yeah .&#10;Speaker: Professor A&#10;Content: Well we 'll have to see what the numbers are .&#10;Speaker: Grad B&#10;Content: Or something like that ,&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: so .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor A&#10;Content: Yeah . But they {disfmarker} they have to weed out enough so that they have enough reviewers .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: So , uh , you know , maybe they didn't r weed out as much as usual , but it 's {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {" />
    <node id=" {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {disfmarker} it 's certainly not {disfmarker} I 'm sure that it 's not down to one in two or something of what 's left .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I 'm sure it 's , you know {disfmarker}&#10;Speaker: Grad B&#10;Content: How {disfmarker} how many awards are there , do you know ?&#10;Speaker: Professor A&#10;Content: Well there 's different numbers of w awards for different size {disfmarker} They have three size grants . This one there 's , um {disfmarker} See the small ones are less than five hundred thousand total over three years and that they have a fair number of them . Um , and the large ones are , uh , boy , I forget , I think , more than , uh , more than a million and a half , more than two million or something like that . And {disfmarker} and we 're in the middle" />
    <node id="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." />
    <node id="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds." />
    <node id=" PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: and you know about , that in principle we might be able to , um , handle breaths by accessi by using cross - talk from the other things , be able that {disfmarker} in principle , maybe we could get rid of them , so maybe {disfmarker} And I was {disfmarker} I {disfmarker} I don't know , I mean we had this an and I didn't {disfmarker} couldn't get back to you ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation ,&#10;Speaker: Professor A&#10;Content: I don't know {disfmarker} think it 'd be ideal .&#10;Speaker: Postdoc F&#10;Content: cuz {disfmarker}&#10;Speaker: PhD G&#10;Content: Uh - uh .&#10;Speaker: Professor A&#10;Content: We - See , we 're {disfmarker} we 're dealing with real speech and we 're" />
    <node id=" I 'm not gonna have time to do in the next few days , but {disfmarker} {vocalsound} but I 'm {disfmarker} I 'm curious about it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Um , uh , OK .&#10;Speaker: Postdoc F&#10;Content: I I did i it did occur to me that this is {disfmarker} uh , the return to the transcription , that there 's one third thing I wanted to {disfmarker} to ex raise as a to as an issue which is , um , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , um , aside from the fact that they 're obviously very time - consuming to encode , uh , the fact that there was some {disfmarker} I had the indication from Dan Ellis in the email that I sent to you ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: and you know about , that in principle we might be able to , um" />
    <node id="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given." />
    <node id=" {disfmarker} on more {disfmarker} more higher level , uh , issues in meetings , from {disfmarker} I guess higher level from my point of view . Uh , {vocalsound} and , uh , meeting mappings , and , uh {disfmarker} so is i for {disfmarker} it was a {vocalsound} proposal for the ITR program , uh , Information Technology Research program 's part of National Science Foundation . It 's the {pause} second year of their doing , uh , these grants . They 're {disfmarker} they 're {disfmarker} a lot of them are {disfmarker} some of them anyway , are larger {disfmarker} larger grants than the usual , small NSF grants , and . So , they 're very competitive , and they have a first phase where you put in pre - proposals , and we {disfmarker} we , uh , got through that . And so th the {disfmarker} the next phase will be {disfmarker} we 'll actually be doing a larger proposal . And I 'm {disfmarker}" />
    <node id="disfmarker} when one reviewer says , uh , &quot; you know , this should be far more detailed &quot; , and the nex the next reviewer says , &quot; you know , there 's way too much detail &quot; .&#10;Speaker: Grad B&#10;Content: Yep . Or &quot; this is way too general &quot; , and the other reviewer says , &quot; this is way too specific &quot; .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: &quot; This is way too hard &quot; , &quot; way too easy &quot; .&#10;Speaker: Professor A&#10;Content: We 'll see . Maybe there 'll be something useful . And {disfmarker} and , uh {disfmarker}&#10;Speaker: Grad B&#10;Content: Well it sounded like they {disfmarker} they {disfmarker} the first gate was pretty easy . Is that right ? That they didn't reject a lot of the pre - proposals ?&#10;Speaker: Professor A&#10;Content: Do you know anything about the numbers ?&#10;Speaker" />
    <node id="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." />
    <node id="&#10;Speaker: Grad B&#10;Content: and the way it wa worked and see if it makes sense and if anyone has any comments on it .&#10;Speaker: Professor A&#10;Content: I see . And the decision here , uh , was to continue with uh the words rather than the {disfmarker} the numerics .&#10;Speaker: Grad B&#10;Content: Uh , yes , although we could switch it back . The problem was O and zero . Although we could switch it back and tell them always to say &quot; zero &quot; or always to say &quot; O &quot; .&#10;Speaker: Postdoc F&#10;Content: Oh {disfmarker}&#10;Speaker: Professor A&#10;Content: Or neither .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But it 's just two thing {disfmarker} ways that you can say it .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: Right ?&#10;Speaker: Grad B&#10;Content: Sure .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;" />
    <node id=" mail . I didn't have anything .&#10;Speaker: Grad B&#10;Content: So , does anyone have any a agenda items other than me ? I actually have one more also which is to talk about the digits .&#10;Speaker: Professor A&#10;Content: Uh , right , so {disfmarker} so I {disfmarker} I was just gonna talk briefly about the NSF ITR .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Grad B&#10;Content: Oh , great .&#10;Speaker: Professor A&#10;Content: Uh , and then , you have {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Can w&#10;Speaker: Professor A&#10;Content: I mean , I won't say much , but {disfmarker} {comment} uh , but then , uh , you said {disfmarker} wanna talk about digits ?&#10;Speaker: Grad B&#10;Content: I have a short thing about digits and then uh I wanna talk a little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the" />
    <node id="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information." />
    <node id=" thousand .&#10;Speaker: PhD G&#10;Content: Yeah , it 's {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah , I would , uh , {vocalsound} tak do the easy way ,&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: yeah .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: It {disfmarker} it 's kinda nice {disfmarker} I mean , wh who knows what studies people will be doing on {disfmarker} on speaker - dependent things&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor A&#10;Content: and so I think having {disfmarker} having it all {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: the speakers who we had is {disfmarker} is at least interesting .&#10;Speaker: PhD G&#10;Content: So you {disfmarker} um , how many digits have been transcribed now ?&#10;Speaker: Grad" />
    <node id="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set." />
    <node id=" , yeah .&#10;Speaker: Professor A&#10;Content: a short meeting would be fine .&#10;Speaker: Postdoc F&#10;Content: This does sound like we 're doing fine , yeah . That won't do .&#10;Speaker: Grad B&#10;Content: So the only thing I wanna say about digits is , we are pretty much done with the first test set . There are probably forms here and there that are marked as having been read that weren't really read . So I won't really know until I go through all the transcriber forms and extract out pieces that are in error . So I wa Uh . Two things . The first is what should we do about digits that were misread ? My opinion is , um , we should just throw them out completely , and have them read again by someone else . You know , the grouping is completely random ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: so it {disfmarker} it 's perfectly fine to put a {disfmarker} a group together again of errors and have them re - read , just to finish out the test set .&#10;Speaker: Postdoc F&#10;Content: Oh ! By {disf" />
    <node id="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated." />
    <node id=" , eh , in m {pause} i in my opinion the {disfmarker} the {disfmarker} the instantaneous frequency , the {disfmarker} the {disfmarker} the behavior , eh , was {disfmarker} th it was very interesting . Because I {disfmarker} I saw {vocalsound} eh , how the spectrum {pause} concentrate , eh ,&#10;Speaker: Professor A&#10;Content: Oh !&#10;Speaker: PhD C&#10;Content: around the {disfmarker} the harmonic . But then when I apply the {disfmarker} the rule , eh , of the {disfmarker} in the {disfmarker} {pause} the instantaneous frequency of the ne of the continuous filter in the {disfmarker} the near filter , the {disfmarker} the rule that , eh , people propose in the paper doesn't work . And I don't know why .&#10;Speaker: Professor A&#10;Content: But the instantaneous frequency , wouldn't that give you something more like the central frequency of the {disfmarker} you know , of the {disfmarker} where most of the energy" />
    <node id="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided." />
    <node id="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings." />
    <node id=" sound files , in {disfmarker} for ba both digits and for , uh , doing recognition . And Liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . So , uh , one thing she would like to have is for all the names to be the same length so that sorting is easier . Um ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: same number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . And that 's easy enough to do . And I don't think we have so many meetings that that 's a big deal just to change the names . So that means , uh , instead of calling it &quot; MR one &quot; , &quot; MR two &quot; , you 'd call it &quot; MRM zero zero one &quot; , &quot; MRM zero zero two &quot; , things like that . Just so that they 're {disfmarker} they 're all the same length .&#10;Speaker: Postdoc F&#10;Content: But , you know , when you , do things like that you can always {disfmarker} as long as you have {d" />
    <node id=" 's looking {disfmarker} that {disfmarker} that 's that guy , uh , Jeremy ? {comment} I think .&#10;Speaker: PhD C&#10;Content: Mm - hmm . &#10;Speaker: Professor A&#10;Content: Anyway , yeah that 's {disfmarker} that 's all I was gonna say is that {disfmarker} that that 's {disfmarker} you know , that 's nice and we 're sorta preceding to the next step , and , {vocalsound} it 'll mean some more work , uh , you know , in {disfmarker} in March in getting the proposal out , and then , it 's , uh , you know {disfmarker} We 'll see what happens . Uh , the last one was {disfmarker} that you had there , {comment} was about naming ?&#10;Speaker: Grad B&#10;Content: Yep . It just , uh {disfmarker} we 've been cutting up sound files , in {disfmarker} for ba both digits and for , uh , doing recognition . And Liz had some suggestions on naming and it just" />
    <node id="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques." />
    <node id="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts." />
    <node id=" Postdoc F&#10;Content: and that wouldn't be a problem to have it , uh , pause plus breath plus laugh plus sneeze ?&#10;Speaker: Professor A&#10;Content: Yeah , i You know there is {disfmarker} there 's this dynamic tension between {disfmarker} between marking absolutely everything , as you know , and {disfmarker} and {disfmarker} and marking just a little bit and counting on the statistical methods . Basically the more we can mark the better . But if there seems to be a lot of effort for a small amount of reward in some area , and this might be one like this {disfmarker} Although I {disfmarker} I {disfmarker} I 'd be interested to h get {disfmarker} get input from Liz and Andreas on this to see if they {disfmarker} Cuz they 've - they 've got lots of experience with the breaths in {disfmarker} in , uh , uh , their transcripts .&#10;Speaker: Grad B&#10;Content: They have lots of experience with breathing ?&#10;Speaker: PhD G&#10;Content: I {disfmarker}&#10;Spe" />
    <node id="Speaker: Professor A&#10;Content: We - See , we 're {disfmarker} we 're dealing with real speech and we 're trying to have it be as real as possible&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: and breaths are part of real speech .&#10;Speaker: Postdoc F&#10;Content: Well , except that these are really truly {disfmarker} I mean , ther there 's a segment in o the one I did {disfmarker} n the first one that I did for {disfmarker} i for this ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: where truly w we 're hearing you breathing like {disfmarker} as if we 're {disfmarker} you 're in our ear , you know , and it 's like {disfmarker} it 's like {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: I y i I mean , breath is natural , but not&#10;Speaker: Professor A&#10;Content: It is {" />
    <node id="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group." />
    <node id=" right .&#10;Speaker: Professor A&#10;Content: to different kind of planes . So . Um . But , um . So it 's all it 's all stuff that none none of us are doing right now , or none of us are funded for , so it 's {disfmarker} so it 's {disfmarker} it would be new .&#10;Speaker: PhD G&#10;Content: So assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ?&#10;Speaker: Professor A&#10;Content: Well there 's evenings , and there 's weekends , and {disfmarker} Uh . Yeah , there {disfmarker} there would be {disfmarker} there would be new hires , and {disfmarker} and there {disfmarker} there would be expansion , but , also , there 's always {disfmarker} {vocalsound} for everybody there 's {disfmarker} there 's always things that are dropping off , grants that are ending , or other things that are ending , so ,&#10;Speaker: PhD G&#10;Content: Right .&#10;Speaker" />
    <node id=" research {disfmarker} to continue the research on the Meeting Recorder stuff ?&#10;Speaker: Professor A&#10;Content: It 's extending the research , right ? Because the other {disfmarker}&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yeah it 's go higher level stuff than we 've been talking about for Meeting Recorder .&#10;Speaker: Professor A&#10;Content: Yeah . Yeah the other things that we have , uh , been working on with , uh , the c with Communicator {disfmarker} uh , especially with the newer things {disfmarker} with the more acoustically - oriented things are {disfmarker} are {disfmarker} are {disfmarker} are lower level . And , this is dealing with , uh , mapping on the level of {disfmarker} of , um , the conversation {disfmarker} of mapping the conversations&#10;Speaker: PhD G&#10;Content: Mm - hmm . Right , right .&#10;Speaker: Professor A&#10;Content: to different kind of planes . So . Um . But , um . So it 's all it '" />
    <node id="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question." />
    <node id="aker: Postdoc F&#10;Content: I y i I mean , breath is natural , but not&#10;Speaker: Professor A&#10;Content: It is {disfmarker} but it is if you record it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Except that we 're {disfmarker} we 're trying to mimic {disfmarker} Oh , I see what you 're saying . You 're saying that the PDA application would have {disfmarker} uh , have to cope with breath .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Well&#10;Speaker: PhD E&#10;Content: No .&#10;Speaker: Postdoc F&#10;Content: But {disfmarker}&#10;Speaker: PhD G&#10;Content: An - any application may have to .&#10;Speaker: Grad B&#10;Content: The P D A might not have to ,&#10;Speaker: PhD E&#10;Content: No {disfmarker} i&#10;Speaker: Grad B&#10;Content: but more people than just PDA users are interested in this corpus .&#10;Speaker: PhD E&#10;Content" />
    <node id="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency." />
    <node id="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck." />
    <node id=" , more than a million and a half , more than two million or something like that . And {disfmarker} and we 're in the middle {disfmarker} middle category .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: I think we 're , uh , uh , I forget what it was . But , um {disfmarker} Uh , I don't remember , but it 's {pause} pr probably along the li I {disfmarker} I could be wrong on this yeah , but probably along the lines of fifteen or {disfmarker} that they 'll fund , or twenty . I mean when they {disfmarker} Do you {disfmarker} do you know how many they funded when they f in {disfmarker} in Chuck 's , that he got last year ?&#10;Speaker: PhD G&#10;Content: I don't {disfmarker} I don't know .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: I thought it was smaller , that it was like four or five , wasn't it ?&#10;Spe" />
    <node id="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis." />
    <node id="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice." />
    <node id=" give you something more like the central frequency of the {disfmarker} you know , of the {disfmarker} where most of the energy is ? I mean , I think if you {disfmarker} Does i does it {disfmarker} Why would it correspond to pitch ?&#10;Speaker: PhD C&#10;Content: Yeah . I {disfmarker} I {disfmarker} I not sure . I {disfmarker} I {disfmarker} I try to {disfmarker} to {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: When {vocalsound} first I {disfmarker} {pause} {vocalsound} I calculate , eh , using the FFT ,&#10;Speaker: Postdoc F&#10;Content: Di - digital camera .&#10;Speaker: PhD C&#10;Content: the {disfmarker} the {disfmarker}&#10;Speaker: Grad B&#10;Content: Keep forgetting .&#10;Speaker: PhD C&#10;Content: I get the {disfmarker} {pause} the spectrum ,&#10;Speaker: Professor A&#10;" />
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target=" , the {disfmarker} the instantaneous frequency ,&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: it probably too , you can find , {vocalsound} eh , that the instantaneous frequency {vocalsound} for the continuous , eh , {vocalsound} eh {disfmarker} the output of the continuous filters are very near . And in {pause} my case {disfmarker} i in {disfmarker} equal with our signal , {vocalsound} it doesn't happened .&#10;Speaker: Professor A&#10;Content: Yeah . I 'd hafta look at that and think about it .&#10;Speaker: PhD C&#10;Content: And {disfmarker}&#10;Speaker: Professor A&#10;Content: It 's {disfmarker} it 's {disfmarker} it 's {disfmarker} I haven't worked with that either so I 'm not sure {disfmarker} The way {disfmarker} {vocalsound} the simple - minded way I suggested was what Chuck was just saying , is that you could make a {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright .">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target=" {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {disfmarker} I use these {disfmarker} these frequency , eh , the range is different , and the resolution is different .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And I observe more {disfmarker} more or less , thing like this . And the paper said that , eh , these frequencies are probably , eh , harmonics .&#10;Speaker: Professor A&#10;Content: I see . Huh .&#10;Speaker: PhD C&#10;Content: But , eh , they used , eh , a rule , eh , based in the {disfmarker} in the {disfmarker} because to {disfmarker} to calculate the instantaneous frequency , they use a Hanning window .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And , they said that , eh , if {pause} these {pause} peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh {disfmarker} w eh eh">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target=" but {disfmarker} but then , given those guesses , try , um , uh , only looking at the energy at multiples of the {disfmarker} of that frequency , and {disfmarker} and see how much of the {disfmarker} take the one that 's maximum . Call that the {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But {disfmarker}&#10;Speaker: PhD C&#10;Content: Using the energy of the {disfmarker} of the multiple of the frequency .&#10;Speaker: Professor A&#10;Content: Of all the harmonics of that . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: Do you hafta do some kind of , uh , low - pass filter before you do that ?&#10;Speaker: PhD C&#10;Content: I don't use .&#10;Speaker: PhD G&#10;Content: Or {disfmarker}&#10;Speaker: PhD C&#10;Content: But , I {disfmarker} I know many people use , eh , low - pass filter to {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target=" .&#10;Speaker: PhD C&#10;Content: I get the {disfmarker} {pause} the spectrum ,&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and I represent all the frequency .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And {disfmarker} when ou I obtained the instantaneous frequency . And I change {vocalsound} the {disfmarker} the {disfmarker} the @ @ , using the instantaneous frequency , here .&#10;Speaker: Professor A&#10;Content: Oh , so you scale {disfmarker} you s you do a {disfmarker} a scaling along that axis according to instantaneous {disfmarker}&#10;Speaker: PhD C&#10;Content: I use {disfmarker} Yeah .&#10;Speaker: Professor A&#10;Content: It 's a kinda normalization .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . Because when {disfmarker} when {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target=" PhD C&#10;Content: But , I {disfmarker} I know many people use , eh , low - pass filter to {disfmarker} to {disfmarker} to get , eh , the pitch .&#10;Speaker: Professor A&#10;Content: No . To get the pitch , yes .&#10;Speaker: PhD C&#10;Content: I don't use . To get the pitch , yes .&#10;Speaker: PhD E&#10;Content: To get the pitch , yeah .&#10;Speaker: PhD C&#10;Content: But the harmonic , no .&#10;Speaker: PhD G&#10;Content: But i But the harmonics are gonna be , uh , uh , I don't know what the right word is . Um , they 're gonna be dampened by the uh , vocal tract , right ? The response of the vocal tract .&#10;Speaker: Professor A&#10;Content: Yeah ?&#10;Speaker: PhD C&#10;Content: Yeah ?&#10;Speaker: PhD G&#10;Content: And so {disfmarker} just looking at the energy on those {disfmarker} at the harmonics , is that gonna {disfmarker} ?&#10;Speaker: Professor A&#10;Content: Well so the thing">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components.">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated.">
      <data key="d0">1</data>
    </edge>
    <edge source="The significance of the instantaneous frequency of the output of continuous filters being very near to each other, as mentioned by Speaker PhD C, is that it suggests that the filters are not effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. If the frequencies of the filtered outputs are very close together, then the filters may not be providing the desired level of separation and specificity. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , the {disfmarker} the instantaneous frequency ,&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: it probably too , you can find , {vocalsound} eh , that the instantaneous frequency {vocalsound} for the continuous , eh , {vocalsound} eh {disfmarker} the output of the continuous filters are very near . And in {pause} my case {disfmarker} i in {disfmarker} equal with our signal , {vocalsound} it doesn't happened .&#10;Speaker: Professor A&#10;Content: Yeah . I 'd hafta look at that and think about it .&#10;Speaker: PhD C&#10;Content: And {disfmarker}&#10;Speaker: Professor A&#10;Content: It 's {disfmarker} it 's {disfmarker} it 's {disfmarker} I haven't worked with that either so I 'm not sure {disfmarker} The way {disfmarker} {vocalsound} the simple - minded way I suggested was what Chuck was just saying , is that you could make a {disf" target="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , the {disfmarker} the instantaneous frequency ,&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: it probably too , you can find , {vocalsound} eh , that the instantaneous frequency {vocalsound} for the continuous , eh , {vocalsound} eh {disfmarker} the output of the continuous filters are very near . And in {pause} my case {disfmarker} i in {disfmarker} equal with our signal , {vocalsound} it doesn't happened .&#10;Speaker: Professor A&#10;Content: Yeah . I 'd hafta look at that and think about it .&#10;Speaker: PhD C&#10;Content: And {disfmarker}&#10;Speaker: Professor A&#10;Content: It 's {disfmarker} it 's {disfmarker} it 's {disfmarker} I haven't worked with that either so I 'm not sure {disfmarker} The way {disfmarker} {vocalsound} the simple - minded way I suggested was what Chuck was just saying , is that you could make a {disf" target="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor A&#10;Content: Should we do the digits ?&#10;Speaker: Grad B&#10;Content: Yep . OK .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: Mmm . Alright ." target="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {disfmarker} I use these {disfmarker} these frequency , eh , the range is different , and the resolution is different .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And I observe more {disfmarker} more or less , thing like this . And the paper said that , eh , these frequencies are probably , eh , harmonics .&#10;Speaker: Professor A&#10;Content: I see . Huh .&#10;Speaker: PhD C&#10;Content: But , eh , they used , eh , a rule , eh , based in the {disfmarker} in the {disfmarker} because to {disfmarker} to calculate the instantaneous frequency , they use a Hanning window .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And , they said that , eh , if {pause} these {pause} peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh {disfmarker} w eh eh" target="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {disfmarker} I use these {disfmarker} these frequency , eh , the range is different , and the resolution is different .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And I observe more {disfmarker} more or less , thing like this . And the paper said that , eh , these frequencies are probably , eh , harmonics .&#10;Speaker: Professor A&#10;Content: I see . Huh .&#10;Speaker: PhD C&#10;Content: But , eh , they used , eh , a rule , eh , based in the {disfmarker} in the {disfmarker} because to {disfmarker} to calculate the instantaneous frequency , they use a Hanning window .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And , they said that , eh , if {pause} these {pause} peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh {disfmarker} w eh eh" target="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: PhD C&#10;Content: I get the {disfmarker} {pause} the spectrum ,&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and I represent all the frequency .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And {disfmarker} when ou I obtained the instantaneous frequency . And I change {vocalsound} the {disfmarker} the {disfmarker} the @ @ , using the instantaneous frequency , here .&#10;Speaker: Professor A&#10;Content: Oh , so you scale {disfmarker} you s you do a {disfmarker} a scaling along that axis according to instantaneous {disfmarker}&#10;Speaker: PhD C&#10;Content: I use {disfmarker} Yeah .&#10;Speaker: Professor A&#10;Content: It 's a kinda normalization .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . Because when {disfmarker} when {disfmarker}&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: eh , when i I {" target="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time.">
      <data key="d0">1</data>
    </edge>
    <edge source=" PhD C&#10;Content: But , I {disfmarker} I know many people use , eh , low - pass filter to {disfmarker} to {disfmarker} to get , eh , the pitch .&#10;Speaker: Professor A&#10;Content: No . To get the pitch , yes .&#10;Speaker: PhD C&#10;Content: I don't use . To get the pitch , yes .&#10;Speaker: PhD E&#10;Content: To get the pitch , yeah .&#10;Speaker: PhD C&#10;Content: But the harmonic , no .&#10;Speaker: PhD G&#10;Content: But i But the harmonics are gonna be , uh , uh , I don't know what the right word is . Um , they 're gonna be dampened by the uh , vocal tract , right ? The response of the vocal tract .&#10;Speaker: Professor A&#10;Content: Yeah ?&#10;Speaker: PhD C&#10;Content: Yeah ?&#10;Speaker: PhD G&#10;Content: And so {disfmarker} just looking at the energy on those {disfmarker} at the harmonics , is that gonna {disfmarker} ?&#10;Speaker: Professor A&#10;Content: Well so the thing" target="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target="isfmarker} eh , FTT . to FFT to {disfmarker} to obtain the {disfmarker} or to study the harmonics from {disfmarker} from the spectrum directly ,&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and to study the energy and the multiples of&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: frequency . And another {disfmarker} another algorithm I have is the {disfmarker} in the {pause} instantaneous frequency , based on {disfmarker} on {disfmarker} on the FFT to {disfmarker} to {disfmarker} to calculate the {disfmarker} the phase derivate in the time . Eh , uh n the d I mean I {disfmarker} I have two {disfmarker} two algorithms .&#10;Speaker: Professor A&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: But , eh , in m {pause} i in my opinion the {disfmarker} the {disfmarker} the instantaneous frequency , the {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target="} No {disfmarker} No . No .&#10;Speaker: PhD G&#10;Content: And then hypothesize a new fundamental and get the energy {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah , that 's wh&#10;Speaker: PhD C&#10;Content: No . I {disfmarker} I {disfmarker} I {disfmarker} I don't proth process the {disfmarker} the fundamental . I {disfmarker} {vocalsound} I , ehm {disfmarker} I calculate the {disfmarker} the phase derivate using the FFT .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And {disfmarker} The algorithm said that , eh , {vocalsound} if you {disfmarker} if you change the {disfmarker} the {disfmarker} {vocalsound} the , eh , nnn {disfmarker} the X - the frequency &quot; X &quot; , eh , using the in the instantaneous frequency , you can find , eh , how , eh , in several frequencies that proba">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target=" this is in {disfmarker} in {disfmarker} in {disfmarker} in bands ? Or {disfmarker} or {disfmarker}&#10;Speaker: PhD C&#10;Content: No , no , no .&#10;Speaker: Professor A&#10;Content: Just {disfmarker} just overall {disfmarker}&#10;Speaker: PhD C&#10;Content: It 's a {disfmarker} it 's a {disfmarker} o i w the band {disfmarker} the band is , eh , from zero to {disfmarker} to four kilohertz . And I {disfmarker} I ot I {disfmarker}&#10;Speaker: Professor A&#10;Content: And you just take the instantaneous frequency ?&#10;Speaker: PhD C&#10;Content: Yeah . I u m t I {disfmarker} I used two m two method {disfmarker} two methods . Eh , one , eh , based on the F {disfmarker} eh , FTT . to FFT to {disfmarker} to obtain the {disfmarker} or to study the">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by the first speaker (Professor A) is not explicitly stated in the transcript. However, they seem to be supportive of the discussion about studying energy and multiples of frequency from a signal or spectrum.&#10;2. Speaker C calculates the phase derivative using the Fast Fourier Transform (FFT) to find the probability of several frequencies using the instantaneous frequency through the following steps:&#10;* Speaker C uses an algorithm that calculates the instantaneous frequency by analyzing the FFT of a signal. The FFT is a method to compute the Discrete Fourier Transform (DFT), which transforms a signal from the time domain to the frequency domain, enabling analysis of its frequency components.&#10;* Using this algorithm, Speaker C calculates the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT. The paper they mention suggests that if one changes the X frequency (instantaneous frequency) using the instantaneous frequency calculated with the FFT, it's possible to find how several frequencies are probably harmonics.&#10;* Speaker C represents all the frequency range and observes more or less significant features when using the instantaneous frequency algorithm. The observed frequencies are then hypothesized to be harmonics.&#10;* They also follow a rule based on the signal bandwidth since, for calculating the instantaneous frequency, they use a Hanning window. This window function reduces spectral leakage in the frequency domain by minimizing discontinuities at the edges of the signal, resulting in more accurate frequency estimation and phase calculation.&#10;* When Speaker C obtains the instantaneous frequency, they scale or normalize their representation along the time axis based on that instantaneous frequency value. This step can help to visualize the significance of frequency components better by adjusting them proportionally to the signal's dominant frequency at each moment in time." target="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.">
      <data key="d0">1</data>
    </edge>
    <edge source="isfmarker} eh , FTT . to FFT to {disfmarker} to obtain the {disfmarker} or to study the harmonics from {disfmarker} from the spectrum directly ,&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: and to study the energy and the multiples of&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: frequency . And another {disfmarker} another algorithm I have is the {disfmarker} in the {pause} instantaneous frequency , based on {disfmarker} on {disfmarker} on the FFT to {disfmarker} to {disfmarker} to calculate the {disfmarker} the phase derivate in the time . Eh , uh n the d I mean I {disfmarker} I have two {disfmarker} two algorithms .&#10;Speaker: Professor A&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: But , eh , in m {pause} i in my opinion the {disfmarker} the {disfmarker} the instantaneous frequency , the {" target="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.">
      <data key="d0">1</data>
    </edge>
    <edge source="} No {disfmarker} No . No .&#10;Speaker: PhD G&#10;Content: And then hypothesize a new fundamental and get the energy {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah , that 's wh&#10;Speaker: PhD C&#10;Content: No . I {disfmarker} I {disfmarker} I {disfmarker} I don't proth process the {disfmarker} the fundamental . I {disfmarker} {vocalsound} I , ehm {disfmarker} I calculate the {disfmarker} the phase derivate using the FFT .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: And {disfmarker} The algorithm said that , eh , {vocalsound} if you {disfmarker} if you change the {disfmarker} the {disfmarker} {vocalsound} the , eh , nnn {disfmarker} the X - the frequency &quot; X &quot; , eh , using the in the instantaneous frequency , you can find , eh , how , eh , in several frequencies that proba" target="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target=": Postdoc F&#10;Content: That 's what they 've been doing . So , within an overlap segment , they {disfmarker} they do this .&#10;Speaker: PhD G&#10;Content: Right . But {disfmarker} Right . But if there 's a big hunk of speech , let 's say on Morgan 's mike where he 's not talking at all , um , don't {disfmarker} don't worry about that .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: So what we 're saying is , there 's no guarantee that , um {disfmarker} So for the chunks that are transcribed , everything 's transcribed . But outside of those boundaries , there could have been stuff that wasn't transcribed . So you just {disfmarker} somebody can't rely on that data and say &quot; that 's perfectly clean data &quot; . Uh {disfmarker} do you see what I 'm saying ?&#10;Speaker: Postdoc F&#10;Content: Yeah , you 're saying it 's {disfmarker} uncharted territory .&#10;Speaker: PhD G&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="} this is actual stuff that we {disfmarker} we wanna work with .&#10;Speaker: Postdoc F&#10;Content: Well this is in very interesting&#10;Speaker: Professor A&#10;Content: So .&#10;Speaker: Postdoc F&#10;Content: because i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in {disfmarker} in discourse and linguistic research , what counts is what 's communit communicative .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: And {disfmarker} breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: and the idea is that the transcripts will {disfmarker} that {disfmarker} get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target=" are the transcriptions going ? Yeah .&#10;Speaker: Postdoc F&#10;Content: The {disfmarker} the news is that I 've {disfmarker} I uh {disfmarker} s So {disfmarker} in s um {disfmarker} So I 've switched to {disfmarker} Start my new sentence . I {disfmarker} I switched to doing the channel - by - channel transcriptions to provide , uh , the {disfmarker} uh , tighter time bins for {disfmarker} partly for use in Thilo 's work and also it 's of relevance to other people in the project . And , um , I discovered in the process a couple of {disfmarker} of interesting things , which , um , one of them is that , um , it seems that there are time lags involved in doing this , uh , uh , using an interface that has so much more complexity to it . And I {disfmarker} and I wanted to maybe ask , uh , Chuck to help me with some of the questions of efficiency . Maybe {disfmarker} I was thinking maybe the best way to do this in">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="disfmarker} let 's think about the practicalities of how we get to that master copy with reference to breaths . So what I would {disfmarker} r r what I would wonder is would it be possible to encode those automatically ? Could we get a breath detector ?&#10;Speaker: Grad B&#10;Content: Oh , just to save the transcribers time .&#10;Speaker: Postdoc F&#10;Content: Well , I mean , you just have no idea . I mean , if you 're getting a breath several times every minute ,&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: and just simply the keystrokes it takes to negotiate , to put the boundaries in , to {disfmarker} to type it in , i it 's just a huge amount of time .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: Oops .&#10;Speaker: Professor A&#10;Content: Wh - what {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: And you wanna be sure it 's used ,">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target=" Postdoc F&#10;Content: just so that they 're {disfmarker} they 're not being overlooked because of that , and count on accuracy during the sparser phases .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Cuz there are large s spaces of the {disfmarker} That 's a good point . There are large spaces where there 's no overlap at all . Someone 's giving a presentation ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: or whatever . That 's {disfmarker} that 's a good {disfmarker} that 's a good thought . And , um , let 's see , there was one other thing I was gonna say . I {disfmarker} I think it 's really interesting data to work with , I have to say , it 's very enjoyable . I really , not {disfmarker} not a problem spending time with these data . Really interesting . And not just because I 'm in there . No , it 's real interesting .&#10;Speaker: Professor A&#10;Content: Uh , well I think it">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: And you wanna be sure it 's used , and you wanna be sure it 's done as efficiently as possible , and if it can be done automatically , that would be ideal .&#10;Speaker: Professor A&#10;Content: what if you put it in but didn't put the boundaries ?&#10;Speaker: Postdoc F&#10;Content: Well , but {disfmarker}&#10;Speaker: Professor A&#10;Content: So you just know it 's between these other things ,&#10;Speaker: Postdoc F&#10;Content: Well , OK . So now there 's {disfmarker} there 's another {disfmarker} another possibility&#10;Speaker: Professor A&#10;Content: right ?&#10;Speaker: Postdoc F&#10;Content: which is , um , the time boundaries could mark off words {comment} from nonwords . And that would be extremely time - effective , if that 's sufficient .&#10;Speaker: Professor A&#10;Content: Yeah I mean I 'm think if it 's too {disfmarker} if it 's too hard for us to annotate the breaths per se ,">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is.">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="The limitations of the transcribed data being used include the fact that there might be portions of the audio recording that were not transcribed. This could be due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data." target="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Postdoc F&#10;Content: That 's what they 've been doing . So , within an overlap segment , they {disfmarker} they do this .&#10;Speaker: PhD G&#10;Content: Right . But {disfmarker} Right . But if there 's a big hunk of speech , let 's say on Morgan 's mike where he 's not talking at all , um , don't {disfmarker} don't worry about that .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: So what we 're saying is , there 's no guarantee that , um {disfmarker} So for the chunks that are transcribed , everything 's transcribed . But outside of those boundaries , there could have been stuff that wasn't transcribed . So you just {disfmarker} somebody can't rely on that data and say &quot; that 's perfectly clean data &quot; . Uh {disfmarker} do you see what I 'm saying ?&#10;Speaker: Postdoc F&#10;Content: Yeah , you 're saying it 's {disfmarker} uncharted territory .&#10;Speaker: PhD G&#10;Content" target="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is.">
      <data key="d0">1</data>
    </edge>
    <edge source="} this is actual stuff that we {disfmarker} we wanna work with .&#10;Speaker: Postdoc F&#10;Content: Well this is in very interesting&#10;Speaker: Professor A&#10;Content: So .&#10;Speaker: Postdoc F&#10;Content: because i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in {disfmarker} in discourse and linguistic research , what counts is what 's communit communicative .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: And {disfmarker} breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: and the idea is that the transcripts will {disfmarker} that {disfmarker} get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses .&#10;Speaker" target="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers.">
      <data key="d0">1</data>
    </edge>
    <edge source="} this is actual stuff that we {disfmarker} we wanna work with .&#10;Speaker: Postdoc F&#10;Content: Well this is in very interesting&#10;Speaker: Professor A&#10;Content: So .&#10;Speaker: Postdoc F&#10;Content: because i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in {disfmarker} in discourse and linguistic research , what counts is what 's communit communicative .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: And {disfmarker} breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: and the idea is that the transcripts will {disfmarker} that {disfmarker} get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses .&#10;Speaker" target="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Postdoc F&#10;Content: just so that they 're {disfmarker} they 're not being overlooked because of that , and count on accuracy during the sparser phases .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Cuz there are large s spaces of the {disfmarker} That 's a good point . There are large spaces where there 's no overlap at all . Someone 's giving a presentation ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: or whatever . That 's {disfmarker} that 's a good {disfmarker} that 's a good thought . And , um , let 's see , there was one other thing I was gonna say . I {disfmarker} I think it 's really interesting data to work with , I have to say , it 's very enjoyable . I really , not {disfmarker} not a problem spending time with these data . Really interesting . And not just because I 'm in there . No , it 's real interesting .&#10;Speaker: Professor A&#10;Content: Uh , well I think it" target="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="Speaker: Professor A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: OK we 're on and we seem to be working .&#10;Speaker: PhD C&#10;Content: Yes .&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: We didn't crash {disfmarker} we 're not crashing anymore&#10;Speaker: PhD C&#10;Content: One , two , three , four , f&#10;Speaker: Grad B&#10;Content: and it really bothers me .&#10;Speaker: Professor A&#10;Content: Yeah ?&#10;Speaker: PhD C&#10;Content: No crashing .&#10;Speaker: PhD G&#10;Content: I do . I crashed when I started this morning .&#10;Speaker: Grad B&#10;Content: You crashed {disfmarker} crashed this morning ? I did not crash this morning .&#10;Speaker: PhD C&#10;Content: Yeah ?&#10;Speaker: Professor A&#10;Content: Oh ! Well maybe it 's just , you know , how many t u u u u how many times you crash in a day .&#10;Speaker: PhD G&#10;Content: Really ? Yeah . Maybe , yeah .&#10;Speaker: Professor A&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target=" you crash in a day .&#10;Speaker: PhD G&#10;Content: Really ? Yeah . Maybe , yeah .&#10;Speaker: Professor A&#10;Content: First time {disfmarker} first time in the day , you know .&#10;Speaker: PhD G&#10;Content: Or maybe it 's once you 've {pause} done enough meetings {comment} it won't crash on you anymore .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: No ?&#10;Speaker: Postdoc F&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: It 's a matter of experience .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Self - learning , yeah .&#10;Speaker: Professor A&#10;Content: That 's {disfmarker} that 's great .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Uh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Do we have an agenda ? Liz {disfmarker} Liz and Andreas can't">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Do we have an agenda ? Liz {disfmarker} Liz and Andreas can't sh can't {disfmarker} uh , can't come .&#10;Speaker: Grad B&#10;Content: I do .&#10;Speaker: Professor A&#10;Content: So , they won't be here .&#10;Speaker: Grad B&#10;Content: I have agenda and it 's all me .&#10;Speaker: PhD G&#10;Content: Did {disfmarker}&#10;Speaker: Grad B&#10;Content: Cuz no one sent me anything else .&#10;Speaker: PhD G&#10;Content: Did they send , uh , the messages to you about the meeting today ?&#10;Speaker: Grad B&#10;Content: I have no idea but I just got it a few minutes ago .&#10;Speaker: PhD G&#10;Content: Oh .&#10;Speaker: Grad B&#10;Content: Right when you were in my office it arrived .&#10;Speaker: PhD G&#10;Content: Oh . OK , cuz I checked my mail . I didn't have anything .&#10;Speaker: Grad B&#10;Content: So , does anyone have any a agenda items other than me ? I actually">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="Speaker: PhD G&#10;Content: Tomorrow .&#10;Speaker: Professor A&#10;Content: Tomorrow . March second , I said .&#10;Speaker: PhD E&#10;Content: Tomorrow ?&#10;Speaker: Grad B&#10;Content: I 've been a day off all week .&#10;Speaker: PhD C&#10;Content: Tomorrow .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: I guess that 's a good thing cuz that way I got my papers done early .&#10;Speaker: PhD G&#10;Content: It would be interesting {disfmarker}&#10;Speaker: Professor A&#10;Content: So that 's amazing you showed up at this meeting !&#10;Speaker: Grad B&#10;Content: It is . It is actually quite amazing .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: It 'll be interesting to see the reviewer 's comments .&#10;Speaker: Professor A&#10;Content: Yeah . Yeah . My favorite is was when {disfmarker} when {disfmarker} when one reviewer says , uh , &quot; you know , this should be far more detailed &quot; , and the nex the next reviewer says">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target=" they didn't reject a lot of the pre - proposals ?&#10;Speaker: Professor A&#10;Content: Do you know anything about the numbers ?&#10;Speaker: Grad B&#10;Content: No . Just {disfmarker} just th&#10;Speaker: PhD G&#10;Content: It 's just from his message it sounded like that .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah . I said something , yeah .&#10;Speaker: PhD G&#10;Content: Gary Strong 's {disfmarker}&#10;Speaker: Professor A&#10;Content: I&#10;Speaker: PhD G&#10;Content: there was a sentence at the end of one of his paragraphs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: I {disfmarker}&#10;Speaker: Professor A&#10;Content: I should go back and look . I didn't {disfmarker} I don't think that 's true .&#10;Speaker: Grad B&#10;Content: Yeah , OK .&#10;Speaker: PhD G&#10;Content: Mmm . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoughts on the concept of a system crashing during the day:&#10;The speakers generally agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system and their level of experience. PhD G mentioned crashing once this morning, to which Grad B replied that they did not experience any crashes. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience.&#10;&#10;2. Do they have an agenda for their discussion?&#10;The group was discussing an upcoming meeting, but there were some confusions regarding whether everyone had received the notification and agenda for the meeting. Grad B mentioned having an agenda, and when asked, no one else offered any additional items. However, it seemed that there might have been some miscommunication about the date of the meeting, as Professor A pointed out that Liz and Andreas would not be able to attend because they &quot;can't sh can't.&quot; Later in the conversation, Grad B confirmed that she was prepared to lead the meeting with her own agenda since no one else had provided any items." target="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Professor A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: OK we 're on and we seem to be working .&#10;Speaker: PhD C&#10;Content: Yes .&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: We didn't crash {disfmarker} we 're not crashing anymore&#10;Speaker: PhD C&#10;Content: One , two , three , four , f&#10;Speaker: Grad B&#10;Content: and it really bothers me .&#10;Speaker: Professor A&#10;Content: Yeah ?&#10;Speaker: PhD C&#10;Content: No crashing .&#10;Speaker: PhD G&#10;Content: I do . I crashed when I started this morning .&#10;Speaker: Grad B&#10;Content: You crashed {disfmarker} crashed this morning ? I did not crash this morning .&#10;Speaker: PhD C&#10;Content: Yeah ?&#10;Speaker: Professor A&#10;Content: Oh ! Well maybe it 's just , you know , how many t u u u u how many times you crash in a day .&#10;Speaker: PhD G&#10;Content: Really ? Yeah . Maybe , yeah .&#10;Speaker: Professor A&#10;Content:" target="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day.">
      <data key="d0">1</data>
    </edge>
    <edge source=" you crash in a day .&#10;Speaker: PhD G&#10;Content: Really ? Yeah . Maybe , yeah .&#10;Speaker: Professor A&#10;Content: First time {disfmarker} first time in the day , you know .&#10;Speaker: PhD G&#10;Content: Or maybe it 's once you 've {pause} done enough meetings {comment} it won't crash on you anymore .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: No ?&#10;Speaker: Postdoc F&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: It 's a matter of experience .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Self - learning , yeah .&#10;Speaker: Professor A&#10;Content: That 's {disfmarker} that 's great .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Uh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Do we have an agenda ? Liz {disfmarker} Liz and Andreas can't" target="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day.">
      <data key="d0">1</data>
    </edge>
    <edge source=" they didn't reject a lot of the pre - proposals ?&#10;Speaker: Professor A&#10;Content: Do you know anything about the numbers ?&#10;Speaker: Grad B&#10;Content: No . Just {disfmarker} just th&#10;Speaker: PhD G&#10;Content: It 's just from his message it sounded like that .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah . I said something , yeah .&#10;Speaker: PhD G&#10;Content: Gary Strong 's {disfmarker}&#10;Speaker: Professor A&#10;Content: I&#10;Speaker: PhD G&#10;Content: there was a sentence at the end of one of his paragraphs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: I {disfmarker}&#10;Speaker: Professor A&#10;Content: I should go back and look . I didn't {disfmarker} I don't think that 's true .&#10;Speaker: Grad B&#10;Content: Yeah , OK .&#10;Speaker: PhD G&#10;Content: Mmm . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Spe" target="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source=" they didn't reject a lot of the pre - proposals ?&#10;Speaker: Professor A&#10;Content: Do you know anything about the numbers ?&#10;Speaker: Grad B&#10;Content: No . Just {disfmarker} just th&#10;Speaker: PhD G&#10;Content: It 's just from his message it sounded like that .&#10;Speaker: PhD E&#10;Content: Yeah . Yeah . I said something , yeah .&#10;Speaker: PhD G&#10;Content: Gary Strong 's {disfmarker}&#10;Speaker: Professor A&#10;Content: I&#10;Speaker: PhD G&#10;Content: there was a sentence at the end of one of his paragraphs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: I {disfmarker}&#10;Speaker: Professor A&#10;Content: I should go back and look . I didn't {disfmarker} I don't think that 's true .&#10;Speaker: Grad B&#10;Content: Yeah , OK .&#10;Speaker: PhD G&#10;Content: Mmm . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Spe" target="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="isfmarker} at the harmonics , is that gonna {disfmarker} ?&#10;Speaker: Professor A&#10;Content: Well so the thing is that the {disfmarker} This is for , uh , a , um {disfmarker}&#10;Speaker: PhD G&#10;Content: I m what you 'd like to do is get rid of the effect of the vocal tract . Right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: And just look at the {disfmarker} at {disfmarker} at the signal coming out of the glottis .&#10;Speaker: Professor A&#10;Content: Yeah . Uh , well , yeah that 'd be good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But , uh {disfmarker} but I {disfmarker} but {disfmarker} {vocalsound} but I don't know that you need to {disfmarker}&#10;Speaker: Grad B&#10;Content: Open wide !&#10;Speaker: Professor A&#10;Content: but I don't need you {disfmarker} know">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target=" {vocalsound} I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be {pause} primarily a low frequency phenomenon . And if you looked at the low frequencies , yes the higher frequencies are gonna {disfmarker} there 's gonna be a spectral slope . The higher frequencies will be lower energy . But so what . I mean {disfmarker} {vocalsound} that 's {disfmarker} that 's w&#10;Speaker: PhD C&#10;Content: I will prepare for the next week eh , all my results about the harmonicity and {pause} will {disfmarker} will try to come in and to discuss here , because , eh , I haven't enough feeling to {disfmarker} {vocalsound} to u {vocalsound} many time to {disfmarker} {vocalsound} to understand what happened with the {disfmarker} with , eh , so many peaks , eh , eh , and {vocalsound} I {disfmarker} I see the harmonics there many time but , eh , {vocalsound} there are a lot of peaks">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target=" {disfmarker} the {disfmarker} the reason we still complain about it is because is {disfmarker} when {disfmarker} when you have more realistic conditions then {disfmarker} then things fall apart .&#10;Speaker: Postdoc F&#10;Content: OK , fair enough . I guess , um , I {disfmarker} uh , what I was wondering is what {disfmarker} what {disfmarker} at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to {disfmarker}&#10;Speaker: Professor A&#10;Content: But that 's a research question , you know ? And so {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Yeah , well , see and that 's">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants in the discussion are trying to analyze the pure vibrations of the vocal cords (glottis) without the influence of the vocal tract. The vocal tract is known to affect the signal by dampening higher frequency harmonics, which can make it difficult to accurately study the frequency components of the original vibration at the glottis. By getting rid of the effect of the vocal tract, the researchers aim to isolate and examine the vibrations at the glottis more precisely, allowing them to better understand the properties of the voice spectra. This approach can help in identifying specific frequency bands or features within a signal and potentially lead to improved voice analysis techniques." target="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {vocalsound} I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be {pause} primarily a low frequency phenomenon . And if you looked at the low frequencies , yes the higher frequencies are gonna {disfmarker} there 's gonna be a spectral slope . The higher frequencies will be lower energy . But so what . I mean {disfmarker} {vocalsound} that 's {disfmarker} that 's w&#10;Speaker: PhD C&#10;Content: I will prepare for the next week eh , all my results about the harmonicity and {pause} will {disfmarker} will try to come in and to discuss here , because , eh , I haven't enough feeling to {disfmarker} {vocalsound} to u {vocalsound} many time to {disfmarker} {vocalsound} to understand what happened with the {disfmarker} with , eh , so many peaks , eh , eh , and {vocalsound} I {disfmarker} I see the harmonics there many time but , eh , {vocalsound} there are a lot of peaks" target="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} the {disfmarker} the reason we still complain about it is because is {disfmarker} when {disfmarker} when you have more realistic conditions then {disfmarker} then things fall apart .&#10;Speaker: Postdoc F&#10;Content: OK , fair enough . I guess , um , I {disfmarker} uh , what I was wondering is what {disfmarker} what {disfmarker} at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to {disfmarker}&#10;Speaker: Professor A&#10;Content: But that 's a research question , you know ? And so {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Yeah , well , see and that 's" target="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} the {disfmarker} the reason we still complain about it is because is {disfmarker} when {disfmarker} when you have more realistic conditions then {disfmarker} then things fall apart .&#10;Speaker: Postdoc F&#10;Content: OK , fair enough . I guess , um , I {disfmarker} uh , what I was wondering is what {disfmarker} what {disfmarker} at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to {disfmarker}&#10;Speaker: Professor A&#10;Content: But that 's a research question , you know ? And so {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Yeah , well , see and that 's" target="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is." target=" errors and have them re - read , just to finish out the test set .&#10;Speaker: Postdoc F&#10;Content: Oh ! By {disfmarker} throw them out completely ?&#10;Speaker: Grad B&#10;Content: Um , the other thing you could do is change the transcript to match what they really said . So those are {disfmarker} those are the two options .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: But there 's often things where people do false starts . I know I 've done it , where I say {disfmarker} say a {disfmarker}&#10;Speaker: Grad B&#10;Content: What the transcribers did with that is if they did a correction , and they eventually did read the right string , {comment} you extract the right string .&#10;Speaker: PhD G&#10;Content: Oh , you 're talking about where they completely read the wrong string and didn't correct it ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yeah . And didn't notice . Which happens">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is." target=" correct it ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yeah . And didn't notice . Which happens in a few places .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD G&#10;Content: Ah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So {disfmarker} so {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Well , and s and you 're talking string - wise , you 're not talking about the entire page ?&#10;Speaker: Grad B&#10;Content: Correct .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: I get it .&#10;Speaker: Grad B&#10;Content: And so the {disfmarker} the two options are change the transcript to match what they really said , but then {disfmarker} but then the transcript isn't the Aurora test set anymore . I don't think that really matters because the conditions are so different . And that would be a little easier .&#10;Speaker: PhD G&#10;Content: Well how many are {disfmarker} how">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is." target=" are so different . And that would be a little easier .&#10;Speaker: PhD G&#10;Content: Well how many are {disfmarker} how {disfmarker} how often does that happen ?&#10;Speaker: Grad B&#10;Content: Mmm , five or six times .&#10;Speaker: PhD G&#10;Content: Oh , so it 's not very much .&#10;Speaker: Grad B&#10;Content: No , it 's not much at all .&#10;Speaker: PhD G&#10;Content: Seems like we should just change the transcripts&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: to match .&#10;Speaker: Professor A&#10;Content: Yeah , it 's five or six times out of {pause} thousands ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Four thousand .&#10;Speaker: Professor A&#10;Content: Four thousand ?&#10;Speaker: PhD C&#10;Content: Four thous Ah ! Four thousand .&#10;Speaker: PhD G&#10;Content: Yeah , it 's {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is." target="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two options for addressing inconsistencies in the transcript are:&#10;&#09;* Throw out the problematic portions completely.&#10;&#09;* Change the transcript to match what was actually said during the recording, correcting any errors or discrepancies.&#10;2. The potential implications of changing the transcript to match what was actually said include:&#10;&#09;* If the changes are made, the altered transcript will no longer be considered part of the original Aurora test set. However, since the conditions under which the data was collected and transcribed were significantly different, this may not pose a major issue.&#10;&#09;* Making corrections would make the transcript more accurate, but it could also introduce subjectivity in interpreting what was said during the recording, especially if there are multiple speakers or overlapping speech.&#10;&#09;* It's important to note that only five or six instances of significant discrepancies were identified among the four thousand transcribed segments, which is not a large proportion, suggesting that most of the transcript is accurate and reliable as it is." target="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source=" are so different . And that would be a little easier .&#10;Speaker: PhD G&#10;Content: Well how many are {disfmarker} how {disfmarker} how often does that happen ?&#10;Speaker: Grad B&#10;Content: Mmm , five or six times .&#10;Speaker: PhD G&#10;Content: Oh , so it 's not very much .&#10;Speaker: Grad B&#10;Content: No , it 's not much at all .&#10;Speaker: PhD G&#10;Content: Seems like we should just change the transcripts&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: to match .&#10;Speaker: Professor A&#10;Content: Yeah , it 's five or six times out of {pause} thousands ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Four thousand .&#10;Speaker: Professor A&#10;Content: Four thousand ?&#10;Speaker: PhD C&#10;Content: Four thous Ah ! Four thousand .&#10;Speaker: PhD G&#10;Content: Yeah , it 's {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah" target="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target="vocalsound} my impression was that the best way to do it was however you {disfmarker} You 've used instantaneous frequency , whatever . {comment} However you 've come up {disfmarker} you {disfmarker} with your candidates , you wanna see how much of the energy is in that&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor A&#10;Content: as coppo as opposed to all of the {disfmarker} all {disfmarker} the total energy . And , um , if it 's voiced , I guess {disfmarker} so {disfmarker} so y I think maybe you do need a voiced - unvoiced determination too . But if it 's voiced ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: um , and the , uh {disfmarker} e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be {disfmarker} then it 's more likely to be an overlap .&#10;Speaker: PhD C&#10;Content: Is height . Yeah .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target=" um {disfmarker} yeah I guess you could {disfmarker} I guess {disfmarker} yeah you 're {disfmarker} so you 're not distinguished between voiced and unvoiced , so {disfmarker} so , i if you don't {disfmarker} if you don't care about that {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: See , if you also wanna {vocalsound} just determine {disfmarker} if you also wanna determine whether it 's unvoiced , {vocalsound} then I think you want to {pause} look {disfmarker} look at high frequencies also , because the f the fact that there 's more energy in the high frequencies is gonna be an ob sort of obvious cue that it 's unvoiced .&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But , i i uh {disfmarker} {vocalsound} I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target="doc F&#10;Content: Yeah , you 're saying it 's {disfmarker} uncharted territory .&#10;Speaker: PhD G&#10;Content: So I would say don't tell them to transcribe anything that 's outside of a grouping of words .&#10;Speaker: Professor A&#10;Content: That sounds like a reasonable {disfmarker} reasonable compromise .&#10;Speaker: PhD E&#10;Content: Yeah , and that 's {disfmarker} that {disfmarker} that quite co corresponds to the way I {disfmarker} I try to train the speech - nonspeech detector , as I really try to {disfmarker} not to detect those breaths which are not within a speech chunk but with {disfmarker} which are just in {disfmarker} in a silence region .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: And they {disfmarker} so they hopefully won't be marked in {disfmarker} in those channel - specific files .&#10;Speaker: Professor A&#10;Content: u I {disfmarker} I wanted to comment a little more just for clarification about this">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target=" be {disfmarker} then it 's more likely to be an overlap .&#10;Speaker: PhD C&#10;Content: Is height . Yeah . This {disfmarker} this is the idea {disfmarker} the idea I {disfmarker} I {disfmarker} I had to {disfmarker} to compare the {disfmarker} the ratio of the {disfmarker} {vocalsound} the energy of the harmonics with the {disfmarker} eh , with the , eh , total energy in the spectrum and try to get a ratio to {disfmarker} to distinguish between overlapping and speech . Mmm .&#10;Speaker: Professor A&#10;Content: But you 're looking a y you 're looking at {disfmarker} Let 's take a second with this . Uh , uh , you 're looking at f at the phase derivative , um , in {disfmarker} in , uh , what domain ? I mean this is {disfmarker} this is in {disfmarker} in {disfmarker} in {disfmarker} in bands ? Or {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the recommended method for differentiating between audio signals of speech and overlapping sounds involves examining the energy distribution of specific frequency bands or features within the signal. This can be done by analyzing the ratio of the energy of the harmonics to the total energy in the spectrum. The participants also mention the possibility of requiring a voiced-unvoiced determination, which could help in distinguishing between speech and high-frequency sounds that are more likely to be unvoiced. Additionally, looking at the phase derivative in specific bands may provide further information to differentiate between speech and overlapping sounds." target="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice.">
      <data key="d0">1</data>
    </edge>
    <edge source="doc F&#10;Content: Yeah , you 're saying it 's {disfmarker} uncharted territory .&#10;Speaker: PhD G&#10;Content: So I would say don't tell them to transcribe anything that 's outside of a grouping of words .&#10;Speaker: Professor A&#10;Content: That sounds like a reasonable {disfmarker} reasonable compromise .&#10;Speaker: PhD E&#10;Content: Yeah , and that 's {disfmarker} that {disfmarker} that quite co corresponds to the way I {disfmarker} I try to train the speech - nonspeech detector , as I really try to {disfmarker} not to detect those breaths which are not within a speech chunk but with {disfmarker} which are just in {disfmarker} in a silence region .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: And they {disfmarker} so they hopefully won't be marked in {disfmarker} in those channel - specific files .&#10;Speaker: Professor A&#10;Content: u I {disfmarker} I wanted to comment a little more just for clarification about this" target="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="marker} it {disfmarker} it 's a different problem . I mean it 's a {disfmarker} it 's a {disfmarker} it 's an interesting problem {disfmarker} I mean , we 've done stuff with numbers before , and yeah sometimes people {disfmarker} If you say s &quot; three nine eight one &quot; sometimes people will say &quot; thirty - nine eighty - one &quot; or &quot; three hundred {disfmarker} three hundred eighty - nine one &quot; , or {disfmarker} I don't think they 'd say that ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: but {disfmarker} but th&#10;Speaker: Grad B&#10;Content: Not very frequently&#10;Speaker: Professor A&#10;Content: no {disfmarker}&#10;Speaker: Grad B&#10;Content: but , {vocalsound} they certainly could .&#10;Speaker: Professor A&#10;Content: But {disfmarker} Yeah . Uh , th thirty - eight ninety - one is probably how they 'd do it .&#10;Speaker: Grad B&#10;Content: So . I mean">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target=" .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I mean if you saw a telephone number you would never see it this way .&#10;Speaker: Grad B&#10;Content: The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="Speaker: PhD G&#10;Content: So you {disfmarker} um , how many digits have been transcribed now ?&#10;Speaker: Grad B&#10;Content: Four thousand lines . And each line is between one and about ten digits .&#10;Speaker: PhD G&#10;Content: Four thousand lines ?&#10;Speaker: Grad B&#10;Content: I didn't {disfmarker} I didn't compute the average . I think the average was around four or five .&#10;Speaker: Professor A&#10;Content: So that 's a couple hours of {disfmarker} of , uh , speech , probably .&#10;Speaker: PhD G&#10;Content: Wow .&#10;Speaker: Grad B&#10;Content: Yep . Yep .&#10;Speaker: Professor A&#10;Content: Which is a yeah reasonable {disfmarker} reasonable test set .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And , Jane , I do have a set of forms which I think you have copies of somewhere .&#10;Speaker: Postdoc F&#10;Content: Mm - hmm . Yeah , true">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers in the transcript discuss the different ways people might interpret and say the number &quot;three ninety-eight one&quot; versus &quot;three hundred ninety-one.&quot; While some people might say &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} it {disfmarker} it 's a different problem . I mean it 's a {disfmarker} it 's a {disfmarker} it 's an interesting problem {disfmarker} I mean , we 've done stuff with numbers before , and yeah sometimes people {disfmarker} If you say s &quot; three nine eight one &quot; sometimes people will say &quot; thirty - nine eighty - one &quot; or &quot; three hundred {disfmarker} three hundred eighty - nine one &quot; , or {disfmarker} I don't think they 'd say that ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: but {disfmarker} but th&#10;Speaker: Grad B&#10;Content: Not very frequently&#10;Speaker: Professor A&#10;Content: no {disfmarker}&#10;Speaker: Grad B&#10;Content: but , {vocalsound} they certainly could .&#10;Speaker: Professor A&#10;Content: But {disfmarker} Yeah . Uh , th thirty - eight ninety - one is probably how they 'd do it .&#10;Speaker: Grad B&#10;Content: So . I mean" target="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I mean if you saw a telephone number you would never see it this way .&#10;Speaker: Grad B&#10;Content: The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" target="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I mean if you saw a telephone number you would never see it this way .&#10;Speaker: Grad B&#10;Content: The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" target="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I mean if you saw a telephone number you would never see it this way .&#10;Speaker: Grad B&#10;Content: The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" target="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information.">
      <data key="d0">1</data>
    </edge>
    <edge source=" .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I mean if you saw a telephone number you would never see it this way .&#10;Speaker: Grad B&#10;Content: The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" target="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD G&#10;Content: So you {disfmarker} um , how many digits have been transcribed now ?&#10;Speaker: Grad B&#10;Content: Four thousand lines . And each line is between one and about ten digits .&#10;Speaker: PhD G&#10;Content: Four thousand lines ?&#10;Speaker: Grad B&#10;Content: I didn't {disfmarker} I didn't compute the average . I think the average was around four or five .&#10;Speaker: Professor A&#10;Content: So that 's a couple hours of {disfmarker} of , uh , speech , probably .&#10;Speaker: PhD G&#10;Content: Wow .&#10;Speaker: Grad B&#10;Content: Yep . Yep .&#10;Speaker: Professor A&#10;Content: Which is a yeah reasonable {disfmarker} reasonable test set .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And , Jane , I do have a set of forms which I think you have copies of somewhere .&#10;Speaker: Postdoc F&#10;Content: Mm - hmm . Yeah , true" target="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD G&#10;Content: So you {disfmarker} um , how many digits have been transcribed now ?&#10;Speaker: Grad B&#10;Content: Four thousand lines . And each line is between one and about ten digits .&#10;Speaker: PhD G&#10;Content: Four thousand lines ?&#10;Speaker: Grad B&#10;Content: I didn't {disfmarker} I didn't compute the average . I think the average was around four or five .&#10;Speaker: Professor A&#10;Content: So that 's a couple hours of {disfmarker} of , uh , speech , probably .&#10;Speaker: PhD G&#10;Content: Wow .&#10;Speaker: Grad B&#10;Content: Yep . Yep .&#10;Speaker: Professor A&#10;Content: Which is a yeah reasonable {disfmarker} reasonable test set .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD G&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And , Jane , I do have a set of forms which I think you have copies of somewhere .&#10;Speaker: Postdoc F&#10;Content: Mm - hmm . Yeah , true" target="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files." target="er} for m the meetings we were thinking about three letters and three numbers for meeting I Ds . Uh , for speakers , M or F and then three numbers , For , uh {disfmarker} and , uh , that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent . Um , and then , uh , the microphone issues . We want some way of specifying , more than looking in the &quot; key &quot; file , what channel and what mike . What channel , what mike , and what broadcaster . Or {disfmarker} I don't know how to s say it . So I mean with this one it 's this particular headset with this particular transmitter w {pause} as a wireless .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yep .&#10;Speaker: Grad B&#10;Content: And you know that one is a different headset and different channel . And so we just need some naming conventions on that .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And , uh ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files." target=" we can also rationalize some of the naming .&#10;Speaker: Postdoc F&#10;Content: I {disfmarker} I would think though that the transcribe {disfmarker} the transcripts themselves wouldn't need to have such lengthy names .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Postdoc F&#10;Content: So , I mean , you 're dealing with a different domain there , and with start and end times and all that , and channels and stuff ,&#10;Speaker: Grad B&#10;Content: Right . So the only thing that would change with that is just the directory names ,&#10;Speaker: Postdoc F&#10;Content: so , it 's a different {pause} set .&#10;Speaker: Grad B&#10;Content: I would change them to match . So instead of being MR one it would be MRM zero zero one . But I don't think that 's a big deal .&#10;Speaker: Postdoc F&#10;Content: Fine . Fine .&#10;Speaker: Grad B&#10;Content: So for {disfmarker} for m the meetings we were thinking about three letters and three numbers for meeting I Ds . Uh , for speakers , M or F and then three">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files." target="&#10;Speaker: Postdoc F&#10;Content: i&#10;Speaker: Grad B&#10;Content: And so if each one of those is a fixed length , the sorting becomes a lot easier .&#10;Speaker: Postdoc F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: She wanted to keep them {vocalsound} the same lengths across different meetings also . So like , the NSA meeting lengths , {comment} all filenames are gonna be the same length as the Meeting Recorder meeting names ?&#10;Speaker: Grad B&#10;Content: Yep . And as I said , the it 's {disfmarker} we just don't have that many that that 's a big deal .&#10;Speaker: PhD G&#10;Content: Cuz of digits .&#10;Speaker: Grad B&#10;Content: And so , uh , um , at some point we have to sort of take a few days off , let the transcribers have a few days off , make sure no one 's touching the data and reorganize the file structures . And when we do that we can also rationalize some of the naming .&#10;Speaker: Postdoc F&#10;Content: I {disfmarker} I would think though that">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files." target=" conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the people who {disfmarker} for whom it 's relevant .&#10;Speaker: Professor A&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: I could always say something about transcription . I 've been {disfmarker} {vocalsound} but {disfmarker} but {disfmarker} uh , well {disfmarker}&#10;Speaker: Professor A&#10;Content: Well if we {disfmarker} Yeah , we shouldn't add things in just to add things in . I 'm actually pretty busy today ,&#10;Speaker: Postdoc F&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: so if we can {disfmarker} {comment} {vocalsound} we {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: Professor A&#10;Content: a short meeting would be fine .&#10;Speaker: Postdoc F&#10;Content: This does sound">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Naming Conventions: It is proposed to use a naming convention that includes three letters and three numbers for meeting IDs. For speakers, they suggest using &quot;M&quot; or &quot;F&quot; followed by three numbers to identify the microphone, headset, transmitter, and broadcaster used by each speaker. This will help maintain consistency and make it easier to manage and sort files.&#10;&#10;Example: If a female speaker uses headset 03 and transmitter 05 with broadcaster 01, her identifier could be &quot;F03-05-01.&quot;&#10;&#10;2. Database System: To assemble a speaker database and maintain consistency in linking speakers to their respective microphone configurations, a simple database system or spreadsheet can be used to store the necessary information. The database should include columns for Name, Gender (M/F), Headset Number, Transmitter Number, Broadcaster Number, and Meeting ID.&#10;&#10;By implementing these naming conventions and using a database system, it will help the team avoid microphone issues, maintain consistency, and enable easier organization of meeting files." target="&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And , uh ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: that 's gonna become especially important once we start changing the microphone set - up . We have some new microphones that I 'd like to start trying out , um , once I test them . And then we 'll {disfmarker} we 'll need to specify that somewhere . So I was just gonna do a fixed list of , uh , microphones and types .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So , as I said {disfmarker}&#10;Speaker: PhD E&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: That sounds good .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Um , {pause} {vocalsound} since we have such a short agenda list I guess I wi I will ask how {disfmarker} how are the transcriptions going ? Yeah .&#10;Speaker: Postdoc F&#10;Content: The {disfmarker} the news is that I 've">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Postdoc F&#10;Content: i&#10;Speaker: Grad B&#10;Content: And so if each one of those is a fixed length , the sorting becomes a lot easier .&#10;Speaker: Postdoc F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: She wanted to keep them {vocalsound} the same lengths across different meetings also . So like , the NSA meeting lengths , {comment} all filenames are gonna be the same length as the Meeting Recorder meeting names ?&#10;Speaker: Grad B&#10;Content: Yep . And as I said , the it 's {disfmarker} we just don't have that many that that 's a big deal .&#10;Speaker: PhD G&#10;Content: Cuz of digits .&#10;Speaker: Grad B&#10;Content: And so , uh , um , at some point we have to sort of take a few days off , let the transcribers have a few days off , make sure no one 's touching the data and reorganize the file structures . And when we do that we can also rationalize some of the naming .&#10;Speaker: Postdoc F&#10;Content: I {disfmarker} I would think though that" target="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers." target=" like training the speech - nonspeech segmentation thing .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Th - it 's necessary to have it more tightly tuned than that .&#10;Speaker: Professor A&#10;Content: OK .&#10;Speaker: Postdoc F&#10;Content: And w and w and , you know , is a It would be wonderful if , uh , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , um , you know , I 've {disfmarker} th the {disfmarker} So , I I don't know exactly where that 's going at this point . But m I was experimenting with doing this by hand and I really do think that it 's wise that we 've had them start the way we have with , uh , m y working off the mixed signal , um , having the interface that doesn't require them to do the ti uh , the time bins for every single channel at a t uh , through the entire interaction .&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: Um , I did discover a couple">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers." target="er} that one of the reason we thought we were so much faster than {disfmarker} than , uh , the {disfmarker} the other transcription , uh , thing was that {disfmarker} that we were using the mixed {pause} file .&#10;Speaker: Postdoc F&#10;Content: Oh , yes . OK . But , um , with the mixed , when you have an overlap , you only have a {disfmarker} a choice of one start and end time for that entire overlap , which means that you 're not tightly , uh , tuning the individual parts th of that overlap by different speakers .&#10;Speaker: Professor A&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Postdoc F&#10;Content: So someone may have only said two words in that entire big chunk of overlap .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: And for purposes of {disfmarker} of , uh , things like {disfmarker} well , so things like training the speech - nonspeech segmentation thing .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Postdoc F has been experimenting with using a mixed signal file for transcription, but discovered that this method does not allow for tight tuning of the individual parts of an overlap by different speakers. This is because there is only one start and end time for the entire overlap when using the mixed file.&#10;2. They found that using the mixed file led to the assumption that they were faster than another transcription method, but this was not accurate.&#10;3. Postdoc F discussed with Chuck the idea of creating a master transcript that includes everything needed for both speech recognition research and discourse research. This is because in discourse and linguistic research, what is communicative is important, while breaths are typically not. However, there are cases where breath can be communicative.&#10;4. Postdoc F discovered that backchannels (such as &quot;mm-hmm&quot; or &quot;uh-huh&quot;) can sometimes be overlooked by transcribers, especially if they occur in a densely populated overlap. To study types of overlaps and analyze them properly, it is necessary to listen to every single channel throughout the entire length for all speakers. This becomes more time-consuming when dealing with a larger number of speakers." target="&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: Um , I did discover a couple other things by doing this though , and one of them is that , um , um , once in a while a backchannel will be overlooked by the transcriber .&#10;Speaker: Professor A&#10;Content: Mm - hmm .&#10;Speaker: Postdoc F&#10;Content: As you might expect ,&#10;Speaker: Professor A&#10;Content: Sure .&#10;Speaker: Postdoc F&#10;Content: because when it 's a b backchannel could well happen in a very densely populated overlap . And if we 're gonna study types of overlaps , which is what I wanna do , an analysis of that , then that really does require listening {comment} to every single channel all the way through the entire {comment} length for all the different speakers . Now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . So it 's li you know , kind of wondering {disfmarker} And I think again it 's like this {disfmarker} it 's">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day." target="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the speakers' discussions in the transcript, they seem to agree that the frequency of a system crashing during the day may depend on factors such as the number of times one uses the system, their level of experience, and the number of meetings they have. PhD G mentioned experiencing a crash when they started the morning, while Grad B did not crash at all during that time. Professor A suggested that it might be related to how many times one crashes in a day, and PhD G agreed, adding that it could also be related to the number of meetings one has. Towards the end of the conversation, PhD G mentioned that it could be a matter of experience. Therefore, it appears that the speakers believe that experience and usage patterns may influence the likelihood of a system crashing during the day." target="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given.">
      <data key="d0">1</data>
    </edge>
    <edge source="The problem being discussed regarding the way people interpret and say the number &quot;three nine eight one&quot; is that it can be ambiguous and might be misunderstood as &quot;thirty-nine eighty-one&quot; or &quot;three hundred eighty-nine one.&quot; While some people might say it correctly as &quot;three ninety-eight one,&quot; these interpretations are less common. The speakers seem to agree that the most likely interpretation would be &quot;three hundred ninety-one,&quot; with the exception of a few instances where someone might say &quot;three ninety-eight one.&quot; Overall, the discussion highlights the potential for ambiguity in how numbers are spoken and interpreted." target="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." target=": Yeah .&#10;Speaker: Grad B&#10;Content: I thought it was smaller , that it was like four or five , wasn't it ?&#10;Speaker: Professor A&#10;Content: Well they fund {disfmarker}&#10;Speaker: PhD G&#10;Content: I {disfmarker} I 'm {disfmarker}&#10;Speaker: Professor A&#10;Content: they {disfmarker}&#10;Speaker: PhD G&#10;Content: I don't remember .&#10;Speaker: Professor A&#10;Content: yeah . I mean {disfmarker}&#10;Speaker: Grad B&#10;Content: Uh it doesn't matter , we 'll find out one way or another .&#10;Speaker: Professor A&#10;Content: Yeah . I mean last time I think they just had two categories , small and big ,&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: and this time they came up with a middle one , so it 'll {disfmarker} there 'll be more of them that they fund than {disfmarker} of the big .&#10;Speaker: PhD G&#10;Content: If we end up getting this ,">
      <data key="d0">1</data>
    </edge>
    <edge source="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." target=" . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Speaker: PhD G&#10;Content: because we didn't want to weed out much in the first phase .&#10;Speaker: PhD E&#10;Content: yeah . Yeah .&#10;Speaker: Professor A&#10;Content: Well we 'll have to see what the numbers are .&#10;Speaker: Grad B&#10;Content: Or something like that ,&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: so .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor A&#10;Content: Yeah . But they {disfmarker} they have to weed out enough so that they have enough reviewers .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: So , uh , you know , maybe they didn't r weed out as much as usual , but it 's {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {">
      <data key="d0">1</data>
    </edge>
    <edge source="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." target=" {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {disfmarker} it 's certainly not {disfmarker} I 'm sure that it 's not down to one in two or something of what 's left .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I 'm sure it 's , you know {disfmarker}&#10;Speaker: Grad B&#10;Content: How {disfmarker} how many awards are there , do you know ?&#10;Speaker: Professor A&#10;Content: Well there 's different numbers of w awards for different size {disfmarker} They have three size grants . This one there 's , um {disfmarker} See the small ones are less than five hundred thousand total over three years and that they have a fair number of them . Um , and the large ones are , uh , boy , I forget , I think , more than , uh , more than a million and a half , more than two million or something like that . And {disfmarker} and we 're in the middle">
      <data key="d0">1</data>
    </edge>
    <edge source="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." target="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given.">
      <data key="d0">1</data>
    </edge>
    <edge source="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." target="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group.">
      <data key="d0">1</data>
    </edge>
    <edge source="From the discussion, it appears that the funding categories for a grant or awards have been changed from having two categories (small and big) to now having three categories. The new middle category is mentioned to be between the previously existing small and big categories, meaning it is intended for proposals seeking an amount of funding between the previous two categories. This change was implemented in order to fund more recipients than before, with the expectation that there will be more awards given out in this new middle category compared to the big category. The exact numbers or specifics of these three categories are not provided in the discussion." target="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . He said the next phase 'll be very , competitive&#10;Speaker: PhD E&#10;Content: Very {disfmarker} very ,&#10;Speaker: PhD G&#10;Content: because we didn't want to weed out much in the first phase .&#10;Speaker: PhD E&#10;Content: yeah . Yeah .&#10;Speaker: Professor A&#10;Content: Well we 'll have to see what the numbers are .&#10;Speaker: Grad B&#10;Content: Or something like that ,&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: so .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor A&#10;Content: Yeah . But they {disfmarker} they have to weed out enough so that they have enough reviewers .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: So , uh , you know , maybe they didn't r weed out as much as usual , but it 's {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {" target="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {disfmarker} it 's certainly not {disfmarker} I 'm sure that it 's not down to one in two or something of what 's left .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor A&#10;Content: I 'm sure it 's , you know {disfmarker}&#10;Speaker: Grad B&#10;Content: How {disfmarker} how many awards are there , do you know ?&#10;Speaker: Professor A&#10;Content: Well there 's different numbers of w awards for different size {disfmarker} They have three size grants . This one there 's , um {disfmarker} See the small ones are less than five hundred thousand total over three years and that they have a fair number of them . Um , and the large ones are , uh , boy , I forget , I think , more than , uh , more than a million and a half , more than two million or something like that . And {disfmarker} and we 're in the middle" target="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The hypothesis proposed by Professor A is not explicitly stated, but she seems interested in studying energy and multiples of frequency from a signal or spectrum.&#10;2. PhD C uses the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. They represent all frequency ranges and observe more or less significant features, which are hypothesized to be harmonics. PhD C also follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;&#10;The relationship between the instantaneous frequency of the output of continuous filters and how it relates to a signal, as discussed by Professor A and PhD C, is that if the instantaneous frequencies of the filtered outputs are very close together, then the filters may not be effectively separating or distinguishing between different frequency components in the signal. This is important because the goal of using filters is often to isolate specific frequency bands or features within a signal. In this conversation, PhD C mentions that they did not observe this issue in their own work, suggesting that their filtering approach may have been more effective at distinguishing between frequency components." target="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds." target=" PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: and you know about , that in principle we might be able to , um , handle breaths by accessi by using cross - talk from the other things , be able that {disfmarker} in principle , maybe we could get rid of them , so maybe {disfmarker} And I was {disfmarker} I {disfmarker} I don't know , I mean we had this an and I didn't {disfmarker} couldn't get back to you ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation ,&#10;Speaker: Professor A&#10;Content: I don't know {disfmarker} think it 'd be ideal .&#10;Speaker: Postdoc F&#10;Content: cuz {disfmarker}&#10;Speaker: PhD G&#10;Content: Uh - uh .&#10;Speaker: Professor A&#10;Content: We - See , we 're {disfmarker} we 're dealing with real speech and we 're">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds." target=" I 'm not gonna have time to do in the next few days , but {disfmarker} {vocalsound} but I 'm {disfmarker} I 'm curious about it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Um , uh , OK .&#10;Speaker: Postdoc F&#10;Content: I I did i it did occur to me that this is {disfmarker} uh , the return to the transcription , that there 's one third thing I wanted to {disfmarker} to ex raise as a to as an issue which is , um , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , um , aside from the fact that they 're obviously very time - consuming to encode , uh , the fact that there was some {disfmarker} I had the indication from Dan Ellis in the email that I sent to you ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: and you know about , that in principle we might be able to , um">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds." target="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds." target="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, it may be possible to eliminate breaths from an audio signal during the recording process using a device such as a PDA (Personal Digital Assistant) with a good breath extractor. However, this is still a research question and there is no definitive answer provided in the conversation. The ideal situation for doing so would likely be during the initial recording phase, before any further processing or analysis of the audio signal takes place. This would help to ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds." target="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question.">
      <data key="d0">1</data>
    </edge>
    <edge source=" I 'm not gonna have time to do in the next few days , but {disfmarker} {vocalsound} but I 'm {disfmarker} I 'm curious about it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Um , uh , OK .&#10;Speaker: Postdoc F&#10;Content: I I did i it did occur to me that this is {disfmarker} uh , the return to the transcription , that there 's one third thing I wanted to {disfmarker} to ex raise as a to as an issue which is , um , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , um , aside from the fact that they 're obviously very time - consuming to encode , uh , the fact that there was some {disfmarker} I had the indication from Dan Ellis in the email that I sent to you ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: and you know about , that in principle we might be able to , um" target="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given." target=" {disfmarker} on more {disfmarker} more higher level , uh , issues in meetings , from {disfmarker} I guess higher level from my point of view . Uh , {vocalsound} and , uh , meeting mappings , and , uh {disfmarker} so is i for {disfmarker} it was a {vocalsound} proposal for the ITR program , uh , Information Technology Research program 's part of National Science Foundation . It 's the {pause} second year of their doing , uh , these grants . They 're {disfmarker} they 're {disfmarker} a lot of them are {disfmarker} some of them anyway , are larger {disfmarker} larger grants than the usual , small NSF grants , and . So , they 're very competitive , and they have a first phase where you put in pre - proposals , and we {disfmarker} we , uh , got through that . And so th the {disfmarker} the next phase will be {disfmarker} we 'll actually be doing a larger proposal . And I 'm {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given." target="disfmarker} when one reviewer says , uh , &quot; you know , this should be far more detailed &quot; , and the nex the next reviewer says , &quot; you know , there 's way too much detail &quot; .&#10;Speaker: Grad B&#10;Content: Yep . Or &quot; this is way too general &quot; , and the other reviewer says , &quot; this is way too specific &quot; .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: &quot; This is way too hard &quot; , &quot; way too easy &quot; .&#10;Speaker: Professor A&#10;Content: We 'll see . Maybe there 'll be something useful . And {disfmarker} and , uh {disfmarker}&#10;Speaker: Grad B&#10;Content: Well it sounded like they {disfmarker} they {disfmarker} the first gate was pretty easy . Is that right ? That they didn't reject a lot of the pre - proposals ?&#10;Speaker: Professor A&#10;Content: Do you know anything about the numbers ?&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given." target="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, the next phase of the funding process is expected to be very competitive, as there were likely many applicants who passed the initial screening. The speakers discuss the potential issue of not weeding out enough applicants in the first phase, which could lead to a shortage of reviewers for the remaining applications. This is because each application requires a significant amount of time and effort to review thoroughly, and there may not be enough reviewers available to handle the increased workload. This could potentially impact the quality of the reviews and the fairness of the selection process. However, the exact numbers or specifics of the applicant pool are not provided in the discussion, so a definitive answer cannot be given." target="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} on more {disfmarker} more higher level , uh , issues in meetings , from {disfmarker} I guess higher level from my point of view . Uh , {vocalsound} and , uh , meeting mappings , and , uh {disfmarker} so is i for {disfmarker} it was a {vocalsound} proposal for the ITR program , uh , Information Technology Research program 's part of National Science Foundation . It 's the {pause} second year of their doing , uh , these grants . They 're {disfmarker} they 're {disfmarker} a lot of them are {disfmarker} some of them anyway , are larger {disfmarker} larger grants than the usual , small NSF grants , and . So , they 're very competitive , and they have a first phase where you put in pre - proposals , and we {disfmarker} we , uh , got through that . And so th the {disfmarker} the next phase will be {disfmarker} we 'll actually be doing a larger proposal . And I 'm {disfmarker}" target="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." target="&#10;Speaker: Grad B&#10;Content: and the way it wa worked and see if it makes sense and if anyone has any comments on it .&#10;Speaker: Professor A&#10;Content: I see . And the decision here , uh , was to continue with uh the words rather than the {disfmarker} the numerics .&#10;Speaker: Grad B&#10;Content: Uh , yes , although we could switch it back . The problem was O and zero . Although we could switch it back and tell them always to say &quot; zero &quot; or always to say &quot; O &quot; .&#10;Speaker: Postdoc F&#10;Content: Oh {disfmarker}&#10;Speaker: Professor A&#10;Content: Or neither .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: But it 's just two thing {disfmarker} ways that you can say it .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: Right ?&#10;Speaker: Grad B&#10;Content: Sure .&#10;Speaker: Postdoc F&#10;Content: Oh .&#10;Speaker: Professor A&#10;Content: Um {disfmarker} um ,&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." target=" mail . I didn't have anything .&#10;Speaker: Grad B&#10;Content: So , does anyone have any a agenda items other than me ? I actually have one more also which is to talk about the digits .&#10;Speaker: Professor A&#10;Content: Uh , right , so {disfmarker} so I {disfmarker} I was just gonna talk briefly about the NSF ITR .&#10;Speaker: PhD C&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Grad B&#10;Content: Oh , great .&#10;Speaker: Professor A&#10;Content: Uh , and then , you have {disfmarker}&#10;Speaker: Postdoc F&#10;Content: Can w&#10;Speaker: Professor A&#10;Content: I mean , I won't say much , but {disfmarker} {comment} uh , but then , uh , you said {disfmarker} wanna talk about digits ?&#10;Speaker: Grad B&#10;Content: I have a short thing about digits and then uh I wanna talk a little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." target="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." target="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." target="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings.">
      <data key="d0">1</data>
    </edge>
    <edge source="During the meeting, there was a discussion about whether to use digits or words for certain elements of their project. The individuals named Professor A, Grad B, PhD C, and Grad D decided to use words instead of digits when referring to numerals. They pointed out that people might read &quot;43&quot; as &quot;forty-three&quot; instead of &quot;four three,&quot; which could create confusion. Additionally, there were issues with distinguishing between &quot;O&quot; and &quot;zero.&quot; The group concluded that using words consistently would help avoid these problems." target="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information." target=" thousand .&#10;Speaker: PhD G&#10;Content: Yeah , it 's {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah , I would , uh , {vocalsound} tak do the easy way ,&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: yeah .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: It {disfmarker} it 's kinda nice {disfmarker} I mean , wh who knows what studies people will be doing on {disfmarker} on speaker - dependent things&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor A&#10;Content: and so I think having {disfmarker} having it all {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: the speakers who we had is {disfmarker} is at least interesting .&#10;Speaker: PhD G&#10;Content: So you {disfmarker} um , how many digits have been transcribed now ?&#10;Speaker: Grad">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information." target="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information." target="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Grad B mentioned that they have transcribed four thousand lines, and each line is between one and about ten digits. However, they didn't provide an exact number of digits transcribed so far. Therefore, the exact number of digits transcribed cannot be determined from the given information." target="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set." target=" , yeah .&#10;Speaker: Professor A&#10;Content: a short meeting would be fine .&#10;Speaker: Postdoc F&#10;Content: This does sound like we 're doing fine , yeah . That won't do .&#10;Speaker: Grad B&#10;Content: So the only thing I wanna say about digits is , we are pretty much done with the first test set . There are probably forms here and there that are marked as having been read that weren't really read . So I won't really know until I go through all the transcriber forms and extract out pieces that are in error . So I wa Uh . Two things . The first is what should we do about digits that were misread ? My opinion is , um , we should just throw them out completely , and have them read again by someone else . You know , the grouping is completely random ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: so it {disfmarker} it 's perfectly fine to put a {disfmarker} a group together again of errors and have them re - read , just to finish out the test set .&#10;Speaker: Postdoc F&#10;Content: Oh ! By {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set." target="Based on the given transcript, the exact number of digits that have been transcribed so far is not mentioned or discussed by any of the individuals. Grad B only states that they have transcribed four thousand lines, with each line containing between one and ten digits. However, an exact number of digits transcribed is not provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set." target="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion for handling misread digits in the first test set, as discussed by Graduate B, PhD C, and Postdoc F during the meeting, is to throw them out completely and have them read again by someone else. Since the grouping of the data is random, it is perfectly fine to put a group together again of errors and have them re-read, just to finish out the test set." target="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated." target=" , eh , in m {pause} i in my opinion the {disfmarker} the {disfmarker} the instantaneous frequency , the {disfmarker} the {disfmarker} the behavior , eh , was {disfmarker} th it was very interesting . Because I {disfmarker} I saw {vocalsound} eh , how the spectrum {pause} concentrate , eh ,&#10;Speaker: Professor A&#10;Content: Oh !&#10;Speaker: PhD C&#10;Content: around the {disfmarker} the harmonic . But then when I apply the {disfmarker} the rule , eh , of the {disfmarker} in the {disfmarker} {pause} the instantaneous frequency of the ne of the continuous filter in the {disfmarker} the near filter , the {disfmarker} the rule that , eh , people propose in the paper doesn't work . And I don't know why .&#10;Speaker: Professor A&#10;Content: But the instantaneous frequency , wouldn't that give you something more like the central frequency of the {disfmarker} you know , of the {disfmarker} where most of the energy">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary issue that Speaker PhD C encountered when applying the rule of the instantaneous frequency of a continuous filter in a near filter is that the resulting instantaneous frequencies were very close together. This was problematic because it suggested that the filters were not effectively separating or distinguishing between different frequency components in the signal, which goes against the goal of using filters to isolate specific frequency bands or features within a signal.&#10;&#10;2. The reason this rule did not work as expected is not explicitly stated in the transcript. However, it can be inferred that the issue may lie in how the rule was applied or formulated. Speaker PhD C mentions that they do not know why the rule does not work in their case and that Professor A also needs to think about it.&#10;&#10;3. The central frequency where most of the energy is concentrated refers to the dominant frequency component in a signal, which can be estimated using the instantaneous frequency. Speaker PhD C mentions that they did not observe the issue of close instantaneous frequencies in their own work when analyzing the vibrations of the vocal cords (glottis). This suggests that their filtering approach may have been more effective at estimating the central frequency and distinguishing between different frequency components in the signal.&#10;&#10;4. In summary, Speaker PhD C encountered issues when applying the rule of the instantaneous frequency of a continuous filter in a near filter because the resulting instantaneous frequencies were very close together. This issue may be due to how the rule was applied or formulated and did not effectively estimate the central frequency where most of the energy is concentrated." target="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice.">
      <data key="d0">1</data>
    </edge>
    <edge source="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings." target=" sound files , in {disfmarker} for ba both digits and for , uh , doing recognition . And Liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . So , uh , one thing she would like to have is for all the names to be the same length so that sorting is easier . Um ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: same number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . And that 's easy enough to do . And I don't think we have so many meetings that that 's a big deal just to change the names . So that means , uh , instead of calling it &quot; MR one &quot; , &quot; MR two &quot; , you 'd call it &quot; MRM zero zero one &quot; , &quot; MRM zero zero two &quot; , things like that . Just so that they 're {disfmarker} they 're all the same length .&#10;Speaker: Postdoc F&#10;Content: But , you know , when you , do things like that you can always {disfmarker} as long as you have {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1) The group wants to standardize the length of sound file names to make sorting easier, as mentioned by Grad B. The idea is to have all the names with the same number of characters so that when sorting filenames, one can easily extract bits and pieces that they want. This would be useful for organizing and managing large collections of sound files.&#10;&#10;2) Liz raised concerns about naming during a previous discussion and suggested having all the names be the same length to facilitate easier sorting, as mentioned at the beginning of the transcript. Additionally, she wanted to ensure that the names were consistent across different meetings, as Grad D pointed out. This consistency in naming conventions would make it simpler for the team to manage their files and avoid confusion when working with multiple sets of data from various meetings." target=" 's looking {disfmarker} that {disfmarker} that 's that guy , uh , Jeremy ? {comment} I think .&#10;Speaker: PhD C&#10;Content: Mm - hmm . &#10;Speaker: Professor A&#10;Content: Anyway , yeah that 's {disfmarker} that 's all I was gonna say is that {disfmarker} that that 's {disfmarker} you know , that 's nice and we 're sorta preceding to the next step , and , {vocalsound} it 'll mean some more work , uh , you know , in {disfmarker} in March in getting the proposal out , and then , it 's , uh , you know {disfmarker} We 'll see what happens . Uh , the last one was {disfmarker} that you had there , {comment} was about naming ?&#10;Speaker: Grad B&#10;Content: Yep . It just , uh {disfmarker} we 've been cutting up sound files , in {disfmarker} for ba both digits and for , uh , doing recognition . And Liz had some suggestions on naming and it just">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the research is currently in the stage where they are discussing and addressing issues related to the analysis of collected raw data. The specific focus of their research is on handling misread digits in the first test set by having them read again by someone else, as well as exploring the possibility of eliminating breaths from an audio signal during the recording process using a device like a PDA with a good breath extractor.&#10;&#10;Accounting for potential errors in the future is important because the limitations of the transcribed data being used include the possibility of portions of the audio recording not being transcribed due to extended periods where a speaker is not talking or overlapping speech between multiple speakers. The transcriptions are not guaranteed to capture everything outside of the main segments of speech, and therefore, users cannot rely on it as perfectly clean data. By addressing these potential errors, the researchers can ensure that their analysis is based on accurate and reliable data, leading to more valid conclusions and improved voice analysis techniques." target="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts." target=" Postdoc F&#10;Content: and that wouldn't be a problem to have it , uh , pause plus breath plus laugh plus sneeze ?&#10;Speaker: Professor A&#10;Content: Yeah , i You know there is {disfmarker} there 's this dynamic tension between {disfmarker} between marking absolutely everything , as you know , and {disfmarker} and {disfmarker} and marking just a little bit and counting on the statistical methods . Basically the more we can mark the better . But if there seems to be a lot of effort for a small amount of reward in some area , and this might be one like this {disfmarker} Although I {disfmarker} I {disfmarker} I 'd be interested to h get {disfmarker} get input from Liz and Andreas on this to see if they {disfmarker} Cuz they 've - they 've got lots of experience with the breaths in {disfmarker} in , uh , uh , their transcripts .&#10;Speaker: Grad B&#10;Content: They have lots of experience with breathing ?&#10;Speaker: PhD G&#10;Content: I {disfmarker}&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The dynamic tension in marking everything versus marking just a little bit and relying on statistical methods refers to the challenge of deciding how much detail to include in transcripts or data analysis. Marking every single detail can provide more accurate results, but it also requires more effort and resources. On the other hand, relying on statistical methods can save time and effort, but it might not capture certain nuances or unique instances in the data.&#10;2. Professor A is open to incorporating breaths, laughs, and sneezes in the transcripts, particularly seeking input from Liz and Andreas regarding their experiences with breathing in transcripts. He acknowledges that while marking every detail is ideal, there might be areas where the effort required for a small reward might not be worth it. By getting input from Liz and Andreas, who have extensive experience with transcribing breath sounds, he hopes to make more informed decisions about how to balance accuracy and efficiency in transcripts." target="Speaker: Professor A&#10;Content: We - See , we 're {disfmarker} we 're dealing with real speech and we 're trying to have it be as real as possible&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor A&#10;Content: and breaths are part of real speech .&#10;Speaker: Postdoc F&#10;Content: Well , except that these are really truly {disfmarker} I mean , ther there 's a segment in o the one I did {disfmarker} n the first one that I did for {disfmarker} i for this ,&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: where truly w we 're hearing you breathing like {disfmarker} as if we 're {disfmarker} you 're in our ear , you know , and it 's like {disfmarker} it 's like {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: I y i I mean , breath is natural , but not&#10;Speaker: Professor A&#10;Content: It is {">
      <data key="d0">1</data>
    </edge>
    <edge source="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group." target=" right .&#10;Speaker: Professor A&#10;Content: to different kind of planes . So . Um . But , um . So it 's all it 's all stuff that none none of us are doing right now , or none of us are funded for , so it 's {disfmarker} so it 's {disfmarker} it would be new .&#10;Speaker: PhD G&#10;Content: So assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ?&#10;Speaker: Professor A&#10;Content: Well there 's evenings , and there 's weekends , and {disfmarker} Uh . Yeah , there {disfmarker} there would be {disfmarker} there would be new hires , and {disfmarker} and there {disfmarker} there would be expansion , but , also , there 's always {disfmarker} {vocalsound} for everybody there 's {disfmarker} there 's always things that are dropping off , grants that are ending , or other things that are ending , so ,&#10;Speaker: PhD G&#10;Content: Right .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="To pursue the new research direction focused on &quot;different kinds of planes,&quot; several steps may be necessary as suggested by the speakers in the transcript. However, specific numbers or details are not provided in the discussion. Here's a summary of possible requirements:&#10;&#10;1. New hires: The group acknowledges that additional human resources will be needed to handle this new research direction. This could mean hiring more students or other staff members.&#10;2. Changes in workload: The speakers discuss utilizing evenings and weekends, which implies an increase in the current workload for some team members.&#10;3. Expansion: There might be a need to expand the current infrastructure or facilities to accommodate this new research direction.&#10;&#10;Professor A also mentions that there could be &quot;things that are dropping off&quot; such as grants ending, which may provide some relief in terms of workload or resources for this new endeavor. While these points offer an insight into what might be required for the new research direction, concrete details and specifics have yet to be discussed by the group." target=" research {disfmarker} to continue the research on the Meeting Recorder stuff ?&#10;Speaker: Professor A&#10;Content: It 's extending the research , right ? Because the other {disfmarker}&#10;Speaker: PhD G&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yeah it 's go higher level stuff than we 've been talking about for Meeting Recorder .&#10;Speaker: Professor A&#10;Content: Yeah . Yeah the other things that we have , uh , been working on with , uh , the c with Communicator {disfmarker} uh , especially with the newer things {disfmarker} with the more acoustically - oriented things are {disfmarker} are {disfmarker} are {disfmarker} are lower level . And , this is dealing with , uh , mapping on the level of {disfmarker} of , um , the conversation {disfmarker} of mapping the conversations&#10;Speaker: PhD G&#10;Content: Mm - hmm . Right , right .&#10;Speaker: Professor A&#10;Content: to different kind of planes . So . Um . But , um . So it 's all it '">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The breathing aspect plays a significant role in the problem since it can affect the accurate analysis of the pure vibrations at the glottis. Breath sounds introduce additional noise and complications that make it difficult to isolate and study the frequency components of the original vibration at the glottis.&#10;2. While the discussion transcript does not provide a definitive answer regarding the feasibility of building a PDA with a good breath extractor, it is mentioned as a possibility. The ideal scenario would be to eliminate breaths during the initial recording phase before further processing or analysis of the audio signal takes place. This would help ensure that the vibrations at the glottis can be more accurately studied without the influence of the vocal tract and associated breath sounds. However, this remains an open research question." target="aker: Postdoc F&#10;Content: I y i I mean , breath is natural , but not&#10;Speaker: Professor A&#10;Content: It is {disfmarker} but it is if you record it .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc F&#10;Content: Except that we 're {disfmarker} we 're trying to mimic {disfmarker} Oh , I see what you 're saying . You 're saying that the PDA application would have {disfmarker} uh , have to cope with breath .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Well&#10;Speaker: PhD E&#10;Content: No .&#10;Speaker: Postdoc F&#10;Content: But {disfmarker}&#10;Speaker: PhD G&#10;Content: An - any application may have to .&#10;Speaker: Grad B&#10;Content: The P D A might not have to ,&#10;Speaker: PhD E&#10;Content: No {disfmarker} i&#10;Speaker: Grad B&#10;Content: but more people than just PDA users are interested in this corpus .&#10;Speaker: PhD E&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency." target="Based on the information provided in the transcript, there is no direct statement from Professor A regarding their reasons for working with real data, including background noise and disturbances. However, it can be inferred that the speakers are working with real data since they are discussing issues related to analyzing voice spectra, which involves dealing with various factors present in actual recordings.&#10;&#10;In the context of analyzing voice spectra, working with real data may provide several benefits:&#10;&#10;1. Better representation of real-world conditions: By using real data that includes background noise and disturbances, researchers can better understand how their analysis techniques perform under less-than-ideal conditions. This can help ensure that their methods are robust enough to handle a variety of situations and environments.&#10;2. Improved ecological validity: Working with real data in meetings and discussions can increase the ecological validity of research findings. Ecological validity refers to how well research results apply to real-world situations, and using real data can help ensure that the findings are relevant to actual voice analysis applications.&#10;3. Opportunities for problem-solving: When working with real data, researchers may encounter unexpected issues or challenges that require creative solutions. These experiences can help build problem-solving skills and foster a deeper understanding of the subject matter.&#10;&#10;Overall, while there is no explicit statement from Professor A regarding their reasons for working with real data, it is likely that they recognize the benefits of using real data to improve the generalizability and applicability of research findings in voice analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first algorithm, supported by Professor A, focuses on analyzing energy and multiples of frequency from a signal or spectrum. The specifics of this algorithm are not explicitly mentioned in the transcript.&#10;2. The second algorithm, discussed by PhD C, involves using the Fast Fourier Transform (FFT) to calculate the phase derivative and find probabilities of several frequencies using the instantaneous frequency. This algorithm is based on analyzing the FFT of a signal to transform it from the time domain to the frequency domain, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency." target="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there is no clear answer to how many graduate fellowships were funded specifically to Chuck in the past year. The speakers discussed the number of awards funded, but they did not provide specific numbers for the past year or for Chuck's awards. Speaker PhD G said that according to a message from Gary Strong, the next phase will be very competitive, but there is no mention of the number of awards funded to Chuck." target=" , more than a million and a half , more than two million or something like that . And {disfmarker} and we 're in the middle {disfmarker} middle category .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor A&#10;Content: I think we 're , uh , uh , I forget what it was . But , um {disfmarker} Uh , I don't remember , but it 's {pause} pr probably along the li I {disfmarker} I could be wrong on this yeah , but probably along the lines of fifteen or {disfmarker} that they 'll fund , or twenty . I mean when they {disfmarker} Do you {disfmarker} do you know how many they funded when they f in {disfmarker} in Chuck 's , that he got last year ?&#10;Speaker: PhD G&#10;Content: I don't {disfmarker} I don't know .&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: I thought it was smaller , that it was like four or five , wasn't it ?&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Based on the discussion transcript, Speaker PhD C used the Fast Fourier Transform (FFT) to calculate the central frequency where most of the energy is concentrated. This was done by transforming the signal from the time domain to the frequency domain using the FFT, calculating the phase derivative in the time domain by taking the derivative of the phase information obtained from the FFT, and then observing significant features in the frequency range, which are hypothesized to be harmonics. Speaker PhD C follows a rule based on the signal bandwidth due to the Hanning window used for calculating the instantaneous frequency.&#10;2. The reason this corresponds to pitch is not explicitly stated in the transcript. However, it can be inferred that the central frequency where most of the energy is concentrated is likely to correspond to the fundamental frequency or pitch of a sound, as this frequency component typically contains a significant amount of the signal's energy and is often used to identify the source or type of sound. In the context of vocal cord vibrations, the central frequency where most of the energy is concentrated would likely correspond to the frequency of the vocal cords' oscillation, which is closely related to the perceived pitch of the voice." target=" give you something more like the central frequency of the {disfmarker} you know , of the {disfmarker} where most of the energy is ? I mean , I think if you {disfmarker} Does i does it {disfmarker} Why would it correspond to pitch ?&#10;Speaker: PhD C&#10;Content: Yeah . I {disfmarker} I {disfmarker} I not sure . I {disfmarker} I {disfmarker} I try to {disfmarker} to {disfmarker}&#10;Speaker: Professor A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: When {vocalsound} first I {disfmarker} {pause} {vocalsound} I calculate , eh , using the FFT ,&#10;Speaker: Postdoc F&#10;Content: Di - digital camera .&#10;Speaker: PhD C&#10;Content: the {disfmarker} the {disfmarker}&#10;Speaker: Grad B&#10;Content: Keep forgetting .&#10;Speaker: PhD C&#10;Content: I get the {disfmarker} {pause} the spectrum ,&#10;Speaker: Professor A&#10;">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
