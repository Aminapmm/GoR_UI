<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." />
    <node id="isfmarker} you find a GIS about {disfmarker} that gives you information on Berkeley ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: and it 's {disfmarker} it 's gonna be there and tell you what it can do and how it wants to do things . and so you can actually interface to such a system without ever having met it before and the function modeler and a self - description of the um external service haggle it out&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: and you can use the same language core , understanding core to interface with planner - A , planner - B , planner - C and so forth .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Grad B&#10;Content: Which is , you know , uh {disfmarker} uh {disfmarker} utopian {disfmarker} completely utopian at the moment , but slowly , you know , getting into the realm of the uh contingent .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Grad B" />
    <node id=" eventually . So {disfmarker} wouldn't That 's an additional reason to have this well - defined interface and keep these things like uh tourist information external .&#10;Speaker: Professor F&#10;Content: Oh , yeah , yeah .&#10;Speaker: PhD A&#10;Content: And then call it external services .&#10;Speaker: Grad B&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: But of course the {disfmarker} the more complex {disfmarker}&#10;Speaker: Grad B&#10;Content: Yeah , there is another philosophical issue that I think you know you can {disfmarker} evade&#10;Speaker: PhD A&#10;Content: yep .&#10;Speaker: Grad B&#10;Content: but , at at least it makes sense to me that sooner or later uh {disfmarker} a service is gonna come and describe itself to you . and that 's sort of what Srini is working on in {disfmarker} in {disfmarker} in the DAML uh project where um you {disfmarker} you find a GIS about {disfmarker} that gives you information on Berkeley ,&#10;Speaker: PhD A&#10;Content:" />
    <node id=" he saying ?&#10;Speaker: Grad B&#10;Content: Um , for example , right now I know the GIS from email is not able to calculate these viewpoints . So that 's a functionality that doesn't exist yet to do that dynamically ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: but if we can offer it that distinction , maybe somebody will go ahead and implement it . Surely nobody 's gonna go ahead and implement it if it 's never gonna be used , so . What have I forgotten about ? Oh yeah , how we do it ,&#10;Speaker: Professor F&#10;Content: Well th uh&#10;Speaker: Grad B&#10;Content: yeah that 's the&#10;Speaker: Professor F&#10;Content: No no . It 's a good time to pause . I s I see {pause} questions on peoples ' faces , so why don't {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh&#10;Speaker: Professor F&#10;Content: let 's {disfmarker} let 's {disfmarker} Let 's hear {disfmarker}&#10;Speaker: PhD A&#10;Content: Well the obvious" />
    <node id="er} th the word &quot; action &quot; , OK , is {disfmarker} is what 's ambiguous here .&#10;Speaker: Grad D&#10;Content: I think . Hmm .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: So , um one thing is there 's an actual planner that tells the person in the tourist domain now ,&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor F&#10;Content: per tells the person how to go , &quot; First go here ,&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: first go there uh , you know , take a bus &quot; , whatever it is . So that 's that form of planning , and action , and a route planner and GIS , all sort of stuff . uh But I think that isn't what you mean .&#10;Speaker: PhD A&#10;Content: No . No , in SmartKom terminology that 's um called a function that 's modeled by a function modeler . And it 's th that 's completely um encapsulated from th the dialogue system . That 's simply a functionality that you give data as in" />
    <node id="Content: Yes , very much so .&#10;Speaker: Grad D&#10;Content: Yeah , very much&#10;Speaker: Professor F&#10;Content: OK , before {disfmarker} before you got put to work ?&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Great . OK , so that 's {disfmarker} Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: and we can d I dunno w w was there uh a time when we were set up to do that ? It probably will work better if we do it later in the week , after {pause} we actually understand uh better what 's going on .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're" />
    <node id=" a bank ? Is it a s town square , is it a statue ? Whatever . So all that kind of information could be combined into decision networks and give you decisions . But the other half of the problem is How would you get that kind of information from the parsed input ? So , um So what you might try to do is just build more templates , saying uh we 're trying to build a templ you know build a template that w uh somehow would capture the fact that he wants to take a picture .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK ? And {disfmarker} and we could {disfmarker} you could do this . And it 's a small enough domain that probably you , you know {disfmarker}&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK . You could do this . But uh from our point of view this is also a research project and there are a couple of people not here for various reasons who are doing doctoral dissertations on this ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and the" />
    <node id="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." />
    <node id=" dialogue manager .&#10;Speaker: Professor F&#10;Content: Yeah&#10;Speaker: PhD A&#10;Content: um is based on slots that have to be filled and the um kind of values in these slots would be fixed things like the a time or a movie title or something like this&#10;Speaker: Professor F&#10;Content: Mm - hmm . Right .&#10;Speaker: PhD A&#10;Content: whereas in the a um tourist domain it might be an entire route . Set - based , or even very complex structured information in these slots&#10;Speaker: Professor F&#10;Content: Indeed . Right .&#10;Speaker: PhD A&#10;Content: and I 'm not sure if {disfmarker} if complex slots of that type are really um being taken into consideration .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: So that 's {disfmarker} that 's really something we&#10;Speaker: Professor F&#10;Content: Could you {disfmarker} could you put a message into the right place to see if we can at least ask that question ?&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content:" />
    <node id=" you know you {disfmarker} are you planning to enter ? Or whatever it {disfmarker} whatever that might be . So that 's {disfmarker} under that model then , There would be a {disfmarker} uh {disfmarker} um a loop in which this thing would formulate a query ,&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: presumably give it to you . That would get expressed and then hopefully you know , you 'd get an answer {pause} back .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Professor F&#10;Content: And that would of course {disfmarker} the answer would have to be parsed .&#10;Speaker: Grad D&#10;Content: Mmm . Yep .&#10;Speaker: Professor F&#10;Content: right and {disfmarker}&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: OK so , {pause} th {pause} that uh , We probably won't do this early on , because the current focus is more on the decision making and stuff like that .&#10;Speaker: PhD A&#10;Content:" />
    <node id=" right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and there will be additional situational information .&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Professor F&#10;Content: Uh , OK ,&#10;Speaker: PhD A&#10;Content: th&#10;Speaker: Professor F&#10;Content: part of it comes from the ontology . The tower is this kind of object .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yeah , OK .&#10;Speaker: Professor F&#10;Content: Part of it comes from the user model .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And the idea of the belief - net is it combines the information from the dialogue which comes across in this general way ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: you know this is a {disfmarker} this is a goal seeking behavior , along with specific information from the ontology about the kinds of objects" />
    <node id=" question&#10;Speaker: PhD A&#10;Content: hmm&#10;Speaker: Grad B&#10;Content: whether we 're {disfmarker} we 're gonna stick to Prolog or not .&#10;Speaker: PhD A&#10;Content: No . No , that 's gonna be phased out .&#10;Speaker: Professor F&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK But I do think the {disfmarker} the function modeling concept has a certain {disfmarker} makes sense in a {disfmarker} in a certain light&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: because the action planner should not be {disfmarker} or the dialogue manager in that case should not um w have to worry about whether it 's interfacing with um something that does route planning in this way or that way&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: I I totally agree .&#10;Speaker: Grad B&#10;Content: huh ,&#10;Speaker: Professor F&#10;Content: Sure .&#10;Speaker: Grad B&#10;Content: it j&#10;Speaker: Professor" />
    <node id=": PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: But , uh th the current design suggests that if it seems to be an important decision and if the belief - net is equivocal so that it doesn't say that one of these is much more probable than the other , then an option is to go back and ask for the information you want .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: Alright ? Now there are two ways one can go {disfmarker} a imagine doing that . For the debugging we 'll probably just have a {disfmarker} a drop - down menu and the {disfmarker} while you 're debugging you will just {disfmarker} OK . But for a full system , then one might very well formulate a query ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: give it to the dialogue planner and say this , you know ar are you know you {disfmarker} are you planning to enter ? Or whatever it {disfmarker} whatever that might be . So that '" />
    <node id=" to happen .&#10;Speaker: Grad B&#10;Content: a lot of , yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: If {disfmarker} if you know if {disfmarker} if you can't make it happen then you {disfmarker} you do your best .&#10;Speaker: PhD A&#10;Content: Yeah but that doesn't necessarily contradict um an architecture where there really is a pers a def well - defined interface . and {disfmarker} and&#10;Speaker: Professor F&#10;Content: I totally agree . But {disfmarker} but what it nee but th what the point is the in that case the dialogue manager is sort of event driven . So the dialogue manager may think it 's in a dialogue state of one sort ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and this {disfmarker} one of these planning modules comes along and says &quot; hey , right now we need to ask a question &quot; . So that forces the dialogue manager to change state .&#10;Speaker: PhD A&#10;Content: Yes&#10;Speaker: Professor F" />
    <node id="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." />
    <node id=" information&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: so it would be a full foreign lexicon .&#10;Speaker: Professor F&#10;Content: And that 's what you have .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: We threw out all the forms .&#10;Speaker: Professor F&#10;Content: What {disfmarker} uh I didn't reme&#10;Speaker: Grad B&#10;Content: We threw out all the forms&#10;Speaker: Professor F&#10;Content: Huh ?&#10;Speaker: Grad B&#10;Content: because , you know , English , well {disfmarker}&#10;Speaker: Professor F&#10;Content: Oh OK , so it {disfmarker} yeah , s s I thought I 'd {disfmarker}&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So in German then you actually do case" />
    <node id=" um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah , but {disfmarker} but it 's used for {disfmarker} for stem forms .&#10;Speaker: Professor F&#10;Content: So w wha&#10;Speaker: PhD A&#10;Content: n Well I think {disfmarker} I think there 's some misunderstanding here&#10;Speaker: Professor F&#10;Content: i&#10;Speaker: PhD A&#10;Content: it 's {disfmarker} Morphix is not used on - line .&#10;Speaker: Grad D&#10;Content: Oh , OK .&#10;Speaker: PhD A&#10;Content: s so the lexicon might be derived by Morphix&#10;Speaker: Grad D&#10;Content: What ?&#10;Speaker: PhD A&#10;Content: but What {disfmarker} what 's happening on - line is just um um a {disfmarker} a retrieval from the lexicon which would give all the stemming information&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: Professor F&#10;Content:" />
    <node id="&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So in German then you actually do case matching and things like in the {disfmarker} in the pattern matcher or not ?&#10;Speaker: Grad D&#10;Content: um Not yet but it 's planned to do that .&#10;Speaker: Professor F&#10;Content: OK . Cuz I r I didn't reme I didn't think I saw it .&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Have we looked at the German ? Oh , I haven yeah that 's {disfmarker} getting it from the lexicon is just fine .&#10;Speaker: PhD A&#10;Content: Sure , right .&#10;Speaker: Grad D&#10;Content: Oh yes .&#10;Speaker: Professor F&#10;Content: Yeah , yeah , yeah . No problem with that . um Yeah and here 's the case where the English and the German might really be significantly different . In terms of if you 're trying to build some fast parser and so forth and {disfmarker} You really might wanna do it in a significantly different way . I don't know ." />
    <node id="&#10;Speaker: Professor F&#10;Content: So y you just connect to the lexicon&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: and uh at least for German you have all {disfmarker} all of the {disfmarker} uh the stemming information .&#10;Speaker: Grad D&#10;Content: Yeah , we can , oh yeah . We have knowledge bases from {disfmarker} from Verbmobil system we can use&#10;Speaker: Professor F&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: and so .&#10;Speaker: Professor F&#10;Content: Right . But it {disfmarker} it {disfmarker} it doesn't look like i you 're using it . I didn't n see it being used in the current template uh parser . I {disfmarker} I didn't see any Uh {disfmarker} of course we l actually only looked at the English .&#10;Speaker: Grad D&#10;Content: It {disfmarker} um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah" />
    <node id="marker} it was pretty ambitious .&#10;Speaker: Grad D&#10;Content: and&#10;Speaker: Professor F&#10;Content: And of course it was English oriented ,&#10;Speaker: Grad D&#10;Content: Yeah , and {disfmarker} and Purely finite - state transducers are not so good for German since there 's um&#10;Speaker: Professor F&#10;Content: um w Right .&#10;Speaker: Grad D&#10;Content: The word order is {disfmarker} is uh not fixed&#10;Speaker: Professor F&#10;Content: Yeah , I guess that 's the point is {disfmarker} is all the morphology and stuff . And English is all th all word order . And it makes a lot more sense .&#10;Speaker: Grad D&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: And {disfmarker} e Yeah , OK . Good point . So in {disfmarker} in {disfmarker} in German you 've got uh most of this done with&#10;Speaker: Grad D&#10;Content: Mm - hmm . Also it 's uh {disfmarker} it 's um {disfmarker} Yes" />
    <node id=" to build some fast parser and so forth and {disfmarker} You really might wanna do it in a significantly different way . I don't know . So you 've {disfmarker} you guys have looked at this ? also ? in terms of You know , w if you 're doing this for English as well as German Um Do you think now that it would be this {disfmarker} doing it similarly ?&#10;Speaker: Grad D&#10;Content: um Yeah , it 's um I think it 's um yes , it 's {disfmarker} it 's um possible to {disfmarker} to do list processing . and Maybe this is um more adequate for English and in German um set processing is used .&#10;Speaker: Professor F&#10;Content: Set .&#10;Speaker: Grad D&#10;Content: Maybe yeah . Some extensions uh have to be made . For {disfmarker} for a English version&#10;Speaker: Professor F&#10;Content: Mmm . OK . Interesting . Not easy .&#10;Speaker: Grad B&#10;Content: Well there 's m I 'm sure there 's gonna be more discussion on that after your talk .&#10;Speaker: Grad D" />
    <node id="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires." />
    <node id="aker: Grad B&#10;Content: OK , geometric center . But what we actually observed in Heidelberg is that most people when they want to go there they actually don't want to enter , because it 's not really interesting . They wanna go to a completely different point where they can look at it and take a picture .&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And so what uh uh a s you s let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . Does he wanna go there to see it ? Does he wanna go there now ? Later ? How does the person wanna go there ? Is that person more likely to want to walk there ? Walk a scenic route ? and so forth . There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . And we are constructing {disfmarker} and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to" />
    <node id="er} and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to the situation . And we also want to look closely on the linguistic information that what we can get from the utterance . That 's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it . And um so the idea is to construct uh um suitable interfaces and a belief - net for a module that actually tries to guess what the underlying intention {pause} was . And then enrich or augment the M - three - L structures with what it thought what more it sort of got out of that utterance . So if it can make a good suggestion , &quot; Hey ! &quot; you know , &quot; that person doesn't wanna enter . That person just wants to take a picture , &quot; cuz he just bought film , or &quot; that person wants to enter because he discussed the admission fee before &quot; . Or &quot; that person wants to enter because he wants to buy something and that you usually do inside of buildings &quot; and so forth . These ah these types of uh these bits of additional information" />
    <node id="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." />
    <node id=": Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're here through Sunday ,&#10;Speaker: Grad D&#10;Content: Oh&#10;Speaker: PhD A&#10;Content: so All through Friday would be fine .&#10;Speaker: Professor F&#10;Content: Oh , OK , so {disfmarker} OK , So {disfmarker} so anyt we 'll find a time later in the week to uh get together and talk about {pause} your understanding of what SmartKom plans are .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and how we can change them .&#10;Speaker: PhD A&#10;Content: Yes . Sure .&#10;Speaker: Professor F&#10;Content: Uh ,&#10;Speaker: Grad B&#10;Content: Should we already set a date for that ? Might be beneficial while we 're all here .&#10;Speaker: Professor F&#10;Content: OK ? um What {disfmarker} what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or {pause} um {pause} most" />
    <node id=" probably won't do this early on , because the current focus is more on the decision making and stuff like that .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Professor F&#10;Content: But While we 're on the subject I just wanted to give you a sort of head 's up that it could be that some months from now we said &quot; OK we 're now ready to try to close that loop &quot; in terms of querying about some of these decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yep . So {disfmarker} my suggestion then is that you um look into the currently ongoing discussion about how the action plans are supposed to look like . And they 're currently um Agreeing or {disfmarker} or in the process of agreeing on an X M L - ification of um something like a state - transition network of how dialogues would proceed . and {disfmarker} The {disfmarker} these um transition networks uh will be what the action planner interprets in a sense .&#10;Speaker: Professor" />
    <node id=" Yeah .&#10;Speaker: PhD A&#10;Content: And then it would be available to action planning and {disfmarker} and others .&#10;Speaker: Grad B&#10;Content: Yeah . the {disfmarker}&#10;Speaker: Professor F&#10;Content: let 's {disfmarker} let 's That w OK that was one question . Is there other {disfmarker} other things that cuz {pause} we wanna not Pa - pass over any {pause} you know , questions or concerns that you have .&#10;Speaker: PhD A&#10;Content: Well there 're {disfmarker} there 're two levels of {disfmarker} of giving an answer and I guess on both levels I don't have any um further questions .&#10;Speaker: Grad D&#10;Content: Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: uh the {disfmarker} the two levels will be as far as I 'm concerned as {pause} uh standing here for the generation module&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: and the other is {disfmarker} is my understanding of what" />
    <node id=" .&#10;Speaker: PhD A&#10;Content: Beyond what 's currently being implemented which is just word lists .&#10;Speaker: Professor F&#10;Content: Yeah , but this is not the st this is not just the state of the discourse .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Of {disfmarker} of special interest .&#10;Speaker: Professor F&#10;Content: This is actually the state of the plan . That 's why&#10;Speaker: PhD A&#10;Content: Yes , Yes , Mm - hmm yeah .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: OK so it {disfmarker} z and s uh , It 's great if people are already taking that into account . But One would have t have to see {disfmarker} see the details .&#10;Speaker: PhD A&#10;Content: The specifics aren't really there yet . Yes . So , there 's work to do there .&#10;Speaker: Professor F&#10;Content: Yeah . So anyway , Robert , that 's why I was thinking that&#10;Speaker: Grad B&#10;" />
    <node id="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." />
    <node id="er} a dialogue manager . cuz that 's what everybody else calls it .&#10;Speaker: Professor F&#10;Content: I would think ,&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: Huh ? So , s So what would happen if we sent a note saying &quot; Gee we 've talked about this and couldn't we change this uh th the whole word ? &quot; I have no idea how complicated these things are .&#10;Speaker: Grad B&#10;Content: Probably close to impossible .&#10;Speaker: PhD A&#10;Content: Depends on who you talk to how . We 'll see . I 'll go check , cause I completely agree . Yeah ,&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: and I think this is just for historical reasons within uh , the preparation phase of the project and not because somebody actually believes it ought to be action planner . So if there is resistance against changing it , that 's just because &quot; Oh , We don't want to change things . &quot; That {disfmarker} that" />
    <node id=" to be able to have um an expressive power that can deal with these structures . And not just um say um {disfmarker} um the dialogue um will consist of ten possible states and th these states really are fixed in {disfmarker} in a certain sense .&#10;Speaker: Professor F&#10;Content: Hmm ?&#10;Speaker: PhD A&#10;Content: You have to {disfmarker}&#10;Speaker: Professor F&#10;Content: Would there be any chance of getting the terminology changed so that the dialogue planner was called a &quot; dialogue planner &quot; ? Because there 's this other thing The o There 's this other thing in {disfmarker} in the tourist domain which is gonna be a route planner&#10;Speaker: PhD A&#10;Content: That 'd be nice .&#10;Speaker: Professor F&#10;Content: or {disfmarker} It 's really gonna be an action planner . And {comment} i it {disfmarker}&#10;Speaker: PhD A&#10;Content: It oughta be called a {disfmarker} a dialogue manager . cuz that 's what everybody else calls it .&#10;Speaker: Professor F&#10;Content: I would think ,&#10;Spe" />
    <node id="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain." />
    <node id=" to be good enough . I I don what uh {disfmarker} what I meant by that . So I think the idea of having a , you know , transition diagram for the grammar of conversations is a good idea .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: OK ? And I think that we do hav definitely have to get in on it and find out {disfmarker} OK . But I think that um when {disfmarker} so , when you get to the tourist domain it 's not just an information retrieval system .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Clearly . Yes .&#10;Speaker: Professor F&#10;Content: Right ? So this i this is where I think this {disfmarker} people are gonna have to think this through a bit more carefully .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So , if it 's only like in {disfmarker} in the {disfmarker} in the film and T V thing , OK , you can do this . And you just get information and give" />
    <node id=" from there to the appropriate decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So another one of these primitive , what are called &quot; image schemas &quot; , is uh goal seeking . So this a notion of a source , path , goal , trajector , possibly obstacles .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And the idea is this is another conceptual primitive .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And that all sorts of things , particularly in the tourist domain , can be represented in terms of uh source , path and goal . So the idea would be could we build an analyser that would take an utterance and say &quot; Aha ! th this utterance is talking about an attempt to reach a goal . The goal is this , the pers the , uh traveller is that , uh the sor w where we are at now is is this , they 've mentioned possible obstacles , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide" />
    <node id="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." />
    <node id=" , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide coverage . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor F&#10;Content: And then , uh The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then uh make decisions about what actions to take . Provides , they claim , a very powerful , general notion of deep semantics . So that 's what we 're really doing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And Nancy is going to {disfmarker} Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm" />
    <node id="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." />
    <node id="s tricky because one could well imagine {disfmarker} I think it will turn out to be the case that uh , this thing we 're talking about , th the extended n uh knowledge modeler will fill in some parameters about what the person wants . One could well imagine that the next thing that 's trying to fill out the detailed uh , route planning , let 's say , will also have questions that it would like to ask the user . You could well imagine you get to a point where it 's got a {disfmarker} a choice to make and it just doesn't know something .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And so y you would like it t also be able to uh formulate a query . And to run that back through uh . the dialogue manager and to the output module and back around .&#10;Speaker: Grad B&#10;Content: hmm&#10;Speaker: Professor F&#10;Content: And a I a a good design would {disfmarker} would allow that to happen .&#10;Speaker: Grad B&#10;Content: a lot of , yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker" />
    <node id=" to ask a question &quot; . So that forces the dialogue manager to change state .&#10;Speaker: PhD A&#10;Content: Yes&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Sure ,&#10;Speaker: Professor F&#10;Content: It could be y&#10;Speaker: PhD A&#10;Content: ye yeah I {disfmarker} I think that 's {disfmarker} that 's the um concept that people have ,&#10;Speaker: Professor F&#10;Content: Yeah , yeah it {disfmarker} it {disfmarker}&#10;Speaker: PhD A&#10;Content: yep .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: And {disfmarker} and the {disfmarker} the underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug uh certain applications like tourist information or um the home scenario with uh controlling a VCR and so on . And then extend it to an arbitrary number of applications eventually . So {disfmarker} wouldn't That 's an additional reason to have this well - defined interface and keep these things like uh tourist information" />
    <node id="} let 's {disfmarker} Let 's hear {disfmarker}&#10;Speaker: PhD A&#10;Content: Well the obvious one would be if {disfmarker} if you envision this as a module within SmartKom , where exactly would that Sit ? That 's the d&#10;Speaker: Grad B&#10;Content: um {disfmarker} so far I 've thought of it as sort of adding it onto the modeler knowledge module .&#10;Speaker: PhD A&#10;Content: OK , yeah .&#10;Speaker: Grad B&#10;Content: So this is one that already adds additional information to the&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Makes perfect sense . Yes .&#10;Speaker: Grad D&#10;Content: Hmm , ah .&#10;Speaker: Grad B&#10;Content: but it could sit anywhere in the attention - recognition I mean basically this is what attention - recognition literally sort of can {disfmarker}&#10;Speaker: PhD A&#10;Content: Well it 's supposed to do . Yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: That 's what it should" />
    <node id="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project." />
    <node id=" in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yep , yep . And how do you envision um the {disfmarker} the um this deep semantic to be worked with . Would it be highly ambiguous if and then there would be another module that takes that um highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or {disfmarker} or a {disfmarker}&#10;Speaker: Professor F&#10;Content: Well that 's {disfmarker} that 's {disfmarker} that 's where the belief - net comes in . So th the idea is , let 's take this business about going to the Powder - Tower .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So part of what you 'll get out of this will be the fact tha w if it works right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: M" />
    <node id=" dissertations on this ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . So a typical one in this formulation is a container . So this is a static thing . And the notion is that all sorts of physical situations are characterized in terms of containers . Going in and out the portals and con&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK . But also , importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way . You get in trouble and you know et cetera&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: and so {disfmarker} s So , what we 're really trying to do is to map from the discourse to the conceptual semantics level . And from there to the appropriate decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So" />
    <node id=" A&#10;Content: Yeah , there {disfmarker} there 's the um practice talk .&#10;Speaker: Grad D&#10;Content: uh Mmm , yeah .&#10;Speaker: Professor F&#10;Content: Great . So you 're going to that .&#10;Speaker: PhD A&#10;Content: Yeah , that {disfmarker} that 's what we were planning to do .&#10;Speaker: Professor F&#10;Content: That 's good , because that will uh tell you a fair amount about The form of semantic construction grammar that we 're using .&#10;Speaker: PhD A&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor F&#10;Content: so {disfmarker} So I th I think that probably as good an introduction as you 'll get .&#10;Speaker: Grad D&#10;Content: Ah .&#10;Speaker: Professor F&#10;Content: Uh to the form of {disfmarker} of uh {disfmarker} conceptual grammar that {disfmarker} that w we have in mind for this .&#10;Speaker: Grad D&#10;Content: Mmm , ah .&#10;Speaker: Professor F&#10;Content: It won't talk particularly about how" />
    <node id="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." />
    <node id=" . Right . This is then out of deference to our non - morning people .&#10;Speaker: PhD A&#10;Content: Mm - hmm . OK . So at eleven ?&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Thursday around eleven ? OK .&#10;Speaker: Professor F&#10;Content: Yeah . And actually we can invite um Andreas as well .&#10;Speaker: Grad B&#10;Content: Uh he will be in Washington , though .&#10;Speaker: Professor F&#10;Content: Oh that 's true . He 's off {disfmarker} off on his trip already .&#10;Speaker: Grad B&#10;Content: but um David is here and he 's actually knows everything about the SmartKom recognizer .&#10;Speaker: Professor F&#10;Content: Thilo . OK well yeah maybe we 'll see if David could make it . That would be good .&#10;Speaker: Grad B&#10;Content: OK so facing to {disfmarker} to what we 've sort of been doing here um well for one thing we 're also using this room to collect data .&#10;Speaker: PhD A&#10;Content: Yeah obviously .&#10;Speaker: Grad" />
    <node id=" supposed to do . Yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: That 's what it should do .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: Right ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: Grad D&#10;Content: Huh .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Well f from my understanding of what the people at Phillips were originally trying to do doesn't seem to quite fit into SmartKom currently so what they 're really doing right now is only selecting among the alternatives , the hypotheses that they 're given enriched by the domain knowledge and the um discourse modeler and so on .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So if {disfmarker} if this is additional information that could be merged in by them .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: And then it would be available to action planning and {disfmarker} and others .&#10;Spe" />
    <node id="marker} what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or {pause} um {pause} most of the time on Friday , not all .&#10;Speaker: Grad B&#10;Content: Thursday morning sounds fine ?&#10;Speaker: Professor F&#10;Content: Wha - but , Johno ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: what are your constraints ?&#10;Speaker: Grad E&#10;Content: um Thursday afternoon doesn't work for me , but {disfmarker}&#10;Speaker: Grad B&#10;Content: Neither does Thursday morning , no ?&#10;Speaker: Grad E&#10;Content: Uh Thursday morning should be fine .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor F&#10;Content: Eleven ? Eleven on Thursday ?&#10;Speaker: Grad E&#10;Content: I was just thinking I w I will {pause} have {pause} leavened by eleven .&#10;Speaker: Professor F&#10;Content: Right . Right . This is then out of deference to our non - morning people .&#10;Speaker: PhD A&#10;Content: Mm - hmm ." />
    <node id="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." />
    <node id="Content: Well you s and {disfmarker} and especially you did some {disfmarker} some um , l um was a learning - based approach which learned from a big corpus of {disfmarker} of trees .&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: And yes the {disfmarker} it {disfmarker} the chunk parser was a finite - state machine that um Mark Light originally w worked on in {disfmarker} while he was in Tuebingen&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: and then somebody else in Tuebingen picked that up . So it was done in Tuebingen , yeah . Definitely .&#10;Speaker: Professor F&#10;Content: But is that the kind of thing y It sounds like the kind of thing that you were thinking of .&#10;Speaker: PhD A&#10;Content: Yeah I guess it 's similar .&#10;Speaker: Grad D&#10;Content: yeah . yeah that 's In this direction , yes&#10;Speaker: Professor F&#10;Content: What ?&#10;" />
    <node id="mm .&#10;Speaker: Grad D&#10;Content: And they also have to be very robust . cuz of um speech recognition errors and&#10;Speaker: Professor F&#10;Content: OK . So , um {disfmarker} So there was a chunk parser in Verbmobil , that was one of the uh branchers . You know they {disfmarker} d th I c There were these various uh , competing uh syntax modules . And I know one of them was a chunk parser and I don't remember {pause} who did that .&#10;Speaker: Grad B&#10;Content: A Alan ?&#10;Speaker: Grad D&#10;Content: I think it 's that might , at Tuebingen I thought .&#10;Speaker: Professor F&#10;Content: Yeah I d I don't remember .&#10;Speaker: Grad D&#10;Content: was {disfmarker} Do you know something about that ?&#10;Speaker: PhD A&#10;Content: Tubingen was at least involved in putting the chunks together&#10;Speaker: Grad D&#10;Content: In Tub - at {disfmarker}&#10;Speaker: PhD A&#10;Content: I {disfmarker} can't quite recall whether they actually produced the chunks" />
    <node id="&#10;Speaker: Grad D&#10;Content: yeah . yeah that 's In this direction , yes&#10;Speaker: Professor F&#10;Content: What ?&#10;Speaker: Grad D&#10;Content: Yeah , it 's in {disfmarker} in this direction .&#10;Speaker: Grad B&#10;Content: The {disfmarker}&#10;Speaker: Professor F&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: From Michael Strube , I 've heard very good stuff about the chunk parser that is done by FORWISS , uh , which is in embassy doing the parsing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: So this is sort of {disfmarker} came as a surprise to me that you know , embassy s {comment} is featuring a nice parser but it 's {pause} what I hear . One could also look at that and see whether there is some synergy possible .&#10;Speaker: Grad D&#10;Content: Mm - hmm , yeah , it would be very interesting , Mm - hmm . Mmm , yeah .&#10;Speaker: Grad B&#10;Content: And they 're doing chunk" />
    <node id=" {disfmarker}&#10;Speaker: PhD A&#10;Content: I {disfmarker} can't quite recall whether they actually produced the chunks in the first place .&#10;Speaker: Grad D&#10;Content: oh&#10;Speaker: Professor F&#10;Content: Uh . I see . Yeah , that 's right .&#10;Speaker: PhD A&#10;Content: Or wh&#10;Speaker: Grad D&#10;Content: Oh from {disfmarker} from Stuttgart ,&#10;Speaker: Professor F&#10;Content: There w That 's right . They w They had {disfmarker} There were {disfmarker} This was done with a two phase thing , where {comment} the chunk parser itself was pretty stupid&#10;Speaker: Grad D&#10;Content: yeah , also&#10;Speaker: Professor F&#10;Content: and then there was a kind of trying to fit them together that h used more context .&#10;Speaker: PhD A&#10;Content: Right . Yeah&#10;Speaker: Professor F&#10;Content: Right ?&#10;Speaker: PhD A&#10;Content: Well you s and {disfmarker} and especially you did some {disfmarker} some um , l um was a learning -" />
    <node id="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." />
    <node id="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience." />
    <node id="marker} I think it 's really {disfmarker} really wrong headed for something that you {disfmarker} that has a lot of state , it 's gonna interact co in a complicated way with the uh understanding parts .&#10;Speaker: Grad B&#10;Content: Yeah . Yeah I think just the {disfmarker} the spatial planner and the route planner I showed you once the interac action between them among them in the deep map system&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad B&#10;Content: so {disfmarker} a printout of the communication between those two fills up I don't know how many pages&#10;Speaker: PhD A&#10;Content: Hmm&#10;Speaker: Grad B&#10;Content: and that 's just part of how do I get to one place . It 's really insane . and uh but um so this is um definitely a good point to get uh Michael into the discussion . Or to enter his discussion , actually .&#10;Speaker: PhD A&#10;Content: Yeah , Marcus .&#10;Speaker: Grad B&#10;Content: That 's the way around . Markus&#10;Speaker: PhD A&#10;Content: Wh - where 's ?&#10;" />
    <node id=" we can at least ask that question ?&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean nothing 's being completely settled there&#10;Speaker: Grad B&#10;Content: rea yep&#10;Speaker: PhD A&#10;Content: so this is really an ongoing discussion&#10;Speaker: Grad B&#10;Content: Mm - hmm&#10;Speaker: PhD A&#10;Content: and that 's&#10;Speaker: Grad B&#10;Content: yeah and um it might actually OK ah also {disfmarker} because um again in in Deep Map we have faced and implemented those problems once already&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: maybe we can even shuffle some know how from there to to Markus and Michael .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Grad B&#10;Content: And um mmm You don't know {disfmarker} OK th I 'll {disfmarker}" />
    <node id="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart." />
    <node id="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." />
    <node id="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability." />
    <node id=" uh , Miel syntactic analysis with um finite state transducers .&#10;Speaker: Professor F&#10;Content: so But the people at D F Yeah . People at DFKI have written a fair number of parsers . Other {disfmarker} you know , people over the years . uh have written various parsers at DFKI . None of them are suitable ? I {disfmarker} I {disfmarker} I d I 'm asking . I don't know .&#10;Speaker: Grad D&#10;Content: Yeah , uh the problem is th that it has to be very fast because um if you want to for more than one path anywhere&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: what 's in the latches from the speech recognizer&#10;Speaker: Professor F&#10;Content: Mm - hmm .&#10;Speaker: Grad D&#10;Content: so it 's speed is crucial . uh And they are not fast enough .&#10;Speaker: Professor F&#10;Content: Mm - hmm .&#10;Speaker: Grad D&#10;Content: And they also have to be very robust . cuz of um speech recognition errors and&#10;Speaker:" />
    <node id=": Professor F&#10;Content: Do you have a particular parser in mind ? Is it uh {disfmarker} partic d I mean have you thought through {disfmarker} ? Is it an HPSG parser ? Is it a whatever ?&#10;Speaker: Grad D&#10;Content: No {disfmarker} no it 's {disfmarker} uh I think it 's it 's totally complicated for it 's just one {disfmarker} one person&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: and so I have to keep the {disfmarker}&#10;Speaker: Professor F&#10;Content: Oh , you have to do it . You have to do it ,&#10;Speaker: Grad D&#10;Content: Yeah ,&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: Grad D&#10;Content: ah and so {vocalsound} things must be simpler&#10;Speaker: Professor F&#10;Content: I see ,&#10;Speaker: Grad D&#10;Content: but uh , Miel syntactic analysis with um finite state transducers .&#10;Speaker: Professor F&#10;Content: so But the people at D F Yeah ." />
    <node id="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information." />
    <node id="&#10;Content: OK because That 's {disfmarker} Those are the {disfmarker} I think the {disfmarker} the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it {disfmarker} and how that is uh specified . I didn't think of the internal working of the uh the action planner and the language {disfmarker} uh the function model as sort of relevant . Because what {disfmarker} what they take is sort of this {disfmarker} this fixed representation of a {disfmarker} of an intention .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And that can be as detailed or as crude as you want it to be . But um the internal workings of of the {disfmarker} whether you know there 're dialogue {disfmarker} action planners that work with belief - nets that are action planners that work with you know state automata . So that shouldn't really matter too much . I mean it does matter because it does have to keep track of you {disfmarker" />
    <node id="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions." />
    <node id="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript." />
    <node id="aker: Grad B&#10;Content: And um mmm You don't know {disfmarker} OK th I 'll {disfmarker} I 'll talk to Michael it 's what I do anyway . Who {disfmarker} How far is the uh the {disfmarker} the M - three - L specification for {disfmarker} for the la natural language input gone on the {disfmarker} the uh I haven't seen anything for the uh tourist path domain .&#10;Speaker: Grad D&#10;Content: Yeah , it 's {disfmarker} it 's not defined yet .&#10;Speaker: Grad B&#10;Content: And um you are probably also involved in that ,&#10;Speaker: Grad D&#10;Content: Um {disfmarker} Yeah .&#10;Speaker: Grad B&#10;Content: right ? uh together with the usual gang , um Petra and Jan&#10;Speaker: Grad D&#10;Content: Mmm . Yeah , there 's a meeting next next week I think&#10;Speaker: Grad B&#10;Content: OK because That 's {disfmarker} Those are the {disfmarker} I think the {disfmarker}" />
    <node id="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." />
    <node id="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system." />
    <node id="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser." />
    <node id="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system." />
    <node id="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon." />
    <node id="&#10;Content: just about the um&#10;Speaker: PhD A&#10;Content: yeah yeah , really .&#10;Speaker: Grad B&#10;Content: First steps .&#10;Speaker: Professor F&#10;Content: Right . The {disfmarker} the construction grammar .&#10;Speaker: Grad B&#10;Content: And she 's gonna start in a minute .&#10;Speaker: Professor F&#10;Content: In a minute .&#10;Speaker: Grad D&#10;Content: Ah , OK .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: Is it i in , then , your place , in five {disfmarker} five - A ?&#10;Speaker: PhD A&#10;Content: Alright ." />
    <node id="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation." />
    <node id=" . Uh . And have you looked {disfmarker} uh just {disfmarker} again for context {disfmarker}&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: There is this {disfmarker} this one that they did at SRI some years ago {disfmarker} Fastus ?&#10;Speaker: Grad D&#10;Content: um&#10;Speaker: Professor F&#10;Content: a {disfmarker}&#10;Speaker: Grad D&#10;Content: yeah , I 've {disfmarker} I 've looked at it but {disfmarker} but it 's no {disfmarker} not much uh information available . I found ,&#10;Speaker: Professor F&#10;Content: ah !&#10;Speaker: Grad D&#10;Content: but it 's also finite - state transducers , I thought .&#10;Speaker: Professor F&#10;Content: It is . Yeah . I mean {disfmarker} it 's {disfmarker} it was pretty ambitious .&#10;Speaker: Grad D&#10;Content: and&#10;Speaker: Professor F&#10;Content: And of course it was" />
    <node id="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly." />
    <node id=" well for one thing we 're also using this room to collect data .&#10;Speaker: PhD A&#10;Content: Yeah obviously .&#10;Speaker: Grad B&#10;Content: um um Not this type of data ,&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Grad B&#10;Content: no not meeting data but sort of {disfmarker} sort ah our version of a wizard experiment such not like the ones in Munich but pretty close to it .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: The major difference to the Munich ones is that we do it via the telephone&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: even though all the recording is done here and so it 's a {disfmarker} sort of a computer call system that gives you tourist information&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: tells you how to get places . And it breaks halfway through the experiment and a human operator comes on . and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking" />
    <node id=" halfway through the experiment and a human operator comes on . and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: and we 're setting it up so that we can {disfmarker} we hope to implant certain intentions in people . For example um we have first looked at a simple sentence that &quot; How do I get to the Powder - Tower ? &quot; OK so you have the {disfmarker} castle of Heidelberg&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: and there is a tower and it 's called Powder - Tower .&#10;Speaker: PhD A&#10;Content: Oh , OK . Yeah .&#10;Speaker: Grad B&#10;Content: and um so What will you parse out of that sentence ? Probably something that we specified in M - three - L , that is @ @ {comment} &quot; action go to whatever domain , object whatever Powder - Tower &quot; .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Grad B&#10;Content: And maybe some" />
    <node id="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions." />
    <node id="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning." />
    <node id="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation." />
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target="isfmarker} you find a GIS about {disfmarker} that gives you information on Berkeley ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: and it 's {disfmarker} it 's gonna be there and tell you what it can do and how it wants to do things . and so you can actually interface to such a system without ever having met it before and the function modeler and a self - description of the um external service haggle it out&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: and you can use the same language core , understanding core to interface with planner - A , planner - B , planner - C and so forth .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Grad B&#10;Content: Which is , you know , uh {disfmarker} uh {disfmarker} utopian {disfmarker} completely utopian at the moment , but slowly , you know , getting into the realm of the uh contingent .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Grad B">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target=" eventually . So {disfmarker} wouldn't That 's an additional reason to have this well - defined interface and keep these things like uh tourist information external .&#10;Speaker: Professor F&#10;Content: Oh , yeah , yeah .&#10;Speaker: PhD A&#10;Content: And then call it external services .&#10;Speaker: Grad B&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: But of course the {disfmarker} the more complex {disfmarker}&#10;Speaker: Grad B&#10;Content: Yeah , there is another philosophical issue that I think you know you can {disfmarker} evade&#10;Speaker: PhD A&#10;Content: yep .&#10;Speaker: Grad B&#10;Content: but , at at least it makes sense to me that sooner or later uh {disfmarker} a service is gonna come and describe itself to you . and that 's sort of what Srini is working on in {disfmarker} in {disfmarker} in the DAML uh project where um you {disfmarker} you find a GIS about {disfmarker} that gives you information on Berkeley ,&#10;Speaker: PhD A&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target=" he saying ?&#10;Speaker: Grad B&#10;Content: Um , for example , right now I know the GIS from email is not able to calculate these viewpoints . So that 's a functionality that doesn't exist yet to do that dynamically ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: but if we can offer it that distinction , maybe somebody will go ahead and implement it . Surely nobody 's gonna go ahead and implement it if it 's never gonna be used , so . What have I forgotten about ? Oh yeah , how we do it ,&#10;Speaker: Professor F&#10;Content: Well th uh&#10;Speaker: Grad B&#10;Content: yeah that 's the&#10;Speaker: Professor F&#10;Content: No no . It 's a good time to pause . I s I see {pause} questions on peoples ' faces , so why don't {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh&#10;Speaker: Professor F&#10;Content: let 's {disfmarker} let 's {disfmarker} Let 's hear {disfmarker}&#10;Speaker: PhD A&#10;Content: Well the obvious">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target="er} th the word &quot; action &quot; , OK , is {disfmarker} is what 's ambiguous here .&#10;Speaker: Grad D&#10;Content: I think . Hmm .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: So , um one thing is there 's an actual planner that tells the person in the tourist domain now ,&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor F&#10;Content: per tells the person how to go , &quot; First go here ,&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: first go there uh , you know , take a bus &quot; , whatever it is . So that 's that form of planning , and action , and a route planner and GIS , all sort of stuff . uh But I think that isn't what you mean .&#10;Speaker: PhD A&#10;Content: No . No , in SmartKom terminology that 's um called a function that 's modeled by a function modeler . And it 's th that 's completely um encapsulated from th the dialogue system . That 's simply a functionality that you give data as in">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target="Content: Yes , very much so .&#10;Speaker: Grad D&#10;Content: Yeah , very much&#10;Speaker: Professor F&#10;Content: OK , before {disfmarker} before you got put to work ?&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Great . OK , so that 's {disfmarker} Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: and we can d I dunno w w was there uh a time when we were set up to do that ? It probably will work better if we do it later in the week , after {pause} we actually understand uh better what 's going on .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target=" a bank ? Is it a s town square , is it a statue ? Whatever . So all that kind of information could be combined into decision networks and give you decisions . But the other half of the problem is How would you get that kind of information from the parsed input ? So , um So what you might try to do is just build more templates , saying uh we 're trying to build a templ you know build a template that w uh somehow would capture the fact that he wants to take a picture .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK ? And {disfmarker} and we could {disfmarker} you could do this . And it 's a small enough domain that probably you , you know {disfmarker}&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK . You could do this . But uh from our point of view this is also a research project and there are a couple of people not here for various reasons who are doing doctoral dissertations on this ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and the">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A GIS (Geographic Information System) for Berkeley exists and provides information.&#10;2. It has certain functionalities, but not all functionalities are available yet, such as calculating viewpoints dynamically.&#10;3. The system can be interfaced with using a standard language core, which would allow for interaction with various planners (e.g., planner A, planner B, etc.) in a consistent manner.&#10;4. Although the idea of services describing themselves to users is currently utopian, there are ongoing projects and efforts to make this a reality, such as the DAML project. This would enable automatic implementation of new functionalities based on user needs." target="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience.">
      <data key="d0">1</data>
    </edge>
    <edge source=" eventually . So {disfmarker} wouldn't That 's an additional reason to have this well - defined interface and keep these things like uh tourist information external .&#10;Speaker: Professor F&#10;Content: Oh , yeah , yeah .&#10;Speaker: PhD A&#10;Content: And then call it external services .&#10;Speaker: Grad B&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: But of course the {disfmarker} the more complex {disfmarker}&#10;Speaker: Grad B&#10;Content: Yeah , there is another philosophical issue that I think you know you can {disfmarker} evade&#10;Speaker: PhD A&#10;Content: yep .&#10;Speaker: Grad B&#10;Content: but , at at least it makes sense to me that sooner or later uh {disfmarker} a service is gonna come and describe itself to you . and that 's sort of what Srini is working on in {disfmarker} in {disfmarker} in the DAML uh project where um you {disfmarker} you find a GIS about {disfmarker} that gives you information on Berkeley ,&#10;Speaker: PhD A&#10;Content:" target="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} th the word &quot; action &quot; , OK , is {disfmarker} is what 's ambiguous here .&#10;Speaker: Grad D&#10;Content: I think . Hmm .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: So , um one thing is there 's an actual planner that tells the person in the tourist domain now ,&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor F&#10;Content: per tells the person how to go , &quot; First go here ,&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: first go there uh , you know , take a bus &quot; , whatever it is . So that 's that form of planning , and action , and a route planner and GIS , all sort of stuff . uh But I think that isn't what you mean .&#10;Speaker: PhD A&#10;Content: No . No , in SmartKom terminology that 's um called a function that 's modeled by a function modeler . And it 's th that 's completely um encapsulated from th the dialogue system . That 's simply a functionality that you give data as in" target="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} th the word &quot; action &quot; , OK , is {disfmarker} is what 's ambiguous here .&#10;Speaker: Grad D&#10;Content: I think . Hmm .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: So , um one thing is there 's an actual planner that tells the person in the tourist domain now ,&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor F&#10;Content: per tells the person how to go , &quot; First go here ,&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: first go there uh , you know , take a bus &quot; , whatever it is . So that 's that form of planning , and action , and a route planner and GIS , all sort of stuff . uh But I think that isn't what you mean .&#10;Speaker: PhD A&#10;Content: No . No , in SmartKom terminology that 's um called a function that 's modeled by a function modeler . And it 's th that 's completely um encapsulated from th the dialogue system . That 's simply a functionality that you give data as in" target="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Yes , very much so .&#10;Speaker: Grad D&#10;Content: Yeah , very much&#10;Speaker: Professor F&#10;Content: OK , before {disfmarker} before you got put to work ?&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Great . OK , so that 's {disfmarker} Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: and we can d I dunno w w was there uh a time when we were set up to do that ? It probably will work better if we do it later in the week , after {pause} we actually understand uh better what 's going on .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're" target="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Yes , very much so .&#10;Speaker: Grad D&#10;Content: Yeah , very much&#10;Speaker: Professor F&#10;Content: OK , before {disfmarker} before you got put to work ?&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Great . OK , so that 's {disfmarker} Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: and we can d I dunno w w was there uh a time when we were set up to do that ? It probably will work better if we do it later in the week , after {pause} we actually understand uh better what 's going on .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're" target="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Yes , very much so .&#10;Speaker: Grad D&#10;Content: Yeah , very much&#10;Speaker: Professor F&#10;Content: OK , before {disfmarker} before you got put to work ?&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Great . OK , so that 's {disfmarker} Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: and we can d I dunno w w was there uh a time when we were set up to do that ? It probably will work better if we do it later in the week , after {pause} we actually understand uh better what 's going on .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're" target="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target=" dialogue manager .&#10;Speaker: Professor F&#10;Content: Yeah&#10;Speaker: PhD A&#10;Content: um is based on slots that have to be filled and the um kind of values in these slots would be fixed things like the a time or a movie title or something like this&#10;Speaker: Professor F&#10;Content: Mm - hmm . Right .&#10;Speaker: PhD A&#10;Content: whereas in the a um tourist domain it might be an entire route . Set - based , or even very complex structured information in these slots&#10;Speaker: Professor F&#10;Content: Indeed . Right .&#10;Speaker: PhD A&#10;Content: and I 'm not sure if {disfmarker} if complex slots of that type are really um being taken into consideration .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: So that 's {disfmarker} that 's really something we&#10;Speaker: Professor F&#10;Content: Could you {disfmarker} could you put a message into the right place to see if we can at least ask that question ?&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target=" you know you {disfmarker} are you planning to enter ? Or whatever it {disfmarker} whatever that might be . So that 's {disfmarker} under that model then , There would be a {disfmarker} uh {disfmarker} um a loop in which this thing would formulate a query ,&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: presumably give it to you . That would get expressed and then hopefully you know , you 'd get an answer {pause} back .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Professor F&#10;Content: And that would of course {disfmarker} the answer would have to be parsed .&#10;Speaker: Grad D&#10;Content: Mmm . Yep .&#10;Speaker: Professor F&#10;Content: right and {disfmarker}&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Professor F&#10;Content: OK so , {pause} th {pause} that uh , We probably won't do this early on , because the current focus is more on the decision making and stuff like that .&#10;Speaker: PhD A&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target=" right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and there will be additional situational information .&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Professor F&#10;Content: Uh , OK ,&#10;Speaker: PhD A&#10;Content: th&#10;Speaker: Professor F&#10;Content: part of it comes from the ontology . The tower is this kind of object .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yeah , OK .&#10;Speaker: Professor F&#10;Content: Part of it comes from the user model .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And the idea of the belief - net is it combines the information from the dialogue which comes across in this general way ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: you know this is a {disfmarker} this is a goal seeking behavior , along with specific information from the ontology about the kinds of objects">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target=" question&#10;Speaker: PhD A&#10;Content: hmm&#10;Speaker: Grad B&#10;Content: whether we 're {disfmarker} we 're gonna stick to Prolog or not .&#10;Speaker: PhD A&#10;Content: No . No , that 's gonna be phased out .&#10;Speaker: Professor F&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK But I do think the {disfmarker} the function modeling concept has a certain {disfmarker} makes sense in a {disfmarker} in a certain light&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: because the action planner should not be {disfmarker} or the dialogue manager in that case should not um w have to worry about whether it 's interfacing with um something that does route planning in this way or that way&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: I I totally agree .&#10;Speaker: Grad B&#10;Content: huh ,&#10;Speaker: Professor F&#10;Content: Sure .&#10;Speaker: Grad B&#10;Content: it j&#10;Speaker: Professor">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target=": PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: But , uh th the current design suggests that if it seems to be an important decision and if the belief - net is equivocal so that it doesn't say that one of these is much more probable than the other , then an option is to go back and ask for the information you want .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: Alright ? Now there are two ways one can go {disfmarker} a imagine doing that . For the debugging we 'll probably just have a {disfmarker} a drop - down menu and the {disfmarker} while you 're debugging you will just {disfmarker} OK . But for a full system , then one might very well formulate a query ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: give it to the dialogue planner and say this , you know ar are you know you {disfmarker} are you planning to enter ? Or whatever it {disfmarker} whatever that might be . So that '">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target=" to happen .&#10;Speaker: Grad B&#10;Content: a lot of , yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: If {disfmarker} if you know if {disfmarker} if you can't make it happen then you {disfmarker} you do your best .&#10;Speaker: PhD A&#10;Content: Yeah but that doesn't necessarily contradict um an architecture where there really is a pers a def well - defined interface . and {disfmarker} and&#10;Speaker: Professor F&#10;Content: I totally agree . But {disfmarker} but what it nee but th what the point is the in that case the dialogue manager is sort of event driven . So the dialogue manager may think it 's in a dialogue state of one sort ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and this {disfmarker} one of these planning modules comes along and says &quot; hey , right now we need to ask a question &quot; . So that forces the dialogue manager to change state .&#10;Speaker: PhD A&#10;Content: Yes&#10;Speaker: Professor F">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are considering an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries. They also mention the possibility of using a well-defined interface for different planning modules, which could allow for more flexibility and event-driven state changes in the dialogue manager." target="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" dialogue manager .&#10;Speaker: Professor F&#10;Content: Yeah&#10;Speaker: PhD A&#10;Content: um is based on slots that have to be filled and the um kind of values in these slots would be fixed things like the a time or a movie title or something like this&#10;Speaker: Professor F&#10;Content: Mm - hmm . Right .&#10;Speaker: PhD A&#10;Content: whereas in the a um tourist domain it might be an entire route . Set - based , or even very complex structured information in these slots&#10;Speaker: Professor F&#10;Content: Indeed . Right .&#10;Speaker: PhD A&#10;Content: and I 'm not sure if {disfmarker} if complex slots of that type are really um being taken into consideration .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: So that 's {disfmarker} that 's really something we&#10;Speaker: Professor F&#10;Content: Could you {disfmarker} could you put a message into the right place to see if we can at least ask that question ?&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content:" target="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain.">
      <data key="d0">1</data>
    </edge>
    <edge source=" right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and there will be additional situational information .&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Professor F&#10;Content: Uh , OK ,&#10;Speaker: PhD A&#10;Content: th&#10;Speaker: Professor F&#10;Content: part of it comes from the ontology . The tower is this kind of object .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yeah , OK .&#10;Speaker: Professor F&#10;Content: Part of it comes from the user model .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And the idea of the belief - net is it combines the information from the dialogue which comes across in this general way ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: you know this is a {disfmarker} this is a goal seeking behavior , along with specific information from the ontology about the kinds of objects" target="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires.">
      <data key="d0">1</data>
    </edge>
    <edge source=" question&#10;Speaker: PhD A&#10;Content: hmm&#10;Speaker: Grad B&#10;Content: whether we 're {disfmarker} we 're gonna stick to Prolog or not .&#10;Speaker: PhD A&#10;Content: No . No , that 's gonna be phased out .&#10;Speaker: Professor F&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK But I do think the {disfmarker} the function modeling concept has a certain {disfmarker} makes sense in a {disfmarker} in a certain light&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: because the action planner should not be {disfmarker} or the dialogue manager in that case should not um w have to worry about whether it 's interfacing with um something that does route planning in this way or that way&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: I I totally agree .&#10;Speaker: Grad B&#10;Content: huh ,&#10;Speaker: Professor F&#10;Content: Sure .&#10;Speaker: Grad B&#10;Content: it j&#10;Speaker: Professor" target="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" question&#10;Speaker: PhD A&#10;Content: hmm&#10;Speaker: Grad B&#10;Content: whether we 're {disfmarker} we 're gonna stick to Prolog or not .&#10;Speaker: PhD A&#10;Content: No . No , that 's gonna be phased out .&#10;Speaker: Professor F&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK But I do think the {disfmarker} the function modeling concept has a certain {disfmarker} makes sense in a {disfmarker} in a certain light&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: because the action planner should not be {disfmarker} or the dialogue manager in that case should not um w have to worry about whether it 's interfacing with um something that does route planning in this way or that way&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: I I totally agree .&#10;Speaker: Grad B&#10;Content: huh ,&#10;Speaker: Professor F&#10;Content: Sure .&#10;Speaker: Grad B&#10;Content: it j&#10;Speaker: Professor" target="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning.">
      <data key="d0">1</data>
    </edge>
    <edge source=" question&#10;Speaker: PhD A&#10;Content: hmm&#10;Speaker: Grad B&#10;Content: whether we 're {disfmarker} we 're gonna stick to Prolog or not .&#10;Speaker: PhD A&#10;Content: No . No , that 's gonna be phased out .&#10;Speaker: Professor F&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: OK But I do think the {disfmarker} the function modeling concept has a certain {disfmarker} makes sense in a {disfmarker} in a certain light&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: because the action planner should not be {disfmarker} or the dialogue manager in that case should not um w have to worry about whether it 's interfacing with um something that does route planning in this way or that way&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: I I totally agree .&#10;Speaker: Grad B&#10;Content: huh ,&#10;Speaker: Professor F&#10;Content: Sure .&#10;Speaker: Grad B&#10;Content: it j&#10;Speaker: Professor" target="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" to happen .&#10;Speaker: Grad B&#10;Content: a lot of , yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: If {disfmarker} if you know if {disfmarker} if you can't make it happen then you {disfmarker} you do your best .&#10;Speaker: PhD A&#10;Content: Yeah but that doesn't necessarily contradict um an architecture where there really is a pers a def well - defined interface . and {disfmarker} and&#10;Speaker: Professor F&#10;Content: I totally agree . But {disfmarker} but what it nee but th what the point is the in that case the dialogue manager is sort of event driven . So the dialogue manager may think it 's in a dialogue state of one sort ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and this {disfmarker} one of these planning modules comes along and says &quot; hey , right now we need to ask a question &quot; . So that forces the dialogue manager to change state .&#10;Speaker: PhD A&#10;Content: Yes&#10;Speaker: Professor F" target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target=" information&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: so it would be a full foreign lexicon .&#10;Speaker: Professor F&#10;Content: And that 's what you have .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: We threw out all the forms .&#10;Speaker: Professor F&#10;Content: What {disfmarker} uh I didn't reme&#10;Speaker: Grad B&#10;Content: We threw out all the forms&#10;Speaker: Professor F&#10;Content: Huh ?&#10;Speaker: Grad B&#10;Content: because , you know , English , well {disfmarker}&#10;Speaker: Professor F&#10;Content: Oh OK , so it {disfmarker} yeah , s s I thought I 'd {disfmarker}&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So in German then you actually do case">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target=" um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah , but {disfmarker} but it 's used for {disfmarker} for stem forms .&#10;Speaker: Professor F&#10;Content: So w wha&#10;Speaker: PhD A&#10;Content: n Well I think {disfmarker} I think there 's some misunderstanding here&#10;Speaker: Professor F&#10;Content: i&#10;Speaker: PhD A&#10;Content: it 's {disfmarker} Morphix is not used on - line .&#10;Speaker: Grad D&#10;Content: Oh , OK .&#10;Speaker: PhD A&#10;Content: s so the lexicon might be derived by Morphix&#10;Speaker: Grad D&#10;Content: What ?&#10;Speaker: PhD A&#10;Content: but What {disfmarker} what 's happening on - line is just um um a {disfmarker} a retrieval from the lexicon which would give all the stemming information&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: Professor F&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target="&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So in German then you actually do case matching and things like in the {disfmarker} in the pattern matcher or not ?&#10;Speaker: Grad D&#10;Content: um Not yet but it 's planned to do that .&#10;Speaker: Professor F&#10;Content: OK . Cuz I r I didn't reme I didn't think I saw it .&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: Have we looked at the German ? Oh , I haven yeah that 's {disfmarker} getting it from the lexicon is just fine .&#10;Speaker: PhD A&#10;Content: Sure , right .&#10;Speaker: Grad D&#10;Content: Oh yes .&#10;Speaker: Professor F&#10;Content: Yeah , yeah , yeah . No problem with that . um Yeah and here 's the case where the English and the German might really be significantly different . In terms of if you 're trying to build some fast parser and so forth and {disfmarker} You really might wanna do it in a significantly different way . I don't know .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target="&#10;Speaker: Professor F&#10;Content: So y you just connect to the lexicon&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: and uh at least for German you have all {disfmarker} all of the {disfmarker} uh the stemming information .&#10;Speaker: Grad D&#10;Content: Yeah , we can , oh yeah . We have knowledge bases from {disfmarker} from Verbmobil system we can use&#10;Speaker: Professor F&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: and so .&#10;Speaker: Professor F&#10;Content: Right . But it {disfmarker} it {disfmarker} it doesn't look like i you 're using it . I didn't n see it being used in the current template uh parser . I {disfmarker} I didn't see any Uh {disfmarker} of course we l actually only looked at the English .&#10;Speaker: Grad D&#10;Content: It {disfmarker} um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target="marker} it was pretty ambitious .&#10;Speaker: Grad D&#10;Content: and&#10;Speaker: Professor F&#10;Content: And of course it was English oriented ,&#10;Speaker: Grad D&#10;Content: Yeah , and {disfmarker} and Purely finite - state transducers are not so good for German since there 's um&#10;Speaker: Professor F&#10;Content: um w Right .&#10;Speaker: Grad D&#10;Content: The word order is {disfmarker} is uh not fixed&#10;Speaker: Professor F&#10;Content: Yeah , I guess that 's the point is {disfmarker} is all the morphology and stuff . And English is all th all word order . And it makes a lot more sense .&#10;Speaker: Grad D&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: And {disfmarker} e Yeah , OK . Good point . So in {disfmarker} in {disfmarker} in German you 've got uh most of this done with&#10;Speaker: Grad D&#10;Content: Mm - hmm . Also it 's uh {disfmarker} it 's um {disfmarker} Yes">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target=" to build some fast parser and so forth and {disfmarker} You really might wanna do it in a significantly different way . I don't know . So you 've {disfmarker} you guys have looked at this ? also ? in terms of You know , w if you 're doing this for English as well as German Um Do you think now that it would be this {disfmarker} doing it similarly ?&#10;Speaker: Grad D&#10;Content: um Yeah , it 's um I think it 's um yes , it 's {disfmarker} it 's um possible to {disfmarker} to do list processing . and Maybe this is um more adequate for English and in German um set processing is used .&#10;Speaker: Professor F&#10;Content: Set .&#10;Speaker: Grad D&#10;Content: Maybe yeah . Some extensions uh have to be made . For {disfmarker} for a English version&#10;Speaker: Professor F&#10;Content: Mmm . OK . Interesting . Not easy .&#10;Speaker: Grad B&#10;Content: Well there 's m I 'm sure there 's gonna be more discussion on that after your talk .&#10;Speaker: Grad D">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated what &quot;forms&quot; they threw out. However, from the context of the conversation, it seems that they were discussing the use of a lexicon and stemming information in natural language processing. Specifically, they mentioned that in the language they were working with, they discarded all the forms, but in German, such information is preserved in the lexicon.&#10;&#10;The reason for this difference might be due to the nature of the languages themselves. As implied in the conversation, English has relatively fixed word order, and much of its grammar can be determined by the position of words in a sentence. On the other hand, German has more flexible word order and relies heavily on morphological cues such as case endings to convey grammatical information. Therefore, preserving stemming information and case matching in the lexicon is more important for processing German than English.&#10;&#10;In summary, while it is not explicitly stated what forms they threw out, it can be inferred from the context that they discarded some form of morphological or grammatical information that was less critical for English but essential for German. The reason for this difference lies in the structural characteristics of each language." target="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser.">
      <data key="d0">1</data>
    </edge>
    <edge source=" information&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: so it would be a full foreign lexicon .&#10;Speaker: Professor F&#10;Content: And that 's what you have .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: We threw out all the forms .&#10;Speaker: Professor F&#10;Content: What {disfmarker} uh I didn't reme&#10;Speaker: Grad B&#10;Content: We threw out all the forms&#10;Speaker: Professor F&#10;Content: Huh ?&#10;Speaker: Grad B&#10;Content: because , you know , English , well {disfmarker}&#10;Speaker: Professor F&#10;Content: Oh OK , so it {disfmarker} yeah , s s I thought I 'd {disfmarker}&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So in German then you actually do case" target="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah , but {disfmarker} but it 's used for {disfmarker} for stem forms .&#10;Speaker: Professor F&#10;Content: So w wha&#10;Speaker: PhD A&#10;Content: n Well I think {disfmarker} I think there 's some misunderstanding here&#10;Speaker: Professor F&#10;Content: i&#10;Speaker: PhD A&#10;Content: it 's {disfmarker} Morphix is not used on - line .&#10;Speaker: Grad D&#10;Content: Oh , OK .&#10;Speaker: PhD A&#10;Content: s so the lexicon might be derived by Morphix&#10;Speaker: Grad D&#10;Content: What ?&#10;Speaker: PhD A&#10;Content: but What {disfmarker} what 's happening on - line is just um um a {disfmarker} a retrieval from the lexicon which would give all the stemming information&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: Professor F&#10;Content:" target="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor F&#10;Content: So y you just connect to the lexicon&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: and uh at least for German you have all {disfmarker} all of the {disfmarker} uh the stemming information .&#10;Speaker: Grad D&#10;Content: Yeah , we can , oh yeah . We have knowledge bases from {disfmarker} from Verbmobil system we can use&#10;Speaker: Professor F&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: and so .&#10;Speaker: Professor F&#10;Content: Right . But it {disfmarker} it {disfmarker} it doesn't look like i you 're using it . I didn't n see it being used in the current template uh parser . I {disfmarker} I didn't see any Uh {disfmarker} of course we l actually only looked at the English .&#10;Speaker: Grad D&#10;Content: It {disfmarker} um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah" target="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Professor F&#10;Content: So y you just connect to the lexicon&#10;Speaker: Grad D&#10;Content: Yeah&#10;Speaker: Professor F&#10;Content: and uh at least for German you have all {disfmarker} all of the {disfmarker} uh the stemming information .&#10;Speaker: Grad D&#10;Content: Yeah , we can , oh yeah . We have knowledge bases from {disfmarker} from Verbmobil system we can use&#10;Speaker: Professor F&#10;Content: Yep .&#10;Speaker: Grad D&#10;Content: and so .&#10;Speaker: Professor F&#10;Content: Right . But it {disfmarker} it {disfmarker} it doesn't look like i you 're using it . I didn't n see it being used in the current template uh parser . I {disfmarker} I didn't see any Uh {disfmarker} of course we l actually only looked at the English .&#10;Speaker: Grad D&#10;Content: It {disfmarker} um&#10;Speaker: Professor F&#10;Content: Did we look at the German ? I don't remember .&#10;Speaker: Grad D&#10;Content: Yeah" target="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} it was pretty ambitious .&#10;Speaker: Grad D&#10;Content: and&#10;Speaker: Professor F&#10;Content: And of course it was English oriented ,&#10;Speaker: Grad D&#10;Content: Yeah , and {disfmarker} and Purely finite - state transducers are not so good for German since there 's um&#10;Speaker: Professor F&#10;Content: um w Right .&#10;Speaker: Grad D&#10;Content: The word order is {disfmarker} is uh not fixed&#10;Speaker: Professor F&#10;Content: Yeah , I guess that 's the point is {disfmarker} is all the morphology and stuff . And English is all th all word order . And it makes a lot more sense .&#10;Speaker: Grad D&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: And {disfmarker} e Yeah , OK . Good point . So in {disfmarker} in {disfmarker} in German you 've got uh most of this done with&#10;Speaker: Grad D&#10;Content: Mm - hmm . Also it 's uh {disfmarker} it 's um {disfmarker} Yes" target="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" to build some fast parser and so forth and {disfmarker} You really might wanna do it in a significantly different way . I don't know . So you 've {disfmarker} you guys have looked at this ? also ? in terms of You know , w if you 're doing this for English as well as German Um Do you think now that it would be this {disfmarker} doing it similarly ?&#10;Speaker: Grad D&#10;Content: um Yeah , it 's um I think it 's um yes , it 's {disfmarker} it 's um possible to {disfmarker} to do list processing . and Maybe this is um more adequate for English and in German um set processing is used .&#10;Speaker: Professor F&#10;Content: Set .&#10;Speaker: Grad D&#10;Content: Maybe yeah . Some extensions uh have to be made . For {disfmarker} for a English version&#10;Speaker: Professor F&#10;Content: Mmm . OK . Interesting . Not easy .&#10;Speaker: Grad B&#10;Content: Well there 's m I 'm sure there 's gonna be more discussion on that after your talk .&#10;Speaker: Grad D" target="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" to build some fast parser and so forth and {disfmarker} You really might wanna do it in a significantly different way . I don't know . So you 've {disfmarker} you guys have looked at this ? also ? in terms of You know , w if you 're doing this for English as well as German Um Do you think now that it would be this {disfmarker} doing it similarly ?&#10;Speaker: Grad D&#10;Content: um Yeah , it 's um I think it 's um yes , it 's {disfmarker} it 's um possible to {disfmarker} to do list processing . and Maybe this is um more adequate for English and in German um set processing is used .&#10;Speaker: Professor F&#10;Content: Set .&#10;Speaker: Grad D&#10;Content: Maybe yeah . Some extensions uh have to be made . For {disfmarker} for a English version&#10;Speaker: Professor F&#10;Content: Mmm . OK . Interesting . Not easy .&#10;Speaker: Grad B&#10;Content: Well there 's m I 'm sure there 's gonna be more discussion on that after your talk .&#10;Speaker: Grad D" target="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires." target="aker: Grad B&#10;Content: OK , geometric center . But what we actually observed in Heidelberg is that most people when they want to go there they actually don't want to enter , because it 's not really interesting . They wanna go to a completely different point where they can look at it and take a picture .&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And so what uh uh a s you s let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . Does he wanna go there to see it ? Does he wanna go there now ? Later ? How does the person wanna go there ? Is that person more likely to want to walk there ? Walk a scenic route ? and so forth . There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . And we are constructing {disfmarker} and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to">
      <data key="d0">1</data>
    </edge>
    <edge source="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires." target="er} and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to the situation . And we also want to look closely on the linguistic information that what we can get from the utterance . That 's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it . And um so the idea is to construct uh um suitable interfaces and a belief - net for a module that actually tries to guess what the underlying intention {pause} was . And then enrich or augment the M - three - L structures with what it thought what more it sort of got out of that utterance . So if it can make a good suggestion , &quot; Hey ! &quot; you know , &quot; that person doesn't wanna enter . That person just wants to take a picture , &quot; cuz he just bought film , or &quot; that person wants to enter because he discussed the admission fee before &quot; . Or &quot; that person wants to enter because he wants to buy something and that you usually do inside of buildings &quot; and so forth . These ah these types of uh these bits of additional information">
      <data key="d0">1</data>
    </edge>
    <edge source="1. User's preferences: Understanding the user's interests and habits can help determine whether they want to enter a location or simply view it from the outside, take a picture, or buy something. This information can be gathered through a user model.&#10;2. Context: The situation and circumstances in which the person is making the request can also provide clues about their intentions. For example, if they have previously discussed admission fees, it may indicate that they want to enter the building. Similarly, if they have bought film, this suggests they plan to take pictures and therefore do not need to enter the location.&#10;3. Ontology: Information about the types of objects and locations can also help infer a person's intentions. For instance, knowing that a tower is an outdoor structure might suggest that someone wants to take a picture of it rather than enter it.&#10;4. Belief network: A belief network can combine information from the dialogue, ontology, and user model to formulate and answer queries more accurately by considering all relevant factors.&#10;5. Interfaces and planning modules: A well-defined interface for different planning modules can allow for more flexibility and event-driven state changes in the dialogue manager, improving its ability to understand a person's intentions and desires." target="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: Grad B&#10;Content: OK , geometric center . But what we actually observed in Heidelberg is that most people when they want to go there they actually don't want to enter , because it 's not really interesting . They wanna go to a completely different point where they can look at it and take a picture .&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And so what uh uh a s you s let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . Does he wanna go there to see it ? Does he wanna go there now ? Later ? How does the person wanna go there ? Is that person more likely to want to walk there ? Walk a scenic route ? and so forth . There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . And we are constructing {disfmarker} and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to" target="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to the situation . And we also want to look closely on the linguistic information that what we can get from the utterance . That 's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it . And um so the idea is to construct uh um suitable interfaces and a belief - net for a module that actually tries to guess what the underlying intention {pause} was . And then enrich or augment the M - three - L structures with what it thought what more it sort of got out of that utterance . So if it can make a good suggestion , &quot; Hey ! &quot; you know , &quot; that person doesn't wanna enter . That person just wants to take a picture , &quot; cuz he just bought film , or &quot; that person wants to enter because he discussed the admission fee before &quot; . Or &quot; that person wants to enter because he wants to buy something and that you usually do inside of buildings &quot; and so forth . These ah these types of uh these bits of additional information" target="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target=": Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're here through Sunday ,&#10;Speaker: Grad D&#10;Content: Oh&#10;Speaker: PhD A&#10;Content: so All through Friday would be fine .&#10;Speaker: Professor F&#10;Content: Oh , OK , so {disfmarker} OK , So {disfmarker} so anyt we 'll find a time later in the week to uh get together and talk about {pause} your understanding of what SmartKom plans are .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and how we can change them .&#10;Speaker: PhD A&#10;Content: Yes . Sure .&#10;Speaker: Professor F&#10;Content: Uh ,&#10;Speaker: Grad B&#10;Content: Should we already set a date for that ? Might be beneficial while we 're all here .&#10;Speaker: Professor F&#10;Content: OK ? um What {disfmarker} what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or {pause} um {pause} most">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target=" probably won't do this early on , because the current focus is more on the decision making and stuff like that .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Professor F&#10;Content: But While we 're on the subject I just wanted to give you a sort of head 's up that it could be that some months from now we said &quot; OK we 're now ready to try to close that loop &quot; in terms of querying about some of these decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yep . So {disfmarker} my suggestion then is that you um look into the currently ongoing discussion about how the action plans are supposed to look like . And they 're currently um Agreeing or {disfmarker} or in the process of agreeing on an X M L - ification of um something like a state - transition network of how dialogues would proceed . and {disfmarker} The {disfmarker} these um transition networks uh will be what the action planner interprets in a sense .&#10;Speaker: Professor">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target=" Yeah .&#10;Speaker: PhD A&#10;Content: And then it would be available to action planning and {disfmarker} and others .&#10;Speaker: Grad B&#10;Content: Yeah . the {disfmarker}&#10;Speaker: Professor F&#10;Content: let 's {disfmarker} let 's That w OK that was one question . Is there other {disfmarker} other things that cuz {pause} we wanna not Pa - pass over any {pause} you know , questions or concerns that you have .&#10;Speaker: PhD A&#10;Content: Well there 're {disfmarker} there 're two levels of {disfmarker} of giving an answer and I guess on both levels I don't have any um further questions .&#10;Speaker: Grad D&#10;Content: Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: uh the {disfmarker} the two levels will be as far as I 'm concerned as {pause} uh standing here for the generation module&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: and the other is {disfmarker} is my understanding of what">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target=" .&#10;Speaker: PhD A&#10;Content: Beyond what 's currently being implemented which is just word lists .&#10;Speaker: Professor F&#10;Content: Yeah , but this is not the st this is not just the state of the discourse .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Of {disfmarker} of special interest .&#10;Speaker: Professor F&#10;Content: This is actually the state of the plan . That 's why&#10;Speaker: PhD A&#10;Content: Yes , Yes , Mm - hmm yeah .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: OK so it {disfmarker} z and s uh , It 's great if people are already taking that into account . But One would have t have to see {disfmarker} see the details .&#10;Speaker: PhD A&#10;Content: The specifics aren't really there yet . Yes . So , there 's work to do there .&#10;Speaker: Professor F&#10;Content: Yeah . So anyway , Robert , that 's why I was thinking that&#10;Speaker: Grad B&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it seems that Grad D and PhD A are available to discuss updates and plans related to the project throughout the week, with the exception of Thursday afternoon. Professor F suggests setting a time later in the week to ensure that everyone has a better understanding of the situation before discussing changes to the plans. However, no specific date or time is set during the conversation. Therefore, the exact date and time for this discussion have not been determined in the transcript." target="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're here through Sunday ,&#10;Speaker: Grad D&#10;Content: Oh&#10;Speaker: PhD A&#10;Content: so All through Friday would be fine .&#10;Speaker: Professor F&#10;Content: Oh , OK , so {disfmarker} OK , So {disfmarker} so anyt we 'll find a time later in the week to uh get together and talk about {pause} your understanding of what SmartKom plans are .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and how we can change them .&#10;Speaker: PhD A&#10;Content: Yes . Sure .&#10;Speaker: Professor F&#10;Content: Uh ,&#10;Speaker: Grad B&#10;Content: Should we already set a date for that ? Might be beneficial while we 're all here .&#10;Speaker: Professor F&#10;Content: OK ? um What {disfmarker} what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or {pause} um {pause} most" target="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Yeah .&#10;Speaker: Professor F&#10;Content: So when do you guys leave ?&#10;Speaker: PhD A&#10;Content: Um we 're here through Sunday ,&#10;Speaker: Grad D&#10;Content: Oh&#10;Speaker: PhD A&#10;Content: so All through Friday would be fine .&#10;Speaker: Professor F&#10;Content: Oh , OK , so {disfmarker} OK , So {disfmarker} so anyt we 'll find a time later in the week to uh get together and talk about {pause} your understanding of what SmartKom plans are .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and how we can change them .&#10;Speaker: PhD A&#10;Content: Yes . Sure .&#10;Speaker: Professor F&#10;Content: Uh ,&#10;Speaker: Grad B&#10;Content: Should we already set a date for that ? Might be beneficial while we 're all here .&#10;Speaker: Professor F&#10;Content: OK ? um What {disfmarker} what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or {pause} um {pause} most" target="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" probably won't do this early on , because the current focus is more on the decision making and stuff like that .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Professor F&#10;Content: But While we 're on the subject I just wanted to give you a sort of head 's up that it could be that some months from now we said &quot; OK we 're now ready to try to close that loop &quot; in terms of querying about some of these decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Yep . So {disfmarker} my suggestion then is that you um look into the currently ongoing discussion about how the action plans are supposed to look like . And they 're currently um Agreeing or {disfmarker} or in the process of agreeing on an X M L - ification of um something like a state - transition network of how dialogues would proceed . and {disfmarker} The {disfmarker} these um transition networks uh will be what the action planner interprets in a sense .&#10;Speaker: Professor" target="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Yeah .&#10;Speaker: PhD A&#10;Content: And then it would be available to action planning and {disfmarker} and others .&#10;Speaker: Grad B&#10;Content: Yeah . the {disfmarker}&#10;Speaker: Professor F&#10;Content: let 's {disfmarker} let 's That w OK that was one question . Is there other {disfmarker} other things that cuz {pause} we wanna not Pa - pass over any {pause} you know , questions or concerns that you have .&#10;Speaker: PhD A&#10;Content: Well there 're {disfmarker} there 're two levels of {disfmarker} of giving an answer and I guess on both levels I don't have any um further questions .&#10;Speaker: Grad D&#10;Content: Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: uh the {disfmarker} the two levels will be as far as I 'm concerned as {pause} uh standing here for the generation module&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: and the other is {disfmarker} is my understanding of what" target="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="er} a dialogue manager . cuz that 's what everybody else calls it .&#10;Speaker: Professor F&#10;Content: I would think ,&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: Huh ? So , s So what would happen if we sent a note saying &quot; Gee we 've talked about this and couldn't we change this uh th the whole word ? &quot; I have no idea how complicated these things are .&#10;Speaker: Grad B&#10;Content: Probably close to impossible .&#10;Speaker: PhD A&#10;Content: Depends on who you talk to how . We 'll see . I 'll go check , cause I completely agree . Yeah ,&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: and I think this is just for historical reasons within uh , the preparation phase of the project and not because somebody actually believes it ought to be action planner . So if there is resistance against changing it , that 's just because &quot; Oh , We don't want to change things . &quot; That {disfmarker} that">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target=" to be able to have um an expressive power that can deal with these structures . And not just um say um {disfmarker} um the dialogue um will consist of ten possible states and th these states really are fixed in {disfmarker} in a certain sense .&#10;Speaker: Professor F&#10;Content: Hmm ?&#10;Speaker: PhD A&#10;Content: You have to {disfmarker}&#10;Speaker: Professor F&#10;Content: Would there be any chance of getting the terminology changed so that the dialogue planner was called a &quot; dialogue planner &quot; ? Because there 's this other thing The o There 's this other thing in {disfmarker} in the tourist domain which is gonna be a route planner&#10;Speaker: PhD A&#10;Content: That 'd be nice .&#10;Speaker: Professor F&#10;Content: or {disfmarker} It 's really gonna be an action planner . And {comment} i it {disfmarker}&#10;Speaker: PhD A&#10;Content: It oughta be called a {disfmarker} a dialogue manager . cuz that 's what everybody else calls it .&#10;Speaker: Professor F&#10;Content: I would think ,&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers suggest changing the terminology of &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager.&quot; They propose this change because the term &quot;dialogue planner&quot; is currently used in the tourist domain for a route planner, which can cause confusion. Additionally, they believe that using the term &quot;action planner&quot; or &quot;dialogue manager&quot; would be more appropriate since these components will handle decision-making and goal-oriented behaviors, as well as interfacing with different planning modules. However, it is also mentioned that there might be ambiguity regarding the word &quot;action,&quot; which they aim to clarify in future discussions." target="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" to be able to have um an expressive power that can deal with these structures . And not just um say um {disfmarker} um the dialogue um will consist of ten possible states and th these states really are fixed in {disfmarker} in a certain sense .&#10;Speaker: Professor F&#10;Content: Hmm ?&#10;Speaker: PhD A&#10;Content: You have to {disfmarker}&#10;Speaker: Professor F&#10;Content: Would there be any chance of getting the terminology changed so that the dialogue planner was called a &quot; dialogue planner &quot; ? Because there 's this other thing The o There 's this other thing in {disfmarker} in the tourist domain which is gonna be a route planner&#10;Speaker: PhD A&#10;Content: That 'd be nice .&#10;Speaker: Professor F&#10;Content: or {disfmarker} It 's really gonna be an action planner . And {comment} i it {disfmarker}&#10;Speaker: PhD A&#10;Content: It oughta be called a {disfmarker} a dialogue manager . cuz that 's what everybody else calls it .&#10;Speaker: Professor F&#10;Content: I would think ,&#10;Spe" target="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain." target=" to be good enough . I I don what uh {disfmarker} what I meant by that . So I think the idea of having a , you know , transition diagram for the grammar of conversations is a good idea .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: OK ? And I think that we do hav definitely have to get in on it and find out {disfmarker} OK . But I think that um when {disfmarker} so , when you get to the tourist domain it 's not just an information retrieval system .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Clearly . Yes .&#10;Speaker: Professor F&#10;Content: Right ? So this i this is where I think this {disfmarker} people are gonna have to think this through a bit more carefully .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So , if it 's only like in {disfmarker} in the {disfmarker} in the film and T V thing , OK , you can do this . And you just get information and give">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain." target=" from there to the appropriate decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So another one of these primitive , what are called &quot; image schemas &quot; , is uh goal seeking . So this a notion of a source , path , goal , trajector , possibly obstacles .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And the idea is this is another conceptual primitive .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And that all sorts of things , particularly in the tourist domain , can be represented in terms of uh source , path and goal . So the idea would be could we build an analyser that would take an utterance and say &quot; Aha ! th this utterance is talking about an attempt to reach a goal . The goal is this , the pers the , uh traveller is that , uh the sor w where we are at now is is this , they 've mentioned possible obstacles , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain." target="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. A more sophisticated dialogue system: The speakers are considering using a more complex system that can handle decision-making and goal-oriented behaviors, which would allow for more flexible and event-driven state changes in the dialogue manager. This system could combine information from the dialogue, ontology, and user model to formulate and answer queries, especially in a tourist domain where it's not just about an information retrieval system.&#10;&#10;2. Transition diagram for conversation grammar: Speaker A suggests having a transition diagram for the grammar of conversations, which is a good idea as it would provide structure and organization for the dialogue. This idea can be applied to an information retrieval system in a tourist domain, where the transition diagram could help manage complex conversations and potentially large amounts of information.&#10;&#10;3. Importance of careful consideration: It is important to think through the implementation of this transition diagram carefully because the tourist domain involves more than just information retrieval; it requires understanding user goals, situational information, and decision-making capabilities. The system must be able to handle these complexities and represent them in a clear and organized manner.&#10;&#10;4. Terminology change: The speakers propose changing the terminology from &quot;dialogue planner&quot; to &quot;action planner&quot; or &quot;dialogue manager&quot; to avoid confusion with route planning in the tourist domain. This change would also better reflect the decision-making and goal-oriented behaviors that the system will handle.&#10;&#10;5. Complex slots: The speakers mention the need to consider complex slots for information storage, especially when dealing with large amounts of structured information like routes or other complex data types in the tourist domain.&#10;&#10;6. Image schemas and goal seeking: Professor F introduces the concept of &quot;image schemas,&quot; specifically &quot;goal seeking,&quot; as a way to represent concepts in terms of source, path, goal, trajector, and possible obstacles. Implementing this concept could help better understand user goals and intents, making the system more effective in the tourist domain." target="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning.">
      <data key="d0">1</data>
    </edge>
    <edge source=" to be good enough . I I don what uh {disfmarker} what I meant by that . So I think the idea of having a , you know , transition diagram for the grammar of conversations is a good idea .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: OK ? And I think that we do hav definitely have to get in on it and find out {disfmarker} OK . But I think that um when {disfmarker} so , when you get to the tourist domain it 's not just an information retrieval system .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Clearly . Yes .&#10;Speaker: Professor F&#10;Content: Right ? So this i this is where I think this {disfmarker} people are gonna have to think this through a bit more carefully .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So , if it 's only like in {disfmarker} in the {disfmarker} in the film and T V thing , OK , you can do this . And you just get information and give" target="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." target=" , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide coverage . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor F&#10;Content: And then , uh The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then uh make decisions about what actions to take . Provides , they claim , a very powerful , general notion of deep semantics . So that 's what we 're really doing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And Nancy is going to {disfmarker} Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." target="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." target="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." target="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." target="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which involves understanding words and language structures that relate to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input.&#10;&#10;2. Compatibility with various planners: The input end should be able to interface with different planning modules using a standard language core. This consistent interaction would allow for seamless communication between the dialogue manager and other components of the system.&#10;&#10;3. Expressive power for complex structures: The input end must have sufficient expressive power to handle intricate data structures, such as routes or other complex data types that may arise in the tourist domain. This would ensure that the system can effectively process and manage large amounts of structured information.&#10;&#10;4. Feedback from planning end: The input end should be designed to accommodate feedback from the planning modules. This two-way communication would allow for more flexible and event-driven state changes, ultimately improving the overall decision-making capabilities of the system." target="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide coverage . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor F&#10;Content: And then , uh The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then uh make decisions about what actions to take . Provides , they claim , a very powerful , general notion of deep semantics . So that 's what we 're really doing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And Nancy is going to {disfmarker} Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm" target="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide coverage . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor F&#10;Content: And then , uh The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then uh make decisions about what actions to take . Provides , they claim , a very powerful , general notion of deep semantics . So that 's what we 're really doing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And Nancy is going to {disfmarker} Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm" target="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , et cetera . &quot; So th the {disfmarker} and this is an {disfmarker} again attempt to get very wide coverage . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Professor F&#10;Content: And then , uh The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then uh make decisions about what actions to take . Provides , they claim , a very powerful , general notion of deep semantics . So that 's what we 're really doing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And Nancy is going to {disfmarker} Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm" target="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target="s tricky because one could well imagine {disfmarker} I think it will turn out to be the case that uh , this thing we 're talking about , th the extended n uh knowledge modeler will fill in some parameters about what the person wants . One could well imagine that the next thing that 's trying to fill out the detailed uh , route planning , let 's say , will also have questions that it would like to ask the user . You could well imagine you get to a point where it 's got a {disfmarker} a choice to make and it just doesn't know something .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And so y you would like it t also be able to uh formulate a query . And to run that back through uh . the dialogue manager and to the output module and back around .&#10;Speaker: Grad B&#10;Content: hmm&#10;Speaker: Professor F&#10;Content: And a I a a good design would {disfmarker} would allow that to happen .&#10;Speaker: Grad B&#10;Content: a lot of , yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target=" to ask a question &quot; . So that forces the dialogue manager to change state .&#10;Speaker: PhD A&#10;Content: Yes&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Sure ,&#10;Speaker: Professor F&#10;Content: It could be y&#10;Speaker: PhD A&#10;Content: ye yeah I {disfmarker} I think that 's {disfmarker} that 's the um concept that people have ,&#10;Speaker: Professor F&#10;Content: Yeah , yeah it {disfmarker} it {disfmarker}&#10;Speaker: PhD A&#10;Content: yep .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: And {disfmarker} and the {disfmarker} the underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug uh certain applications like tourist information or um the home scenario with uh controlling a VCR and so on . And then extend it to an arbitrary number of applications eventually . So {disfmarker} wouldn't That 's an additional reason to have this well - defined interface and keep these things like uh tourist information">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target="} let 's {disfmarker} Let 's hear {disfmarker}&#10;Speaker: PhD A&#10;Content: Well the obvious one would be if {disfmarker} if you envision this as a module within SmartKom , where exactly would that Sit ? That 's the d&#10;Speaker: Grad B&#10;Content: um {disfmarker} so far I 've thought of it as sort of adding it onto the modeler knowledge module .&#10;Speaker: PhD A&#10;Content: OK , yeah .&#10;Speaker: Grad B&#10;Content: So this is one that already adds additional information to the&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Makes perfect sense . Yes .&#10;Speaker: Grad D&#10;Content: Hmm , ah .&#10;Speaker: Grad B&#10;Content: but it could sit anywhere in the attention - recognition I mean basically this is what attention - recognition literally sort of can {disfmarker}&#10;Speaker: PhD A&#10;Content: Well it 's supposed to do . Yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: That 's what it should">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep semantic grammar recognition: The input end of the system should be capable of recognizing and processing deep semantic grammar, which includes understanding words and language structures related to containers, goals, and other complex concepts. This would enable the system to make informed decisions about what actions to take based on the input. For the extended knowledge modeler to formulate and run queries, it needs to understand the user's intent and the context of the conversation, which can be facilitated by deep semantic grammar recognition." target="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system.">
      <data key="d0">1</data>
    </edge>
    <edge source="s tricky because one could well imagine {disfmarker} I think it will turn out to be the case that uh , this thing we 're talking about , th the extended n uh knowledge modeler will fill in some parameters about what the person wants . One could well imagine that the next thing that 's trying to fill out the detailed uh , route planning , let 's say , will also have questions that it would like to ask the user . You could well imagine you get to a point where it 's got a {disfmarker} a choice to make and it just doesn't know something .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: And so y you would like it t also be able to uh formulate a query . And to run that back through uh . the dialogue manager and to the output module and back around .&#10;Speaker: Grad B&#10;Content: hmm&#10;Speaker: Professor F&#10;Content: And a I a a good design would {disfmarker} would allow that to happen .&#10;Speaker: Grad B&#10;Content: a lot of , yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker" target="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="} let 's {disfmarker} Let 's hear {disfmarker}&#10;Speaker: PhD A&#10;Content: Well the obvious one would be if {disfmarker} if you envision this as a module within SmartKom , where exactly would that Sit ? That 's the d&#10;Speaker: Grad B&#10;Content: um {disfmarker} so far I 've thought of it as sort of adding it onto the modeler knowledge module .&#10;Speaker: PhD A&#10;Content: OK , yeah .&#10;Speaker: Grad B&#10;Content: So this is one that already adds additional information to the&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Makes perfect sense . Yes .&#10;Speaker: Grad D&#10;Content: Hmm , ah .&#10;Speaker: Grad B&#10;Content: but it could sit anywhere in the attention - recognition I mean basically this is what attention - recognition literally sort of can {disfmarker}&#10;Speaker: PhD A&#10;Content: Well it 's supposed to do . Yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: That 's what it should" target="Based on the transcript provided, there are no unresolved questions or concerns regarding the two levels of giving an answer for the generation module. Speaker PhD A explicitly states that they don't have any further questions at two points in the discussion (Content: &quot;I don't have any um further questions&quot; and &quot;as far as I'm concerned as standing here for the generation module, and the other is my understanding of what&quot;). The other participants also do not raise any additional questions or concerns about this topic. Therefore, it appears that this aspect of the discussion has been adequately addressed and resolved in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project." target=" in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yep , yep . And how do you envision um the {disfmarker} the um this deep semantic to be worked with . Would it be highly ambiguous if and then there would be another module that takes that um highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or {disfmarker} or a {disfmarker}&#10;Speaker: Professor F&#10;Content: Well that 's {disfmarker} that 's {disfmarker} that 's where the belief - net comes in . So th the idea is , let 's take this business about going to the Powder - Tower .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So part of what you 'll get out of this will be the fact tha w if it works right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: M">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project." target=" dissertations on this ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . So a typical one in this formulation is a container . So this is a static thing . And the notion is that all sorts of physical situations are characterized in terms of containers . Going in and out the portals and con&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK . But also , importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way . You get in trouble and you know et cetera&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: and so {disfmarker} s So , what we 're really trying to do is to map from the discourse to the conceptual semantics level . And from there to the appropriate decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project." target=" A&#10;Content: Yeah , there {disfmarker} there 's the um practice talk .&#10;Speaker: Grad D&#10;Content: uh Mmm , yeah .&#10;Speaker: Professor F&#10;Content: Great . So you 're going to that .&#10;Speaker: PhD A&#10;Content: Yeah , that {disfmarker} that 's what we were planning to do .&#10;Speaker: Professor F&#10;Content: That 's good , because that will uh tell you a fair amount about The form of semantic construction grammar that we 're using .&#10;Speaker: PhD A&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor F&#10;Content: so {disfmarker} So I th I think that probably as good an introduction as you 'll get .&#10;Speaker: Grad D&#10;Content: Ah .&#10;Speaker: Professor F&#10;Content: Uh to the form of {disfmarker} of uh {disfmarker} conceptual grammar that {disfmarker} that w we have in mind for this .&#10;Speaker: Grad D&#10;Content: Mmm , ah .&#10;Speaker: Professor F&#10;Content: It won't talk particularly about how">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project." target="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Deep Conceptual Basis as Interface: The speakers are discussing the idea of using a deep conceptual basis as a universal interface across a wide range of domains in language processing. This deep conceptual basis would allow for the recognition and processing of complex concepts, such as containers and goals, which could then be used to make informed decisions about what actions to take based on the input.&#10;2. Language Processing: The speakers mention that this deep semantic grammar could be used in language processing by recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end. This would provide a powerful and general notion of deep semantics for language processing.&#10;3. Children's Learning: The speakers also discuss the application of this deep conceptual basis in children's learning, specifically in how children might learn a deep semantic grammar. Nancy's talk will focus on modeling this process.&#10;4. Belief Networks: The speakers consider an alternative approach to a simple dialogue system, which involves using a more complex system with belief networks and additional situational information. This system would be able to handle more sophisticated decision-making and goal-oriented behaviors, and could combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. Conceptual Schemas: The speakers also mention the idea that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity, such as the concept of a container. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.&#10;6. Semantic Construction Grammar: The speakers mention the form of semantic construction grammar they are using, which will be introduced in the practice talk that one of them is attending. This form of conceptual grammar is what they have in mind for this project." target="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yep , yep . And how do you envision um the {disfmarker} the um this deep semantic to be worked with . Would it be highly ambiguous if and then there would be another module that takes that um highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or {disfmarker} or a {disfmarker}&#10;Speaker: Professor F&#10;Content: Well that 's {disfmarker} that 's {disfmarker} that 's where the belief - net comes in . So th the idea is , let 's take this business about going to the Powder - Tower .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So part of what you 'll get out of this will be the fact tha w if it works right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: M" target="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" in applications , but about modeling how children might learn this kind of uh deep semantic grammar .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yep , yep . And how do you envision um the {disfmarker} the um this deep semantic to be worked with . Would it be highly ambiguous if and then there would be another module that takes that um highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or {disfmarker} or a {disfmarker}&#10;Speaker: Professor F&#10;Content: Well that 's {disfmarker} that 's {disfmarker} that 's where the belief - net comes in . So th the idea is , let 's take this business about going to the Powder - Tower .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So part of what you 'll get out of this will be the fact tha w if it works right , OK , that this is an agent that wants to go to this place and that 's their goal&#10;Speaker: PhD A&#10;Content: M" target="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" dissertations on this ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . So a typical one in this formulation is a container . So this is a static thing . And the notion is that all sorts of physical situations are characterized in terms of containers . Going in and out the portals and con&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK . But also , importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way . You get in trouble and you know et cetera&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: and so {disfmarker} s So , what we 're really trying to do is to map from the discourse to the conceptual semantics level . And from there to the appropriate decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So" target="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system.">
      <data key="d0">1</data>
    </edge>
    <edge source=" dissertations on this ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . So a typical one in this formulation is a container . So this is a static thing . And the notion is that all sorts of physical situations are characterized in terms of containers . Going in and out the portals and con&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: OK . But also , importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way . You get in trouble and you know et cetera&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: and so {disfmarker} s So , what we 're really trying to do is to map from the discourse to the conceptual semantics level . And from there to the appropriate decisions .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: So" target="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" A&#10;Content: Yeah , there {disfmarker} there 's the um practice talk .&#10;Speaker: Grad D&#10;Content: uh Mmm , yeah .&#10;Speaker: Professor F&#10;Content: Great . So you 're going to that .&#10;Speaker: PhD A&#10;Content: Yeah , that {disfmarker} that 's what we were planning to do .&#10;Speaker: Professor F&#10;Content: That 's good , because that will uh tell you a fair amount about The form of semantic construction grammar that we 're using .&#10;Speaker: PhD A&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Professor F&#10;Content: so {disfmarker} So I th I think that probably as good an introduction as you 'll get .&#10;Speaker: Grad D&#10;Content: Ah .&#10;Speaker: Professor F&#10;Content: Uh to the form of {disfmarker} of uh {disfmarker} conceptual grammar that {disfmarker} that w we have in mind for this .&#10;Speaker: Grad D&#10;Content: Mmm , ah .&#10;Speaker: Professor F&#10;Content: It won't talk particularly about how" target="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target=" . Right . This is then out of deference to our non - morning people .&#10;Speaker: PhD A&#10;Content: Mm - hmm . OK . So at eleven ?&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Thursday around eleven ? OK .&#10;Speaker: Professor F&#10;Content: Yeah . And actually we can invite um Andreas as well .&#10;Speaker: Grad B&#10;Content: Uh he will be in Washington , though .&#10;Speaker: Professor F&#10;Content: Oh that 's true . He 's off {disfmarker} off on his trip already .&#10;Speaker: Grad B&#10;Content: but um David is here and he 's actually knows everything about the SmartKom recognizer .&#10;Speaker: Professor F&#10;Content: Thilo . OK well yeah maybe we 'll see if David could make it . That would be good .&#10;Speaker: Grad B&#10;Content: OK so facing to {disfmarker} to what we 've sort of been doing here um well for one thing we 're also using this room to collect data .&#10;Speaker: PhD A&#10;Content: Yeah obviously .&#10;Speaker: Grad">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target=" supposed to do . Yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: That 's what it should do .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: Right ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: Grad D&#10;Content: Huh .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Well f from my understanding of what the people at Phillips were originally trying to do doesn't seem to quite fit into SmartKom currently so what they 're really doing right now is only selecting among the alternatives , the hypotheses that they 're given enriched by the domain knowledge and the um discourse modeler and so on .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So if {disfmarker} if this is additional information that could be merged in by them .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: And then it would be available to action planning and {disfmarker} and others .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="marker} what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or {pause} um {pause} most of the time on Friday , not all .&#10;Speaker: Grad B&#10;Content: Thursday morning sounds fine ?&#10;Speaker: Professor F&#10;Content: Wha - but , Johno ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: what are your constraints ?&#10;Speaker: Grad E&#10;Content: um Thursday afternoon doesn't work for me , but {disfmarker}&#10;Speaker: Grad B&#10;Content: Neither does Thursday morning , no ?&#10;Speaker: Grad E&#10;Content: Uh Thursday morning should be fine .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Professor F&#10;Content: Eleven ? Eleven on Thursday ?&#10;Speaker: Grad E&#10;Content: I was just thinking I w I will {pause} have {pause} leavened by eleven .&#10;Speaker: Professor F&#10;Content: Right . Right . This is then out of deference to our non - morning people .&#10;Speaker: PhD A&#10;Content: Mm - hmm .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that all participants are available to meet on Thursday morning before 11:00 AM, with the exception of Grad E, who has an earlier departure time. However, Grad E mentioned that Thursday morning should be fine for them. Therefore, a suitable time for the discussion would be Thursday morning at 11:00 AM, keeping in mind that Professor F is unavailable during Thursday afternoon." target="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . Right . This is then out of deference to our non - morning people .&#10;Speaker: PhD A&#10;Content: Mm - hmm . OK . So at eleven ?&#10;Speaker: Grad D&#10;Content: Hmm .&#10;Speaker: PhD A&#10;Content: Thursday around eleven ? OK .&#10;Speaker: Professor F&#10;Content: Yeah . And actually we can invite um Andreas as well .&#10;Speaker: Grad B&#10;Content: Uh he will be in Washington , though .&#10;Speaker: Professor F&#10;Content: Oh that 's true . He 's off {disfmarker} off on his trip already .&#10;Speaker: Grad B&#10;Content: but um David is here and he 's actually knows everything about the SmartKom recognizer .&#10;Speaker: Professor F&#10;Content: Thilo . OK well yeah maybe we 'll see if David could make it . That would be good .&#10;Speaker: Grad B&#10;Content: OK so facing to {disfmarker} to what we 've sort of been doing here um well for one thing we 're also using this room to collect data .&#10;Speaker: PhD A&#10;Content: Yeah obviously .&#10;Speaker: Grad" target="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" supposed to do . Yeah&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Professor F&#10;Content: That 's what it should do .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: Right ,&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: Grad D&#10;Content: Huh .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Well f from my understanding of what the people at Phillips were originally trying to do doesn't seem to quite fit into SmartKom currently so what they 're really doing right now is only selecting among the alternatives , the hypotheses that they 're given enriched by the domain knowledge and the um discourse modeler and so on .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So if {disfmarker} if this is additional information that could be merged in by them .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: And then it would be available to action planning and {disfmarker} and others .&#10;Spe" target="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="Content: Well you s and {disfmarker} and especially you did some {disfmarker} some um , l um was a learning - based approach which learned from a big corpus of {disfmarker} of trees .&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: And yes the {disfmarker} it {disfmarker} the chunk parser was a finite - state machine that um Mark Light originally w worked on in {disfmarker} while he was in Tuebingen&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: and then somebody else in Tuebingen picked that up . So it was done in Tuebingen , yeah . Definitely .&#10;Speaker: Professor F&#10;Content: But is that the kind of thing y It sounds like the kind of thing that you were thinking of .&#10;Speaker: PhD A&#10;Content: Yeah I guess it 's similar .&#10;Speaker: Grad D&#10;Content: yeah . yeah that 's In this direction , yes&#10;Speaker: Professor F&#10;Content: What ?&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="mm .&#10;Speaker: Grad D&#10;Content: And they also have to be very robust . cuz of um speech recognition errors and&#10;Speaker: Professor F&#10;Content: OK . So , um {disfmarker} So there was a chunk parser in Verbmobil , that was one of the uh branchers . You know they {disfmarker} d th I c There were these various uh , competing uh syntax modules . And I know one of them was a chunk parser and I don't remember {pause} who did that .&#10;Speaker: Grad B&#10;Content: A Alan ?&#10;Speaker: Grad D&#10;Content: I think it 's that might , at Tuebingen I thought .&#10;Speaker: Professor F&#10;Content: Yeah I d I don't remember .&#10;Speaker: Grad D&#10;Content: was {disfmarker} Do you know something about that ?&#10;Speaker: PhD A&#10;Content: Tubingen was at least involved in putting the chunks together&#10;Speaker: Grad D&#10;Content: In Tub - at {disfmarker}&#10;Speaker: PhD A&#10;Content: I {disfmarker} can't quite recall whether they actually produced the chunks">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="&#10;Speaker: Grad D&#10;Content: yeah . yeah that 's In this direction , yes&#10;Speaker: Professor F&#10;Content: What ?&#10;Speaker: Grad D&#10;Content: Yeah , it 's in {disfmarker} in this direction .&#10;Speaker: Grad B&#10;Content: The {disfmarker}&#10;Speaker: Professor F&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: From Michael Strube , I 've heard very good stuff about the chunk parser that is done by FORWISS , uh , which is in embassy doing the parsing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: So this is sort of {disfmarker} came as a surprise to me that you know , embassy s {comment} is featuring a nice parser but it 's {pause} what I hear . One could also look at that and see whether there is some synergy possible .&#10;Speaker: Grad D&#10;Content: Mm - hmm , yeah , it would be very interesting , Mm - hmm . Mmm , yeah .&#10;Speaker: Grad B&#10;Content: And they 're doing chunk">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target=" {disfmarker}&#10;Speaker: PhD A&#10;Content: I {disfmarker} can't quite recall whether they actually produced the chunks in the first place .&#10;Speaker: Grad D&#10;Content: oh&#10;Speaker: Professor F&#10;Content: Uh . I see . Yeah , that 's right .&#10;Speaker: PhD A&#10;Content: Or wh&#10;Speaker: Grad D&#10;Content: Oh from {disfmarker} from Stuttgart ,&#10;Speaker: Professor F&#10;Content: There w That 's right . They w They had {disfmarker} There were {disfmarker} This was done with a two phase thing , where {comment} the chunk parser itself was pretty stupid&#10;Speaker: Grad D&#10;Content: yeah , also&#10;Speaker: Professor F&#10;Content: and then there was a kind of trying to fit them together that h used more context .&#10;Speaker: PhD A&#10;Content: Right . Yeah&#10;Speaker: Professor F&#10;Content: Right ?&#10;Speaker: PhD A&#10;Content: Well you s and {disfmarker} and especially you did some {disfmarker} some um , l um was a learning -">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach that was developed in Tuebingen is a chunk parser that uses a finite-state machine to analyze a big corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also involves parsing and analyzing natural language input to understand its structure and meaning. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="1. The trickiness in implementing a dialogue system that can separate logical structure from content and formulate its requests in an abstract way, as discussed by Professor F and Graduate B, likely refers to the challenge of creating a system that can understand and process natural language input with sufficient complexity to handle decision-making and goal-oriented behaviors.&#10;2. This would involve parsing and analyzing the input to understand its structure and meaning, similar to the chunk parser approach developed in Tuebingen. However, adapting this approach for a dialogue system would require addressing domain-specific challenges related to understanding user goals, situational information, and decision-making capabilities.&#10;3. Additionally, the system would need to be able to combine information from multiple sources (dialogue, ontology, and user model) to formulate and answer queries in a flexible and event-driven manner, allowing for more sophisticated state changes in the dialogue manager.&#10;4. The use of a well-defined interface for different planning modules could help address some of these challenges by providing a clear structure for how the system handles different types of information and decision-making processes. However, implementing this approach would still require careful consideration of the specific details of how to represent and process natural language input in a way that allows for abstract query formulation while maintaining logical structure and meaning.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Well you s and {disfmarker} and especially you did some {disfmarker} some um , l um was a learning - based approach which learned from a big corpus of {disfmarker} of trees .&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: And yes the {disfmarker} it {disfmarker} the chunk parser was a finite - state machine that um Mark Light originally w worked on in {disfmarker} while he was in Tuebingen&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: and then somebody else in Tuebingen picked that up . So it was done in Tuebingen , yeah . Definitely .&#10;Speaker: Professor F&#10;Content: But is that the kind of thing y It sounds like the kind of thing that you were thinking of .&#10;Speaker: PhD A&#10;Content: Yeah I guess it 's similar .&#10;Speaker: Grad D&#10;Content: yeah . yeah that 's In this direction , yes&#10;Speaker: Professor F&#10;Content: What ?&#10;" target="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart.">
      <data key="d0">1</data>
    </edge>
    <edge source="mm .&#10;Speaker: Grad D&#10;Content: And they also have to be very robust . cuz of um speech recognition errors and&#10;Speaker: Professor F&#10;Content: OK . So , um {disfmarker} So there was a chunk parser in Verbmobil , that was one of the uh branchers . You know they {disfmarker} d th I c There were these various uh , competing uh syntax modules . And I know one of them was a chunk parser and I don't remember {pause} who did that .&#10;Speaker: Grad B&#10;Content: A Alan ?&#10;Speaker: Grad D&#10;Content: I think it 's that might , at Tuebingen I thought .&#10;Speaker: Professor F&#10;Content: Yeah I d I don't remember .&#10;Speaker: Grad D&#10;Content: was {disfmarker} Do you know something about that ?&#10;Speaker: PhD A&#10;Content: Tubingen was at least involved in putting the chunks together&#10;Speaker: Grad D&#10;Content: In Tub - at {disfmarker}&#10;Speaker: PhD A&#10;Content: I {disfmarker} can't quite recall whether they actually produced the chunks" target="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: Grad D&#10;Content: yeah . yeah that 's In this direction , yes&#10;Speaker: Professor F&#10;Content: What ?&#10;Speaker: Grad D&#10;Content: Yeah , it 's in {disfmarker} in this direction .&#10;Speaker: Grad B&#10;Content: The {disfmarker}&#10;Speaker: Professor F&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: From Michael Strube , I 've heard very good stuff about the chunk parser that is done by FORWISS , uh , which is in embassy doing the parsing .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: So this is sort of {disfmarker} came as a surprise to me that you know , embassy s {comment} is featuring a nice parser but it 's {pause} what I hear . One could also look at that and see whether there is some synergy possible .&#10;Speaker: Grad D&#10;Content: Mm - hmm , yeah , it would be very interesting , Mm - hmm . Mmm , yeah .&#10;Speaker: Grad B&#10;Content: And they 're doing chunk" target="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker}&#10;Speaker: PhD A&#10;Content: I {disfmarker} can't quite recall whether they actually produced the chunks in the first place .&#10;Speaker: Grad D&#10;Content: oh&#10;Speaker: Professor F&#10;Content: Uh . I see . Yeah , that 's right .&#10;Speaker: PhD A&#10;Content: Or wh&#10;Speaker: Grad D&#10;Content: Oh from {disfmarker} from Stuttgart ,&#10;Speaker: Professor F&#10;Content: There w That 's right . They w They had {disfmarker} There were {disfmarker} This was done with a two phase thing , where {comment} the chunk parser itself was pretty stupid&#10;Speaker: Grad D&#10;Content: yeah , also&#10;Speaker: Professor F&#10;Content: and then there was a kind of trying to fit them together that h used more context .&#10;Speaker: PhD A&#10;Content: Right . Yeah&#10;Speaker: Professor F&#10;Content: Right ?&#10;Speaker: PhD A&#10;Content: Well you s and {disfmarker} and especially you did some {disfmarker} some um , l um was a learning -" target="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." target="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." target="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." target="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="The group plans to meet on Thursday morning at 11:00 AM to discuss updates on the project and go over plans. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." target="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience." target="marker} I think it 's really {disfmarker} really wrong headed for something that you {disfmarker} that has a lot of state , it 's gonna interact co in a complicated way with the uh understanding parts .&#10;Speaker: Grad B&#10;Content: Yeah . Yeah I think just the {disfmarker} the spatial planner and the route planner I showed you once the interac action between them among them in the deep map system&#10;Speaker: Professor F&#10;Content: Right .&#10;Speaker: Grad B&#10;Content: so {disfmarker} a printout of the communication between those two fills up I don't know how many pages&#10;Speaker: PhD A&#10;Content: Hmm&#10;Speaker: Grad B&#10;Content: and that 's just part of how do I get to one place . It 's really insane . and uh but um so this is um definitely a good point to get uh Michael into the discussion . Or to enter his discussion , actually .&#10;Speaker: PhD A&#10;Content: Yeah , Marcus .&#10;Speaker: Grad B&#10;Content: That 's the way around . Markus&#10;Speaker: PhD A&#10;Content: Wh - where 's ?&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with integrating multiple components, such as a spatial planner and a route planner, in a deep map system is that they can interact in complex ways, leading to potentially large amounts of communication between these components. This could result in increased complexity and difficulty in managing the overall system.&#10;&#10;2. Involving Michael (presumably an expert or stakeholder) in the discussion about this complexity would be beneficial because he can provide valuable insights and potential solutions for handling the complicated interactions between different planning modules. His involvement might help in developing a more efficient and manageable deep map system by leveraging his expertise and experience." target=" we can at least ask that question ?&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: I mean nothing 's being completely settled there&#10;Speaker: Grad B&#10;Content: rea yep&#10;Speaker: PhD A&#10;Content: so this is really an ongoing discussion&#10;Speaker: Grad B&#10;Content: Mm - hmm&#10;Speaker: PhD A&#10;Content: and that 's&#10;Speaker: Grad B&#10;Content: yeah and um it might actually OK ah also {disfmarker} because um again in in Deep Map we have faced and implemented those problems once already&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: maybe we can even shuffle some know how from there to to Markus and Michael .&#10;Speaker: PhD A&#10;Content: Yes .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: Yep .&#10;Speaker: Grad B&#10;Content: And um mmm You don't know {disfmarker} OK th I 'll {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart." target="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability.">
      <data key="d0">1</data>
    </edge>
    <edge source="The learning-based approach developed in Tuebingen, as discussed in the transcript, involves using a finite-state chunk parser to analyze a large corpus of trees. This approach is similar to the one being discussed in the dialogue system context, as it also parses and analyzes natural language input to understand its structure and meaning. The specifics of how this approach was adapted for the dialogue system are not provided in the transcript. Additionally, the team in Tuebingen worked on making the chunk parser robust to speech recognition errors. It is mentioned that there were competing syntax modules in Verbmobil, one of which was a chunk parser, but it is unclear who specifically developed this module. The team at Tuebingen was involved in putting the chunks together, but it is not clear if they produced the chunks themselves or obtained them from another source such as Stuttgart." target="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion between the speakers suggests that English finite-state transducers are more focused on word order, while German ones rely more heavily on morphological cues such as case endings. This is because German has a more flexible word order than English, and much of its grammar can be determined by the morphological endings of words rather than their position in a sentence.&#10;&#10;Purely finite-state transducers may not be as effective for German as they are for English because they are less capable of handling morphological cues that are essential for processing German natural language input. Specifically, purely finite-state transducers may struggle to accurately identify the grammatical roles of words in a sentence based solely on their position, since word order is more flexible in German than in English.&#10;&#10;Therefore, it is important to use a learning-based approach that can handle the morphological cues present in German natural language input. The chunk parser developed in Tuebingen and discussed in the dialogue system context appears to be an example of such an approach, as it uses a finite-state machine to analyze a big corpus of trees and parse natural language input. However, the specific details of how this approach was adapted for the dialogue system are not provided in the transcript." target="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability." target=" uh , Miel syntactic analysis with um finite state transducers .&#10;Speaker: Professor F&#10;Content: so But the people at D F Yeah . People at DFKI have written a fair number of parsers . Other {disfmarker} you know , people over the years . uh have written various parsers at DFKI . None of them are suitable ? I {disfmarker} I {disfmarker} I d I 'm asking . I don't know .&#10;Speaker: Grad D&#10;Content: Yeah , uh the problem is th that it has to be very fast because um if you want to for more than one path anywhere&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: what 's in the latches from the speech recognizer&#10;Speaker: Professor F&#10;Content: Mm - hmm .&#10;Speaker: Grad D&#10;Content: so it 's speed is crucial . uh And they are not fast enough .&#10;Speaker: Professor F&#10;Content: Mm - hmm .&#10;Speaker: Grad D&#10;Content: And they also have to be very robust . cuz of um speech recognition errors and&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speed: The parsers developed by the DFKI team may not be fast enough to handle real-time speech recognition, as mentioned in the transcript. This is critical for Miel syntactic analysis since it involves analyzing natural language input from users, which can include multiple paths and require quick processing times.&#10;&#10;2. Robustness against speech recognition errors: The parsers developed by the DFKI team may not be robust enough to handle the errors that commonly occur in speech recognition. This is particularly important for Miel syntactic analysis since it involves analyzing natural language input from users, which can include misrecognitions and other errors due to the inherent challenges of speech recognition technology.&#10;&#10;Without more specific information about the parsers developed by the DFKI team, it is difficult to provide a more detailed explanation for why they may not be suitable for Miel syntactic analysis in terms of speed and robustness against speech recognition errors. However, based on the information provided in the transcript, these appear to be the primary reasons for their unsuitability." target=": Professor F&#10;Content: Do you have a particular parser in mind ? Is it uh {disfmarker} partic d I mean have you thought through {disfmarker} ? Is it an HPSG parser ? Is it a whatever ?&#10;Speaker: Grad D&#10;Content: No {disfmarker} no it 's {disfmarker} uh I think it 's it 's totally complicated for it 's just one {disfmarker} one person&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: Grad D&#10;Content: and so I have to keep the {disfmarker}&#10;Speaker: Professor F&#10;Content: Oh , you have to do it . You have to do it ,&#10;Speaker: Grad D&#10;Content: Yeah ,&#10;Speaker: Professor F&#10;Content: yeah .&#10;Speaker: Grad D&#10;Content: ah and so {vocalsound} things must be simpler&#10;Speaker: Professor F&#10;Content: I see ,&#10;Speaker: Grad D&#10;Content: but uh , Miel syntactic analysis with um finite state transducers .&#10;Speaker: Professor F&#10;Content: so But the people at D F Yeah .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information." target="&#10;Content: OK because That 's {disfmarker} Those are the {disfmarker} I think the {disfmarker} the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it {disfmarker} and how that is uh specified . I didn't think of the internal working of the uh the action planner and the language {disfmarker} uh the function model as sort of relevant . Because what {disfmarker} what they take is sort of this {disfmarker} this fixed representation of a {disfmarker} of an intention .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And that can be as detailed or as crude as you want it to be . But um the internal workings of of the {disfmarker} whether you know there 're dialogue {disfmarker} action planners that work with belief - nets that are action planners that work with you know state automata . So that shouldn't really matter too much . I mean it does matter because it does have to keep track of you {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information." target="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Belief-net based dialogue action planners: These use belief networks to combine information from the dialogue, ontology, and user model for more accurate query formulation and answering. The level of detail in an intention's representation can vary depending on how detailed the belief network is.&#10;&#10;2. State automata-based dialogue action planners: These utilize state automata to manage the dialogue. The level of detail in an intention's representation depends on the states defined within the automaton and their transitions.&#10;&#10;3. Simple dialogue action planners: These use a fixed representation of an intention, which may not be as flexible or nuanced as other types of dialogue action planners. However, they can still handle user preferences, context, ontology, and belief networks to some extent.&#10;&#10;The mechanism of each type of dialogue action planner affects the level of detail in an intention's representation by determining how information is processed and combined. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle decision-making and goal-oriented behaviors while combining information from various sources. In contrast, simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information." target="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Content: OK because That 's {disfmarker} Those are the {disfmarker} I think the {disfmarker} the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it {disfmarker} and how that is uh specified . I didn't think of the internal working of the uh the action planner and the language {disfmarker} uh the function model as sort of relevant . Because what {disfmarker} what they take is sort of this {disfmarker} this fixed representation of a {disfmarker} of an intention .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: And that can be as detailed or as crude as you want it to be . But um the internal workings of of the {disfmarker} whether you know there 're dialogue {disfmarker} action planners that work with belief - nets that are action planners that work with you know state automata . So that shouldn't really matter too much . I mean it does matter because it does have to keep track of you {disfmarker" target="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The internal workings of the action planner and language function model are significant because they determine how the system understands and processes the input from the user. Different mechanisms for processing and integrating information (such as belief networks or state automata) can provide a more detailed and accurate understanding of a user's intentions by handling decision-making and goal-oriented behaviors while combining information from various sources.&#10;2. The level of detail in the representation of an intention plays a crucial role in the performance of the action planner and language function model. A more sophisticated system that uses belief networks or state automata can provide a more detailed and accurate understanding of a user's intentions, as they can handle complex data structures and make informed decisions based on the input.&#10;3. Simpler systems may have less expressive power in representing complex intentions due to their limited mechanisms for processing and integrating information. However, these systems can still handle user preferences, context, ontology, and belief networks to some extent.&#10;4. In summary, the internal workings of the action planner and language function model are essential for understanding and processing the user's input, and the level of detail in the representation of an intention directly impacts their performance. More sophisticated systems can provide a more detailed and accurate understanding of a user's intentions, while simpler systems may have less expressive power in representing complex intentions." target="1. The ambiguity of the term &quot;action&quot; in this context arises from the fact that it could refer to two different concepts: (a) a possible action or decision in a dialogue system, or (b) physical actions related to route planning in a tourist domain. The speakers aim to clarify this ambiguity in future discussions.&#10;2. In SmartKom terminology, a function modeled by a function modeler is an entirely separate concept from the &quot;action&quot; being discussed in the context of dialogue systems. A function modeled by a function modeler refers to a specific functionality (such as route planning) that is encapsulated from the dialogue system and does not form part of the core decision-making or goal-oriented behaviors within the system.&#10;&#10;In summary, the ambiguity of the term &quot;action&quot; in this context arises from its potential overlap with physical actions related to route planning. However, it should be distinguished from the concept of a function modeled by a function modeler in SmartKom terminology, which is an encapsulated functionality that is separate from the core decision-making and goal-oriented behaviors within a dialogue system.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript." target="aker: Grad B&#10;Content: And um mmm You don't know {disfmarker} OK th I 'll {disfmarker} I 'll talk to Michael it 's what I do anyway . Who {disfmarker} How far is the uh the {disfmarker} the M - three - L specification for {disfmarker} for the la natural language input gone on the {disfmarker} the uh I haven't seen anything for the uh tourist path domain .&#10;Speaker: Grad D&#10;Content: Yeah , it 's {disfmarker} it 's not defined yet .&#10;Speaker: Grad B&#10;Content: And um you are probably also involved in that ,&#10;Speaker: Grad D&#10;Content: Um {disfmarker} Yeah .&#10;Speaker: Grad B&#10;Content: right ? uh together with the usual gang , um Petra and Jan&#10;Speaker: Grad D&#10;Content: Mmm . Yeah , there 's a meeting next next week I think&#10;Speaker: Grad B&#10;Content: OK because That 's {disfmarker} Those are the {disfmarker} I think the {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript." target="Based on the transcript, it is unclear whether the stemming information and knowledge bases from the Verbmobil system were specifically utilized in the current template parser for analyzing both English and German texts. However, it is mentioned that the current template parser, which was only looked at for English, did not appear to be using the stemming information for German. It is also noted that the M-3-L specification for natural language input in the tourist path domain has not been defined yet, and a meeting with Petra and Jan to discuss this matter is scheduled for next week. Therefore, it is possible that these resources were planned to be implemented but have not yet been integrated into the current parser.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the M-3-L specification for natural language input in the tourist path domain has not been defined yet. The next meeting to discuss this matter with Petra and Jan is scheduled for next week, though the exact date and time are not mentioned in the transcript." target="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion in the transcript, a suitable time for getting together to discuss and potentially modify SmartKom plans would be Thursday morning at 11:00 AM. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. However, it is important to note that Professor F is unavailable during Thursday afternoon. The group aims to have this discussion later in the week after establishing a better understanding of the current situation." target="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Professor F and their colleagues are attempting to create a universal interface for language processing that utilizes a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. In addition to these applications, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system." target="1. Professor F and his colleagues are working on creating a universal interface for language processing based on a deep conceptual basis derived from cognitive linguistics. This interface would be able to recognize and process complex concepts, such as containers and goals, from discourse and use this information to make informed decisions.&#10;2. They aim to demonstrate the wide applicability of this deep conceptual basis by showing that it can be used across a range of domains in language processing. By recognizing words and structures related to complex concepts at the input end, and making decisions about what actions to take at the output end, they claim that this provides a powerful and general notion of deep semantics for language processing.&#10;3. They are also interested in modeling how children might learn a deep semantic grammar, which would involve studying how children recognize and process complex concepts in language.&#10;4. Additionally, they are considering using belief networks and additional situational information in their system to handle more sophisticated decision-making and goal-oriented behaviors. This would allow the system to combine information from the dialogue, ontology, and user model to formulate and answer queries.&#10;5. The use of primitive conceptual schemas, such as the container schema, allows for representation of both physical and metaphorical situations, broadening the scope and applicability of their system. They aim to map from discourse to the conceptual semantics level, and then to the appropriate decisions.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are no specific preparations mentioned for the discussion on construction grammar. However, PhD A mentions a &quot;practice talk&quot; that they are planning to attend, which might be related to the topic of the discussion. The discussion is estimated to start at 11:00 AM on Thursday, as decided by the participants. This time was chosen because all participants are available in the morning, with the exception of Grad E who has an earlier departure time but mentioned that Thursday morning should be fine for them. It's also worth noting that Professor F is unavailable during Thursday afternoon." target="&#10;Content: just about the um&#10;Speaker: PhD A&#10;Content: yeah yeah , really .&#10;Speaker: Grad B&#10;Content: First steps .&#10;Speaker: Professor F&#10;Content: Right . The {disfmarker} the construction grammar .&#10;Speaker: Grad B&#10;Content: And she 's gonna start in a minute .&#10;Speaker: Professor F&#10;Content: In a minute .&#10;Speaker: Grad D&#10;Content: Ah , OK .&#10;Speaker: Professor F&#10;Content: OK .&#10;Speaker: PhD G&#10;Content: Is it i in , then , your place , in five {disfmarker} five - A ?&#10;Speaker: PhD A&#10;Content: Alright .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, the project called Fastus was an ambitious one conducted at SRI some years ago. However, there is not much information available about it because there is limited documentation or details about the project that can be found. It appears to have involved finite-state transducers, based on the discussion between Grad D and Professor F. The project may have been innovative and complex in nature, but its specific features or outcomes are not mentioned in the conversation." target=" . Uh . And have you looked {disfmarker} uh just {disfmarker} again for context {disfmarker}&#10;Speaker: Grad D&#10;Content: Mm - hmm .&#10;Speaker: Professor F&#10;Content: There is this {disfmarker} this one that they did at SRI some years ago {disfmarker} Fastus ?&#10;Speaker: Grad D&#10;Content: um&#10;Speaker: Professor F&#10;Content: a {disfmarker}&#10;Speaker: Grad D&#10;Content: yeah , I 've {disfmarker} I 've looked at it but {disfmarker} but it 's no {disfmarker} not much uh information available . I found ,&#10;Speaker: Professor F&#10;Content: ah !&#10;Speaker: Grad D&#10;Content: but it 's also finite - state transducers , I thought .&#10;Speaker: Professor F&#10;Content: It is . Yeah . I mean {disfmarker} it 's {disfmarker} it was pretty ambitious .&#10;Speaker: Grad D&#10;Content: and&#10;Speaker: Professor F&#10;Content: And of course it was">
      <data key="d0">1</data>
    </edge>
    <edge source="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly." target=" well for one thing we 're also using this room to collect data .&#10;Speaker: PhD A&#10;Content: Yeah obviously .&#10;Speaker: Grad B&#10;Content: um um Not this type of data ,&#10;Speaker: PhD A&#10;Content: Oh , OK .&#10;Speaker: Grad B&#10;Content: no not meeting data but sort of {disfmarker} sort ah our version of a wizard experiment such not like the ones in Munich but pretty close to it .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: The major difference to the Munich ones is that we do it via the telephone&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: even though all the recording is done here and so it 's a {disfmarker} sort of a computer call system that gives you tourist information&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: tells you how to get places . And it breaks halfway through the experiment and a human operator comes on . and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking">
      <data key="d0">1</data>
    </edge>
    <edge source="From the transcript, it appears that the researchers are collecting spoken language data related to tourists' information needs and their interactions with a computer-based system providing tourist information. The system is set up to switch from machine-provided information to a human operator midway through the interaction, allowing the researchers to compare how people's language use changes when interacting with a machine versus a human.&#10;&#10;The researchers are specifically interested in examining whether certain types of extra-linguistic parameters (such as user characteristics or situational factors) and linguistic information from the user's utterances can be used to infer the user's underlying intentions and enrich the system's response accordingly. This involves developing a belief-net module that makes guesses about the user's intention based on the data collected during the interaction and augmenting M-3-L structures (likely referring to some form of language representation or processing framework) with this additional information.&#10;&#10;Overall, it seems that the researchers are collecting spoken language data in order to develop a more sophisticated tourist information system that can better understand users' needs and intentions and respond accordingly." target=" halfway through the experiment and a human operator comes on . and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: and we 're setting it up so that we can {disfmarker} we hope to implant certain intentions in people . For example um we have first looked at a simple sentence that &quot; How do I get to the Powder - Tower ? &quot; OK so you have the {disfmarker} castle of Heidelberg&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: and there is a tower and it 's called Powder - Tower .&#10;Speaker: PhD A&#10;Content: Oh , OK . Yeah .&#10;Speaker: Grad B&#10;Content: and um so What will you parse out of that sentence ? Probably something that we specified in M - three - L , that is @ @ {comment} &quot; action go to whatever domain , object whatever Powder - Tower &quot; .&#10;Speaker: Grad D&#10;Content: Mmm .&#10;Speaker: Grad B&#10;Content: And maybe some">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
