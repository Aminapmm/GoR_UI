<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." />
    <node id=" or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If you say {pause} uh {pause} If you have a place {pause} characteristic and a manner characteristic , how do you {disfmarker}&#10;Speaker: PhD D&#10;Content: It - It 's the single net ,&#10;Speaker: PhD A&#10;Content: I think they have one output .&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Professor B&#10;Content: Oh , it 's just one net .&#10;Speaker: PhD D&#10;Content: It 's one net with {pause} um {pause} twenty - seven outputs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: mm - hmm&#10;Speaker: PhD D&#10;Content: if we have twenty - seven classes ,&#10;Speaker: Professor B&#10;Content: I see . I see , OK .&#10;Speaker: PhD D&#10;Content: yeah . So it 's {disfmarker} Well , it 's basically a standard net with fewer {pause} classes .&#10;Speaker: Professor B&#10;Content" />
    <node id=" 's {disfmarker} Well , it 's basically a standard net with fewer {pause} classes .&#10;Speaker: Professor B&#10;Content: So you 're sort of going the other way of what you were saying a bit ago instead of {disfmarker} yeah .&#10;Speaker: PhD D&#10;Content: Yeah , but I think {disfmarker} Yeah . B b including the features , yeah .&#10;Speaker: Grad F&#10;Content: But including the features .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: I don't think this {pause} will work {pause} alone . I think it will get worse because Well , I believe the effect that {disfmarker} of {disfmarker} of too reducing too much the information is {pause} basically {disfmarker} basically what happens&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: Professor B&#10;Content: But you think if you include that {pause} plus the other features ,&#10;Speaker: PhD D&#10;Content: but {disfmarker" />
    <node id=": but {disfmarker} but&#10;Speaker: PhD E&#10;Content: Maybe .&#10;Speaker: Professor B&#10;Content: yeah .&#10;Speaker: PhD E&#10;Content: I don't know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh , OK .&#10;Speaker: PhD D&#10;Content: Uh so there is this combination , yeah . Working on combination obviously .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Um , I will start work on multi - band . And {pause} we {pause} plan to work also on the idea of using both {pause} features {pause} and net outputs .&#10;Speaker: PhD E&#10;Content: &#10;Speaker: PhD D&#10;Content: Um . And {pause} we think that {pause} with this approach perhaps {pause} we could reduce the number of outputs of the neural network . Um , So , get simpler networks , because we still have the features . So we have um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically" />
    <node id=" have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disfmarker} how many nets do you have ? No nets .&#10;Speaker: PhD D&#10;Content: I mean , {pause} It 's just {disfmarker} Were we just changing {pause} the labels to retrain nets {pause} with fewer out outputs .&#10;Speaker: PhD E&#10;Content: Begin to work in this . We are @ @ .&#10;Speaker: Professor B&#10;Content: Right . But {disfmarker} but I didn't understand {disfmarker}&#10;Speaker: PhD D&#10;Content: And then {disfmarker} Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh . {pause} the software currently just has {disfmarker} uh a {disfmarker} allows for I think , the one {disfmarker} one hot output . So you 're having multiple nets and combining them , or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If" />
    <node id="Content: But you think if you include that {pause} plus the other features ,&#10;Speaker: PhD D&#10;Content: but {disfmarker} Yeah , because {pause} there is perhaps one important thing that the net {pause} brings , and OGI show showed that , is {pause} the distinction between {pause} sp speech and silence Because these nets are trained on well - controlled condition . I mean the labels are obtained on clean speech , and we add noise after . So this is one thing And But perhaps , something intermediary using also {pause} some broad classes could {disfmarker} could bring so much more information . Uh .&#10;Speaker: Professor B&#10;Content: So {disfmarker} so again then we have these broad classes and {disfmarker} well , somewhat broad . I mean , it 's twenty - seven instead of sixty - four , {pause} basically . And you have the original features .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Which are PLP , or something .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And then uh , just to remind me ," />
    <node id=" um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically we have three {pause} types of broad phonetic classes . Well , something using place of articulation which {disfmarker} which leads to {pause} nine , I think , {pause} broad classes . Uh , another which is based on manner , which is {disfmarker} is also something like nine classes . And then , {pause} something that combine both , and we have {pause} twenty f {pause} twenty - five ?&#10;Speaker: Grad F&#10;Content: Twenty - seven .&#10;Speaker: PhD D&#10;Content: Twenty - seven broad classes . So like , uh , oh , I don't know , like back vowels , front vowels .&#10;Speaker: Professor B&#10;Content: So what you do {disfmarker} um I just wanna understand&#10;Speaker: PhD D&#10;Content: Um For the moments we do not {disfmarker} don't have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disf" />
    <node id="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." />
    <node id=" but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker} So , it 's {disfmarker} it 's three or {disfmarker} three and four .&#10;Speaker: PhD E&#10;Content: The early experiment that {disfmarker}&#10;Speaker: PhD A&#10;Content: Did you do different languages from digits ?&#10;Speaker: PhD D&#10;Content: Uh . No . You mean {pause} training digits {pause} on one language and using the net {pause} to recognize on the other ?&#10;Speaker: PhD A&#10;Content: Digits on another language ?&#10;Speaker: PhD D&#10;Content: No .&#10;Speaker: Professor B&#10;Content: See , I thought you showed me something like that last week . You had a {disfmarker} you had a little {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , {pause} No , I don't think so .&#10;Speaker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio" />
    <node id=" . So you trained on {pause} one type of digits and tested on another . Didn - Wasn't there something of that ? Where you , {pause} say , trained on Spanish and tested on {disfmarker} on TI - digits , or the other way around ? Something like that ?&#10;Speaker: PhD E&#10;Content: No .&#10;Speaker: Professor B&#10;Content: I thought there was something like that , {pause} that he showed me {pause} last week . We 'll have to wait till we get {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , that would be interesting .&#10;Speaker: Professor B&#10;Content: Um , This may have been what I was asking before , Stephane , but {disfmarker} {pause} but , um , wasn't there something that you did , {pause} where you trained {pause} on one language and tested on another ? I mean no {disfmarker} no mixture but just {disfmarker}&#10;Speaker: Grad F&#10;Content: I 'll get it for you .&#10;Speaker: PhD D&#10;Content: Uh , no , no .&#10;Speaker: Professor B&#10;Content" />
    <node id=" Um {pause} and {pause} um But , {pause} when you add in more training data but keep the neural net the same size , {pause} it {pause} um performs worse on the TI - digits . OK , now all of this is {disfmarker} {pause} This is noisy {pause} TI - digits , I assume ? Both training and test ?&#10;Speaker: PhD D&#10;Content: &#10;Speaker: Professor B&#10;Content: Yeah . OK . Um OK . Well . {pause} We {disfmarker} we {disfmarker} we may just need to uh {disfmarker} So I mean it 's interesting that h going to a different {disfmarker} different task didn't seem to hurt us that much , and going to a different language um It doesn't seem to matter {disfmarker} The difference between three and four is not particularly great , so that means that {pause} whether you have the language in or not is not such a big deal .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: It sounds like um {pause} uh {pause} we may need to have" />
    <node id=" using the same output ? This multi - language {pause} uh labelling ?&#10;Speaker: Grad F&#10;Content: He was using uh sixty - four phonemes from {pause} SAMPA .&#10;Speaker: PhD A&#10;Content: OK , OK .&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So this would {disfmarker} {pause} From this you would say , &quot; well , it doesn't really matter if we put Finnish {pause} into {pause} the training of the neural net , {pause} if there 's {pause} gonna be , {pause} you know , Finnish in the test data . &quot; Right ?&#10;Speaker: Professor B&#10;Content: Well , it 's {disfmarker} it sounds {disfmarker} {pause} I mean , we have to be careful , cuz we haven't gotten a good result yet .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And comparing different bad results can be {pause} tricky .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But I {disfmark" />
    <node id=" be {pause} tricky .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But I {disfmarker} I {disfmarker} I {disfmarker} {pause} I think it does suggest that it 's not so much uh {pause} uh cross {pause} language as cross type of speech .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: It 's {disfmarker} it 's um {disfmarker} {vocalsound} But we did {disfmarker} Oh yeah , the other thing I was asking him , though , is that I think that in the case {disfmarker} Yeah , you {disfmarker} you do have to be careful because of com compounded results . I think we got some earlier results {pause} in which you trained on one language and tested on another and you didn't have {pause} three , but you just had one {pause} language . So you trained on {pause} one type of digits and tested on another . Didn - Wasn't there something of that ? Where you , {pause" />
    <node id=" training and TI - digits as test ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh different words , I 'm sure ,&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but {disfmarker} {pause} but uh , uh the same {pause} task and so on .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: If we call that &quot; one &quot; , {pause} then what you 're saying is {pause} that the word error rate {pause} for the same language but using {pause} uh different training data than you 're testing on , say TIMIT and so forth , {pause} it 's one point one .&#10;Speaker: PhD D&#10;Content: Mm - hmm . Yeah , it 's around one point one .&#10;Speaker: Professor B&#10;Content: Right . And if it 's {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: you {pause} do {pause} go to {pause}" />
    <node id="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." />
    <node id=" Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {disfmarker} there is {disfmarker} another difference , is that the noise {disfmarker} the noises are different .&#10;Speaker: Professor B&#10;Content: In {disfmarker} in what ?&#10;Speaker: PhD D&#10;Content: Well , For {disfmarker} for the Italian part I mean the {pause} uh {pause} the um {pause} networks are trained with noise from {pause} Aurora {disfmarker} TI - digits ,&#10;Speaker: PhD E&#10;Content: Aurora - two .&#10;Speaker: PhD D&#10;Content: mmm .&#10;Speaker: Professor B&#10;Content: And the noise is different in th&#10;Speaker: PhD D&#10;Content: Yeah . And perhaps the noise are {pause} quite different from the noises {pause} in the speech that Italian .&#10;Speaker: Professor B&#10;Content: Do we have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora" />
    <node id=" baseline Aurora .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well .&#10;Speaker: Professor B&#10;Content: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker}&#10;Speaker: PhD C&#10;Content: Chicken on the grill . Try that corner .&#10;Speaker: PhD A&#10;Content: How about over th from the front of the room ?&#10;Speaker: PhD C&#10;Content" />
    <node id=" But {disfmarker} but the question is if you train on one language {pause} but you have a broad coverage {pause} and then test in another , {pause} does that {disfmarker} {pause} is that improve things {pause} i c in comparison ?&#10;Speaker: PhD D&#10;Content: If we use the same language ?&#10;Speaker: Professor B&#10;Content: No , no , no . Different lang So {pause} um {pause} If you train on TI - digits {pause} and test on Italian digits , {pause} you do poorly , {pause} let 's say .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I don't have the numbers in front of me ,&#10;Speaker: PhD D&#10;Content: But {disfmarker} Yeah but I did not uh do that .&#10;Speaker: Professor B&#10;Content: so I 'm just imagining . E So , you didn't train on {pause} TIMIT and test on {disfmarker} {pause} on Italian digits , say ?&#10;Speaker: PhD D&#10;Content: We {disfmarker}" />
    <node id=" results are {vocalsound} uh {pause} stranger um {pause} Mmm . So what appears is that perhaps Spanish is {pause} not very close to Italian because uh , well , {pause} when using the {disfmarker} the network trained only on Spanish it 's {disfmarker} {pause} the error rate is {pause} almost uh twice {pause} the baseline error rate .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . {vocalsound} Uh .&#10;Speaker: Professor B&#10;Content: Well , I mean , let 's see . Is there any difference in {disfmarker} So it 's in {pause} the uh {disfmarker} So you 're saying that {pause} when you train on English {pause} and {pause} uh {pause} and {disfmarker} and test on {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {" />
    <node id="aker: Grad F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: PhD D&#10;Content: and it 's divided in three {pause} rows {pause} of four {disfmarker} four rows each .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: And the first four rows is well - matched , then the s the second group of four rows is mismatched , and {pause} finally highly mismatched . And then the lower part is for Italian and it 's the same {disfmarker} {pause} the same thing .&#10;Speaker: PhD A&#10;Content: So , so the upper part is training {pause} TI - digits ?&#10;Speaker: PhD D&#10;Content: So . It 's {disfmarker} it 's the HTK results , I mean . So it 's {pause} HTK training testings {pause} with different kind of features&#10;Speaker: PhD A&#10;Content: Ah .&#10;Speaker: PhD D&#10;Content: and what appears in the {pause} uh left column is {pause} the networks that are" />
    <node id="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." />
    <node id=" mean and variances {pause} measured across the whole database .&#10;Speaker: Professor B&#10;Content: Right . Right .&#10;Speaker: PhD D&#10;Content: And Pratibha did something different is that he {disfmarker} uh she initialed the um values of the mean and variance {pause} by computing {pause} this on the {pause} twenty - five first frames of each utterance . Mmm . There were other minor differences , the fact that {pause} she used fifteen dissities instead s instead of thirteen , and that she used C - zero instead of log energy . Uh , but the main differences concerns the recursion . So . {pause} Uh , I changed the code uh and now we have a baseline that 's similar to the OGI baseline .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: We {disfmarker} It {disfmarker} it 's slightly {pause} uh different because {pause} I don't exactly initialize the same way she does . Actually I start , {pause} mmm , I don't wait to a fifteen {disfmarker} twenty - five {disfmarker} twenty" />
    <node id=" And Pratibha used five percent .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: So it adapts more {pause} quickly&#10;Speaker: Professor B&#10;Content: Yes . Yeah .&#10;Speaker: PhD D&#10;Content: Um , but , yeah . I assume that this was not important because {pause} uh previous results from {disfmarker} from Dan and {disfmarker} show that basically {pause} the {pause} both {disfmarker} both values g give the same {disfmarker} same {pause} uh results . It was true on uh {pause} TI - digits but it 's not true on Italian .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , second thing is the initialization of the {pause} stuff . Actually , {pause} uh what we were doing is to start the recursion from the beginning of the {pause} utterance . And using initial values that are the global mean and variances {pause} measured across the whole database .&#10;Speaker: Professor B&#10;Content: Right . Right .&#10;Speaker: PhD D" />
    <node id=": PhD D&#10;Content: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {pause} uh the way we were doing this was not correct , but {pause} still {pause} the networks {pause} are very good . When we use the networks {pause} our number are better that {pause} uh Pratibha results .&#10;Speaker: PhD E&#10;Content: We improve .&#10;Speaker: Professor B&#10;Content: So , do you know what was wrong with the on - line normalization , or {disfmarker} ?&#10;Speaker: PhD D&#10;Content: Yeah . There were diff there were different things and {pause} basically , {pause} the first thing is the mmm , {pause} alpha uh {pause} value . So , the recursion {pause} uh {pause} part . um , {pause} I used point five percent , {pause} which was the default value in the {disfmarker} {pause} in the programs here . And Pratibha used five percent .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: So it adapts" />
    <node id=" leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content:" />
    <node id="} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content: Where is that ? seventy - nine , fifty&#10;Speaker: Professor B&#10;Content: Uh , it 's just sort of sitting right on the uh {disfmarker} the column line .&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: PhD E&#10;Content: Fifty - one ? This {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh I see , OK .&#10;Speaker: Professor B&#10;Content: Uh . {pause} Yeah .&#10;Speaker: PhD D&#10;Content: Just {disfmarker} uh Yeah . So these are the results of {pause} OGI with {pause} on - line normalization and straight features to HTK . And the previous result , eighty - six and so on , {pause} are with our {pause} features straight to HTK .&#10;Speaker: Professor B&#10;Content: Yes . Yes .&#10;Speaker: PhD D&#10;Content: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {" />
    <node id=" D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: It sounds like um {pause} uh {pause} we may need to have more {pause} of uh things that are similar to a target language or {disfmarker} I mean . {pause} You have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just {disfmarker} {pause} just not enough {pause} complexity to it to represent {pause} the variab increased variability in the {disfmarker} in the training set . That {disfmarker} that could be . Um {pause} So , what about {disfmarker} So these are results with {pause} uh th {pause} that you 're describing now , that {pause} they are pretty similar for the different features or {disfmarker} {pause} or uh {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , let me check . Uh .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: So . This was for the PLP ,&#10;Speaker: Professor B" />
    <node id="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." />
    <node id="isfmarker} I was looking at it I was {pause} mostly thinking about the {disfmarker} {pause} the VAD . And um , it ap {pause} it ap Oh what does {disfmarker} what does ASP ? Oh that 's {disfmarker}&#10;Speaker: PhD D&#10;Content: The features , yeah . Yeah .&#10;Speaker: PhD E&#10;Content: I don't understand also&#10;Speaker: Professor B&#10;Content: It says &quot; baseline ASP &quot; .&#10;Speaker: PhD E&#10;Content: what is {disfmarker} {pause} what is the difference between ASP and uh baseline over ?&#10;Speaker: PhD C&#10;Content: ASP .&#10;Speaker: PhD D&#10;Content: Yeah , I don't know .&#10;Speaker: PhD E&#10;Content: This is {disfmarker}&#10;Speaker: Professor B&#10;Content: Anybody know {pause} any {disfmarker}&#10;Speaker: PhD C&#10;Content: Oh . There it is .&#10;Speaker: Professor B&#10;Content: Um Cuz there 's &quot; baseline Aurora &quot; {pause} above it .&#10;Speaker: PhD C&#10;Content:" />
    <node id="Content: Yeah .&#10;Speaker: PhD D&#10;Content: I think {disfmarker} {pause} I think it 's the C - zero {disfmarker} using C - zero instead of log energy .&#10;Speaker: PhD E&#10;Content: Ah , OK , mm - hmm .&#10;Speaker: PhD D&#10;Content: Yeah , it 's this .&#10;Speaker: Professor B&#10;Content: Oh . OK .&#10;Speaker: PhD E&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: It should be that , yeah .&#10;Speaker: PhD A&#10;Content: They s they say in here that the VAD is not used as an additional feature .&#10;Speaker: Professor B&#10;Content: Shouldn't it be {disfmarker}&#10;Speaker: PhD D&#10;Content: Because {disfmarker}&#10;Speaker: PhD A&#10;Content: Does {disfmarker} does anybody know how they 're using it ?&#10;Speaker: Professor B&#10;Content: Yeah . So {disfmarker} so what they 're doing here is , {pause} i&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker" />
    <node id="aker: Professor B&#10;Content: Um Cuz there 's &quot; baseline Aurora &quot; {pause} above it .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: And it 's {disfmarker} This is mostly better than baseline , although in some cases it 's a little worse , in a couple cases .&#10;Speaker: PhD C&#10;Content: Well , it says baseline ASP is twenty - three mill {pause} minus thirteen .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah , it says what it is . But I don't how that 's different {pause} from {disfmarker}&#10;Speaker: PhD C&#10;Content: From the baseline . {comment} OK .&#10;Speaker: Professor B&#10;Content: I think this was {disfmarker} {pause} I think this is the same point we were at when {disfmarker} when we were up in Oregon .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: I think {disfmarker} {pause} I think it 's the C -" />
    <node id="Content: Ah .&#10;Speaker: PhD D&#10;Content: and what appears in the {pause} uh left column is {pause} the networks that are used for doing this .&#10;Speaker: Professor B&#10;Content: Hmm .&#10;Speaker: PhD D&#10;Content: So . Uh Yeah .&#10;Speaker: Professor B&#10;Content: Well , What was is that i What was it that you had {pause} done {pause} last week when you showed {disfmarker} Do you remember ? Wh - when you showed me {pause} the {disfmarker} your table last week ?&#10;Speaker: PhD D&#10;Content: It - It was part of these results . Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: So where is the baseline {pause} for the TI - digits {pause} located in here ?&#10;Speaker: PhD D&#10;Content: You mean the HTK Aurora baseline ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: It 's uh the one hundred number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline .&#10;Speaker: PhD A&#10;Content:" />
    <node id="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." />
    <node id=" A&#10;Content: I see .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: OK ? Um {pause} So uh , I think this will take some {pause} looking at , thinking about . But , {pause} what is uh {disfmarker} what is currently running , that 's {disfmarker} uh , i that {disfmarker} just filling in the holes here or {disfmarker} or {disfmarker} ? {comment} {pause} pretty much ?&#10;Speaker: PhD D&#10;Content: Uh , no we don't plan to fill the holes&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: but {pause} actually there is something important , is that {pause} um we made a lot of assumption concerning the on - line normalization and we just noticed {pause} uh recently that {pause} uh the {pause} approach that we were using {pause} was not {pause} uh {pause} leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So" />
    <node id="marker} for Aurora ?&#10;Speaker: PhD D&#10;Content: For HTK ?&#10;Speaker: Professor B&#10;Content: For {disfmarker} Yeah . For the Aurora ?&#10;Speaker: PhD D&#10;Content: Uh Training is longer .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK . Well , I don't know how we can {disfmarker} I don't know how to {disfmarker} Do we have HTK source ? Is that {disfmarker} Yeah .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: You would think that would fairly trivially {disfmarker} the training would , anyway , th the testing {pause} uh I don't {disfmarker} I don't {pause} think would {pause} parallelize all that well . But I think {pause} that {pause} you could {pause} certainly do d um , {pause} distributed , sort of {disfmarker} {pause} Ah , no , it 's the {disfmarker}" />
    <node id=" yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: So basically what I expect is that {pause} these numbers will a little bit go down but {pause} perhaps not {disfmarker} not so much&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: because {pause} I think the neural networks learn perhaps {pause} to {disfmarker}&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: even if the features are not {pause} normalized . It {disfmarker} it will learn how to normalize and {disfmarker}&#10;Speaker: Professor B&#10;Content: OK , but I think that {pause} given the pressure of time we probably want to draw {disfmarker} because of that {pause} especially , we wanna draw some conclusions from this , do some reductions {pause} in what we 're looking at ,&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and make some strong decisions for what we 're gonna do testing on before next week . So do you {disf" />
    <node id="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." />
    <node id=" point four case {disfmarker} does it include the training data for the one point one case ?&#10;Speaker: PhD D&#10;Content: Uh yeah .&#10;Speaker: Grad F&#10;Content: Yeah , a fraction of it .&#10;Speaker: PhD D&#10;Content: A part of it , yeah .&#10;Speaker: Professor B&#10;Content: How m how much bigger is it ?&#10;Speaker: PhD D&#10;Content: Um {pause} It 's two times ,&#10;Speaker: Grad F&#10;Content: Yeah , um .&#10;Speaker: PhD D&#10;Content: actually ? Yeah . Um . The English data {disfmarker} {pause} No , the multilingual databases are two times the {pause} broad English {pause} data . We just wanted to keep this , w well , not too huge . So .&#10;Speaker: Professor B&#10;Content: So it 's two times , but it includes the {disfmarker} but it includes the broad English data .&#10;Speaker: PhD D&#10;Content: I think so . Do you {disfmarker} Uh , Yeah .&#10;Speaker: Professor B&#10;Content: And the broad English data is what you got this" />
    <node id=" Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um {pause} for uh TI - digits for ins example {pause} uh when we go from TI - digits training to {pause} TIMIT training {pause} uh we lose {pause} uh around ten percent , uh . The error rate increase u of {disfmarker} of {disfmarker} of ten percent , relative .&#10;Speaker: Professor B&#10;Content: Relative . Right .&#10;Speaker: PhD D&#10;Content: So this is not so bad . And then when we jump to the multilingual data it 's uh it become worse and , well Around uh , let 's say , {pause} twenty perc twenty percent further .&#10;Speaker: Professor B&#10;Content: Ab - about how much ?&#10;Speaker: PhD D&#10;Content: So . Yeah .&#10;Speaker: Professor B&#10;Content: Twenty percent further ?&#10;Speaker: PhD D&#10;Content: Twenty to {disfmarker} to thirty percent further . Yeah .&#10;Speaker: PhD A&#10;Content: And so , remind me , the multilingual stuff is just" />
    <node id=" {disfmarker}&#10;Speaker: PhD A&#10;Content: OK ?&#10;Speaker: PhD D&#10;Content: Yeah . Uh {pause} So , basically when it 's trained on the {disfmarker} the multilingual broad data {pause} um or number {disfmarker} so , the {disfmarker} the {pause} ratio of our error rates uh with the {pause} baseline error rate is around {pause} uh one point one .&#10;Speaker: Professor B&#10;Content: Yes . {vocalsound} And it 's something like one point three of {disfmarker} of the {pause} uh {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: I i if you compare everything to the first case at the baseline , you get something like one point one for the {disfmarker} for the using the same language but a different task , and something like one point three {pause} for three {disfmarker} three languages {pause} broad stuff .&#10;Speaker: PhD D&#10;Content: No no no . Uh same language we are at uh {disfmarker" />
    <node id="Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: you {pause} do {pause} go to {pause} three languages including the English , {pause} it 's something like one point three . That 's what you were just saying , I think .&#10;Speaker: PhD D&#10;Content: Ye Uh , more actually .&#10;Speaker: PhD A&#10;Content: One point four ?&#10;Speaker: PhD D&#10;Content: If I {disfmarker} Yeah .&#10;Speaker: PhD A&#10;Content: So , it 's an additional thirty percent .&#10;Speaker: PhD D&#10;Content: What would you say ? Around one point four&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Professor B&#10;Content: And if you exclude {pause} English , {pause} from this combination , what 's that ?&#10;Speaker: PhD D&#10;Content: If we exclude English , {pause} um {pause} there is {pause} not much difference with the {pause} data with English .&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD D&#10;Content" />
    <node id="pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B&#10;Content: the one that it 's {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: In&#10;Speaker: PhD D&#10;Content: But {pause} not digits . I mean it 's {disfmarker}&#10;Speaker: PhD A&#10;Content: The three languages {pause} is not digits ,&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: it 's the broad {pause} data . OK .&#10;Speaker: PhD D&#10;Content: Yeah And the fourth test is uh {pause} excluding from these three languages the language {pause} that is {pause} the task language .&#10;Speaker: Professor B&#10;Content: Oh , OK , yeah , so , that is what I wanted to know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um" />
    <node id="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." />
    <node id=" on {disfmarker} {pause} on Italian digits , say ?&#10;Speaker: PhD D&#10;Content: We {disfmarker} No , we did four {disfmarker} four kind of {disfmarker} of testing , actually . The first testing is {pause} with task data {disfmarker} So , with nets trained on task data . So for Italian on the Italian speech @ @ . The second test is trained on a single language um with broad database , but the same language as the t task data .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: But for Italian we choose Spanish which {pause} we assume is close to Italian . The third test is by using , um the three language database&#10;Speaker: Professor B&#10;Content: W which in {disfmarker}&#10;Speaker: PhD D&#10;Content: and the fourth is&#10;Speaker: Professor B&#10;Content: It has three languages . That 's including the w the {disfmarker} {pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B" />
    <node id="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." />
    <node id=" that is {pause} very distinguishable from {pause} speech .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: So that the {disfmarker} the silence model in HTK will always pick it up .&#10;Speaker: Professor B&#10;Content: Yeah . So I {disfmarker} I {disfmarker} that 's what I thought they would do . or else , uh {pause} uh maybe there is some indicator to tell it to start and stop , I don't know .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But whatever they did , I mean they have to play within the rules of this specific evaluation .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: We c we can find out .&#10;Speaker: PhD A&#10;Content: Cuz you gotta do something . Otherwise , if it 's just a bunch of speech , stuck together {disfmarker}&#10;Speaker: Professor B&#10;Content: No they 're {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker" />
    <node id=" um , {pause} there 's um , {pause} the issue of the {pause} um Mu law {pause} business {pause} uh {pause} versus the logarithm , um , {pause} so .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So what i what is going on right now ? What 's right {disfmarker} you 've got {pause} nets retraining , Are there {disfmarker} is there {disfmarker} are there any H T K {pause} trainings {disfmarker} testings going on ?&#10;Speaker: PhD D&#10;Content: N&#10;Speaker: PhD E&#10;Content: I {disfmarker} I {disfmarker} I 'm trying the HTK with eh , {pause} PLP twelve on - line delta - delta and MSG filter {pause} together .&#10;Speaker: Professor B&#10;Content: The combination , I see .&#10;Speaker: PhD E&#10;Content: The combination , yeah . But I haven't result {vocalsound} at this moment .&#10;Speaker: Professor B&#10;Content:" />
    <node id="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." />
    <node id=" will never occur {pause} in one language and will occur frequently in the other , so the qu the issue of getting enough training {pause} for a particular kind of context becomes harder . We already actually don't have a huge amount of training data um&#10;Speaker: PhD D&#10;Content: Yeah , but {disfmarker} mmm , I mean , {pause} the {disfmarker} the way we {disfmarker} we do it now is that we have a neural network and {pause} basically {pause} the net network is trained almost to give binary decisions .&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: And {pause} uh {disfmarker} binary decisions about phonemes . Nnn {disfmarker} Uh It 's {disfmarker}&#10;Speaker: Professor B&#10;Content: Almost . But I mean it {disfmarker} it {disfmarker} it does give a distribution .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: It 's {disfmarker} and {disfmarker} and {pause} it is" />
    <node id=" PhD D&#10;Content: So {disfmarker}&#10;Speaker: Professor B&#10;Content: right ? Any - anyway go ahead .&#10;Speaker: PhD D&#10;Content: Yeah . So uh what we were thinking about is perhaps {pause} um one way {pause} to solve this problem is increase the number of {pause} outputs of the neural networks . Doing something like , um {pause} um phonemes within context and , well , basically context dependent phonemes .&#10;Speaker: Professor B&#10;Content: Maybe . I mean , I {disfmarker} I think {pause} you could make {pause} the same argument , it 'd be just as legitimate , {pause} for hybrid systems {pause} as well . Right .&#10;Speaker: PhD D&#10;Content: Yeah but , we know that {disfmarker}&#10;Speaker: Professor B&#10;Content: And in fact , {pause} th things get better with context dependent {pause} versions . Right ?&#10;Speaker: PhD D&#10;Content: Ye - yeah but here it 's something different . We want to have features&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: uh" />
    <node id=" basically perhaps a flaw in the {disfmarker} in the {disfmarker} the stuff because {pause} we {pause} trained the networks {disfmarker} If we trained the networks on the {disfmarker} on {pause} a language and a t or a specific {pause} task ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: um , what we ask is {disfmarker} to the network {disfmarker} is to put the bound the decision boundaries somewhere in the space .&#10;Speaker: Professor B&#10;Content: Mmm .&#10;Speaker: PhD D&#10;Content: And uh {pause} mmm and ask the network to put one , {pause} at one side of the {disfmarker} for {disfmarker} for a particular phoneme at one side of the boundary {disfmarker} decision boundary and one for another phoneme at the other side . And {pause} so there is kind of reduction of the information there that 's not correct because if we change task {pause} and if the phonemes are not in the same context in the new" />
    <node id="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments." />
    <node id=" 're doing this with H T&#10;Speaker: PhD A&#10;Content: Yeah , that 's what I was just gonna ask .&#10;Speaker: Professor B&#10;Content: This is {disfmarker}&#10;Speaker: PhD A&#10;Content: How can you just throw out frames ?&#10;Speaker: Professor B&#10;Content: Yeah . Well , you {disfmarker} you can ,&#10;Speaker: PhD D&#10;Content: i&#10;Speaker: Professor B&#10;Content: right ? I mean y you {disfmarker} you {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: it stretches again . For single frames I think it would be pretty hard .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: But if you say speech starts here , speech ends there .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Right ?&#10;Speaker: PhD C&#10;Content: Huh .&#10;Speaker: PhD D&#10;Content: Yeah . Yeah , you can basically remove the {disfmarker} the frames from the feature" />
    <node id=" wise VAD and the {disfmarker} {pause} the median filter say that there 's a stretch of silence . And then it 's going through and just throwing the data away .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: Right ? So um {disfmarker}&#10;Speaker: PhD A&#10;Content: So it 's {disfmarker} it 's {disfmarker} I don't understand . You mean it 's throwing out frames ? Before {disfmarker}&#10;Speaker: Professor B&#10;Content: It 's throwing out chunks of frames , yeah . There 's {disfmarker} the {disfmarker} the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So it 's throwing out frames and the thing is {pause} um , {pause} what I don't understand is how they 're doing this with H T&#10;Speaker: PhD A&#10;Content: Yeah , that 's what I was just gonna ask .&#10;Speaker:" />
    <node id=" not much difference with the {pause} data with English .&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD D&#10;Content: So . Yeah .&#10;Speaker: Professor B&#10;Content: That 's interesting . {pause} That 's interesting . Do you see ? Because {disfmarker} Uh ,&#10;Speaker: PhD D&#10;Content: Uh .&#10;Speaker: Professor B&#10;Content: so {disfmarker} No , that {disfmarker} that 's important . So what {disfmarker} what it 's saying here is just that &quot; yes , there is a reduction {pause} in performance , {pause} when you don't {pause} um {pause} have the s {pause} when you don't have {pause} um&#10;Speaker: PhD A&#10;Content: Task data .&#10;Speaker: Professor B&#10;Content: Wait a minute , th th the {disfmarker}&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: No , actually {pause} it 's interesting . So it 's {disfmarker} So when you go to a different task ," />
    <node id="disfmarker} so what they 're doing here is , {pause} i&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: if you look down at the block diagram , {pause} um , {pause} they estimate {disfmarker} they get a {disfmarker} {pause} they get an estimate {pause} of whether it 's speech or silence ,&#10;Speaker: PhD A&#10;Content: But that {disfmarker}&#10;Speaker: Professor B&#10;Content: and then they have a median filter of it .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: And so um , {pause} basically they 're trying to find stretches . The median filter is enforcing a {disfmarker} i it having some continuity .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: You find stretches where the {pause} combination of the {pause} frame wise VAD and the {disfmarker} {pause} the median filter say that there 's a stretch of silence . And then it 's" />
    <node id="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart." />
    <node id="aker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio to baseline ?&#10;Speaker: Professor B&#10;Content: So , I mean wha what 's the {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: This {disfmarker} this chart {disfmarker} this table that we 're looking at {pause} is um , show is all testing for TI - digits , or {disfmarker} ?&#10;Speaker: Grad F&#10;Content: Bigger is worse .&#10;Speaker: PhD D&#10;Content: So you have uh basically two {pause} uh parts .&#10;Speaker: Grad F&#10;Content: This is error rate , I think .&#10;Speaker: PhD C&#10;Content: Ratio .&#10;Speaker: Grad F&#10;Content: No . {pause} No .&#10;Speaker: PhD D&#10;Content: The upper part is for TI - digits&#10;Speaker: Grad F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: PhD D&#10;Content: and it 's divided in three {pause}" />
    <node id="isfmarker} let 's use the conventional meaning of baseline .&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: I {disfmarker} I {disfmarker} By baseline here I meant {pause} uh using the task specific data .&#10;Speaker: PhD D&#10;Content: Oh yeah , the f Yeah , OK .&#10;Speaker: Professor B&#10;Content: But uh {disfmarker} {pause} uh , because that 's what you were just doing with this ten percent .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So I was just {disfmarker} I just trying to understand that .&#10;Speaker: PhD D&#10;Content: Yeah . Sure .&#10;Speaker: Professor B&#10;Content: So if we call {pause} a factor of w just one , just normalized to one , the word error rate {pause} that you have {pause} for using TI - digits as {disfmarker} as {pause} training and TI - digits as test ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh different words" />
    <node id=" number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline .&#10;Speaker: PhD A&#10;Content: Ah ! Ah , OK , OK .&#10;Speaker: Professor B&#10;Content: So this is word {disfmarker} word error rate , so a high number is bad .&#10;Speaker: PhD D&#10;Content: Yeah , this is {pause} a word error rate ratio .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: OK , I see .&#10;Speaker: PhD D&#10;Content: Yeah . So , seventy point two means that {pause} we reduced the error rate uh by thirty {disfmarker} thirty percent .&#10;Speaker: PhD A&#10;Content: OK , OK , gotcha .&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: OK , {vocalsound} so if we take&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: uh um let 's see PLP {pause} uh with on - line {pause} normalization and {pause} delta - del so that 's this thing" />
    <node id="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame." />
    <node id="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." />
    <node id=" have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora ?&#10;Speaker: PhD D&#10;Content: And {disfmarker}&#10;Speaker: PhD E&#10;Content: Mmm , no .&#10;Speaker: PhD D&#10;Content: No .&#10;Speaker: PhD A&#10;Content: Can I ask something real quick ? In {disfmarker} in the upper part {disfmarker} {pause} in the English {pause} stuff , {pause} it looks like the very best number is sixty point nine ? and that 's in the uh {disfmarker} {pause} the third {pause} section in the upper part under PLP JRASTA , sort of the middle column ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I is that {pause} a noisy condition ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So that 's matched training ? Is that what that is ?&#10;Speaker: PhD D&#10;Content: It 's {disfmarker} no , the" />
    <node id="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian." />
    <node id="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." />
    <node id=" slightly worse when we don't use delta but it 's not {disfmarker} {pause} not that much .&#10;Speaker: Professor B&#10;Content: Right . So w w So , I 'm sorry . I missed that . What 's MF , MS and ME ?&#10;Speaker: PhD A&#10;Content: Multi - French , Multi - Spanish&#10;Speaker: PhD D&#10;Content: So . Multi - French , Multi - Spanish , and Multi - English .&#10;Speaker: Professor B&#10;Content: Uh OK . So , it 's {pause} uh {pause} broader vocabulary . Then {disfmarker} And {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK so I think what I 'm {disfmarker} what I saw in your smaller chart that I was thinking of was {disfmarker} was {pause} there were some numbers I saw , I think , that included these multiple languages and it {disfmarker} and I was seeing {pause} that it got worse . I {disfmarker} I think that was all it was . You had some very limited results that {" />
    <node id=" seeing {pause} that it got worse . I {disfmarker} I think that was all it was . You had some very limited results that {disfmarker} at that point&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: which showed {pause} having in these {disfmarker} these other languages . In fact it might have been just this last category , {pause} having two languages broad that were {disfmarker} where {disfmarker} where English was removed . So that was cross language and the {disfmarker} and the result was quite poor . What I {disfmarker} {pause} we hadn't seen yet was that if you added in the English , it 's still poor .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh {vocalsound} {vocalsound} Um now , what 's the noise condition {pause} um {pause} of the training data {disfmarker}&#10;Speaker: PhD D&#10;Content: Still poor .&#10;Speaker: Professor B&#10;Content: Well , I think this is what you were explaining ." />
    <node id="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context." />
    <node id=" Yes , I don't know . That 's {disfmarker} that 's {disfmarker} so that 's a {disfmarker} that 's a very good question , then {disfmarker} now that it {disfmarker} {pause} I understand it . It 's &quot; yeah , where does the LDA come from ? &quot; In the {disfmarker} In {pause} earlier experiments , they had taken LDA {pause} from a completely different database , right ?&#10;Speaker: PhD E&#10;Content: Yeah . Yeah , because maybe it the same situation that the neural network training with their own&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: PhD E&#10;Content: set .&#10;Speaker: Professor B&#10;Content: So that 's a good question . Where does it come from ? Yeah , I don't know . Um , {pause} but uh to tell you the {pause} truth , I wasn't actually looking at the LDA so much when I {disfmarker} I was looking at it I was {pause} mostly thinking about the {disfmarker} {pause} the VAD . And" />
    <node id=" , anyway .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So um Their uh {disfmarker} {pause} the results look pretty good . Um , {pause} I mean , not uniformly .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean , there 's a {disfmarker} an example or two {pause} that you can find , where it made it slightly worse , but {pause} uh in {disfmarker} in all but a couple {pause} examples .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Uh .&#10;Speaker: PhD E&#10;Content: But they have a question of the result . Um how are trained the {disfmarker} the LDA filter ? How obtained the LDA filter ?&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: I I 'm sorry . I don't understand your question .&#10;Speaker: PhD E&#10;Content: Yes , um the LDA filter {pause} needs some {pause} training set {" />
    <node id="'t understand your question .&#10;Speaker: PhD E&#10;Content: Yes , um the LDA filter {pause} needs some {pause} training set {pause} to obtain the filter . Maybe I don't know exactly how {pause} they are obtained .&#10;Speaker: Professor B&#10;Content: It 's on {pause} training .&#10;Speaker: PhD E&#10;Content: Training , with the training test of each {disfmarker} You understand me ?&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: PhD E&#10;Content: Yeah , uh for example , {pause} LDA filter {pause} need a set of {disfmarker} {pause} a set of training {pause} to obtain the filter .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD E&#10;Content: And maybe {pause} for the Italian , for the TD {pause} TE on for Finnish , these filter are {disfmarker} are obtained with their own training set .&#10;Speaker: Professor B&#10;Content: Yes , I don't know . That 's {disfmarker} that 's {disfmarker} so that 's a {d" />
    <node id="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." />
    <node id=" again , it 's the silence {disfmarker} So they 've just trained up a net {pause} which has two outputs , I believe . Um {vocalsound} I asked uh {pause} Hynek whether {disfmarker} I haven't talked to Sunil {disfmarker} I asked Hynek whether {pause} they compared that to {pause} just taking the nets we already had {pause} and summing up the probabilities .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh . {pause} To get the speech {disfmarker} voice activity detection , or else just using the silence , {pause} if there 's only one {pause} silence output . Um {pause} And , he didn't think they had , um . But on the other hand , maybe they can get by with a smaller net and {pause} maybe {pause} sometimes you don't run the other , maybe there 's a computational advantage to having a separate net , anyway .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So um Their uh {" />
    <node id="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task." />
    <node id="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured." />
    <node id="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations." />
    <node id=": what do we do in four or five days ? Uh , and {disfmarker} {pause} so we have {pause} to be concerned {pause} with Are we gonna look at any combinations of things , you know once the nets get retrained so you have this problem out of it .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Um , are we going to look at {pause} multi - band ? Are we gonna look at combinations of things ? Uh , what questions are we gonna ask , uh now that , I mean , {pause} we should probably turn shortly to this O G I note . Um , how are we going to {pause} combine {pause} with what they 've been focusing on ? Uh , {pause} Uh we haven't been doing any of the L D A RASTA sort of thing .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: And they , although they don't talk about it in this note , um , {pause} there 's um , {pause} the issue of the {pause} um Mu law {pause} business {pause} uh {" />
    <node id="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided." />
    <node id=": I 'll get it for you .&#10;Speaker: PhD D&#10;Content: Uh , no , no .&#10;Speaker: Professor B&#10;Content: We 've never just trained on one lang&#10;Speaker: PhD D&#10;Content: Training on a single language , you mean , and testing on the other one ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Uh , no .&#10;Speaker: PhD E&#10;Content: Not yet .&#10;Speaker: PhD D&#10;Content: So the only {pause} task that 's similar to this is the training on two languages , and {comment} that {disfmarker}&#10;Speaker: Professor B&#10;Content: But we 've done a bunch of things where we just trained on one language . Right ? I mean , you haven't {disfmarker} you haven't done all your tests on multiple languages .&#10;Speaker: PhD D&#10;Content: Uh , No . Either thi this is test with {pause} uh the same language {pause} but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker}" />
    <node id="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles." />
    <node id=" or something .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And then uh , just to remind me , all of that goes {pause} into {disfmarker} uh , that all of that is transformed by uh , uh , K - KL or something , or {disfmarker} ?&#10;Speaker: PhD D&#10;Content: Mm - hmm . There will probably be ,&#10;Speaker: PhD E&#10;Content: Mu .&#10;Speaker: PhD D&#10;Content: yeah , one single KL to transform everything&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: or {vocalsound} {pause} uh ,&#10;Speaker: PhD E&#10;Content: No transform the PLP&#10;Speaker: PhD D&#10;Content: per&#10;Speaker: PhD E&#10;Content: and only transform the other I 'm not sure .&#10;Speaker: Professor B&#10;Content: Well no ,&#10;Speaker: PhD D&#10;Content: This is {pause} still something {pause} that&#10;Speaker: Professor B&#10;Content: I think {disfmarker} I see .&#10;Speaker: PhD D&#10;Content" />
    <node id="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine." />
    <node id=" {pause} um I could try to get {pause} um the train the neural network trainings or the HTK stuff running under Linux , and to start with I 'm {pause} wondering which one I should pick first .&#10;Speaker: Professor B&#10;Content: Uh , probably the neural net cuz it 's probably {disfmarker} it {disfmarker} it 's {disfmarker} {pause} it 's um {disfmarker} Well , I {disfmarker} I don't know . They both {disfmarker} HTK we use for {pause} um {pause} this Aurora stuff Um {pause} Um , I think {pause} It 's not clear yet what we 're gonna use {pause} for trainings uh {disfmarker} Well , {pause} there 's the trainings uh {disfmarker} is it the training that takes the time , or the decoding ? Uh , is it about equal {pause} between the two ? For {disfmarker} for Aurora ?&#10;Speaker: PhD D&#10;Content: For HTK ?&#10;Speaker: Professor B&#10;Content: For {disf" />
    <node id=" I think you 're {disfmarker} you 're sort of held up by both , right ? If the {disfmarker} if the neural net trainings were a hundred times faster {pause} you still wouldn't {pause} be anything {disfmarker} running through these a hundred times faster because you 'd {pause} be stuck by the HTK trainings ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: right ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: But if the HTK {disfmarker} I mean I think they 're both {disfmarker} It sounded like they were roughly equal ? Is that about right ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Because , um {pause} I think that 'll be running Linux , and Sw - Swede and Fudge are already running Linux so , {pause} um I could try to get {pause} um the train the neural network trainings or the HTK stuff running under Linux , and to start" />
    <node id=" somebody to do the work on {disfmarker} {pause} on getting our code running {pause} on that machine with two processors {pause} even though there aren't five or eight . There 's {disfmarker} there 's {disfmarker} there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . But . {pause} Notice how I said somebody and {vocalsound} turned my head your direction . That 's one thing you don't get in these recordings . You don't get the {disfmarker} {pause} don't get the visuals but {disfmarker}&#10;Speaker: Grad G&#10;Content: I is it um {pause} mostly um the neural network trainings that are {pause} um slowing us down or the HTK runs that are slowing us down ?&#10;Speaker: Professor B&#10;Content: Uh , I think yes . Uh , {vocalsound} Isn't that right ? I mean I think you 're {disfmarker} you 're sort of held up by both , right ? If the {disfmarker} if" />
    <node id="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages." />
    <node id=" Did {disfmarker} did {disfmarker} {pause} did I interrupt you ?&#10;Speaker: PhD E&#10;Content: Yeah , I have one .&#10;Speaker: Professor B&#10;Content: Were there other things that you wanted to {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , no . I don't think so .&#10;Speaker: PhD E&#10;Content: &#10;Speaker: PhD D&#10;Content: Yeah , I have one .&#10;Speaker: Grad G&#10;Content: Oh , thanks .&#10;Speaker: Professor B&#10;Content: Ah ! {pause} OK . {pause} OK , we have {pause} lots of them .&#10;Speaker: PhD E&#10;Content: We have one . &#10;Speaker: Professor B&#10;Content: OK , so {vocalsound} um , Something I asked {disfmarker} So they 're {disfmarker} they 're doing {pause} the {disfmarker} the VAD I guess they mean voice activity detection So again , it 's the silence {disfmarker} So they 've just trained up a net {pause} which has two outputs , I believe" />
    <node id="0% (according to PhD D's response, there is not much difference when excluding English from the combination)." />
    <node id="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another." />
    <node id="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team." />
    <node id="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems." />
    <node id="'t what their scripts are {pause} set up to do for the Aurora stuff , but {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Something that we haven't really settled on yet is other than {pause} this Aurora stuff , {pause} uh what do we do , large vocabulary {pause} training slash testing {pause} for uh tandem systems . Cuz we hadn't really done much with tandem systems for larger stuff . Cuz we had this one collaboration with CMU and we used SPHINX . Uh , we 're also gonna be collaborating with SRI and we have their {disfmarker} have theirs . Um {pause} So {pause} I don't know Um . So I {disfmarker} I think the {disfmarker} the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for a lot of the things we 're doing ,&#10;Speaker: Grad G&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: whereas , w exactly which HMM {disfmarker} Gaussian - mixture - based HMM thing" />
    <node id="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript." />
    <node id=" um , {pause} distributed , sort of {disfmarker} {pause} Ah , no , it 's the {disfmarker} {pause} each individual {pause} sentence is pretty tricky to parallelize . But you could split up the sentences in a test set .&#10;Speaker: PhD A&#10;Content: They have a {disfmarker} they have a thing for doing that and th they have for awhile , in H T And you can parallelize the training .&#10;Speaker: Professor B&#10;Content: Yeah ?&#10;Speaker: PhD A&#10;Content: And run it on several machines&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD A&#10;Content: and it just basically keeps counts . And there 's something {disfmarker} {pause} a final {pause} thing that you run and it accumulates all the counts together .&#10;Speaker: Professor B&#10;Content: I see .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: I don't what their scripts are {pause} set up to do for the Aurora stuff , but {disfmarker}&#10;Speaker: PhD D&#10;Content" />
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target=" or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If you say {pause} uh {pause} If you have a place {pause} characteristic and a manner characteristic , how do you {disfmarker}&#10;Speaker: PhD D&#10;Content: It - It 's the single net ,&#10;Speaker: PhD A&#10;Content: I think they have one output .&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Professor B&#10;Content: Oh , it 's just one net .&#10;Speaker: PhD D&#10;Content: It 's one net with {pause} um {pause} twenty - seven outputs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: mm - hmm&#10;Speaker: PhD D&#10;Content: if we have twenty - seven classes ,&#10;Speaker: Professor B&#10;Content: I see . I see , OK .&#10;Speaker: PhD D&#10;Content: yeah . So it 's {disfmarker} Well , it 's basically a standard net with fewer {pause} classes .&#10;Speaker: Professor B&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target=" 's {disfmarker} Well , it 's basically a standard net with fewer {pause} classes .&#10;Speaker: Professor B&#10;Content: So you 're sort of going the other way of what you were saying a bit ago instead of {disfmarker} yeah .&#10;Speaker: PhD D&#10;Content: Yeah , but I think {disfmarker} Yeah . B b including the features , yeah .&#10;Speaker: Grad F&#10;Content: But including the features .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: I don't think this {pause} will work {pause} alone . I think it will get worse because Well , I believe the effect that {disfmarker} of {disfmarker} of too reducing too much the information is {pause} basically {disfmarker} basically what happens&#10;Speaker: Professor B&#10;Content: Uh - huh .&#10;Speaker: PhD D&#10;Content: and {disfmarker}&#10;Speaker: Professor B&#10;Content: But you think if you include that {pause} plus the other features ,&#10;Speaker: PhD D&#10;Content: but {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target=": but {disfmarker} but&#10;Speaker: PhD E&#10;Content: Maybe .&#10;Speaker: Professor B&#10;Content: yeah .&#10;Speaker: PhD E&#10;Content: I don't know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh , OK .&#10;Speaker: PhD D&#10;Content: Uh so there is this combination , yeah . Working on combination obviously .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Um , I will start work on multi - band . And {pause} we {pause} plan to work also on the idea of using both {pause} features {pause} and net outputs .&#10;Speaker: PhD E&#10;Content: &#10;Speaker: PhD D&#10;Content: Um . And {pause} we think that {pause} with this approach perhaps {pause} we could reduce the number of outputs of the neural network . Um , So , get simpler networks , because we still have the features . So we have um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target=" have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disfmarker} how many nets do you have ? No nets .&#10;Speaker: PhD D&#10;Content: I mean , {pause} It 's just {disfmarker} Were we just changing {pause} the labels to retrain nets {pause} with fewer out outputs .&#10;Speaker: PhD E&#10;Content: Begin to work in this . We are @ @ .&#10;Speaker: Professor B&#10;Content: Right . But {disfmarker} but I didn't understand {disfmarker}&#10;Speaker: PhD D&#10;Content: And then {disfmarker} Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh . {pause} the software currently just has {disfmarker} uh a {disfmarker} allows for I think , the one {disfmarker} one hot output . So you 're having multiple nets and combining them , or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target="Content: But you think if you include that {pause} plus the other features ,&#10;Speaker: PhD D&#10;Content: but {disfmarker} Yeah , because {pause} there is perhaps one important thing that the net {pause} brings , and OGI show showed that , is {pause} the distinction between {pause} sp speech and silence Because these nets are trained on well - controlled condition . I mean the labels are obtained on clean speech , and we add noise after . So this is one thing And But perhaps , something intermediary using also {pause} some broad classes could {disfmarker} could bring so much more information . Uh .&#10;Speaker: Professor B&#10;Content: So {disfmarker} so again then we have these broad classes and {disfmarker} well , somewhat broad . I mean , it 's twenty - seven instead of sixty - four , {pause} basically . And you have the original features .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Which are PLP , or something .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And then uh , just to remind me ,">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target=" um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically we have three {pause} types of broad phonetic classes . Well , something using place of articulation which {disfmarker} which leads to {pause} nine , I think , {pause} broad classes . Uh , another which is based on manner , which is {disfmarker} is also something like nine classes . And then , {pause} something that combine both , and we have {pause} twenty f {pause} twenty - five ?&#10;Speaker: Grad F&#10;Content: Twenty - seven .&#10;Speaker: PhD D&#10;Content: Twenty - seven broad classes . So like , uh , oh , I don't know , like back vowels , front vowels .&#10;Speaker: Professor B&#10;Content: So what you do {disfmarker} um I just wanna understand&#10;Speaker: PhD D&#10;Content: Um For the moments we do not {disfmarker} don't have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing the idea of using a standard neural network with fewer classes but including additional features. The majority of the speakers, including PhD A, Professor B, PhD E, and Grad F, seem open to this idea, as indicated by their affirmative responses and lack of objections.&#10;&#10;However, speaker PhD D expresses some skepticism about this approach. They believe that using a standard net with fewer classes alone might not work well and could potentially worsen the situation. The reason for their concern is that they think reducing too much information in the network can have an adverse effect on its performance. Specifically, PhD D mentions the problem of over-reducing the information, which they believe would negatively impact the neural network's ability to function effectively.&#10;&#10;In summary, while most speakers are open to the idea of using a standard net with fewer classes and additional features, PhD D expresses some skepticism about this approach, fearing that reducing too much information could potentially worsen the neural network's performance." target="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team.">
      <data key="d0">1</data>
    </edge>
    <edge source=" or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If you say {pause} uh {pause} If you have a place {pause} characteristic and a manner characteristic , how do you {disfmarker}&#10;Speaker: PhD D&#10;Content: It - It 's the single net ,&#10;Speaker: PhD A&#10;Content: I think they have one output .&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Professor B&#10;Content: Oh , it 's just one net .&#10;Speaker: PhD D&#10;Content: It 's one net with {pause} um {pause} twenty - seven outputs&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Grad F&#10;Content: mm - hmm&#10;Speaker: PhD D&#10;Content: if we have twenty - seven classes ,&#10;Speaker: Professor B&#10;Content: I see . I see , OK .&#10;Speaker: PhD D&#10;Content: yeah . So it 's {disfmarker} Well , it 's basically a standard net with fewer {pause} classes .&#10;Speaker: Professor B&#10;Content" target="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations.">
      <data key="d0">1</data>
    </edge>
    <edge source=": but {disfmarker} but&#10;Speaker: PhD E&#10;Content: Maybe .&#10;Speaker: Professor B&#10;Content: yeah .&#10;Speaker: PhD E&#10;Content: I don't know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh , OK .&#10;Speaker: PhD D&#10;Content: Uh so there is this combination , yeah . Working on combination obviously .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Um , I will start work on multi - band . And {pause} we {pause} plan to work also on the idea of using both {pause} features {pause} and net outputs .&#10;Speaker: PhD E&#10;Content: &#10;Speaker: PhD D&#10;Content: Um . And {pause} we think that {pause} with this approach perhaps {pause} we could reduce the number of outputs of the neural network . Um , So , get simpler networks , because we still have the features . So we have um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically" target="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations.">
      <data key="d0">1</data>
    </edge>
    <edge source=" have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disfmarker} how many nets do you have ? No nets .&#10;Speaker: PhD D&#10;Content: I mean , {pause} It 's just {disfmarker} Were we just changing {pause} the labels to retrain nets {pause} with fewer out outputs .&#10;Speaker: PhD E&#10;Content: Begin to work in this . We are @ @ .&#10;Speaker: Professor B&#10;Content: Right . But {disfmarker} but I didn't understand {disfmarker}&#10;Speaker: PhD D&#10;Content: And then {disfmarker} Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh . {pause} the software currently just has {disfmarker} uh a {disfmarker} allows for I think , the one {disfmarker} one hot output . So you 're having multiple nets and combining them , or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If" target="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: But you think if you include that {pause} plus the other features ,&#10;Speaker: PhD D&#10;Content: but {disfmarker} Yeah , because {pause} there is perhaps one important thing that the net {pause} brings , and OGI show showed that , is {pause} the distinction between {pause} sp speech and silence Because these nets are trained on well - controlled condition . I mean the labels are obtained on clean speech , and we add noise after . So this is one thing And But perhaps , something intermediary using also {pause} some broad classes could {disfmarker} could bring so much more information . Uh .&#10;Speaker: Professor B&#10;Content: So {disfmarker} so again then we have these broad classes and {disfmarker} well , somewhat broad . I mean , it 's twenty - seven instead of sixty - four , {pause} basically . And you have the original features .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Which are PLP , or something .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And then uh , just to remind me ," target="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another.">
      <data key="d0">1</data>
    </edge>
    <edge source=" um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically we have three {pause} types of broad phonetic classes . Well , something using place of articulation which {disfmarker} which leads to {pause} nine , I think , {pause} broad classes . Uh , another which is based on manner , which is {disfmarker} is also something like nine classes . And then , {pause} something that combine both , and we have {pause} twenty f {pause} twenty - five ?&#10;Speaker: Grad F&#10;Content: Twenty - seven .&#10;Speaker: PhD D&#10;Content: Twenty - seven broad classes . So like , uh , oh , I don't know , like back vowels , front vowels .&#10;Speaker: Professor B&#10;Content: So what you do {disfmarker} um I just wanna understand&#10;Speaker: PhD D&#10;Content: Um For the moments we do not {disfmarker} don't have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disf" target="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations.">
      <data key="d0">1</data>
    </edge>
    <edge source=" um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically we have three {pause} types of broad phonetic classes . Well , something using place of articulation which {disfmarker} which leads to {pause} nine , I think , {pause} broad classes . Uh , another which is based on manner , which is {disfmarker} is also something like nine classes . And then , {pause} something that combine both , and we have {pause} twenty f {pause} twenty - five ?&#10;Speaker: Grad F&#10;Content: Twenty - seven .&#10;Speaker: PhD D&#10;Content: Twenty - seven broad classes . So like , uh , oh , I don't know , like back vowels , front vowels .&#10;Speaker: Professor B&#10;Content: So what you do {disfmarker} um I just wanna understand&#10;Speaker: PhD D&#10;Content: Um For the moments we do not {disfmarker} don't have nets ,&#10;Speaker: Professor B&#10;Content: so {pause} You have two net or three nets ? Was this ? How many {disf" target="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target=" but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker} So , it 's {disfmarker} it 's three or {disfmarker} three and four .&#10;Speaker: PhD E&#10;Content: The early experiment that {disfmarker}&#10;Speaker: PhD A&#10;Content: Did you do different languages from digits ?&#10;Speaker: PhD D&#10;Content: Uh . No . You mean {pause} training digits {pause} on one language and using the net {pause} to recognize on the other ?&#10;Speaker: PhD A&#10;Content: Digits on another language ?&#10;Speaker: PhD D&#10;Content: No .&#10;Speaker: Professor B&#10;Content: See , I thought you showed me something like that last week . You had a {disfmarker} you had a little {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , {pause} No , I don't think so .&#10;Speaker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target=" . So you trained on {pause} one type of digits and tested on another . Didn - Wasn't there something of that ? Where you , {pause} say , trained on Spanish and tested on {disfmarker} on TI - digits , or the other way around ? Something like that ?&#10;Speaker: PhD E&#10;Content: No .&#10;Speaker: Professor B&#10;Content: I thought there was something like that , {pause} that he showed me {pause} last week . We 'll have to wait till we get {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , that would be interesting .&#10;Speaker: Professor B&#10;Content: Um , This may have been what I was asking before , Stephane , but {disfmarker} {pause} but , um , wasn't there something that you did , {pause} where you trained {pause} on one language and tested on another ? I mean no {disfmarker} no mixture but just {disfmarker}&#10;Speaker: Grad F&#10;Content: I 'll get it for you .&#10;Speaker: PhD D&#10;Content: Uh , no , no .&#10;Speaker: Professor B&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target=" Um {pause} and {pause} um But , {pause} when you add in more training data but keep the neural net the same size , {pause} it {pause} um performs worse on the TI - digits . OK , now all of this is {disfmarker} {pause} This is noisy {pause} TI - digits , I assume ? Both training and test ?&#10;Speaker: PhD D&#10;Content: &#10;Speaker: Professor B&#10;Content: Yeah . OK . Um OK . Well . {pause} We {disfmarker} we {disfmarker} we may just need to uh {disfmarker} So I mean it 's interesting that h going to a different {disfmarker} different task didn't seem to hurt us that much , and going to a different language um It doesn't seem to matter {disfmarker} The difference between three and four is not particularly great , so that means that {pause} whether you have the language in or not is not such a big deal .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: It sounds like um {pause} uh {pause} we may need to have">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target=" using the same output ? This multi - language {pause} uh labelling ?&#10;Speaker: Grad F&#10;Content: He was using uh sixty - four phonemes from {pause} SAMPA .&#10;Speaker: PhD A&#10;Content: OK , OK .&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So this would {disfmarker} {pause} From this you would say , &quot; well , it doesn't really matter if we put Finnish {pause} into {pause} the training of the neural net , {pause} if there 's {pause} gonna be , {pause} you know , Finnish in the test data . &quot; Right ?&#10;Speaker: Professor B&#10;Content: Well , it 's {disfmarker} it sounds {disfmarker} {pause} I mean , we have to be careful , cuz we haven't gotten a good result yet .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And comparing different bad results can be {pause} tricky .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But I {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target=" be {pause} tricky .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But I {disfmarker} I {disfmarker} I {disfmarker} {pause} I think it does suggest that it 's not so much uh {pause} uh cross {pause} language as cross type of speech .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: It 's {disfmarker} it 's um {disfmarker} {vocalsound} But we did {disfmarker} Oh yeah , the other thing I was asking him , though , is that I think that in the case {disfmarker} Yeah , you {disfmarker} you do have to be careful because of com compounded results . I think we got some earlier results {pause} in which you trained on one language and tested on another and you didn't have {pause} three , but you just had one {pause} language . So you trained on {pause} one type of digits and tested on another . Didn - Wasn't there something of that ? Where you , {pause">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target=" training and TI - digits as test ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh different words , I 'm sure ,&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: but {disfmarker} {pause} but uh , uh the same {pause} task and so on .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: If we call that &quot; one &quot; , {pause} then what you 're saying is {pause} that the word error rate {pause} for the same language but using {pause} uh different training data than you 're testing on , say TIMIT and so forth , {pause} it 's one point one .&#10;Speaker: PhD D&#10;Content: Mm - hmm . Yeah , it 's around one point one .&#10;Speaker: Professor B&#10;Content: Right . And if it 's {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: you {pause} do {pause} go to {pause}">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that there was a discussion among the group about an early experiment involving training digits in one language and testing recognition on another language. However, there was no positive confirmation from any of the participants that such an experiment had taken place. Speaker PhD D explicitly denied that they did different languages for training and testing digits, and Grad F also did not confirm when Professor B asked them directly. Therefore, it can be inferred that while the topic was brought up in conversation, there is no evidence to suggest that such an early experiment actually occurred." target="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles.">
      <data key="d0">1</data>
    </edge>
    <edge source=" but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker} So , it 's {disfmarker} it 's three or {disfmarker} three and four .&#10;Speaker: PhD E&#10;Content: The early experiment that {disfmarker}&#10;Speaker: PhD A&#10;Content: Did you do different languages from digits ?&#10;Speaker: PhD D&#10;Content: Uh . No . You mean {pause} training digits {pause} on one language and using the net {pause} to recognize on the other ?&#10;Speaker: PhD A&#10;Content: Digits on another language ?&#10;Speaker: PhD D&#10;Content: No .&#10;Speaker: Professor B&#10;Content: See , I thought you showed me something like that last week . You had a {disfmarker} you had a little {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , {pause} No , I don't think so .&#10;Speaker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio" target="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker} So , it 's {disfmarker} it 's three or {disfmarker} three and four .&#10;Speaker: PhD E&#10;Content: The early experiment that {disfmarker}&#10;Speaker: PhD A&#10;Content: Did you do different languages from digits ?&#10;Speaker: PhD D&#10;Content: Uh . No . You mean {pause} training digits {pause} on one language and using the net {pause} to recognize on the other ?&#10;Speaker: PhD A&#10;Content: Digits on another language ?&#10;Speaker: PhD D&#10;Content: No .&#10;Speaker: Professor B&#10;Content: See , I thought you showed me something like that last week . You had a {disfmarker} you had a little {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , {pause} No , I don't think so .&#10;Speaker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio" target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . So you trained on {pause} one type of digits and tested on another . Didn - Wasn't there something of that ? Where you , {pause} say , trained on Spanish and tested on {disfmarker} on TI - digits , or the other way around ? Something like that ?&#10;Speaker: PhD E&#10;Content: No .&#10;Speaker: Professor B&#10;Content: I thought there was something like that , {pause} that he showed me {pause} last week . We 'll have to wait till we get {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , that would be interesting .&#10;Speaker: Professor B&#10;Content: Um , This may have been what I was asking before , Stephane , but {disfmarker} {pause} but , um , wasn't there something that you did , {pause} where you trained {pause} on one language and tested on another ? I mean no {disfmarker} no mixture but just {disfmarker}&#10;Speaker: Grad F&#10;Content: I 'll get it for you .&#10;Speaker: PhD D&#10;Content: Uh , no , no .&#10;Speaker: Professor B&#10;Content" target="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Um {pause} and {pause} um But , {pause} when you add in more training data but keep the neural net the same size , {pause} it {pause} um performs worse on the TI - digits . OK , now all of this is {disfmarker} {pause} This is noisy {pause} TI - digits , I assume ? Both training and test ?&#10;Speaker: PhD D&#10;Content: &#10;Speaker: Professor B&#10;Content: Yeah . OK . Um OK . Well . {pause} We {disfmarker} we {disfmarker} we may just need to uh {disfmarker} So I mean it 's interesting that h going to a different {disfmarker} different task didn't seem to hurt us that much , and going to a different language um It doesn't seem to matter {disfmarker} The difference between three and four is not particularly great , so that means that {pause} whether you have the language in or not is not such a big deal .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: It sounds like um {pause} uh {pause} we may need to have" target="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits.">
      <data key="d0">1</data>
    </edge>
    <edge source=" using the same output ? This multi - language {pause} uh labelling ?&#10;Speaker: Grad F&#10;Content: He was using uh sixty - four phonemes from {pause} SAMPA .&#10;Speaker: PhD A&#10;Content: OK , OK .&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So this would {disfmarker} {pause} From this you would say , &quot; well , it doesn't really matter if we put Finnish {pause} into {pause} the training of the neural net , {pause} if there 's {pause} gonna be , {pause} you know , Finnish in the test data . &quot; Right ?&#10;Speaker: Professor B&#10;Content: Well , it 's {disfmarker} it sounds {disfmarker} {pause} I mean , we have to be careful , cuz we haven't gotten a good result yet .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And comparing different bad results can be {pause} tricky .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But I {disfmark" target="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area.">
      <data key="d0">1</data>
    </edge>
    <edge source=" using the same output ? This multi - language {pause} uh labelling ?&#10;Speaker: Grad F&#10;Content: He was using uh sixty - four phonemes from {pause} SAMPA .&#10;Speaker: PhD A&#10;Content: OK , OK .&#10;Speaker: Grad F&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So this would {disfmarker} {pause} From this you would say , &quot; well , it doesn't really matter if we put Finnish {pause} into {pause} the training of the neural net , {pause} if there 's {pause} gonna be , {pause} you know , Finnish in the test data . &quot; Right ?&#10;Speaker: Professor B&#10;Content: Well , it 's {disfmarker} it sounds {disfmarker} {pause} I mean , we have to be careful , cuz we haven't gotten a good result yet .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And comparing different bad results can be {pause} tricky .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But I {disfmark" target="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target=" Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {disfmarker} there is {disfmarker} another difference , is that the noise {disfmarker} the noises are different .&#10;Speaker: Professor B&#10;Content: In {disfmarker} in what ?&#10;Speaker: PhD D&#10;Content: Well , For {disfmarker} for the Italian part I mean the {pause} uh {pause} the um {pause} networks are trained with noise from {pause} Aurora {disfmarker} TI - digits ,&#10;Speaker: PhD E&#10;Content: Aurora - two .&#10;Speaker: PhD D&#10;Content: mmm .&#10;Speaker: Professor B&#10;Content: And the noise is different in th&#10;Speaker: PhD D&#10;Content: Yeah . And perhaps the noise are {pause} quite different from the noises {pause} in the speech that Italian .&#10;Speaker: Professor B&#10;Content: Do we have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target=" baseline Aurora .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well .&#10;Speaker: Professor B&#10;Content: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker}&#10;Speaker: PhD C&#10;Content: Chicken on the grill . Try that corner .&#10;Speaker: PhD A&#10;Content: How about over th from the front of the room ?&#10;Speaker: PhD C&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target=" But {disfmarker} but the question is if you train on one language {pause} but you have a broad coverage {pause} and then test in another , {pause} does that {disfmarker} {pause} is that improve things {pause} i c in comparison ?&#10;Speaker: PhD D&#10;Content: If we use the same language ?&#10;Speaker: Professor B&#10;Content: No , no , no . Different lang So {pause} um {pause} If you train on TI - digits {pause} and test on Italian digits , {pause} you do poorly , {pause} let 's say .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: I don't have the numbers in front of me ,&#10;Speaker: PhD D&#10;Content: But {disfmarker} Yeah but I did not uh do that .&#10;Speaker: Professor B&#10;Content: so I 'm just imagining . E So , you didn't train on {pause} TIMIT and test on {disfmarker} {pause} on Italian digits , say ?&#10;Speaker: PhD D&#10;Content: We {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target=" results are {vocalsound} uh {pause} stranger um {pause} Mmm . So what appears is that perhaps Spanish is {pause} not very close to Italian because uh , well , {pause} when using the {disfmarker} the network trained only on Spanish it 's {disfmarker} {pause} the error rate is {pause} almost uh twice {pause} the baseline error rate .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . {vocalsound} Uh .&#10;Speaker: Professor B&#10;Content: Well , I mean , let 's see . Is there any difference in {disfmarker} So it 's in {pause} the uh {disfmarker} So you 're saying that {pause} when you train on English {pause} and {pause} uh {pause} and {disfmarker} and test on {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="aker: Grad F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: PhD D&#10;Content: and it 's divided in three {pause} rows {pause} of four {disfmarker} four rows each .&#10;Speaker: Grad F&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: And the first four rows is well - matched , then the s the second group of four rows is mismatched , and {pause} finally highly mismatched . And then the lower part is for Italian and it 's the same {disfmarker} {pause} the same thing .&#10;Speaker: PhD A&#10;Content: So , so the upper part is training {pause} TI - digits ?&#10;Speaker: PhD D&#10;Content: So . It 's {disfmarker} it 's the HTK results , I mean . So it 's {pause} HTK training testings {pause} with different kind of features&#10;Speaker: PhD A&#10;Content: Ah .&#10;Speaker: PhD D&#10;Content: and what appears in the {pause} uh left column is {pause} the networks that are">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript suggests that Professor B and PhD D discussed the difference between the noises in the Aurora TI-digits dataset and the speech data in Italian. It is also mentioned that they have trained neural networks on both English (TI-digits) and Italian datasets, as well as broad databases including English, French, and Spanish. However, there is no clear answer to the question about test sets in other languages with the same type of noise as Aurora TI-digits.&#10;&#10;Towards the end of the transcript, PhD D does mention something about &quot;HTK training testings with different kind of features&quot; and before that, Professor B asked if there's any difference when testing on mismatched data. These statements suggest that they might be using different datasets or types of noise for training and testing, but it's not explicitly stated in the transcript.&#10;&#10;Therefore, based on the provided transcript, it is unclear if they have test sets in other languages with the same type of noise as Aurora TI-digits." target="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {disfmarker} there is {disfmarker} another difference , is that the noise {disfmarker} the noises are different .&#10;Speaker: Professor B&#10;Content: In {disfmarker} in what ?&#10;Speaker: PhD D&#10;Content: Well , For {disfmarker} for the Italian part I mean the {pause} uh {pause} the um {pause} networks are trained with noise from {pause} Aurora {disfmarker} TI - digits ,&#10;Speaker: PhD E&#10;Content: Aurora - two .&#10;Speaker: PhD D&#10;Content: mmm .&#10;Speaker: Professor B&#10;Content: And the noise is different in th&#10;Speaker: PhD D&#10;Content: Yeah . And perhaps the noise are {pause} quite different from the noises {pause} in the speech that Italian .&#10;Speaker: Professor B&#10;Content: Do we have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora" target="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {disfmarker} there is {disfmarker} another difference , is that the noise {disfmarker} the noises are different .&#10;Speaker: Professor B&#10;Content: In {disfmarker} in what ?&#10;Speaker: PhD D&#10;Content: Well , For {disfmarker} for the Italian part I mean the {pause} uh {pause} the um {pause} networks are trained with noise from {pause} Aurora {disfmarker} TI - digits ,&#10;Speaker: PhD E&#10;Content: Aurora - two .&#10;Speaker: PhD D&#10;Content: mmm .&#10;Speaker: Professor B&#10;Content: And the noise is different in th&#10;Speaker: PhD D&#10;Content: Yeah . And perhaps the noise are {pause} quite different from the noises {pause} in the speech that Italian .&#10;Speaker: Professor B&#10;Content: Do we have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora" target="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {disfmarker} there is {disfmarker} another difference , is that the noise {disfmarker} the noises are different .&#10;Speaker: Professor B&#10;Content: In {disfmarker} in what ?&#10;Speaker: PhD D&#10;Content: Well , For {disfmarker} for the Italian part I mean the {pause} uh {pause} the um {pause} networks are trained with noise from {pause} Aurora {disfmarker} TI - digits ,&#10;Speaker: PhD E&#10;Content: Aurora - two .&#10;Speaker: PhD D&#10;Content: mmm .&#10;Speaker: Professor B&#10;Content: And the noise is different in th&#10;Speaker: PhD D&#10;Content: Yeah . And perhaps the noise are {pause} quite different from the noises {pause} in the speech that Italian .&#10;Speaker: Professor B&#10;Content: Do we have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora" target="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source=" baseline Aurora .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well .&#10;Speaker: Professor B&#10;Content: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker}&#10;Speaker: PhD C&#10;Content: Chicken on the grill . Try that corner .&#10;Speaker: PhD A&#10;Content: How about over th from the front of the room ?&#10;Speaker: PhD C&#10;Content" target="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline.">
      <data key="d0">1</data>
    </edge>
    <edge source=" baseline Aurora .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well .&#10;Speaker: Professor B&#10;Content: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker}&#10;Speaker: PhD C&#10;Content: Chicken on the grill . Try that corner .&#10;Speaker: PhD A&#10;Content: How about over th from the front of the room ?&#10;Speaker: PhD C&#10;Content" target="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source=" baseline Aurora .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well .&#10;Speaker: Professor B&#10;Content: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker}&#10;Speaker: PhD C&#10;Content: Chicken on the grill . Try that corner .&#10;Speaker: PhD A&#10;Content: How about over th from the front of the room ?&#10;Speaker: PhD C&#10;Content" target="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" baseline Aurora .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well .&#10;Speaker: Professor B&#10;Content: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker}&#10;Speaker: PhD C&#10;Content: Chicken on the grill . Try that corner .&#10;Speaker: PhD A&#10;Content: How about over th from the front of the room ?&#10;Speaker: PhD C&#10;Content" target="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" results are {vocalsound} uh {pause} stranger um {pause} Mmm . So what appears is that perhaps Spanish is {pause} not very close to Italian because uh , well , {pause} when using the {disfmarker} the network trained only on Spanish it 's {disfmarker} {pause} the error rate is {pause} almost uh twice {pause} the baseline error rate .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . {vocalsound} Uh .&#10;Speaker: Professor B&#10;Content: Well , I mean , let 's see . Is there any difference in {disfmarker} So it 's in {pause} the uh {disfmarker} So you 're saying that {pause} when you train on English {pause} and {pause} uh {pause} and {disfmarker} and test on {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: No , you don't have training on English testing {disfmarker}&#10;Speaker: PhD D&#10;Content: There {" target="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target=" mean and variances {pause} measured across the whole database .&#10;Speaker: Professor B&#10;Content: Right . Right .&#10;Speaker: PhD D&#10;Content: And Pratibha did something different is that he {disfmarker} uh she initialed the um values of the mean and variance {pause} by computing {pause} this on the {pause} twenty - five first frames of each utterance . Mmm . There were other minor differences , the fact that {pause} she used fifteen dissities instead s instead of thirteen , and that she used C - zero instead of log energy . Uh , but the main differences concerns the recursion . So . {pause} Uh , I changed the code uh and now we have a baseline that 's similar to the OGI baseline .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: We {disfmarker} It {disfmarker} it 's slightly {pause} uh different because {pause} I don't exactly initialize the same way she does . Actually I start , {pause} mmm , I don't wait to a fifteen {disfmarker} twenty - five {disfmarker} twenty">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target=" And Pratibha used five percent .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: So it adapts more {pause} quickly&#10;Speaker: Professor B&#10;Content: Yes . Yeah .&#10;Speaker: PhD D&#10;Content: Um , but , yeah . I assume that this was not important because {pause} uh previous results from {disfmarker} from Dan and {disfmarker} show that basically {pause} the {pause} both {disfmarker} both values g give the same {disfmarker} same {pause} uh results . It was true on uh {pause} TI - digits but it 's not true on Italian .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , second thing is the initialization of the {pause} stuff . Actually , {pause} uh what we were doing is to start the recursion from the beginning of the {pause} utterance . And using initial values that are the global mean and variances {pause} measured across the whole database .&#10;Speaker: Professor B&#10;Content: Right . Right .&#10;Speaker: PhD D">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target=": PhD D&#10;Content: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {pause} uh the way we were doing this was not correct , but {pause} still {pause} the networks {pause} are very good . When we use the networks {pause} our number are better that {pause} uh Pratibha results .&#10;Speaker: PhD E&#10;Content: We improve .&#10;Speaker: Professor B&#10;Content: So , do you know what was wrong with the on - line normalization , or {disfmarker} ?&#10;Speaker: PhD D&#10;Content: Yeah . There were diff there were different things and {pause} basically , {pause} the first thing is the mmm , {pause} alpha uh {pause} value . So , the recursion {pause} uh {pause} part . um , {pause} I used point five percent , {pause} which was the default value in the {disfmarker} {pause} in the programs here . And Pratibha used five percent .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: So it adapts">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target=" leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target="} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content: Where is that ? seventy - nine , fifty&#10;Speaker: Professor B&#10;Content: Uh , it 's just sort of sitting right on the uh {disfmarker} the column line .&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: PhD E&#10;Content: Fifty - one ? This {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh I see , OK .&#10;Speaker: Professor B&#10;Content: Uh . {pause} Yeah .&#10;Speaker: PhD D&#10;Content: Just {disfmarker} uh Yeah . So these are the results of {pause} OGI with {pause} on - line normalization and straight features to HTK . And the previous result , eighty - six and so on , {pause} are with our {pause} features straight to HTK .&#10;Speaker: Professor B&#10;Content: Yes . Yes .&#10;Speaker: PhD D&#10;Content: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target=" D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: It sounds like um {pause} uh {pause} we may need to have more {pause} of uh things that are similar to a target language or {disfmarker} I mean . {pause} You have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just {disfmarker} {pause} just not enough {pause} complexity to it to represent {pause} the variab increased variability in the {disfmarker} in the training set . That {disfmarker} that could be . Um {pause} So , what about {disfmarker} So these are results with {pause} uh th {pause} that you 're describing now , that {pause} they are pretty similar for the different features or {disfmarker} {pause} or uh {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , let me check . Uh .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: So . This was for the PLP ,&#10;Speaker: Professor B">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Initialization: Instead of using global mean and variance measured across the whole database, Pratibha initialized the values of mean and variance by computing this on the first 25 frames of each utterance. Pratibha also used different initial values for the recursion, starting with the first frame instead of waiting for the 15th or 25th frame as in the OGI baseline.&#10;&#10;2. Recursion: The main difference is that Pratibha implemented a different recursive approach compared to the OGI baseline. She used a value of 0.05 (5%) for the alpha parameter, which controls the rate of adaptation, while the OGI baseline uses the default value of 0.005 (0.5%) in their programs. This difference in the recursion method and alpha value caused variations in the results obtained by both methods, with Pratibha's approach adapting more quickly to the data but not necessarily providing better performance." target="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian.">
      <data key="d0">1</data>
    </edge>
    <edge source=" mean and variances {pause} measured across the whole database .&#10;Speaker: Professor B&#10;Content: Right . Right .&#10;Speaker: PhD D&#10;Content: And Pratibha did something different is that he {disfmarker} uh she initialed the um values of the mean and variance {pause} by computing {pause} this on the {pause} twenty - five first frames of each utterance . Mmm . There were other minor differences , the fact that {pause} she used fifteen dissities instead s instead of thirteen , and that she used C - zero instead of log energy . Uh , but the main differences concerns the recursion . So . {pause} Uh , I changed the code uh and now we have a baseline that 's similar to the OGI baseline .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: We {disfmarker} It {disfmarker} it 's slightly {pause} uh different because {pause} I don't exactly initialize the same way she does . Actually I start , {pause} mmm , I don't wait to a fifteen {disfmarker} twenty - five {disfmarker} twenty" target="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame.">
      <data key="d0">1</data>
    </edge>
    <edge source=" And Pratibha used five percent .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: So it adapts more {pause} quickly&#10;Speaker: Professor B&#10;Content: Yes . Yeah .&#10;Speaker: PhD D&#10;Content: Um , but , yeah . I assume that this was not important because {pause} uh previous results from {disfmarker} from Dan and {disfmarker} show that basically {pause} the {pause} both {disfmarker} both values g give the same {disfmarker} same {pause} uh results . It was true on uh {pause} TI - digits but it 's not true on Italian .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Uh , second thing is the initialization of the {pause} stuff . Actually , {pause} uh what we were doing is to start the recursion from the beginning of the {pause} utterance . And using initial values that are the global mean and variances {pause} measured across the whole database .&#10;Speaker: Professor B&#10;Content: Right . Right .&#10;Speaker: PhD D" target="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame.">
      <data key="d0">1</data>
    </edge>
    <edge source=": PhD D&#10;Content: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {pause} uh the way we were doing this was not correct , but {pause} still {pause} the networks {pause} are very good . When we use the networks {pause} our number are better that {pause} uh Pratibha results .&#10;Speaker: PhD E&#10;Content: We improve .&#10;Speaker: Professor B&#10;Content: So , do you know what was wrong with the on - line normalization , or {disfmarker} ?&#10;Speaker: PhD D&#10;Content: Yeah . There were diff there were different things and {pause} basically , {pause} the first thing is the mmm , {pause} alpha uh {pause} value . So , the recursion {pause} uh {pause} part . um , {pause} I used point five percent , {pause} which was the default value in the {disfmarker} {pause} in the programs here . And Pratibha used five percent .&#10;Speaker: Professor B&#10;Content: Uh&#10;Speaker: PhD D&#10;Content: So it adapts" target="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame.">
      <data key="d0">1</data>
    </edge>
    <edge source=" leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content:" target="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach.">
      <data key="d0">1</data>
    </edge>
    <edge source=" leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content:" target="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame.">
      <data key="d0">1</data>
    </edge>
    <edge source=" leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content:" target="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian.">
      <data key="d0">1</data>
    </edge>
    <edge source=" leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content:" target="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles.">
      <data key="d0">1</data>
    </edge>
    <edge source="} uh his on - line normalization {disfmarker} uh her on - line normalization approach .&#10;Speaker: PhD A&#10;Content: Where is that ? seventy - nine , fifty&#10;Speaker: Professor B&#10;Content: Uh , it 's just sort of sitting right on the uh {disfmarker} the column line .&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: PhD E&#10;Content: Fifty - one ? This {disfmarker}&#10;Speaker: PhD A&#10;Content: Oh I see , OK .&#10;Speaker: Professor B&#10;Content: Uh . {pause} Yeah .&#10;Speaker: PhD D&#10;Content: Just {disfmarker} uh Yeah . So these are the results of {pause} OGI with {pause} on - line normalization and straight features to HTK . And the previous result , eighty - six and so on , {pause} are with our {pause} features straight to HTK .&#10;Speaker: Professor B&#10;Content: Yes . Yes .&#10;Speaker: PhD D&#10;Content: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {" target="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach.">
      <data key="d0">1</data>
    </edge>
    <edge source=" D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: It sounds like um {pause} uh {pause} we may need to have more {pause} of uh things that are similar to a target language or {disfmarker} I mean . {pause} You have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just {disfmarker} {pause} just not enough {pause} complexity to it to represent {pause} the variab increased variability in the {disfmarker} in the training set . That {disfmarker} that could be . Um {pause} So , what about {disfmarker} So these are results with {pause} uh th {pause} that you 're describing now , that {pause} they are pretty similar for the different features or {disfmarker} {pause} or uh {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , let me check . Uh .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: So . This was for the PLP ,&#10;Speaker: Professor B" target="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="isfmarker} I was looking at it I was {pause} mostly thinking about the {disfmarker} {pause} the VAD . And um , it ap {pause} it ap Oh what does {disfmarker} what does ASP ? Oh that 's {disfmarker}&#10;Speaker: PhD D&#10;Content: The features , yeah . Yeah .&#10;Speaker: PhD E&#10;Content: I don't understand also&#10;Speaker: Professor B&#10;Content: It says &quot; baseline ASP &quot; .&#10;Speaker: PhD E&#10;Content: what is {disfmarker} {pause} what is the difference between ASP and uh baseline over ?&#10;Speaker: PhD C&#10;Content: ASP .&#10;Speaker: PhD D&#10;Content: Yeah , I don't know .&#10;Speaker: PhD E&#10;Content: This is {disfmarker}&#10;Speaker: Professor B&#10;Content: Anybody know {pause} any {disfmarker}&#10;Speaker: PhD C&#10;Content: Oh . There it is .&#10;Speaker: Professor B&#10;Content: Um Cuz there 's &quot; baseline Aurora &quot; {pause} above it .&#10;Speaker: PhD C&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="Content: Yeah .&#10;Speaker: PhD D&#10;Content: I think {disfmarker} {pause} I think it 's the C - zero {disfmarker} using C - zero instead of log energy .&#10;Speaker: PhD E&#10;Content: Ah , OK , mm - hmm .&#10;Speaker: PhD D&#10;Content: Yeah , it 's this .&#10;Speaker: Professor B&#10;Content: Oh . OK .&#10;Speaker: PhD E&#10;Content: yeah .&#10;Speaker: PhD D&#10;Content: It should be that , yeah .&#10;Speaker: PhD A&#10;Content: They s they say in here that the VAD is not used as an additional feature .&#10;Speaker: Professor B&#10;Content: Shouldn't it be {disfmarker}&#10;Speaker: PhD D&#10;Content: Because {disfmarker}&#10;Speaker: PhD A&#10;Content: Does {disfmarker} does anybody know how they 're using it ?&#10;Speaker: Professor B&#10;Content: Yeah . So {disfmarker} so what they 're doing here is , {pause} i&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="aker: Professor B&#10;Content: Um Cuz there 's &quot; baseline Aurora &quot; {pause} above it .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: And it 's {disfmarker} This is mostly better than baseline , although in some cases it 's a little worse , in a couple cases .&#10;Speaker: PhD C&#10;Content: Well , it says baseline ASP is twenty - three mill {pause} minus thirteen .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah , it says what it is . But I don't how that 's different {pause} from {disfmarker}&#10;Speaker: PhD C&#10;Content: From the baseline . {comment} OK .&#10;Speaker: Professor B&#10;Content: I think this was {disfmarker} {pause} I think this is the same point we were at when {disfmarker} when we were up in Oregon .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: I think {disfmarker} {pause} I think it 's the C -">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="Content: Ah .&#10;Speaker: PhD D&#10;Content: and what appears in the {pause} uh left column is {pause} the networks that are used for doing this .&#10;Speaker: Professor B&#10;Content: Hmm .&#10;Speaker: PhD D&#10;Content: So . Uh Yeah .&#10;Speaker: Professor B&#10;Content: Well , What was is that i What was it that you had {pause} done {pause} last week when you showed {disfmarker} Do you remember ? Wh - when you showed me {pause} the {disfmarker} your table last week ?&#10;Speaker: PhD D&#10;Content: It - It was part of these results . Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: So where is the baseline {pause} for the TI - digits {pause} located in here ?&#10;Speaker: PhD D&#10;Content: You mean the HTK Aurora baseline ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: It 's uh the one hundred number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline .&#10;Speaker: PhD A&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion about the difference between &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; is in regards to the noise reduction process in speech recognition. The speakers are discussing different types of noise present in the Aurora TI-digits dataset and speech data in Italian.&#10;&#10;&quot;Baseline ASP&quot; refers to the baseline results obtained using Automatic Speech Recognition (ASR) features, while &quot;baseline Aurora&quot; likely refers to the Aurora TI-digits dataset's own baseline results for noise reduction. These baselines are used as a comparison to evaluate the performance of different noise reduction techniques.&#10;&#10;The speakers mention that they have trained neural networks on English (TI-digits) and Italian datasets, as well as broader databases including English, French, and Spanish. The discussion revolves around understanding how these different baselines compare to one another in various scenarios.&#10;&#10;In summary, &quot;baseline ASP&quot; and &quot;baseline Aurora&quot; are two different baselines used for comparing the performance of noise reduction techniques in speech recognition, with &quot;baseline ASP&quot; referring to results obtained using ASR features, and &quot;baseline Aurora&quot; pertaining to the Aurora TI-digits dataset's own baseline." target="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Ah .&#10;Speaker: PhD D&#10;Content: and what appears in the {pause} uh left column is {pause} the networks that are used for doing this .&#10;Speaker: Professor B&#10;Content: Hmm .&#10;Speaker: PhD D&#10;Content: So . Uh Yeah .&#10;Speaker: Professor B&#10;Content: Well , What was is that i What was it that you had {pause} done {pause} last week when you showed {disfmarker} Do you remember ? Wh - when you showed me {pause} the {disfmarker} your table last week ?&#10;Speaker: PhD D&#10;Content: It - It was part of these results . Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: So where is the baseline {pause} for the TI - digits {pause} located in here ?&#10;Speaker: PhD D&#10;Content: You mean the HTK Aurora baseline ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: It 's uh the one hundred number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline .&#10;Speaker: PhD A&#10;Content:" target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart.">
      <data key="d0">1</data>
    </edge>
    <edge source="Content: Ah .&#10;Speaker: PhD D&#10;Content: and what appears in the {pause} uh left column is {pause} the networks that are used for doing this .&#10;Speaker: Professor B&#10;Content: Hmm .&#10;Speaker: PhD D&#10;Content: So . Uh Yeah .&#10;Speaker: Professor B&#10;Content: Well , What was is that i What was it that you had {pause} done {pause} last week when you showed {disfmarker} Do you remember ? Wh - when you showed me {pause} the {disfmarker} your table last week ?&#10;Speaker: PhD D&#10;Content: It - It was part of these results . Mmm . Mmm .&#10;Speaker: PhD A&#10;Content: So where is the baseline {pause} for the TI - digits {pause} located in here ?&#10;Speaker: PhD D&#10;Content: You mean the HTK Aurora baseline ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: It 's uh the one hundred number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline .&#10;Speaker: PhD A&#10;Content:" target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." target=" A&#10;Content: I see .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: OK ? Um {pause} So uh , I think this will take some {pause} looking at , thinking about . But , {pause} what is uh {disfmarker} what is currently running , that 's {disfmarker} uh , i that {disfmarker} just filling in the holes here or {disfmarker} or {disfmarker} ? {comment} {pause} pretty much ?&#10;Speaker: PhD D&#10;Content: Uh , no we don't plan to fill the holes&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: but {pause} actually there is something important , is that {pause} um we made a lot of assumption concerning the on - line normalization and we just noticed {pause} uh recently that {pause} uh the {pause} approach that we were using {pause} was not {pause} uh {pause} leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." target="marker} for Aurora ?&#10;Speaker: PhD D&#10;Content: For HTK ?&#10;Speaker: Professor B&#10;Content: For {disfmarker} Yeah . For the Aurora ?&#10;Speaker: PhD D&#10;Content: Uh Training is longer .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK . Well , I don't know how we can {disfmarker} I don't know how to {disfmarker} Do we have HTK source ? Is that {disfmarker} Yeah .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: You would think that would fairly trivially {disfmarker} the training would , anyway , th the testing {pause} uh I don't {disfmarker} I don't {pause} think would {pause} parallelize all that well . But I think {pause} that {pause} you could {pause} certainly do d um , {pause} distributed , sort of {disfmarker} {pause} Ah , no , it 's the {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." target=" yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: So basically what I expect is that {pause} these numbers will a little bit go down but {pause} perhaps not {disfmarker} not so much&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: because {pause} I think the neural networks learn perhaps {pause} to {disfmarker}&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: even if the features are not {pause} normalized . It {disfmarker} it will learn how to normalize and {disfmarker}&#10;Speaker: Professor B&#10;Content: OK , but I think that {pause} given the pressure of time we probably want to draw {disfmarker} because of that {pause} especially , we wanna draw some conclusions from this , do some reductions {pause} in what we 're looking at ,&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and make some strong decisions for what we 're gonna do testing on before next week . So do you {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." target="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." target="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers discussed the realization that their assumption about online normalization was not leading to good results when used with straight features and the HTK. They noted that they had made a lot of assumptions concerning online normalization, but had recently discovered that the approach they were using was not working well with straight features to HTK. This realization prompted them to reconsider their previous results obtained for Italian with straight PLP features using online normalization, and to compare them with the results obtained by Pratibha using her own online normalization approach." target="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team.">
      <data key="d0">1</data>
    </edge>
    <edge source=" A&#10;Content: I see .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: OK ? Um {pause} So uh , I think this will take some {pause} looking at , thinking about . But , {pause} what is uh {disfmarker} what is currently running , that 's {disfmarker} uh , i that {disfmarker} just filling in the holes here or {disfmarker} or {disfmarker} ? {comment} {pause} pretty much ?&#10;Speaker: PhD D&#10;Content: Uh , no we don't plan to fill the holes&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: but {pause} actually there is something important , is that {pause} um we made a lot of assumption concerning the on - line normalization and we just noticed {pause} uh recently that {pause} uh the {pause} approach that we were using {pause} was not {pause} uh {pause} leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So" target="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information.">
      <data key="d0">1</data>
    </edge>
    <edge source=" yeah .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: So basically what I expect is that {pause} these numbers will a little bit go down but {pause} perhaps not {disfmarker} not so much&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: because {pause} I think the neural networks learn perhaps {pause} to {disfmarker}&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: even if the features are not {pause} normalized . It {disfmarker} it will learn how to normalize and {disfmarker}&#10;Speaker: Professor B&#10;Content: OK , but I think that {pause} given the pressure of time we probably want to draw {disfmarker} because of that {pause} especially , we wanna draw some conclusions from this , do some reductions {pause} in what we 're looking at ,&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: and make some strong decisions for what we 're gonna do testing on before next week . So do you {disf" target="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target=" point four case {disfmarker} does it include the training data for the one point one case ?&#10;Speaker: PhD D&#10;Content: Uh yeah .&#10;Speaker: Grad F&#10;Content: Yeah , a fraction of it .&#10;Speaker: PhD D&#10;Content: A part of it , yeah .&#10;Speaker: Professor B&#10;Content: How m how much bigger is it ?&#10;Speaker: PhD D&#10;Content: Um {pause} It 's two times ,&#10;Speaker: Grad F&#10;Content: Yeah , um .&#10;Speaker: PhD D&#10;Content: actually ? Yeah . Um . The English data {disfmarker} {pause} No , the multilingual databases are two times the {pause} broad English {pause} data . We just wanted to keep this , w well , not too huge . So .&#10;Speaker: Professor B&#10;Content: So it 's two times , but it includes the {disfmarker} but it includes the broad English data .&#10;Speaker: PhD D&#10;Content: I think so . Do you {disfmarker} Uh , Yeah .&#10;Speaker: Professor B&#10;Content: And the broad English data is what you got this">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target=" Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um {pause} for uh TI - digits for ins example {pause} uh when we go from TI - digits training to {pause} TIMIT training {pause} uh we lose {pause} uh around ten percent , uh . The error rate increase u of {disfmarker} of {disfmarker} of ten percent , relative .&#10;Speaker: Professor B&#10;Content: Relative . Right .&#10;Speaker: PhD D&#10;Content: So this is not so bad . And then when we jump to the multilingual data it 's uh it become worse and , well Around uh , let 's say , {pause} twenty perc twenty percent further .&#10;Speaker: Professor B&#10;Content: Ab - about how much ?&#10;Speaker: PhD D&#10;Content: So . Yeah .&#10;Speaker: Professor B&#10;Content: Twenty percent further ?&#10;Speaker: PhD D&#10;Content: Twenty to {disfmarker} to thirty percent further . Yeah .&#10;Speaker: PhD A&#10;Content: And so , remind me , the multilingual stuff is just">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target=" {disfmarker}&#10;Speaker: PhD A&#10;Content: OK ?&#10;Speaker: PhD D&#10;Content: Yeah . Uh {pause} So , basically when it 's trained on the {disfmarker} the multilingual broad data {pause} um or number {disfmarker} so , the {disfmarker} the {pause} ratio of our error rates uh with the {pause} baseline error rate is around {pause} uh one point one .&#10;Speaker: Professor B&#10;Content: Yes . {vocalsound} And it 's something like one point three of {disfmarker} of the {pause} uh {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: I i if you compare everything to the first case at the baseline , you get something like one point one for the {disfmarker} for the using the same language but a different task , and something like one point three {pause} for three {disfmarker} three languages {pause} broad stuff .&#10;Speaker: PhD D&#10;Content: No no no . Uh same language we are at uh {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target="Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: you {pause} do {pause} go to {pause} three languages including the English , {pause} it 's something like one point three . That 's what you were just saying , I think .&#10;Speaker: PhD D&#10;Content: Ye Uh , more actually .&#10;Speaker: PhD A&#10;Content: One point four ?&#10;Speaker: PhD D&#10;Content: If I {disfmarker} Yeah .&#10;Speaker: PhD A&#10;Content: So , it 's an additional thirty percent .&#10;Speaker: PhD D&#10;Content: What would you say ? Around one point four&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Professor B&#10;Content: And if you exclude {pause} English , {pause} from this combination , what 's that ?&#10;Speaker: PhD D&#10;Content: If we exclude English , {pause} um {pause} there is {pause} not much difference with the {pause} data with English .&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD D&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target="pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B&#10;Content: the one that it 's {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: In&#10;Speaker: PhD D&#10;Content: But {pause} not digits . I mean it 's {disfmarker}&#10;Speaker: PhD A&#10;Content: The three languages {pause} is not digits ,&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: it 's the broad {pause} data . OK .&#10;Speaker: PhD D&#10;Content: Yeah And the fourth test is uh {pause} excluding from these three languages the language {pause} that is {pause} the task language .&#10;Speaker: Professor B&#10;Content: Oh , OK , yeah , so , that is what I wanted to know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, one of the speakers (PhD D) mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English. PhD A then asked if it's a 30% increase, to which PhD D responded around 1.4, confirming a 40% approximation. However, the transcript does not explicitly state that this 40% increase is due to including English in the calculation of the number of languages spoken. The exact percentage increase for this specific condition cannot be accurately determined from the given transcript." target="0% (according to PhD D's response, there is not much difference when excluding English from the combination).">
      <data key="d0">1</data>
    </edge>
    <edge source=" point four case {disfmarker} does it include the training data for the one point one case ?&#10;Speaker: PhD D&#10;Content: Uh yeah .&#10;Speaker: Grad F&#10;Content: Yeah , a fraction of it .&#10;Speaker: PhD D&#10;Content: A part of it , yeah .&#10;Speaker: Professor B&#10;Content: How m how much bigger is it ?&#10;Speaker: PhD D&#10;Content: Um {pause} It 's two times ,&#10;Speaker: Grad F&#10;Content: Yeah , um .&#10;Speaker: PhD D&#10;Content: actually ? Yeah . Um . The English data {disfmarker} {pause} No , the multilingual databases are two times the {pause} broad English {pause} data . We just wanted to keep this , w well , not too huge . So .&#10;Speaker: Professor B&#10;Content: So it 's two times , but it includes the {disfmarker} but it includes the broad English data .&#10;Speaker: PhD D&#10;Content: I think so . Do you {disfmarker} Uh , Yeah .&#10;Speaker: Professor B&#10;Content: And the broad English data is what you got this" target="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source=" point four case {disfmarker} does it include the training data for the one point one case ?&#10;Speaker: PhD D&#10;Content: Uh yeah .&#10;Speaker: Grad F&#10;Content: Yeah , a fraction of it .&#10;Speaker: PhD D&#10;Content: A part of it , yeah .&#10;Speaker: Professor B&#10;Content: How m how much bigger is it ?&#10;Speaker: PhD D&#10;Content: Um {pause} It 's two times ,&#10;Speaker: Grad F&#10;Content: Yeah , um .&#10;Speaker: PhD D&#10;Content: actually ? Yeah . Um . The English data {disfmarker} {pause} No , the multilingual databases are two times the {pause} broad English {pause} data . We just wanted to keep this , w well , not too huge . So .&#10;Speaker: Professor B&#10;Content: So it 's two times , but it includes the {disfmarker} but it includes the broad English data .&#10;Speaker: PhD D&#10;Content: I think so . Do you {disfmarker} Uh , Yeah .&#10;Speaker: Professor B&#10;Content: And the broad English data is what you got this" target="0% (according to PhD D's response, there is not much difference when excluding English from the combination).">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um {pause} for uh TI - digits for ins example {pause} uh when we go from TI - digits training to {pause} TIMIT training {pause} uh we lose {pause} uh around ten percent , uh . The error rate increase u of {disfmarker} of {disfmarker} of ten percent , relative .&#10;Speaker: Professor B&#10;Content: Relative . Right .&#10;Speaker: PhD D&#10;Content: So this is not so bad . And then when we jump to the multilingual data it 's uh it become worse and , well Around uh , let 's say , {pause} twenty perc twenty percent further .&#10;Speaker: Professor B&#10;Content: Ab - about how much ?&#10;Speaker: PhD D&#10;Content: So . Yeah .&#10;Speaker: Professor B&#10;Content: Twenty percent further ?&#10;Speaker: PhD D&#10;Content: Twenty to {disfmarker} to thirty percent further . Yeah .&#10;Speaker: PhD A&#10;Content: And so , remind me , the multilingual stuff is just" target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: you {pause} do {pause} go to {pause} three languages including the English , {pause} it 's something like one point three . That 's what you were just saying , I think .&#10;Speaker: PhD D&#10;Content: Ye Uh , more actually .&#10;Speaker: PhD A&#10;Content: One point four ?&#10;Speaker: PhD D&#10;Content: If I {disfmarker} Yeah .&#10;Speaker: PhD A&#10;Content: So , it 's an additional thirty percent .&#10;Speaker: PhD D&#10;Content: What would you say ? Around one point four&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: yeah .&#10;Speaker: Professor B&#10;Content: And if you exclude {pause} English , {pause} from this combination , what 's that ?&#10;Speaker: PhD D&#10;Content: If we exclude English , {pause} um {pause} there is {pause} not much difference with the {pause} data with English .&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD D&#10;Content" target="0% (according to PhD D's response, there is not much difference when excluding English from the combination).">
      <data key="d0">1</data>
    </edge>
    <edge source="pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B&#10;Content: the one that it 's {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: In&#10;Speaker: PhD D&#10;Content: But {pause} not digits . I mean it 's {disfmarker}&#10;Speaker: PhD A&#10;Content: The three languages {pause} is not digits ,&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: it 's the broad {pause} data . OK .&#10;Speaker: PhD D&#10;Content: Yeah And the fourth test is uh {pause} excluding from these three languages the language {pause} that is {pause} the task language .&#10;Speaker: Professor B&#10;Content: Oh , OK , yeah , so , that is what I wanted to know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um" target="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B&#10;Content: the one that it 's {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: In&#10;Speaker: PhD D&#10;Content: But {pause} not digits . I mean it 's {disfmarker}&#10;Speaker: PhD A&#10;Content: The three languages {pause} is not digits ,&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: it 's the broad {pause} data . OK .&#10;Speaker: PhD D&#10;Content: Yeah And the fourth test is uh {pause} excluding from these three languages the language {pause} that is {pause} the task language .&#10;Speaker: Professor B&#10;Content: Oh , OK , yeah , so , that is what I wanted to know .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I just wasn't saying it very well , I guess .&#10;Speaker: PhD D&#10;Content: Uh , yeah . So um" target="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles.">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target=" on {disfmarker} {pause} on Italian digits , say ?&#10;Speaker: PhD D&#10;Content: We {disfmarker} No , we did four {disfmarker} four kind of {disfmarker} of testing , actually . The first testing is {pause} with task data {disfmarker} So , with nets trained on task data . So for Italian on the Italian speech @ @ . The second test is trained on a single language um with broad database , but the same language as the t task data .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: But for Italian we choose Spanish which {pause} we assume is close to Italian . The third test is by using , um the three language database&#10;Speaker: Professor B&#10;Content: W which in {disfmarker}&#10;Speaker: PhD D&#10;Content: and the fourth is&#10;Speaker: Professor B&#10;Content: It has three languages . That 's including the w the {disfmarker} {pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area.">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian.">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available.">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task.">
      <data key="d0">1</data>
    </edge>
    <edge source="The fact that the error rate is almost twice the baseline rate when using a network trained only on Spanish to understand Italian suggests that Spanish is not very close to Italian in terms of language similarity. This finding indicates that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided.">
      <data key="d0">1</data>
    </edge>
    <edge source=" on {disfmarker} {pause} on Italian digits , say ?&#10;Speaker: PhD D&#10;Content: We {disfmarker} No , we did four {disfmarker} four kind of {disfmarker} of testing , actually . The first testing is {pause} with task data {disfmarker} So , with nets trained on task data . So for Italian on the Italian speech @ @ . The second test is trained on a single language um with broad database , but the same language as the t task data .&#10;Speaker: Professor B&#10;Content: OK .&#10;Speaker: PhD D&#10;Content: But for Italian we choose Spanish which {pause} we assume is close to Italian . The third test is by using , um the three language database&#10;Speaker: Professor B&#10;Content: W which in {disfmarker}&#10;Speaker: PhD D&#10;Content: and the fourth is&#10;Speaker: Professor B&#10;Content: It has three languages . That 's including the w the {disfmarker} {pause} the {disfmarker}&#10;Speaker: PhD D&#10;Content: This includes {disfmarker}&#10;Speaker: Professor B" target="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." target=" that is {pause} very distinguishable from {pause} speech .&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: So that the {disfmarker} the silence model in HTK will always pick it up .&#10;Speaker: Professor B&#10;Content: Yeah . So I {disfmarker} I {disfmarker} that 's what I thought they would do . or else , uh {pause} uh maybe there is some indicator to tell it to start and stop , I don't know .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: But whatever they did , I mean they have to play within the rules of this specific evaluation .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: We c we can find out .&#10;Speaker: PhD A&#10;Content: Cuz you gotta do something . Otherwise , if it 's just a bunch of speech , stuck together {disfmarker}&#10;Speaker: Professor B&#10;Content: No they 're {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." target=" um , {pause} there 's um , {pause} the issue of the {pause} um Mu law {pause} business {pause} uh {pause} versus the logarithm , um , {pause} so .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So what i what is going on right now ? What 's right {disfmarker} you 've got {pause} nets retraining , Are there {disfmarker} is there {disfmarker} are there any H T K {pause} trainings {disfmarker} testings going on ?&#10;Speaker: PhD D&#10;Content: N&#10;Speaker: PhD E&#10;Content: I {disfmarker} I {disfmarker} I 'm trying the HTK with eh , {pause} PLP twelve on - line delta - delta and MSG filter {pause} together .&#10;Speaker: Professor B&#10;Content: The combination , I see .&#10;Speaker: PhD E&#10;Content: The combination , yeah . But I haven't result {vocalsound} at this moment .&#10;Speaker: Professor B&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." target="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." target="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." target="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript provided, Professors B and A are discussing the implementation of a silence model in the HTK (Hidden Markov Model Toolkit) to distinguish speech from non-speech sounds in the context of a specific evaluation. They acknowledge that the rules of this evaluation must be followed and express that they can find out more about how the silence model is working. However, there are no explicit statements regarding their thoughts or opinions on the matter. Therefore, it's not possible to provide a clear answer to the question without additional context or information." target="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages.">
      <data key="d0">1</data>
    </edge>
    <edge source="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." target=" will never occur {pause} in one language and will occur frequently in the other , so the qu the issue of getting enough training {pause} for a particular kind of context becomes harder . We already actually don't have a huge amount of training data um&#10;Speaker: PhD D&#10;Content: Yeah , but {disfmarker} mmm , I mean , {pause} the {disfmarker} the way we {disfmarker} we do it now is that we have a neural network and {pause} basically {pause} the net network is trained almost to give binary decisions .&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: And {pause} uh {disfmarker} binary decisions about phonemes . Nnn {disfmarker} Uh It 's {disfmarker}&#10;Speaker: Professor B&#10;Content: Almost . But I mean it {disfmarker} it {disfmarker} it does give a distribution .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: It 's {disfmarker} and {disfmarker} and {pause} it is">
      <data key="d0">1</data>
    </edge>
    <edge source="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." target=" PhD D&#10;Content: So {disfmarker}&#10;Speaker: Professor B&#10;Content: right ? Any - anyway go ahead .&#10;Speaker: PhD D&#10;Content: Yeah . So uh what we were thinking about is perhaps {pause} um one way {pause} to solve this problem is increase the number of {pause} outputs of the neural networks . Doing something like , um {pause} um phonemes within context and , well , basically context dependent phonemes .&#10;Speaker: Professor B&#10;Content: Maybe . I mean , I {disfmarker} I think {pause} you could make {pause} the same argument , it 'd be just as legitimate , {pause} for hybrid systems {pause} as well . Right .&#10;Speaker: PhD D&#10;Content: Yeah but , we know that {disfmarker}&#10;Speaker: Professor B&#10;Content: And in fact , {pause} th things get better with context dependent {pause} versions . Right ?&#10;Speaker: PhD D&#10;Content: Ye - yeah but here it 's something different . We want to have features&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: uh">
      <data key="d0">1</data>
    </edge>
    <edge source="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." target=" basically perhaps a flaw in the {disfmarker} in the {disfmarker} the stuff because {pause} we {pause} trained the networks {disfmarker} If we trained the networks on the {disfmarker} on {pause} a language and a t or a specific {pause} task ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: um , what we ask is {disfmarker} to the network {disfmarker} is to put the bound the decision boundaries somewhere in the space .&#10;Speaker: Professor B&#10;Content: Mmm .&#10;Speaker: PhD D&#10;Content: And uh {pause} mmm and ask the network to put one , {pause} at one side of the {disfmarker} for {disfmarker} for a particular phoneme at one side of the boundary {disfmarker} decision boundary and one for another phoneme at the other side . And {pause} so there is kind of reduction of the information there that 's not correct because if we change task {pause} and if the phonemes are not in the same context in the new">
      <data key="d0">1</data>
    </edge>
    <edge source="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." target="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task.">
      <data key="d0">1</data>
    </edge>
    <edge source="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." target="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="The current approach suggested to address the issue of limited training data and language differences for neural networks to make binary decisions about phonemes is to increase the number of outputs of the neural network. This could be accomplished by having context-dependent phonemes, where the network would consider the specific context in which a phoneme occurs. However, there is also discussion about the potential use of hybrid systems for this purpose.&#10;&#10;Additionally, there is a proposal to explore multi-language labeling using sixty-four phonemes from SAMPA (Speech Assessment Methods Phonetic Alphabet) as a way to address the challenges posed by limited training data and language differences. This approach could potentially help to reduce the reliance on large amounts of monolingual training data for each individual language.&#10;&#10;However, it is important to note that there are concerns about the effectiveness of these approaches, particularly given that the current results have not been successful yet. Therefore, further research and experimentation may be necessary to determine the best way to improve performance in this area." target="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" basically perhaps a flaw in the {disfmarker} in the {disfmarker} the stuff because {pause} we {pause} trained the networks {disfmarker} If we trained the networks on the {disfmarker} on {pause} a language and a t or a specific {pause} task ,&#10;Speaker: Professor B&#10;Content: Mm - hmm .&#10;Speaker: PhD D&#10;Content: um , what we ask is {disfmarker} to the network {disfmarker} is to put the bound the decision boundaries somewhere in the space .&#10;Speaker: Professor B&#10;Content: Mmm .&#10;Speaker: PhD D&#10;Content: And uh {pause} mmm and ask the network to put one , {pause} at one side of the {disfmarker} for {disfmarker} for a particular phoneme at one side of the boundary {disfmarker} decision boundary and one for another phoneme at the other side . And {pause} so there is kind of reduction of the information there that 's not correct because if we change task {pause} and if the phonemes are not in the same context in the new" target="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task.">
      <data key="d0">1</data>
    </edge>
    <edge source="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments." target=" 're doing this with H T&#10;Speaker: PhD A&#10;Content: Yeah , that 's what I was just gonna ask .&#10;Speaker: Professor B&#10;Content: This is {disfmarker}&#10;Speaker: PhD A&#10;Content: How can you just throw out frames ?&#10;Speaker: Professor B&#10;Content: Yeah . Well , you {disfmarker} you can ,&#10;Speaker: PhD D&#10;Content: i&#10;Speaker: Professor B&#10;Content: right ? I mean y you {disfmarker} you {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: it stretches again . For single frames I think it would be pretty hard .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: But if you say speech starts here , speech ends there .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Right ?&#10;Speaker: PhD C&#10;Content: Huh .&#10;Speaker: PhD D&#10;Content: Yeah . Yeah , you can basically remove the {disfmarker} the frames from the feature">
      <data key="d0">1</data>
    </edge>
    <edge source="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments." target=" wise VAD and the {disfmarker} {pause} the median filter say that there 's a stretch of silence . And then it 's going through and just throwing the data away .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: Right ? So um {disfmarker}&#10;Speaker: PhD A&#10;Content: So it 's {disfmarker} it 's {disfmarker} I don't understand . You mean it 's throwing out frames ? Before {disfmarker}&#10;Speaker: Professor B&#10;Content: It 's throwing out chunks of frames , yeah . There 's {disfmarker} the {disfmarker} the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So it 's throwing out frames and the thing is {pause} um , {pause} what I don't understand is how they 're doing this with H T&#10;Speaker: PhD A&#10;Content: Yeah , that 's what I was just gonna ask .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments." target=" not much difference with the {pause} data with English .&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD D&#10;Content: So . Yeah .&#10;Speaker: Professor B&#10;Content: That 's interesting . {pause} That 's interesting . Do you see ? Because {disfmarker} Uh ,&#10;Speaker: PhD D&#10;Content: Uh .&#10;Speaker: Professor B&#10;Content: so {disfmarker} No , that {disfmarker} that 's important . So what {disfmarker} what it 's saying here is just that &quot; yes , there is a reduction {pause} in performance , {pause} when you don't {pause} um {pause} have the s {pause} when you don't have {pause} um&#10;Speaker: PhD A&#10;Content: Task data .&#10;Speaker: Professor B&#10;Content: Wait a minute , th th the {disfmarker}&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: No , actually {pause} it 's interesting . So it 's {disfmarker} So when you go to a different task ,">
      <data key="d0">1</data>
    </edge>
    <edge source="To remove or throw out frames when analyzing speech in terms of start and end points, one approach is to use a Voice Activity Detection (VAD) system combined with a median filter. The VAD system estimates whether each frame contains speech or silence, while the median filter ensures some continuity by enforcing that it's not dealing with single, isolated frames. By applying these techniques together, they can identify stretches of consecutive silent frames and remove or discard those frames from analysis. This process helps distinguish between speech and non-speech sounds in the signal, allowing for more accurate analysis of the speech segments." target="disfmarker} so what they 're doing here is , {pause} i&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: if you look down at the block diagram , {pause} um , {pause} they estimate {disfmarker} they get a {disfmarker} {pause} they get an estimate {pause} of whether it 's speech or silence ,&#10;Speaker: PhD A&#10;Content: But that {disfmarker}&#10;Speaker: Professor B&#10;Content: and then they have a median filter of it .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: And so um , {pause} basically they 're trying to find stretches . The median filter is enforcing a {disfmarker} i it having some continuity .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: You find stretches where the {pause} combination of the {pause} frame wise VAD and the {disfmarker} {pause} the median filter say that there 's a stretch of silence . And then it 's">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart." target="aker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio to baseline ?&#10;Speaker: Professor B&#10;Content: So , I mean wha what 's the {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: This {disfmarker} this chart {disfmarker} this table that we 're looking at {pause} is um , show is all testing for TI - digits , or {disfmarker} ?&#10;Speaker: Grad F&#10;Content: Bigger is worse .&#10;Speaker: PhD D&#10;Content: So you have uh basically two {pause} uh parts .&#10;Speaker: Grad F&#10;Content: This is error rate , I think .&#10;Speaker: PhD C&#10;Content: Ratio .&#10;Speaker: Grad F&#10;Content: No . {pause} No .&#10;Speaker: PhD D&#10;Content: The upper part is for TI - digits&#10;Speaker: Grad F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: PhD D&#10;Content: and it 's divided in three {pause}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart." target="isfmarker} let 's use the conventional meaning of baseline .&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: I {disfmarker} I {disfmarker} By baseline here I meant {pause} uh using the task specific data .&#10;Speaker: PhD D&#10;Content: Oh yeah , the f Yeah , OK .&#10;Speaker: Professor B&#10;Content: But uh {disfmarker} {pause} uh , because that 's what you were just doing with this ten percent .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So I was just {disfmarker} I just trying to understand that .&#10;Speaker: PhD D&#10;Content: Yeah . Sure .&#10;Speaker: Professor B&#10;Content: So if we call {pause} a factor of w just one , just normalized to one , the word error rate {pause} that you have {pause} for using TI - digits as {disfmarker} as {pause} training and TI - digits as test ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh different words">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart." target=" number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline .&#10;Speaker: PhD A&#10;Content: Ah ! Ah , OK , OK .&#10;Speaker: Professor B&#10;Content: So this is word {disfmarker} word error rate , so a high number is bad .&#10;Speaker: PhD D&#10;Content: Yeah , this is {pause} a word error rate ratio .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: OK , I see .&#10;Speaker: PhD D&#10;Content: Yeah . So , seventy point two means that {pause} we reduced the error rate uh by thirty {disfmarker} thirty percent .&#10;Speaker: PhD A&#10;Content: OK , OK , gotcha .&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: OK , {vocalsound} so if we take&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: uh um let 's see PLP {pause} uh with on - line {pause} normalization and {pause} delta - del so that 's this thing">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and &quot;and what appears in the uh left column is the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline&quot; and by PhD A when they request &quot;let's use the conventional meaning of baseline.&quot;&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This is pointed out by Grad F when they say &quot;Bigger is worse&quot; and later clarified by PhD D that a value like 0.702 means that the error rate was reduced by 30%.&#10;4. The baseline value to which the numbers are being compared seems to be related to the HTK Aurora benchmark, as mentioned by PhD D when asked about the location of the baseline in the chart." target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: Professor B&#10;Content: Um What {disfmarker}&#10;Speaker: PhD C&#10;Content: These numbers are uh {pause} ratio to baseline ?&#10;Speaker: Professor B&#10;Content: So , I mean wha what 's the {disfmarker}&#10;Speaker: PhD D&#10;Content: So .&#10;Speaker: Professor B&#10;Content: This {disfmarker} this chart {disfmarker} this table that we 're looking at {pause} is um , show is all testing for TI - digits , or {disfmarker} ?&#10;Speaker: Grad F&#10;Content: Bigger is worse .&#10;Speaker: PhD D&#10;Content: So you have uh basically two {pause} uh parts .&#10;Speaker: Grad F&#10;Content: This is error rate , I think .&#10;Speaker: PhD C&#10;Content: Ratio .&#10;Speaker: Grad F&#10;Content: No . {pause} No .&#10;Speaker: PhD D&#10;Content: The upper part is for TI - digits&#10;Speaker: Grad F&#10;Content: Yeah , yeah , yeah .&#10;Speaker: PhD D&#10;Content: and it 's divided in three {pause}" target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured.">
      <data key="d0">1</data>
    </edge>
    <edge source="isfmarker} let 's use the conventional meaning of baseline .&#10;Speaker: PhD D&#10;Content: Hmm .&#10;Speaker: Professor B&#10;Content: I {disfmarker} I {disfmarker} By baseline here I meant {pause} uh using the task specific data .&#10;Speaker: PhD D&#10;Content: Oh yeah , the f Yeah , OK .&#10;Speaker: Professor B&#10;Content: But uh {disfmarker} {pause} uh , because that 's what you were just doing with this ten percent .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: So I was just {disfmarker} I just trying to understand that .&#10;Speaker: PhD D&#10;Content: Yeah . Sure .&#10;Speaker: Professor B&#10;Content: So if we call {pause} a factor of w just one , just normalized to one , the word error rate {pause} that you have {pause} for using TI - digits as {disfmarker} as {pause} training and TI - digits as test ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: uh different words" target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The significance of Pratibha's use of five percent (0.05) for the alpha parameter is that it controls the rate of adaptation in the recursive approach. Using a higher value like 0.05 causes the system to adapt more quickly to the data compared to the OGI baseline's default value of 0.005 (0.5%). However, this doesn't necessarily mean better performance. Pratibha's approach adapts faster but may not provide superior results.&#10;2. Previous results didn't emphasize the importance of the five percent alpha value because, in TI-digits, both values (0.005 and 0.05) gave similar results. However, when applied to Italian data, the difference between the two became significant, with Pratibha's approach adapting more quickly but not providing better performance.&#10;3. The initial approach for recursion in the OGI baseline involved starting the recursion from the beginning of the utterance using global mean and variances measured across the whole database as initial values.&#10;4. This approach was changed to initialize the values of mean and variance by computing this on the first 25 frames of each utterance, similar to Pratibha's method. Additionally, instead of waiting for the 15th or 25th frame to start the recursion as in the OGI baseline, Pratibha started the recursion from the first frame." target="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target=" have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora ?&#10;Speaker: PhD D&#10;Content: And {disfmarker}&#10;Speaker: PhD E&#10;Content: Mmm , no .&#10;Speaker: PhD D&#10;Content: No .&#10;Speaker: PhD A&#10;Content: Can I ask something real quick ? In {disfmarker} in the upper part {disfmarker} {pause} in the English {pause} stuff , {pause} it looks like the very best number is sixty point nine ? and that 's in the uh {disfmarker} {pause} the third {pause} section in the upper part under PLP JRASTA , sort of the middle column ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: I is that {pause} a noisy condition ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: So that 's matched training ? Is that what that is ?&#10;Speaker: PhD D&#10;Content: It 's {disfmarker} no , the">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="Based on the transcript, the following are the Italian recognition results using different normalization approaches:&#10;&#10;* With straight PLP features and online normalization (using global mean and variance measured across the whole database as initial values), the recognition results for Italian were 86, 100, and 143 for three separate tests.&#10;* Pratibha obtained recognition results of 79, 54, and 42 for Italian using her own online normalization approach with a faster adaptation rate (alpha value of 0.05) and different initialization values (computing mean and variance on the first 25 frames of each utterance and starting recursion from the first frame).&#10;&#10;The table mentioned in the transcript is not provided, so I cannot answer with exact numbers regarding how these results compare to each other. However, it can be observed that there are differences in the recognition results obtained using straight PLP features and online normalization compared to Pratibha's on-line normalization approach for Italian.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="0% (according to PhD D's response, there is not much difference when excluding English from the combination).">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="The summary question is: &quot;What does the discussion reveal about the similarity between Spanish and Italian in the context of speech recognition?&quot;&#10;&#10;The transcript indicates that there was a test conducted where a network trained only on Spanish data was used to recognize Italian speech. The error rate for this test was almost twice the baseline rate, suggesting that Spanish is not very close to Italian in terms of language similarity. This finding implies that there might be significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. To improve the performance of speech recognition systems for Italian, it may be necessary to use different approaches or techniques tailored specifically to the characteristics of the Italian language." target="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." target=" slightly worse when we don't use delta but it 's not {disfmarker} {pause} not that much .&#10;Speaker: Professor B&#10;Content: Right . So w w So , I 'm sorry . I missed that . What 's MF , MS and ME ?&#10;Speaker: PhD A&#10;Content: Multi - French , Multi - Spanish&#10;Speaker: PhD D&#10;Content: So . Multi - French , Multi - Spanish , and Multi - English .&#10;Speaker: Professor B&#10;Content: Uh OK . So , it 's {pause} uh {pause} broader vocabulary . Then {disfmarker} And {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: OK so I think what I 'm {disfmarker} what I saw in your smaller chart that I was thinking of was {disfmarker} was {pause} there were some numbers I saw , I think , that included these multiple languages and it {disfmarker} and I was seeing {pause} that it got worse . I {disfmarker} I think that was all it was . You had some very limited results that {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." target=" seeing {pause} that it got worse . I {disfmarker} I think that was all it was . You had some very limited results that {disfmarker} at that point&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: which showed {pause} having in these {disfmarker} these other languages . In fact it might have been just this last category , {pause} having two languages broad that were {disfmarker} where {disfmarker} where English was removed . So that was cross language and the {disfmarker} and the result was quite poor . What I {disfmarker} {pause} we hadn't seen yet was that if you added in the English , it 's still poor .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Uh {vocalsound} {vocalsound} Um now , what 's the noise condition {pause} um {pause} of the training data {disfmarker}&#10;Speaker: PhD D&#10;Content: Still poor .&#10;Speaker: Professor B&#10;Content: Well , I think this is what you were explaining .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." target="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." target="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." target="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, Professor B observed that there were some numbers in a smaller chart which showed worse performance when multiple languages, specifically Multi-French, Multi-Spanish, and Multi-English, were included during training. This was inferred from the conversation where Professor B mentioned seeing the deterioration in performance in the chart and linking it to an experiment involving different languages for training and testing digits, although there was no explicit confirmation of such an experiment taking place. Additionally, the negative impact on performance was quantified when PhD D mentioned that the ratio of error rates with the baseline error rate is around 1.1 when trained on multilingual broad data, including English, implying a decline in accuracy." target="0% (according to PhD D's response, there is not much difference when excluding English from the combination).">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context." target=" Yes , I don't know . That 's {disfmarker} that 's {disfmarker} so that 's a {disfmarker} that 's a very good question , then {disfmarker} now that it {disfmarker} {pause} I understand it . It 's &quot; yeah , where does the LDA come from ? &quot; In the {disfmarker} In {pause} earlier experiments , they had taken LDA {pause} from a completely different database , right ?&#10;Speaker: PhD E&#10;Content: Yeah . Yeah , because maybe it the same situation that the neural network training with their own&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: PhD E&#10;Content: set .&#10;Speaker: Professor B&#10;Content: So that 's a good question . Where does it come from ? Yeah , I don't know . Um , {pause} but uh to tell you the {pause} truth , I wasn't actually looking at the LDA so much when I {disfmarker} I was looking at it I was {pause} mostly thinking about the {disfmarker} {pause} the VAD . And">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context." target=" , anyway .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So um Their uh {disfmarker} {pause} the results look pretty good . Um , {pause} I mean , not uniformly .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: I mean , there 's a {disfmarker} an example or two {pause} that you can find , where it made it slightly worse , but {pause} uh in {disfmarker} in all but a couple {pause} examples .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Uh .&#10;Speaker: PhD E&#10;Content: But they have a question of the result . Um how are trained the {disfmarker} the LDA filter ? How obtained the LDA filter ?&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: I I 'm sorry . I don't understand your question .&#10;Speaker: PhD E&#10;Content: Yes , um the LDA filter {pause} needs some {pause} training set {">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context." target="'t understand your question .&#10;Speaker: PhD E&#10;Content: Yes , um the LDA filter {pause} needs some {pause} training set {pause} to obtain the filter . Maybe I don't know exactly how {pause} they are obtained .&#10;Speaker: Professor B&#10;Content: It 's on {pause} training .&#10;Speaker: PhD E&#10;Content: Training , with the training test of each {disfmarker} You understand me ?&#10;Speaker: Professor B&#10;Content: No .&#10;Speaker: PhD E&#10;Content: Yeah , uh for example , {pause} LDA filter {pause} need a set of {disfmarker} {pause} a set of training {pause} to obtain the filter .&#10;Speaker: Professor B&#10;Content: Yes .&#10;Speaker: PhD E&#10;Content: And maybe {pause} for the Italian , for the TD {pause} TE on for Finnish , these filter are {disfmarker} are obtained with their own training set .&#10;Speaker: Professor B&#10;Content: Yes , I don't know . That 's {disfmarker} that 's {disfmarker} so that 's a {d">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion does not provide explicit information about the similarity between Spanish and Italian in the context of speech recognition. However, it can be inferred that there might be significant differences between the two languages, as a network trained only on Spanish data performed poorly when recognizing Italian speech.&#10;&#10;The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context." target="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target=" again , it 's the silence {disfmarker} So they 've just trained up a net {pause} which has two outputs , I believe . Um {vocalsound} I asked uh {pause} Hynek whether {disfmarker} I haven't talked to Sunil {disfmarker} I asked Hynek whether {pause} they compared that to {pause} just taking the nets we already had {pause} and summing up the probabilities .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh . {pause} To get the speech {disfmarker} voice activity detection , or else just using the silence , {pause} if there 's only one {pause} silence output . Um {pause} And , he didn't think they had , um . But on the other hand , maybe they can get by with a smaller net and {pause} maybe {pause} sometimes you don't run the other , maybe there 's a computational advantage to having a separate net , anyway .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So um Their uh {">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target="When training networks to make decisions about phoneme boundaries in a specific language and task, one issue that arises is the reduction of information, as discussed by PhD D. By setting decision boundaries for a particular phoneme on one side and another phoneme on the other side, the network may not correctly account for changes in context or task. This can lead to reduced performance when attempting to recognize phonemes in different contexts or tasks.&#10;&#10;In the discussion, it is mentioned that training a network only on Spanish data resulted in an error rate almost twice the baseline rate when recognizing Italian speech. This suggests that there are significant differences between the two languages that make it challenging for models trained on one to effectively recognize the other. Thus, another issue is the language similarity problem - using a model trained on one language may not be sufficient for recognizing another language with adequate accuracy, even if the two languages are somewhat similar.&#10;&#10;To address these issues, further research and experimentation are necessary to determine the best way to improve performance in making binary decisions about phonemes in different contexts and tasks, taking into account the specific characteristics of each language. This might involve using different approaches or techniques tailored to the characteristics of the target language, rather than relying solely on models trained on a single language or task.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details about the results of Hynek's comparison between training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing nets. However, it is mentioned that Professor B asked Hynek if they had compared these approaches, but there is no mention of Hynek's response or the outcome of the comparison. Therefore, based on the provided transcript, the results of Hynek's comparison are not available." target="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team.">
      <data key="d0">1</data>
    </edge>
    <edge source=" again , it 's the silence {disfmarker} So they 've just trained up a net {pause} which has two outputs , I believe . Um {vocalsound} I asked uh {pause} Hynek whether {disfmarker} I haven't talked to Sunil {disfmarker} I asked Hynek whether {pause} they compared that to {pause} just taking the nets we already had {pause} and summing up the probabilities .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: Uh . {pause} To get the speech {disfmarker} voice activity detection , or else just using the silence , {pause} if there 's only one {pause} silence output . Um {pause} And , he didn't think they had , um . But on the other hand , maybe they can get by with a smaller net and {pause} maybe {pause} sometimes you don't run the other , maybe there 's a computational advantage to having a separate net , anyway .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: So um Their uh {" target="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The chart being discussed contains testing results for TI-digits, which is a specific type of task or dataset. This is mentioned by PhD D when they say &quot;The upper part is for TI-digits&quot; and describe what appears in the left column as &quot;the networks that are used for doing this.&quot;&#10;2. The numbers in the chart are presented as ratios to a baseline value. This is stated by PhD D when they mention &quot;all these numbers are the ratio with respect to the baseline.&quot; In this context, using the conventional meaning of baseline implies comparing the results to a condition where only TI-digits data is used for both training and testing.&#10;3. When it comes to interpreting the numbers, bigger values are typically worse in this context. This was inferred when Professor B said &quot;By baseline here I meant ... using the task specific data&quot; and linked it to the ten percent normalization that was done previously. Additionally, PhD D confirmed that a value like 0.702 means that the error rate was reduced by 30%.&#10;&#10;In summary, the chart being discussed contains testing results for TI-digits presented as ratios to a baseline where only TI-digits data is used for both training and testing. In this context, bigger values are typically worse for the word error rate being measured." target="1. Focus on the most critical features: Given that reducing information might negatively impact the neural network's performance, Professor B and PhD D should prioritize identifying and retaining the most important features for their specific task. This may involve further analysis of the current feature set or exploring new features that could improve the model's performance.&#10;2. Evaluate alternative normalization techniques: Since their current online normalization approach is not working well with straight features in HTK, they should consider testing other normalization methods. Comparing their results to Pratibha's online normalization approach might provide insights into more effective strategies for feature normalization.&#10;3. Experiment with different neural network architectures: To ensure that the reduction in classes does not worsen performance, Professor B and PhD D could explore various neural network architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which might be more resilient to reduced class information.&#10;4. Set specific testing scenarios for next week: Based on their discussions about mismatched data and different types of noise in training and testing datasets, they should establish clear testing scenarios for the following week. This will help them make stronger decisions about what to test and ensure that their conclusions are as accurate and informative as possible.&#10;5. Document their findings and assumptions: As they continue their exploration, Professor B and PhD D should keep detailed notes on their experiments, findings, and any remaining assumptions. This documentation will be valuable for tracking progress, identifying patterns, and communicating their results to the rest of the team.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations." target=": what do we do in four or five days ? Uh , and {disfmarker} {pause} so we have {pause} to be concerned {pause} with Are we gonna look at any combinations of things , you know once the nets get retrained so you have this problem out of it .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: Um , are we going to look at {pause} multi - band ? Are we gonna look at combinations of things ? Uh , what questions are we gonna ask , uh now that , I mean , {pause} we should probably turn shortly to this O G I note . Um , how are we going to {pause} combine {pause} with what they 've been focusing on ? Uh , {pause} Uh we haven't been doing any of the L D A RASTA sort of thing .&#10;Speaker: PhD D&#10;Content: Mm - hmm .&#10;Speaker: Professor B&#10;Content: And they , although they don't talk about it in this note , um , {pause} there 's um , {pause} the issue of the {pause} um Mu law {pause} business {pause} uh {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it appears that your team is in the process of reconfiguring the software to work with a single net that has twenty-seven outputs, which corresponds to twenty-seven broad phonetic classes. This net is being trained with fewer classes compared to the original setup. Additionally, there are discussions about exploring multi-band and combining features and net outputs to simplify the networks and reduce the number of outputs. The team also mentioned not having nets yet and discussing retraining nets, which suggests that they are working on fine-tuning the software to handle these changes in output settings and network configurations." target="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided." target=": I 'll get it for you .&#10;Speaker: PhD D&#10;Content: Uh , no , no .&#10;Speaker: Professor B&#10;Content: We 've never just trained on one lang&#10;Speaker: PhD D&#10;Content: Training on a single language , you mean , and testing on the other one ?&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: PhD D&#10;Content: Uh , no .&#10;Speaker: PhD E&#10;Content: Not yet .&#10;Speaker: PhD D&#10;Content: So the only {pause} task that 's similar to this is the training on two languages , and {comment} that {disfmarker}&#10;Speaker: Professor B&#10;Content: But we 've done a bunch of things where we just trained on one language . Right ? I mean , you haven't {disfmarker} you haven't done all your tests on multiple languages .&#10;Speaker: PhD D&#10;Content: Uh , No . Either thi this is test with {pause} uh the same language {pause} but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The main question revolves around the origin of the LDA (Latent Dirichlet Allocation) used in an experiment where it was taken from a different database. The conversation reveals that the LDA came from a separate training set, and its filter was obtained using that specific training set. This implies that the LDA was not originally designed for or trained on the same data as the current experiment. It was likely borrowed or adapted from another dataset to be used in this context.&#10;&#10;Answer: No, the transcript does not provide explicit information about a previous experiment where training was conducted on one language and testing was done on another without using a mixture of the two. However, there is a mention of an experiment involving different languages for training and testing digits, but no specific details are provided." target="0% (according to PhD D's response, there is not much difference when excluding English from the combination).">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide enough context to determine the exact role of KL or PLP in transforming the information provided during the conversation between Professor B, PhD D, and PhD E. However, based on the relevant extracts from the transcript, it can be inferred that KL (Kullback-Leibler divergence) is a measure used to compare two probability distributions, while PLP (Perceptual Linear Prediction) is a feature extraction method used to improve speech recognition performance.&#10;&#10;In the context of this conversation, KL or PLP might be relevant when discussing data transformation techniques applicable to their research. Here are some key extracts related to these terms:&#10;&#10;* &quot;all of that goes into that all of that is transformed by uh , uh , K - KL or something&quot; (PhD D)&#10;* &quot;one single KL to transform everything&quot; (PhD D)&#10;* &quot;transform the PLP per&quot; (PhD E)&#10;* &quot;only transform the other I 'm not sure&quot; (PhD E)&#10;&#10;It's clear that KL and PLP were mentioned in the conversation, but without further context, it is impossible to determine their specific roles." target=" or something .&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: And then uh , just to remind me , all of that goes {pause} into {disfmarker} uh , that all of that is transformed by uh , uh , K - KL or something , or {disfmarker} ?&#10;Speaker: PhD D&#10;Content: Mm - hmm . There will probably be ,&#10;Speaker: PhD E&#10;Content: Mu .&#10;Speaker: PhD D&#10;Content: yeah , one single KL to transform everything&#10;Speaker: Professor B&#10;Content: Right .&#10;Speaker: PhD D&#10;Content: or {vocalsound} {pause} uh ,&#10;Speaker: PhD E&#10;Content: No transform the PLP&#10;Speaker: PhD D&#10;Content: per&#10;Speaker: PhD E&#10;Content: and only transform the other I 'm not sure .&#10;Speaker: Professor B&#10;Content: Well no ,&#10;Speaker: PhD D&#10;Content: This is {pause} still something {pause} that&#10;Speaker: Professor B&#10;Content: I think {disfmarker} I see .&#10;Speaker: PhD D&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine." target=" {pause} um I could try to get {pause} um the train the neural network trainings or the HTK stuff running under Linux , and to start with I 'm {pause} wondering which one I should pick first .&#10;Speaker: Professor B&#10;Content: Uh , probably the neural net cuz it 's probably {disfmarker} it {disfmarker} it 's {disfmarker} {pause} it 's um {disfmarker} Well , I {disfmarker} I don't know . They both {disfmarker} HTK we use for {pause} um {pause} this Aurora stuff Um {pause} Um , I think {pause} It 's not clear yet what we 're gonna use {pause} for trainings uh {disfmarker} Well , {pause} there 's the trainings uh {disfmarker} is it the training that takes the time , or the decoding ? Uh , is it about equal {pause} between the two ? For {disfmarker} for Aurora ?&#10;Speaker: PhD D&#10;Content: For HTK ?&#10;Speaker: Professor B&#10;Content: For {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine." target=" I think you 're {disfmarker} you 're sort of held up by both , right ? If the {disfmarker} if the neural net trainings were a hundred times faster {pause} you still wouldn't {pause} be anything {disfmarker} running through these a hundred times faster because you 'd {pause} be stuck by the HTK trainings ,&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: Professor B&#10;Content: right ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: But if the HTK {disfmarker} I mean I think they 're both {disfmarker} It sounded like they were roughly equal ? Is that about right ?&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Yeah .&#10;Speaker: Grad G&#10;Content: Because , um {pause} I think that 'll be running Linux , and Sw - Swede and Fudge are already running Linux so , {pause} um I could try to get {pause} um the train the neural network trainings or the HTK stuff running under Linux , and to start">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, it is not explicitly stated who or what is causing the delay in getting the code running on the two-processor machine. However, it is mentioned that both the neural network trainings and the HTK runs might be contributing to the hold-up. It is also suggested that there will be debugging hassles involved in setting up the code on the new machine." target=" somebody to do the work on {disfmarker} {pause} on getting our code running {pause} on that machine with two processors {pause} even though there aren't five or eight . There 's {disfmarker} there 's {disfmarker} there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . But . {pause} Notice how I said somebody and {vocalsound} turned my head your direction . That 's one thing you don't get in these recordings . You don't get the {disfmarker} {pause} don't get the visuals but {disfmarker}&#10;Speaker: Grad G&#10;Content: I is it um {pause} mostly um the neural network trainings that are {pause} um slowing us down or the HTK runs that are slowing us down ?&#10;Speaker: Professor B&#10;Content: Uh , I think yes . Uh , {vocalsound} Isn't that right ? I mean I think you 're {disfmarker} you 're sort of held up by both , right ? If the {disfmarker} if">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages." target=" Did {disfmarker} did {disfmarker} {pause} did I interrupt you ?&#10;Speaker: PhD E&#10;Content: Yeah , I have one .&#10;Speaker: Professor B&#10;Content: Were there other things that you wanted to {disfmarker}&#10;Speaker: PhD D&#10;Content: Uh , no . I don't think so .&#10;Speaker: PhD E&#10;Content: &#10;Speaker: PhD D&#10;Content: Yeah , I have one .&#10;Speaker: Grad G&#10;Content: Oh , thanks .&#10;Speaker: Professor B&#10;Content: Ah ! {pause} OK . {pause} OK , we have {pause} lots of them .&#10;Speaker: PhD E&#10;Content: We have one . &#10;Speaker: Professor B&#10;Content: OK , so {vocalsound} um , Something I asked {disfmarker} So they 're {disfmarker} they 're doing {pause} the {disfmarker} the VAD I guess they mean voice activity detection So again , it 's the silence {disfmarker} So they 've just trained up a net {pause} which has two outputs , I believe">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers have been discussing a network trained for voice activity detection (VAD) that distinguishes speech from non-speech sounds, specifically focusing on silence. They mentioned two approaches: training a new network with two outputs for speech/voice activity detection and summing up the probabilities from existing networks. However, it is unclear if they compared these methods, as the discussion does not provide specific results or details about Hynek's response. The network has been trained to output either speech or silence, and the speakers are considering whether using a separate net for silence detection could offer computational advantages." target="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another.">
      <data key="d0">1</data>
    </edge>
    <edge source="The discussion highlights the significance of using broad phonetic classes, original features, and the distinction between speech and silence when training a net under well-controlled conditions. This approach allows for distinguishing spoken content from silence effectively, which is crucial for accurate speech recognition. By utilizing broad phonetic classes based on place of articulation and manner, it becomes possible to reduce the number of outputs and simplify the network configuration without losing essential linguistic information.&#10;&#10;This method addresses a common issue in speech recognition when using nets trained on one language (like Spanish) for another language (like Italian). In this case, the error rate was almost twice the baseline, indicating that there are significant differences between the languages that can impact performance. By combining broad phonetic classes with original features, the system can potentially generalize better across languages and adapt to various speech patterns.&#10;&#10;The team's discussion also touches upon the idea of exploring multi-band approaches and merging features and net outputs to further simplify networks and minimize the number of outputs. This exploration may lead to improved computational efficiency and enhanced cross-lingual recognition capabilities, enabling better performance when deploying nets trained on one language for another." target="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems." target="'t what their scripts are {pause} set up to do for the Aurora stuff , but {disfmarker}&#10;Speaker: PhD D&#10;Content: Yeah .&#10;Speaker: Professor B&#10;Content: Something that we haven't really settled on yet is other than {pause} this Aurora stuff , {pause} uh what do we do , large vocabulary {pause} training slash testing {pause} for uh tandem systems . Cuz we hadn't really done much with tandem systems for larger stuff . Cuz we had this one collaboration with CMU and we used SPHINX . Uh , we 're also gonna be collaborating with SRI and we have their {disfmarker} have theirs . Um {pause} So {pause} I don't know Um . So I {disfmarker} I think the {disfmarker} the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for a lot of the things we 're doing ,&#10;Speaker: Grad G&#10;Content: OK .&#10;Speaker: Professor B&#10;Content: whereas , w exactly which HMM {disfmarker} Gaussian - mixture - based HMM thing">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The options being considered for large vocabulary training and testing in tandem systems include using HMM (Hidden Markov Model) based methods and exploring multi-band approaches with merged features and network outputs. These techniques aim to simplify the networks, minimize the number of outputs, and improve computational efficiency.&#10;&#10;2. The advantage of using a neural net approach for these tasks is that it allows for the utilization of neural network trainings across various applications, making it a versatile choice for different projects. Moreover, the team had previously collaborated with Carnegie Mellon University (CMU) and used SPHINX, and they will be working with SRI, which suggests that they are already familiar with using neural nets in tandem systems." target="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="The transcript does not provide specific details on how the training of a machine learning model is distributed across multiple machines for the Aurora project. However, it mentions that there is a possibility to split up the sentences in a test set and parallelize the training on several machines. This suggests that some form of distributed computing or parallel processing might be employed to handle the large amount of data and computations required for speech recognition tasks. It is also noted that there are scripts set up for the Aurora stuff, but the specifics of these scripts are not discussed in the transcript." target=" um , {pause} distributed , sort of {disfmarker} {pause} Ah , no , it 's the {disfmarker} {pause} each individual {pause} sentence is pretty tricky to parallelize . But you could split up the sentences in a test set .&#10;Speaker: PhD A&#10;Content: They have a {disfmarker} they have a thing for doing that and th they have for awhile , in H T And you can parallelize the training .&#10;Speaker: Professor B&#10;Content: Yeah ?&#10;Speaker: PhD A&#10;Content: And run it on several machines&#10;Speaker: Professor B&#10;Content: Aha !&#10;Speaker: PhD A&#10;Content: and it just basically keeps counts . And there 's something {disfmarker} {pause} a final {pause} thing that you run and it accumulates all the counts together .&#10;Speaker: Professor B&#10;Content: I see .&#10;Speaker: PhD D&#10;Content: Mmm .&#10;Speaker: PhD A&#10;Content: I don't what their scripts are {pause} set up to do for the Aurora stuff , but {disfmarker}&#10;Speaker: PhD D&#10;Content">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
