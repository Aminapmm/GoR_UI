<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." />
    <node id=" , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here 's a number of things that could be done . &quot; So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one {disfmarker} one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and {disfmarker} and CPU it takes , but it seems like the filtering {pause} Uh , I mean , the VAD stuff they both had , right ? And , um , so {disfmarker} and they both had some kind of on - line normalization , right ?&#10;Speaker: PhD A&#10;Content: Uh , yeah .&#10;Speaker: Professor D&#10;Content: Of sorts , yeah ? So {disfmarker} so , it seems like the main different there is the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmark" />
    <node id="s probably a good time to look at what 's really going on and seeing if there 's a {disfmarker} there 's a way to combine the best ideas while at the same time not blowing up the amount of , uh , resources used , cuz that 's {disfmarker} that 's critical for this {disfmarker} this test .&#10;Speaker: PhD C&#10;Content: Do we know anything about {disfmarker} who {disfmarker} who 's was it that had the lowest on the dev set ?&#10;Speaker: Professor D&#10;Content: Um , uh , the , uh , the there were two systems that were put forth by a combination of {disfmarker} of , uh , French Telecom and Alcatel . And , um they {disfmarker} they differed in some respects , but they e em one was called the French Telecom Alcatel System the other was called the Alcatel French Telecom System , {vocalsound} uh , which is the biggest difference , I think . But {disfmarker} but there 're {disfmarker} there 're {disfmarker} there 're some other differences ," />
    <node id="aker: PhD A&#10;Content: yeah .&#10;Speaker: Professor D&#10;Content: just with the missing columns filled in .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Well , that 'll be good . So , I 'll dis I 'll disregard these numbers . That 's {disfmarker} that 's {disfmarker} that 's good .&#10;Speaker: PhD A&#10;Content: So , Hynek will try to push for trying to combine , uh , different things ? Or Hmm ?&#10;Speaker: Professor D&#10;Content: Uh , well that 's {pause} um yeah I mean , I think the question is &quot; Is there {disfmarker} is there some advantage ? &quot; I mean , you could just take the best system and say that 's the standard . But the thing is that if different systems are getting at good things , um , a again within the constraint of the resources , if there 's something simple that you can do Now for instance , uh , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here" />
    <node id=" the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmarker} shouldn't take a lot of memory to do that Uh , and I also wouldn't think the CPU , uh , would be much either for that part . So , if you can {disfmarker} if you can add those in {pause} um {pause} then , uh , you can cut the data rate in half .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So it seems like the right thing to do is to {disfmarker} on the {disfmarker} on the terminal 's side , take what they did , if it {disfmarker} if it does seem to generalize well to German and Danish , uh , take what they did add in a filter , and add in some stuff on the server 's side and {disfmarker} and {disfmarker} and that 's probably a reasonable standard . Um {pause} Uh&#10;Speaker: PhD A&#10;Content: They are working on this already ? Because {disfmarker} yeah , Su" />
    <node id=" a different car , and so on . So it 's {disfmarker} this is a an optim somewhat optimistic view on it , uh , so , you know , the real thing is somewhere in between the two .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , uh , but&#10;Speaker: PhD A&#10;Content: But the {disfmarker} I mean , the {pause} th th&#10;Speaker: Professor D&#10;Content: Even the optimistic one is&#10;Speaker: PhD A&#10;Content: it doesn't work .&#10;Speaker: Professor D&#10;Content: Yeah ,&#10;Speaker: PhD A&#10;Content: It {disfmarker}&#10;Speaker: Professor D&#10;Content: right . Right , it doesn't work . So , in a way , that 's , you know , that 's sort of the dominant thing is that even , say on the development set stuff that we saw , the , uh , the numbers that , uh , that Alcatel was getting when choosing out the best single numbers , {vocalsound} it was just {disfmarker} you know , it wasn't good enough for {disfmarker" />
    <node id=" Well , n I mean , this was just a ph phoney thing just to {disfmarker} to fit into the {disfmarker} the software that was testing the errors {disfmarker} channel errors and so on .&#10;Speaker: PhD C&#10;Content: Oh . Oh .&#10;Speaker: Professor D&#10;Content: So {disfmarker} so in reality , if you put this {disfmarker} this system in into , uh , the field , it would be twenty - four hundred bits per second , not forty - eight hundred . So , um , so that 's a nice feature of what {disfmarker} what we did . Um , but , um , well , we still have to see how it all comes out .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: Um , and then there 's the whole standards process , which is another thing altogether .&#10;Speaker: PhD C&#10;Content: When is the development set {disfmarker} I mean , the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably" />
    <node id="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." />
    <node id=" particular standards process once you {disfmarker} you go to this meeting . So , be interested in hearing . So , uh , I 'd be , uh , interested in hearing , uh , your thoughts now I mean you 're almost done . I mean , you 're done in the sense that , um , you may be able to get some new features from Sunil , and we 'll re - run it . Uh , but other than that , you 're {disfmarker} you 're basically done , right ? So , uh , I 'm interested in hearing {disfmarker} hearing your thoughts about {pause} where you think we should go from this .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: I mean , we tried a lot of things in a hurry , and , uh , if we can back off from this now and sort of take our time with something , and not have doing things quickly be quite so much the constraint , what {disfmarker} what you think would be the best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {d" />
    <node id=" be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , so Yeah , well , if we don't have an anything else to discuss , we should , uh , turn off the machine and then say the real nasty things .&#10;Speaker: PhD C&#10;Content: Should we do digits first ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Oh , yeah , digits .&#10;Speaker: Professor D&#10;Content: Oh yeah , digits ! Yeah . Good point . Yeah , good thinking . Why don't you go ahead .&#10;Speaker: PhD C&#10;Content: OK . OK ." />
    <node id=" the best system than ours ?&#10;Speaker: Professor D&#10;Content: So Well , we don't know yet .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor D&#10;Content: Uh , I mean , first place , there 's still this thing to {disfmarker} to work out , and second place {disfmarker} second thing is that the only results that we have so far from before were really development set results .&#10;Speaker: PhD C&#10;Content: Oh , OK .&#10;Speaker: Professor D&#10;Content: So , I think in this community that 's of interest . It 's not like everything is being pinned on the evaluation set . But , um , for the development set , our best result was a little bit short of fifty percent . And the best result of any system was about fifty - four , where these numbers are the , uh , relative , uh , reduction in , uh , word error rate .&#10;Speaker: PhD C&#10;Content: Oh , OK .&#10;Speaker: Professor D&#10;Content: And , um , the other systems were , uh , somewhat lower than that . There was actually {disfmarker} there was much less of a" />
    <node id="rum {pause} down by , you know {pause} a fourth of them to , uh , a half of them . Somewhere in there , depending on the {pause} exact case . So So that 's good . I mean , I think that , uh , one of the things that Hynek was talking about was understanding what was in the other really good proposals and {disfmarker} and trying to see if what should ultimately be proposed is some , uh , combination of things . Um , if , uh {disfmarker} Cuz there 's things that they are doing {pause} there that we certainly are not doing . And there 's things that we 're doing that {pause} they 're not doing . And {disfmarker} and they all seem like good things .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So&#10;Speaker: PhD E&#10;Content: Mmm , yeah .&#10;Speaker: PhD C&#10;Content: How much {disfmarker} how much better was the best system than ours ?&#10;Speaker: Professor D&#10;Content: So Well , we don't know yet .&#10;Speaker: PhD C&#10;Content" />
    <node id="Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content: Y Actually , uh , um , for the Danish , there 's still some kind of mystery because , um , um , when we use the straight features , we are not able to get these nice number with the ICSI OGI one , I mean . We don't have this ninety - three seventy - eight , we have eight&#10;Speaker: PhD E&#10;Content: Eighty - nine forty - four .&#10;Speaker: PhD A&#10;Content: yeah . Uh , so , uh , that 's probably something wrong with the features that we get from OGI . Uh , and Sunil is working on {disfmarker} on trying to {disfmarker} to check everything .&#10;Speaker: Professor D&#10;Content: Oh , and {disfmarker} and we have a little time on that {disfmarker} and {disfmarker} actually so&#10;Speaker: PhD A&#10;Content: Hmm ?&#10;Speaker: Professor D&#10;Content: We have a little bit of time on that , actually .&#10;Speaker: PhD" />
    <node id="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." />
    <node id=" No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content: I mean , if you have ten digits for a phone number {comment} I mean , every now and then you 'll get it right . I mean , it 's {disfmarker} it 's , uh , {vocalsound} um So , I mean , the other thing is that , uh {disfmarker} And {disfmarker} and {disfmarker} a and {disfmarker} and also , um {pause} part of what 's nice about this is that this is , uh , {vocalsound} um {pause} a realistic {disfmarker} almost realistic database . I mean , it 's still not people who are really trying to accomplish something , but {disfmarker} but , uh , within the artificial setup , it isn't noise artificially added , you know , simulated , uh , additive noise .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's real noise condition . And , um , {voc" />
    <node id=" where it was {disfmarker} it was in a hallway where it was very reverberant and we {disfmarker} we made some recordings there . And then we {vocalsound} {disfmarker} we , uh {disfmarker} uh , made a simulation of the {disfmarker} of the room acoustics there and {disfmarker} and applied it to other things ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: and uh But it was all pretty artificial , and {disfmarker} and , you know , how often would you really try to have your most crucial conversations in this very reverberant hallway ? Um {pause} So , uh {pause} This is what 's nice about the Aurora data and the data here , is that {disfmarker} is that it 's sort of a realistic room situation {pause} uh , acoustics {disfmarker} acoustic situation , both terms in noise and reflections , and so on and n n And , uh , uh , with something that 's still relatively realistic , it 's still very very hard to do very well ." />
    <node id=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:" />
    <node id=" best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {disfmarker} at the speech {pause} {vocalsound} from these databases because , well , we tried several thing , but we did not really look {vocalsound} at what what 's happening , and {vocalsound} where is the noise , and&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Eh&#10;Speaker: Professor D&#10;Content: It 's a novel idea . Look at the data . OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Or more generally , I guess , what {disfmarker} what is causing the degradation .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . Actually , there is one thing that {disfmarker} well {pause} Um , generally we {disfmarker} we think that {vocalsound} most of the errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker}" />
    <node id=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing" />
    <node id=" mean the speed and the kind of road , is different for training and testing , is that right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: And the last condition is close microphone for training and distant for testing . Yeah .&#10;Speaker: Professor D&#10;Content: Uh , OK ,&#10;Speaker: PhD A&#10;Content: So {disfmarker} {vocalsound} s so {disfmarker}&#10;Speaker: Professor D&#10;Content: so I see . So , yeah , so the high {disfmarker} so the {disfmarker} right {disfmarker} so the highly mismatched {vocalsound} case {pause} is in some sense a good model for what we 've been , you know , typically talking about when we talk about additive noise in {disfmarker} And so {disfmarker} and i i k it does correspond to a realistic situation in the sense that , {vocalsound} um , people might really be trying to , uh , call out telephone numbers or some or something like that , in {disfmarker} in their cars&#10;Speaker: PhD A&#10;Content:" />
    <node id="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable." />
    <node id="ound} y you 're thinking that you didn't get to that you would like to do if you had more time ? Uh&#10;Speaker: PhD E&#10;Content: Oh , f a lot of thing . Because we trying a lot of s {pause} thing , and we doesn't work , {vocalsound} we remove these . Maybe {vocalsound} we trying again with the articulatory feature . I don't know exactly because we tried {disfmarker} we {disfmarker} some {disfmarker} one experiment that doesn't work . Um , forgot it , something {pause} I don't know exactly&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: because , tsk {comment} {vocalsound} maybe do better some step the general , {vocalsound} eh , diagram .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: I don't know exactly s to think what we can improve .&#10;Speaker: Professor D&#10;Content: Yeah , cuz a lot of time it 's true , there were a lot of times when we 've" />
    <node id=" . But , um , that was just sort of one try , right ? You just took one filter , threw it there ,&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: right ? And it seems to me that , um , if that is an important idea , which , you know , might be , that one could work at it for a while , as you 're saying .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: And , uh Uh , and you had , you know , you had the multi - band things also , and , you know , there was issue of that .&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: Um , Barry 's going to be , uh , continuing working on multi - band things as well .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: We were just talking about , um , {vocalsound} some , uh , some work that we 're interested in . Kind of inspired by the stuff by Larry Saul with the , uh {pause} uh , learning articulatory feature in {disf" />
    <node id="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." />
    <node id="} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker: Professor D&#10;Content: The other thing that strikes me , just looking at these numbers is , just taking the best cases , I mean , some of these , of course , even with all of our {disfmarker} our wonderful processing , still are horrible kinds of numbers . But just take the best case , the well - matched {pause} uh , German case after {disfmarker} er well - matched Danish after we {disfmarker}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: the kind of numbers we 're getting are about eight or nine {pause} uh {pause} p percent {pause} error {pause} per digit .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor D&#10;Content: This is obviously not usable ,&#10;Speaker: PhD A&#10;Content: No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content" />
    <node id="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." />
    <node id="&#10;Content: Mmm . Yeah .&#10;Speaker: Professor D&#10;Content: Good , OK . So , um So , we 'll {disfmarker} we 'll hold off on that a little bit . I mean , even with these results as they are , it 's {disfmarker} it 's {disfmarker} it 's really not that bad . But {disfmarker} but , uh , um And it looks like the overall result as they are now , even without , you know , any {disfmarker} any bugs being fixed is that , uh , on the {disfmarker} the other tasks , we had this average of , uh , forty uh {disfmarker} nine percent , or so , improvement . And here we have somewhat better than that than the Danish , and somewhat worse than that on the German , but I mean , it sounds like , uh , one way or another , the methods that we 're doing can reduce the error rate from {disfmarker} from mel ceptrum {pause} down by , you know {pause} a fourth of them to , uh , a half of them . Somewhere in there , depending on the" />
    <node id="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." />
    <node id="aker: Professor D&#10;Content: So , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind the different languages , just having acoustic conditions rather than training them all up in one , would it be helpful to have different ones ? So , um That was a question that was kind of raised by Mike Shire 's thesis , and on {disfmarker} in that case in terms of reverberation . Right ? That {disfmarker} that sometimes it might be better to do that . But , um , {vocalsound} I don't think we know for sure . So , um Right . So , next week , we , uh , won't meet because you 'll be in Europe . Whe - when are you two getting back ?&#10;Speaker: PhD E&#10;Content: Um , I 'm&#10;Speaker: PhD A&#10;Content: You on Friday or S on Saturday or {pause} ?&#10;Speaker: PhD E&#10;Content: Sunday&#10;Speaker: PhD A&#10;Content: S oh yeah , Sunday , yeah .&#10;Speaker: PhD E&#10;Content: because it 's {disfmarker} it 's less expensive , the price {" />
    <node id=" Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Uh , so , yeah . I don't know if we can get some hand - labeled data from other languages .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It 's not so easy to find .&#10;Speaker: PhD C&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: But {pause} that would be something interesting t to {disfmarker} to see .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Also , uh , {vocalsound} I mean , there was just the whole notion of having multiple nets that were trained on different data . So one form of different data was {disfmarker} is from different languages , but the other Well , i in fact , uh , m in those experiments it wasn't so much combining multiple nets , it was a single net that had different&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind" />
    <node id="&#10;Speaker: PhD A&#10;Content: So , training is done {vocalsound} on different conditions and different microphones , and testing also is done {pause} on different microphone and conditions . So , probably if we only take the close microphones , {vocalsound} I guess the results should be much much better than this .&#10;Speaker: Professor D&#10;Content: I see .&#10;Speaker: PhD A&#10;Content: Mmm .&#10;Speaker: Professor D&#10;Content: Oh , OK ,&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: that explains it partially . Wha - what about i in {disfmarker} so the {disfmarker} the {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , so {disfmarker} there is this , the mismatched is , um {pause} the same kind of thing ,&#10;Speaker: Professor D&#10;Content: go ahead .&#10;Speaker: PhD A&#10;Content: but {pause} the driving conditions , I mean the speed and the kind of road , is different for training and testing , is that right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" />
    <node id=" A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's real noise condition . And , um , {vocalsound} the {disfmarker} the training {disfmarker} the training , I guess , is always done on the close talking&#10;Speaker: PhD A&#10;Content: No , actually {disfmarker} actually the well - matched condition {pause} is {pause} still quite di still quite difficult .&#10;Speaker: Professor D&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: I mean , it 's {disfmarker} they have all these data from the close mike and from the distant mike , {vocalsound} from different driving condition , open window , closed window ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: and they take all of this and they take seventy percent , I think , for training and thirty percent for testing .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: So , training is done {vocalsound} on different conditions and different microphones , and testing also is done {" />
    <node id="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet." />
    <node id="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." />
    <node id=" best single numbers , {vocalsound} it was just {disfmarker} you know , it wasn't good enough for {disfmarker} for {pause} a {disfmarker} a {disfmarker} for a real system .&#10;Speaker: PhD A&#10;Content: Mmm . Mm - hmm .&#10;Speaker: Professor D&#10;Content: You {disfmarker} you {disfmarker} you , {vocalsound} um So , uh , we still have stuff to do .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , and , uh I don't know So , looking at the data , where , you know {disfmarker} what 's the {disfmarker} what 's {disfmarker} what 's th what 's characteristic i e yeah , I think that 's {disfmarker} that 's a good thing . Does a any you have any thoughts about what else {vocalsound} y you 're thinking that you didn't get to that you would like to do if you had more time ? Uh&#10;Speaker: PhD E" />
    <node id="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work." />
    <node id=" Sunday , yeah .&#10;Speaker: PhD E&#10;Content: because it 's {disfmarker} it 's less expensive , the price {disfmarker} the price the ticket .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor D&#10;Content: Yeah , that 's right . You 've gotta S have a Saturday overnight , right ?&#10;Speaker: PhD A&#10;Content: I 'll be back on Tuesday .&#10;Speaker: Professor D&#10;Content: Tuesday .&#10;Speaker: PhD C&#10;Content: Where {disfmarker} where 's the meeting ?&#10;Speaker: Professor D&#10;Content: Uh , Amsterdam , I think , yeah ?&#10;Speaker: PhD A&#10;Content: Yeah , Amsterdam .&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah , yeah . Yep . Um {pause} So , we 'll skip next week , and we 'll meet two weeks from now . And , uh , I guess the main topic will be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah ." />
    <node id=" the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably the day after they leave , but we 'll have to {disfmarker} {vocalsound} we 'll have to stop it the day before {comment} we leave .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . So&#10;Speaker: PhD C&#10;Content: Huh .&#10;Speaker: Professor D&#10;Content: I think tha I think the {disfmarker} the meeting is on the thirteenth or something .&#10;Speaker: PhD A&#10;Content: Yeah , this Tuesday , yeah .&#10;Speaker: Professor D&#10;Content: And , uh , they , uh Right . And the {disfmarker} the , uh , results are due like the day before the meeting or something . So&#10;Speaker: PhD A&#10;Content: Yeah , probably , well&#10;Speaker: Professor D&#10;Content: I th I think {disfmarker} I I think they are ,&#10;Speaker: PhD A&#10;Content: Yeah , well&#10;Speaker: Professor D&#10;Content: yeah . So {pause} {vocals" />
    <node id="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800." />
    <node id=" in the modulation spectrum , which allows us to downsample . So , uh , as a result of that we have a reduced , um , transmission rate for the bits .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: That was misreported the first time out . It {disfmarker} it said the same amount because for convenience sake in the particular way that this is being tested , uh , they were repeating the packets . So it was {disfmarker} they were s they {disfmarker} they had twenty - four hundred bits per second , but they were literally creating forty - eight hundred bits per second , {vocalsound} um , even though y it was just repeated .&#10;Speaker: PhD C&#10;Content: Oh . Mm - hmm . Right .&#10;Speaker: Professor D&#10;Content: So , uh , in practice&#10;Speaker: PhD C&#10;Content: So you could 've had a repeat count in there or something .&#10;Speaker: Professor D&#10;Content: Well , n I mean , this was just a ph phoney thing just to {disfmarker} to fit into the {disfmarker}" />
    <node id="s being real conscious of how much memory and how much CPU they 're using&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: because these , {vocalsound} {vocalsound} {vocalsound} uh , standards are supposed to go on cell phones with m moderate resources in both respects .&#10;Speaker: PhD C&#10;Content: Did anybody , uh , do anything with the models as a {disfmarker} an experiment ? Or&#10;Speaker: Professor D&#10;Content: Uh , they didn't report it , if they did .&#10;Speaker: PhD C&#10;Content: N nobody reported it ?&#10;Speaker: Professor D&#10;Content: Yeah . I think everybody was focused elsewhere . Um , now , one of the things that 's nice about what we did is , we do have a {disfmarker} a , uh {disfmarker} a filtering , which leads to a {disfmarker} a , uh {disfmarker} a reduction in the bandwidth in the modulation spectrum , which allows us to downsample . So , uh , as a result of that we have a reduced , um , transmission rate for the" />
    <node id="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." />
    <node id="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript." />
    <node id="marker} just in computer time is just a day or so , right ?&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: So&#10;Speaker: PhD A&#10;Content: it 's very short interval .&#10;Speaker: Professor D&#10;Content: yeah . So , I think the who the whole reason for having as long as we have , which was {pause} like a week and a half , is {disfmarker} is because of bugs like that . So Huh So , we 're gonna end up with these same kind of sheets that have the {pause} the percentages and so on just for the {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , so there are two more columns in the sheets ,&#10;Speaker: Professor D&#10;Content: Oh , I guess it 's the same sheets ,&#10;Speaker: PhD A&#10;Content: two . Yeah , it 's the same sheets ,&#10;Speaker: Professor D&#10;Content: yeah , yeah {disfmarker}&#10;Speaker: PhD A&#10;Content: yeah .&#10;Speaker: Professor D&#10;Content: just with the missing columns filled in .&#10;Speaker: PhD A" />
    <node id=" are ,&#10;Speaker: PhD A&#10;Content: Yeah , well&#10;Speaker: Professor D&#10;Content: yeah . So {pause} {vocalsound} um , since we have a bit farther to travel than {vocalsound} some of the others , {vocalsound} uh , we 'll have to get done a little quicker . But , um , I mean , it 's just tracing down these bugs . I mean , just exactly this sort of thing of , you know , why {disfmarker} why these features seem to be behaving differently , uh , in California than in Oregon .&#10;Speaker: PhD C&#10;Content:  Hmm .&#10;Speaker: Professor D&#10;Content: Might have something to do with electricity shortage . Uh , we didn't {disfmarker} we didn't have enough electrons here and Uh , but , um Uh , I think , you know , the main reason for having {disfmarker} I mean , it only takes w to run the {disfmarker} the two test sets in {disfmarker} just in computer time is just a day or so , right ?&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor" />
    <node id="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications." />
    <node id="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features." />
    <node id=" we 're interested in . Kind of inspired by the stuff by Larry Saul with the , uh {pause} uh , learning articulatory feature in {disfmarker} I think , in the case of his paper {disfmarker} with sonorance based on , uh , multi - band information where you have a {disfmarker} a combination of gradient learning an and , uh , EM .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Um , and {pause} {vocalsound} {vocalsound} Um , so , I think that , you know , this is a , uh {disfmarker} this is a neat data set . Um , and then , uh , as we mentioned before , we also have the {disfmarker} the new , uh , digit set coming up from recordings in this room . So , there 's a lot of things to work with . Um and , uh what I like about it , in a way , is that , uh , the results are still so terrible . Uh {pause} {vocalsound} Uh {pause} {vocalsound} I mean , they 're much better" />
    <node id=" {disfmarker} but there 're {disfmarker} there 're {disfmarker} there 're some other differences , too . Uh , and {disfmarker} and , uh , they both did very well ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: you know ? So , {vocalsound} um , my impression is they also did very well on {disfmarker} on the {disfmarker} the , uh , evaluation set , but , um , I {disfmarker} I we haven't seen {disfmarker} you 've - you haven't seen any final results for that&#10;Speaker: PhD C&#10;Content: And they used {disfmarker} the main thing that {disfmarker} that they used was spectral subtraction ?&#10;Speaker: Professor D&#10;Content: yeah .&#10;Speaker: PhD C&#10;Content: Or&#10;Speaker: Professor D&#10;Content: There is a couple pieces to it . There 's a spectral subtraction style piece {disfmarker} it was basically , you know , Wiener filtering . And then {d" />
    <node id="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development." />
    <node id="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages." />
    <node id=" Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing that , uh , we were thin thinking {disfmarker} thinking that it would work , but it didn't work . And , eh , so there is kind of {disfmarker} of {pause} not a bug , but something wrong in what we are doing , perhaps .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Right . Right .&#10;Speaker: PhD A&#10;Content: Uh , something wrong , perhaps in the {disfmarker} just in the {disfmarker} the fact that the labels are {disfmarker}&#10;Speaker: PhD C&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: well&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: What worked best is the hand - labeled data .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Uh , so , yeah . I don't know if we can get some hand" />
    <node id="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language." />
    <node id=" the {disfmarker} the ICSI OGI one .&#10;Speaker: PhD A&#10;Content: Oh yeah .&#10;Speaker: Professor D&#10;Content: So {pause} um , I wan wanna {disfmarker} wanna see what that is . But , uh , you know , so we 'll see what it is comparatively later . But {pause} it looks like , um&#10;Speaker: PhD A&#10;Content: M yeah .&#10;Speaker: Professor D&#10;Content: You know most of the time , even {disfmarker} I mean even though it 's true that the overall number for Danish {disfmarker} we didn't improve it If you look at it individually , what it really says is that there 's , um , uh Looks like out of the six cases , between the different kinds of , uh , matching conditions {pause} out of the six cases , there 's basically , um , a couple where it stays about the same , uh , three where it gets better , and one where it gets worse .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content" />
    <node id="Speaker: Professor D&#10;Content: OK . So , uh You can fill those out , uh {pause} after , actually , so So , I got , uh {pause} these results from , uh , Stephane . Also , um , I think that , uh {pause} um {pause} we might hear later today , about other results . I think s that , uh , there were some other very good results that we 're gonna wanna compare to . But , {vocalsound} r our results from other {disfmarker} other places , yeah .&#10;Speaker: PhD A&#10;Content: I I 'm sorry ? I didn't&#10;Speaker: Professor D&#10;Content: Um , I got this from you&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: and then I sent a note to Sunil about the {disfmarker} cuz he has been running some other systems&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: other than the {disfmarker} the ICSI OGI one .&#10;Speaker: PhD A&#10;Content: Oh yeah .&#10;Speaker: Professor" />
    <node id="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish." />
    <node id="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech." />
    <node id="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;" />
    <node id=" A&#10;Content: Hmm ?&#10;Speaker: Professor D&#10;Content: We have a little bit of time on that , actually .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: We have a day or so , so When {disfmarker} when {disfmarker} when do you folks leave ?&#10;Speaker: PhD A&#10;Content: Uh , Sunday .&#10;Speaker: Professor D&#10;Content: Sunday ? So So , uh Yeah , until Saturday midnight , or something , we have W we {disfmarker} we have time , yeah . Well , that would be good . That 'd be good .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Uh , and , you know , i u when whenever anybody figures it out they should also , for sure , email Hynek because Hynek will be over there {vocalsound} telling people {vocalsound} what we did , so he should know .&#10;Speaker: PhD A&#10;Content: Mmm . Yeah .&#10;Speaker: Professor D&#10;Content: Good , OK . So , um So , we 'll {disf" />
    <node id="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes." />
    <node id="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment." />
    <node id="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer." />
    <node id="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary." />
    <node id="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling." />
    <node id=" results are still so terrible . Uh {pause} {vocalsound} Uh {pause} {vocalsound} I mean , they 're much better than they were , you know . We 're talking about thirty to sixty percent , uh , error rate reduction . That 's {disfmarker} that 's really great stuff to {disfmarker} to do that in relatively short time . But even after that it 's still , you know , so poor that {disfmarker} that , uh , no one could really use it . So , um I think that 's great that {disfmarker} because {disfmarker} and y also because again , it 's not something {disfmarker} sometimes we 've gotten terrible results by taking some data , and artificially , you know , convolving it with some room response , or something {disfmarker} we take a very {disfmarker} Uh , at one point , uh , Brian and I went downstairs into the {disfmarker} the basement where it was {disfmarker} it was in a hallway where it was very reverberant and we {disfmarker} we made some recordings" />
    <node id=" so on and n n And , uh , uh , with something that 's still relatively realistic , it 's still very very hard to do very well . So Yeah .&#10;Speaker: PhD A&#10;Content: Yeah , so d well Actually , this is {disfmarker} tha that 's why we {disfmarker} well , it 's a different kind of data . We 're not {disfmarker} we 're not used to work with this kind of data . That 's why we should have a loo more closer look at what 's going on .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Yeah . So this would be the first thing , and then , of course , try to {disfmarker} well , {vocalsound} kind of debug what was wrong , eh , when we do Aurora test on the MSG {pause} particularly , and on the multi - band .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah" />
    <node id="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency." />
    <node id="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems." />
    <node id="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." />
    <node id="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions." />
    <node id=" it . There 's a spectral subtraction style piece {disfmarker} it was basically , you know , Wiener filtering . And then {disfmarker} then there was some p some modification of the cepstral parameters , where they {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , actually , something that 's close to cepstral mean subtraction . But , uh , the way the mean is adapted {disfmarker} um , it 's signal dependent . I 'm {disfmarker} I 'm , uh So , basically , the mean is adapted during speech and not during silence .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: But it 's very close to {disfmarker} to cepstral mean subtraction .&#10;Speaker: Professor D&#10;Content: But some people have done {vocalsound} {pause} exactly that sort of thing , of {disfmarker} of {disfmarker} and the {disfmarker} I mean it 's not {disfmarker} To {disfmarker} to look in {pause}" />
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target=" , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here 's a number of things that could be done . &quot; So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one {disfmarker} one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and {disfmarker} and CPU it takes , but it seems like the filtering {pause} Uh , I mean , the VAD stuff they both had , right ? And , um , so {disfmarker} and they both had some kind of on - line normalization , right ?&#10;Speaker: PhD A&#10;Content: Uh , yeah .&#10;Speaker: Professor D&#10;Content: Of sorts , yeah ? So {disfmarker} so , it seems like the main different there is the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="s probably a good time to look at what 's really going on and seeing if there 's a {disfmarker} there 's a way to combine the best ideas while at the same time not blowing up the amount of , uh , resources used , cuz that 's {disfmarker} that 's critical for this {disfmarker} this test .&#10;Speaker: PhD C&#10;Content: Do we know anything about {disfmarker} who {disfmarker} who 's was it that had the lowest on the dev set ?&#10;Speaker: Professor D&#10;Content: Um , uh , the , uh , the there were two systems that were put forth by a combination of {disfmarker} of , uh , French Telecom and Alcatel . And , um they {disfmarker} they differed in some respects , but they e em one was called the French Telecom Alcatel System the other was called the Alcatel French Telecom System , {vocalsound} uh , which is the biggest difference , I think . But {disfmarker} but there 're {disfmarker} there 're {disfmarker} there 're some other differences ,">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="aker: PhD A&#10;Content: yeah .&#10;Speaker: Professor D&#10;Content: just with the missing columns filled in .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Well , that 'll be good . So , I 'll dis I 'll disregard these numbers . That 's {disfmarker} that 's {disfmarker} that 's good .&#10;Speaker: PhD A&#10;Content: So , Hynek will try to push for trying to combine , uh , different things ? Or Hmm ?&#10;Speaker: Professor D&#10;Content: Uh , well that 's {pause} um yeah I mean , I think the question is &quot; Is there {disfmarker} is there some advantage ? &quot; I mean , you could just take the best system and say that 's the standard . But the thing is that if different systems are getting at good things , um , a again within the constraint of the resources , if there 's something simple that you can do Now for instance , uh , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target=" the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmarker} shouldn't take a lot of memory to do that Uh , and I also wouldn't think the CPU , uh , would be much either for that part . So , if you can {disfmarker} if you can add those in {pause} um {pause} then , uh , you can cut the data rate in half .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So it seems like the right thing to do is to {disfmarker} on the {disfmarker} on the terminal 's side , take what they did , if it {disfmarker} if it does seem to generalize well to German and Danish , uh , take what they did add in a filter , and add in some stuff on the server 's side and {disfmarker} and {disfmarker} and that 's probably a reasonable standard . Um {pause} Uh&#10;Speaker: PhD A&#10;Content: They are working on this already ? Because {disfmarker} yeah , Su">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target=" a different car , and so on . So it 's {disfmarker} this is a an optim somewhat optimistic view on it , uh , so , you know , the real thing is somewhere in between the two .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , uh , but&#10;Speaker: PhD A&#10;Content: But the {disfmarker} I mean , the {pause} th th&#10;Speaker: Professor D&#10;Content: Even the optimistic one is&#10;Speaker: PhD A&#10;Content: it doesn't work .&#10;Speaker: Professor D&#10;Content: Yeah ,&#10;Speaker: PhD A&#10;Content: It {disfmarker}&#10;Speaker: Professor D&#10;Content: right . Right , it doesn't work . So , in a way , that 's , you know , that 's sort of the dominant thing is that even , say on the development set stuff that we saw , the , uh , the numbers that , uh , that Alcatel was getting when choosing out the best single numbers , {vocalsound} it was just {disfmarker} you know , it wasn't good enough for {disfmarker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target=" Well , n I mean , this was just a ph phoney thing just to {disfmarker} to fit into the {disfmarker} the software that was testing the errors {disfmarker} channel errors and so on .&#10;Speaker: PhD C&#10;Content: Oh . Oh .&#10;Speaker: Professor D&#10;Content: So {disfmarker} so in reality , if you put this {disfmarker} this system in into , uh , the field , it would be twenty - four hundred bits per second , not forty - eight hundred . So , um , so that 's a nice feature of what {disfmarker} what we did . Um , but , um , well , we still have to see how it all comes out .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: Um , and then there 's the whole standards process , which is another thing altogether .&#10;Speaker: PhD C&#10;Content: When is the development set {disfmarker} I mean , the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filtering method: The speaker mentions that there is a difference in the filtering method used by the systems presented by French Telecom and Alcatel on the terminal side. They suggest examining whether these differences can be combined to create a more effective standard while also not increasing resource usage significantly.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD (Voice Activity Detection) methods. This implies that any changes or additions to the filtering method should be evaluated based on their resource usage.&#10;&#10;3. Data rate reduction: One of the potential benefits of incorporating these changes is a reduction in data rate by half, which could improve the overall performance and efficiency of the system.&#10;&#10;However, there are some challenges mentioned during the conversation as well:&#10;&#10;1. Compatibility with German and Danish languages: The proposed filtering method should be tested to ensure it generalizes well to other languages like German and Danish.&#10;&#10;2. Real-world performance: The real-world performance of this new combined standard may not match the optimistic projections, so a more realistic assessment is needed.&#10;&#10;3. Standards process: Finally, any changes to the existing standard would need to go through the standards approval process before being implemented.&#10;&#10;In conclusion, the primary difference on the terminal side lies in the filtering method used by French Telecom and Alcatel systems. Combining the best aspects of these methods while minimizing resource usage could lead to improved overall functionality, potentially cutting data rate in half. However, compatibility with other languages, real-world performance, and adherence to standards approval processes should also be taken into consideration before implementing any changes." target="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here 's a number of things that could be done . &quot; So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one {disfmarker} one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and {disfmarker} and CPU it takes , but it seems like the filtering {pause} Uh , I mean , the VAD stuff they both had , right ? And , um , so {disfmarker} and they both had some kind of on - line normalization , right ?&#10;Speaker: PhD A&#10;Content: Uh , yeah .&#10;Speaker: Professor D&#10;Content: Of sorts , yeah ? So {disfmarker} so , it seems like the main different there is the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmark" target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here 's a number of things that could be done . &quot; So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one {disfmarker} one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and {disfmarker} and CPU it takes , but it seems like the filtering {pause} Uh , I mean , the VAD stuff they both had , right ? And , um , so {disfmarker} and they both had some kind of on - line normalization , right ?&#10;Speaker: PhD A&#10;Content: Uh , yeah .&#10;Speaker: Professor D&#10;Content: Of sorts , yeah ? So {disfmarker} so , it seems like the main different there is the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmark" target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here 's a number of things that could be done . &quot; So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one {disfmarker} one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and {disfmarker} and CPU it takes , but it seems like the filtering {pause} Uh , I mean , the VAD stuff they both had , right ? And , um , so {disfmarker} and they both had some kind of on - line normalization , right ?&#10;Speaker: PhD A&#10;Content: Uh , yeah .&#10;Speaker: Professor D&#10;Content: Of sorts , yeah ? So {disfmarker} so , it seems like the main different there is the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmark" target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary.">
      <data key="d0">1</data>
    </edge>
    <edge source=" , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here 's a number of things that could be done . &quot; So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one {disfmarker} one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and {disfmarker} and CPU it takes , but it seems like the filtering {pause} Uh , I mean , the VAD stuff they both had , right ? And , um , so {disfmarker} and they both had some kind of on - line normalization , right ?&#10;Speaker: PhD A&#10;Content: Uh , yeah .&#10;Speaker: Professor D&#10;Content: Of sorts , yeah ? So {disfmarker} so , it seems like the main different there is the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmark" target="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency.">
      <data key="d0">1</data>
    </edge>
    <edge source="s probably a good time to look at what 's really going on and seeing if there 's a {disfmarker} there 's a way to combine the best ideas while at the same time not blowing up the amount of , uh , resources used , cuz that 's {disfmarker} that 's critical for this {disfmarker} this test .&#10;Speaker: PhD C&#10;Content: Do we know anything about {disfmarker} who {disfmarker} who 's was it that had the lowest on the dev set ?&#10;Speaker: Professor D&#10;Content: Um , uh , the , uh , the there were two systems that were put forth by a combination of {disfmarker} of , uh , French Telecom and Alcatel . And , um they {disfmarker} they differed in some respects , but they e em one was called the French Telecom Alcatel System the other was called the Alcatel French Telecom System , {vocalsound} uh , which is the biggest difference , I think . But {disfmarker} but there 're {disfmarker} there 're {disfmarker} there 're some other differences ," target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="s probably a good time to look at what 's really going on and seeing if there 's a {disfmarker} there 's a way to combine the best ideas while at the same time not blowing up the amount of , uh , resources used , cuz that 's {disfmarker} that 's critical for this {disfmarker} this test .&#10;Speaker: PhD C&#10;Content: Do we know anything about {disfmarker} who {disfmarker} who 's was it that had the lowest on the dev set ?&#10;Speaker: Professor D&#10;Content: Um , uh , the , uh , the there were two systems that were put forth by a combination of {disfmarker} of , uh , French Telecom and Alcatel . And , um they {disfmarker} they differed in some respects , but they e em one was called the French Telecom Alcatel System the other was called the Alcatel French Telecom System , {vocalsound} uh , which is the biggest difference , I think . But {disfmarker} but there 're {disfmarker} there 're {disfmarker} there 're some other differences ," target="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD A&#10;Content: yeah .&#10;Speaker: Professor D&#10;Content: just with the missing columns filled in .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Well , that 'll be good . So , I 'll dis I 'll disregard these numbers . That 's {disfmarker} that 's {disfmarker} that 's good .&#10;Speaker: PhD A&#10;Content: So , Hynek will try to push for trying to combine , uh , different things ? Or Hmm ?&#10;Speaker: Professor D&#10;Content: Uh , well that 's {pause} um yeah I mean , I think the question is &quot; Is there {disfmarker} is there some advantage ? &quot; I mean , you could just take the best system and say that 's the standard . But the thing is that if different systems are getting at good things , um , a again within the constraint of the resources , if there 's something simple that you can do Now for instance , uh , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here" target="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD A&#10;Content: yeah .&#10;Speaker: Professor D&#10;Content: just with the missing columns filled in .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Well , that 'll be good . So , I 'll dis I 'll disregard these numbers . That 's {disfmarker} that 's {disfmarker} that 's good .&#10;Speaker: PhD A&#10;Content: So , Hynek will try to push for trying to combine , uh , different things ? Or Hmm ?&#10;Speaker: Professor D&#10;Content: Uh , well that 's {pause} um yeah I mean , I think the question is &quot; Is there {disfmarker} is there some advantage ? &quot; I mean , you could just take the best system and say that 's the standard . But the thing is that if different systems are getting at good things , um , a again within the constraint of the resources , if there 's something simple that you can do Now for instance , uh , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , &quot; Here" target="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmarker} shouldn't take a lot of memory to do that Uh , and I also wouldn't think the CPU , uh , would be much either for that part . So , if you can {disfmarker} if you can add those in {pause} um {pause} then , uh , you can cut the data rate in half .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So it seems like the right thing to do is to {disfmarker} on the {disfmarker} on the terminal 's side , take what they did , if it {disfmarker} if it does seem to generalize well to German and Danish , uh , take what they did add in a filter , and add in some stuff on the server 's side and {disfmarker} and {disfmarker} and that 's probably a reasonable standard . Um {pause} Uh&#10;Speaker: PhD A&#10;Content: They are working on this already ? Because {disfmarker} yeah , Su" target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the {disfmarker} is the , uh , filtering . And the filtering {disfmarker} I think if you can {disfmarker} shouldn't take a lot of memory to do that Uh , and I also wouldn't think the CPU , uh , would be much either for that part . So , if you can {disfmarker} if you can add those in {pause} um {pause} then , uh , you can cut the data rate in half .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So it seems like the right thing to do is to {disfmarker} on the {disfmarker} on the terminal 's side , take what they did , if it {disfmarker} if it does seem to generalize well to German and Danish , uh , take what they did add in a filter , and add in some stuff on the server 's side and {disfmarker} and {disfmarker} and that 's probably a reasonable standard . Um {pause} Uh&#10;Speaker: PhD A&#10;Content: They are working on this already ? Because {disfmarker} yeah , Su" target="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency.">
      <data key="d0">1</data>
    </edge>
    <edge source=" a different car , and so on . So it 's {disfmarker} this is a an optim somewhat optimistic view on it , uh , so , you know , the real thing is somewhere in between the two .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , uh , but&#10;Speaker: PhD A&#10;Content: But the {disfmarker} I mean , the {pause} th th&#10;Speaker: Professor D&#10;Content: Even the optimistic one is&#10;Speaker: PhD A&#10;Content: it doesn't work .&#10;Speaker: Professor D&#10;Content: Yeah ,&#10;Speaker: PhD A&#10;Content: It {disfmarker}&#10;Speaker: Professor D&#10;Content: right . Right , it doesn't work . So , in a way , that 's , you know , that 's sort of the dominant thing is that even , say on the development set stuff that we saw , the , uh , the numbers that , uh , that Alcatel was getting when choosing out the best single numbers , {vocalsound} it was just {disfmarker} you know , it wasn't good enough for {disfmarker" target="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Well , n I mean , this was just a ph phoney thing just to {disfmarker} to fit into the {disfmarker} the software that was testing the errors {disfmarker} channel errors and so on .&#10;Speaker: PhD C&#10;Content: Oh . Oh .&#10;Speaker: Professor D&#10;Content: So {disfmarker} so in reality , if you put this {disfmarker} this system in into , uh , the field , it would be twenty - four hundred bits per second , not forty - eight hundred . So , um , so that 's a nice feature of what {disfmarker} what we did . Um , but , um , well , we still have to see how it all comes out .&#10;Speaker: PhD C&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: Um , and then there 's the whole standards process , which is another thing altogether .&#10;Speaker: PhD C&#10;Content: When is the development set {disfmarker} I mean , the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably" target="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target=" particular standards process once you {disfmarker} you go to this meeting . So , be interested in hearing . So , uh , I 'd be , uh , interested in hearing , uh , your thoughts now I mean you 're almost done . I mean , you 're done in the sense that , um , you may be able to get some new features from Sunil , and we 'll re - run it . Uh , but other than that , you 're {disfmarker} you 're basically done , right ? So , uh , I 'm interested in hearing {disfmarker} hearing your thoughts about {pause} where you think we should go from this .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: I mean , we tried a lot of things in a hurry , and , uh , if we can back off from this now and sort of take our time with something , and not have doing things quickly be quite so much the constraint , what {disfmarker} what you think would be the best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target=" be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , so Yeah , well , if we don't have an anything else to discuss , we should , uh , turn off the machine and then say the real nasty things .&#10;Speaker: PhD C&#10;Content: Should we do digits first ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Oh , yeah , digits .&#10;Speaker: Professor D&#10;Content: Oh yeah , digits ! Yeah . Good point . Yeah , good thinking . Why don't you go ahead .&#10;Speaker: PhD C&#10;Content: OK . OK .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target=" the best system than ours ?&#10;Speaker: Professor D&#10;Content: So Well , we don't know yet .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor D&#10;Content: Uh , I mean , first place , there 's still this thing to {disfmarker} to work out , and second place {disfmarker} second thing is that the only results that we have so far from before were really development set results .&#10;Speaker: PhD C&#10;Content: Oh , OK .&#10;Speaker: Professor D&#10;Content: So , I think in this community that 's of interest . It 's not like everything is being pinned on the evaluation set . But , um , for the development set , our best result was a little bit short of fifty percent . And the best result of any system was about fifty - four , where these numbers are the , uh , relative , uh , reduction in , uh , word error rate .&#10;Speaker: PhD C&#10;Content: Oh , OK .&#10;Speaker: Professor D&#10;Content: And , um , the other systems were , uh , somewhat lower than that . There was actually {disfmarker} there was much less of a">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="rum {pause} down by , you know {pause} a fourth of them to , uh , a half of them . Somewhere in there , depending on the {pause} exact case . So So that 's good . I mean , I think that , uh , one of the things that Hynek was talking about was understanding what was in the other really good proposals and {disfmarker} and trying to see if what should ultimately be proposed is some , uh , combination of things . Um , if , uh {disfmarker} Cuz there 's things that they are doing {pause} there that we certainly are not doing . And there 's things that we 're doing that {pause} they 're not doing . And {disfmarker} and they all seem like good things .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So&#10;Speaker: PhD E&#10;Content: Mmm , yeah .&#10;Speaker: PhD C&#10;Content: How much {disfmarker} how much better was the best system than ours ?&#10;Speaker: Professor D&#10;Content: So Well , we don't know yet .&#10;Speaker: PhD C&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content: Y Actually , uh , um , for the Danish , there 's still some kind of mystery because , um , um , when we use the straight features , we are not able to get these nice number with the ICSI OGI one , I mean . We don't have this ninety - three seventy - eight , we have eight&#10;Speaker: PhD E&#10;Content: Eighty - nine forty - four .&#10;Speaker: PhD A&#10;Content: yeah . Uh , so , uh , that 's probably something wrong with the features that we get from OGI . Uh , and Sunil is working on {disfmarker} on trying to {disfmarker} to check everything .&#10;Speaker: Professor D&#10;Content: Oh , and {disfmarker} and we have a little time on that {disfmarker} and {disfmarker} actually so&#10;Speaker: PhD A&#10;Content: Hmm ?&#10;Speaker: Professor D&#10;Content: We have a little bit of time on that , actually .&#10;Speaker: PhD">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Thoroughly examine the filtering method differences between French Telecom and Alcatel systems to potentially create a more effective standard with minimal resource usage increase. This could lead to a data rate reduction by half, improving overall system performance and efficiency.&#10;&#10;2. Take time to consider new features and ideas without rushing, as there is no constraint for quick decisions now.&#10;&#10;3. Test the compatibility of any changes with other languages like German and Danish.&#10;&#10;4. Assess the real-world performance of any proposed changes to ensure they meet or exceed expectations.&#10;&#10;5. Consider combining elements from different successful proposals in the community, as some systems may have unique features that could improve overall performance when combined.&#10;&#10;6. Address issues with Danish language processing using OGI features and allow time for further investigation into this matter." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary.">
      <data key="d0">1</data>
    </edge>
    <edge source=" particular standards process once you {disfmarker} you go to this meeting . So , be interested in hearing . So , uh , I 'd be , uh , interested in hearing , uh , your thoughts now I mean you 're almost done . I mean , you 're done in the sense that , um , you may be able to get some new features from Sunil , and we 'll re - run it . Uh , but other than that , you 're {disfmarker} you 're basically done , right ? So , uh , I 'm interested in hearing {disfmarker} hearing your thoughts about {pause} where you think we should go from this .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: I mean , we tried a lot of things in a hurry , and , uh , if we can back off from this now and sort of take our time with something , and not have doing things quickly be quite so much the constraint , what {disfmarker} what you think would be the best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {d" target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work.">
      <data key="d0">1</data>
    </edge>
    <edge source=" particular standards process once you {disfmarker} you go to this meeting . So , be interested in hearing . So , uh , I 'd be , uh , interested in hearing , uh , your thoughts now I mean you 're almost done . I mean , you 're done in the sense that , um , you may be able to get some new features from Sunil , and we 'll re - run it . Uh , but other than that , you 're {disfmarker} you 're basically done , right ? So , uh , I 'm interested in hearing {disfmarker} hearing your thoughts about {pause} where you think we should go from this .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: I mean , we tried a lot of things in a hurry , and , uh , if we can back off from this now and sort of take our time with something , and not have doing things quickly be quite so much the constraint , what {disfmarker} what you think would be the best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {d" target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development.">
      <data key="d0">1</data>
    </edge>
    <edge source=" be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , so Yeah , well , if we don't have an anything else to discuss , we should , uh , turn off the machine and then say the real nasty things .&#10;Speaker: PhD C&#10;Content: Should we do digits first ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Oh , yeah , digits .&#10;Speaker: Professor D&#10;Content: Oh yeah , digits ! Yeah . Good point . Yeah , good thinking . Why don't you go ahead .&#10;Speaker: PhD C&#10;Content: OK . OK ." target="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable.">
      <data key="d0">1</data>
    </edge>
    <edge source=" be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , so Yeah , well , if we don't have an anything else to discuss , we should , uh , turn off the machine and then say the real nasty things .&#10;Speaker: PhD C&#10;Content: Should we do digits first ?&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Oh , yeah , digits .&#10;Speaker: Professor D&#10;Content: Oh yeah , digits ! Yeah . Good point . Yeah , good thinking . Why don't you go ahead .&#10;Speaker: PhD C&#10;Content: OK . OK ." target="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the best system than ours ?&#10;Speaker: Professor D&#10;Content: So Well , we don't know yet .&#10;Speaker: PhD C&#10;Content: Mmm .&#10;Speaker: Professor D&#10;Content: Uh , I mean , first place , there 's still this thing to {disfmarker} to work out , and second place {disfmarker} second thing is that the only results that we have so far from before were really development set results .&#10;Speaker: PhD C&#10;Content: Oh , OK .&#10;Speaker: Professor D&#10;Content: So , I think in this community that 's of interest . It 's not like everything is being pinned on the evaluation set . But , um , for the development set , our best result was a little bit short of fifty percent . And the best result of any system was about fifty - four , where these numbers are the , uh , relative , uh , reduction in , uh , word error rate .&#10;Speaker: PhD C&#10;Content: Oh , OK .&#10;Speaker: Professor D&#10;Content: And , um , the other systems were , uh , somewhat lower than that . There was actually {disfmarker} there was much less of a" target="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="rum {pause} down by , you know {pause} a fourth of them to , uh , a half of them . Somewhere in there , depending on the {pause} exact case . So So that 's good . I mean , I think that , uh , one of the things that Hynek was talking about was understanding what was in the other really good proposals and {disfmarker} and trying to see if what should ultimately be proposed is some , uh , combination of things . Um , if , uh {disfmarker} Cuz there 's things that they are doing {pause} there that we certainly are not doing . And there 's things that we 're doing that {pause} they 're not doing . And {disfmarker} and they all seem like good things .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So&#10;Speaker: PhD E&#10;Content: Mmm , yeah .&#10;Speaker: PhD C&#10;Content: How much {disfmarker} how much better was the best system than ours ?&#10;Speaker: Professor D&#10;Content: So Well , we don't know yet .&#10;Speaker: PhD C&#10;Content" target="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content: Y Actually , uh , um , for the Danish , there 's still some kind of mystery because , um , um , when we use the straight features , we are not able to get these nice number with the ICSI OGI one , I mean . We don't have this ninety - three seventy - eight , we have eight&#10;Speaker: PhD E&#10;Content: Eighty - nine forty - four .&#10;Speaker: PhD A&#10;Content: yeah . Uh , so , uh , that 's probably something wrong with the features that we get from OGI . Uh , and Sunil is working on {disfmarker} on trying to {disfmarker} to check everything .&#10;Speaker: Professor D&#10;Content: Oh , and {disfmarker} and we have a little time on that {disfmarker} and {disfmarker} actually so&#10;Speaker: PhD A&#10;Content: Hmm ?&#10;Speaker: Professor D&#10;Content: We have a little bit of time on that , actually .&#10;Speaker: PhD" target="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content: Y Actually , uh , um , for the Danish , there 's still some kind of mystery because , um , um , when we use the straight features , we are not able to get these nice number with the ICSI OGI one , I mean . We don't have this ninety - three seventy - eight , we have eight&#10;Speaker: PhD E&#10;Content: Eighty - nine forty - four .&#10;Speaker: PhD A&#10;Content: yeah . Uh , so , uh , that 's probably something wrong with the features that we get from OGI . Uh , and Sunil is working on {disfmarker} on trying to {disfmarker} to check everything .&#10;Speaker: Professor D&#10;Content: Oh , and {disfmarker} and we have a little time on that {disfmarker} and {disfmarker} actually so&#10;Speaker: PhD A&#10;Content: Hmm ?&#10;Speaker: Professor D&#10;Content: We have a little bit of time on that , actually .&#10;Speaker: PhD" target="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target=" No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content: I mean , if you have ten digits for a phone number {comment} I mean , every now and then you 'll get it right . I mean , it 's {disfmarker} it 's , uh , {vocalsound} um So , I mean , the other thing is that , uh {disfmarker} And {disfmarker} and {disfmarker} a and {disfmarker} and also , um {pause} part of what 's nice about this is that this is , uh , {vocalsound} um {pause} a realistic {disfmarker} almost realistic database . I mean , it 's still not people who are really trying to accomplish something , but {disfmarker} but , uh , within the artificial setup , it isn't noise artificially added , you know , simulated , uh , additive noise .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's real noise condition . And , um , {voc">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target=" where it was {disfmarker} it was in a hallway where it was very reverberant and we {disfmarker} we made some recordings there . And then we {vocalsound} {disfmarker} we , uh {disfmarker} uh , made a simulation of the {disfmarker} of the room acoustics there and {disfmarker} and applied it to other things ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: and uh But it was all pretty artificial , and {disfmarker} and , you know , how often would you really try to have your most crucial conversations in this very reverberant hallway ? Um {pause} So , uh {pause} This is what 's nice about the Aurora data and the data here , is that {disfmarker} is that it 's sort of a realistic room situation {pause} uh , acoustics {disfmarker} acoustic situation , both terms in noise and reflections , and so on and n n And , uh , uh , with something that 's still relatively realistic , it 's still very very hard to do very well .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target=" best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {disfmarker} at the speech {pause} {vocalsound} from these databases because , well , we tried several thing , but we did not really look {vocalsound} at what what 's happening , and {vocalsound} where is the noise , and&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Eh&#10;Speaker: Professor D&#10;Content: It 's a novel idea . Look at the data . OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Or more generally , I guess , what {disfmarker} what is causing the degradation .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . Actually , there is one thing that {disfmarker} well {pause} Um , generally we {disfmarker} we think that {vocalsound} most of the errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target=" mean the speed and the kind of road , is different for training and testing , is that right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: And the last condition is close microphone for training and distant for testing . Yeah .&#10;Speaker: Professor D&#10;Content: Uh , OK ,&#10;Speaker: PhD A&#10;Content: So {disfmarker} {vocalsound} s so {disfmarker}&#10;Speaker: Professor D&#10;Content: so I see . So , yeah , so the high {disfmarker} so the {disfmarker} right {disfmarker} so the highly mismatched {vocalsound} case {pause} is in some sense a good model for what we 've been , you know , typically talking about when we talk about additive noise in {disfmarker} And so {disfmarker} and i i k it does correspond to a realistic situation in the sense that , {vocalsound} um , people might really be trying to , uh , call out telephone numbers or some or something like that , in {disfmarker} in their cars&#10;Speaker: PhD A&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The database referred to by Professor D is unique because it is a &quot;realistic&quot; database with real noise conditions, as opposed to artificially added noise.&#10;2. Realistic room acoustics were recorded in a reverberant hallway and then simulated to apply to other things.&#10;3. This differs from other artificial databases because the noise present in this database is natural and reflects a realistic situation, while many other artificial databases might include simulated or artificially added noise." target="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content: I mean , if you have ten digits for a phone number {comment} I mean , every now and then you 'll get it right . I mean , it 's {disfmarker} it 's , uh , {vocalsound} um So , I mean , the other thing is that , uh {disfmarker} And {disfmarker} and {disfmarker} a and {disfmarker} and also , um {pause} part of what 's nice about this is that this is , uh , {vocalsound} um {pause} a realistic {disfmarker} almost realistic database . I mean , it 's still not people who are really trying to accomplish something , but {disfmarker} but , uh , within the artificial setup , it isn't noise artificially added , you know , simulated , uh , additive noise .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's real noise condition . And , um , {voc" target="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content: I mean , if you have ten digits for a phone number {comment} I mean , every now and then you 'll get it right . I mean , it 's {disfmarker} it 's , uh , {vocalsound} um So , I mean , the other thing is that , uh {disfmarker} And {disfmarker} and {disfmarker} a and {disfmarker} and also , um {pause} part of what 's nice about this is that this is , uh , {vocalsound} um {pause} a realistic {disfmarker} almost realistic database . I mean , it 's still not people who are really trying to accomplish something , but {disfmarker} but , uh , within the artificial setup , it isn't noise artificially added , you know , simulated , uh , additive noise .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's real noise condition . And , um , {voc" target="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source=" where it was {disfmarker} it was in a hallway where it was very reverberant and we {disfmarker} we made some recordings there . And then we {vocalsound} {disfmarker} we , uh {disfmarker} uh , made a simulation of the {disfmarker} of the room acoustics there and {disfmarker} and applied it to other things ,&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: and uh But it was all pretty artificial , and {disfmarker} and , you know , how often would you really try to have your most crucial conversations in this very reverberant hallway ? Um {pause} So , uh {pause} This is what 's nice about the Aurora data and the data here , is that {disfmarker} is that it 's sort of a realistic room situation {pause} uh , acoustics {disfmarker} acoustic situation , both terms in noise and reflections , and so on and n n And , uh , uh , with something that 's still relatively realistic , it 's still very very hard to do very well ." target="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling.">
      <data key="d0">1</data>
    </edge>
    <edge source=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:" target="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable.">
      <data key="d0">1</data>
    </edge>
    <edge source=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:" target="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:" target="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:" target="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker} I don't think it 's still true when we add noise , and {vocalsound} so we have {disfmarker} I {disfmarker} I guess the confusion ma the confusion matrices are very different when {disfmarker} when we have noise , and when it 's clean speech . And probably , there is much more {pause} between classes errors for noisy speech .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} so , um Yeah , so perhaps we could have a {disfmarker} a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: And {vocalsound} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker:" target="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {disfmarker} at the speech {pause} {vocalsound} from these databases because , well , we tried several thing , but we did not really look {vocalsound} at what what 's happening , and {vocalsound} where is the noise , and&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Eh&#10;Speaker: Professor D&#10;Content: It 's a novel idea . Look at the data . OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Or more generally , I guess , what {disfmarker} what is causing the degradation .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . Actually , there is one thing that {disfmarker} well {pause} Um , generally we {disfmarker} we think that {vocalsound} most of the errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker}" target="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {disfmarker} at the speech {pause} {vocalsound} from these databases because , well , we tried several thing , but we did not really look {vocalsound} at what what 's happening , and {vocalsound} where is the noise , and&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Eh&#10;Speaker: Professor D&#10;Content: It 's a novel idea . Look at the data . OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Or more generally , I guess , what {disfmarker} what is causing the degradation .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . Actually , there is one thing that {disfmarker} well {pause} Um , generally we {disfmarker} we think that {vocalsound} most of the errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker}" target="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {disfmarker} at the speech {pause} {vocalsound} from these databases because , well , we tried several thing , but we did not really look {vocalsound} at what what 's happening , and {vocalsound} where is the noise , and&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Eh&#10;Speaker: Professor D&#10;Content: It 's a novel idea . Look at the data . OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Or more generally , I guess , what {disfmarker} what is causing the degradation .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . Actually , there is one thing that {disfmarker} well {pause} Um , generally we {disfmarker} we think that {vocalsound} most of the errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker}" target="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" best thing to do .&#10;Speaker: PhD A&#10;Content: Uh , well Hmm Well , first , uh , to really have a look at {disfmarker} at the speech {pause} {vocalsound} from these databases because , well , we tried several thing , but we did not really look {vocalsound} at what what 's happening , and {vocalsound} where is the noise , and&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD A&#10;Content: Eh&#10;Speaker: Professor D&#10;Content: It 's a novel idea . Look at the data . OK .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Or more generally , I guess , what {disfmarker} what is causing the degradation .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . Actually , there is one thing that {disfmarker} well {pause} Um , generally we {disfmarker} we think that {vocalsound} most of the errors are within phoneme classes , and so I think it could be interesting to {disfmarker} to see if it {disfmarker}" target="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing" target="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing" target="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing" target="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing" target="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features.">
      <data key="d0">1</data>
    </edge>
    <edge source=": Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . No , I {disfmarker} I think there 's lots of {disfmarker} lots of good things to do with this . So Um So let 's {disfmarker} I guess {pause} You were gonna say something else ? Oh , OK . What do you think ?&#10;Speaker: PhD C&#10;Content: About&#10;Speaker: Professor D&#10;Content: Anything&#10;Speaker: PhD C&#10;Content: About other experiments ? Uh , now , I 'm interested in , um , uh {pause} looking at the experiments where you use , um {pause} uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but {pause} that would be some it 'd be interesting to me .&#10;Speaker: PhD A&#10;Content: Yeah , but&#10;Speaker: Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing" target="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable." target="ound} y you 're thinking that you didn't get to that you would like to do if you had more time ? Uh&#10;Speaker: PhD E&#10;Content: Oh , f a lot of thing . Because we trying a lot of s {pause} thing , and we doesn't work , {vocalsound} we remove these . Maybe {vocalsound} we trying again with the articulatory feature . I don't know exactly because we tried {disfmarker} we {disfmarker} some {disfmarker} one experiment that doesn't work . Um , forgot it , something {pause} I don't know exactly&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: because , tsk {comment} {vocalsound} maybe do better some step the general , {vocalsound} eh , diagram .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: I don't know exactly s to think what we can improve .&#10;Speaker: Professor D&#10;Content: Yeah , cuz a lot of time it 's true , there were a lot of times when we 've">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable." target=" . But , um , that was just sort of one try , right ? You just took one filter , threw it there ,&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: right ? And it seems to me that , um , if that is an important idea , which , you know , might be , that one could work at it for a while , as you 're saying .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: And , uh Uh , and you had , you know , you had the multi - band things also , and , you know , there was issue of that .&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: Um , Barry 's going to be , uh , continuing working on multi - band things as well .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: We were just talking about , um , {vocalsound} some , uh , some work that we 're interested in . Kind of inspired by the stuff by Larry Saul with the , uh {pause} uh , learning articulatory feature in {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable." target="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Articulatory features: PhD E mentioned trying again with articulatory features, which suggests that they had previously attempted to incorporate articulatory features but were not successful. They might be looking to improve their experiment by refining their approach to using articulatory features.&#10;2. General diagram: Both PhD E and Professor D discussed improving the general diagram or flowchart of their experiment. This implies that there might have been issues with understanding the overall design or steps in their process. Clarifying and optimizing the general diagram could help make the experiment more effective and understandable." target="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features.">
      <data key="d0">1</data>
    </edge>
    <edge source="ound} y you 're thinking that you didn't get to that you would like to do if you had more time ? Uh&#10;Speaker: PhD E&#10;Content: Oh , f a lot of thing . Because we trying a lot of s {pause} thing , and we doesn't work , {vocalsound} we remove these . Maybe {vocalsound} we trying again with the articulatory feature . I don't know exactly because we tried {disfmarker} we {disfmarker} some {disfmarker} one experiment that doesn't work . Um , forgot it , something {pause} I don't know exactly&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: because , tsk {comment} {vocalsound} maybe do better some step the general , {vocalsound} eh , diagram .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD E&#10;Content: I don't know exactly s to think what we can improve .&#10;Speaker: Professor D&#10;Content: Yeah , cuz a lot of time it 's true , there were a lot of times when we 've" target="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features.">
      <data key="d0">1</data>
    </edge>
    <edge source=" . But , um , that was just sort of one try , right ? You just took one filter , threw it there ,&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: right ? And it seems to me that , um , if that is an important idea , which , you know , might be , that one could work at it for a while , as you 're saying .&#10;Speaker: PhD A&#10;Content: Hmm .&#10;Speaker: Professor D&#10;Content: And , uh Uh , and you had , you know , you had the multi - band things also , and , you know , there was issue of that .&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: Um , Barry 's going to be , uh , continuing working on multi - band things as well .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: We were just talking about , um , {vocalsound} some , uh , some work that we 're interested in . Kind of inspired by the stuff by Larry Saul with the , uh {pause} uh , learning articulatory feature in {disf" target="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker: Professor D&#10;Content: The other thing that strikes me , just looking at these numbers is , just taking the best cases , I mean , some of these , of course , even with all of our {disfmarker} our wonderful processing , still are horrible kinds of numbers . But just take the best case , the well - matched {pause} uh , German case after {disfmarker} er well - matched Danish after we {disfmarker}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: the kind of numbers we 're getting are about eight or nine {pause} uh {pause} p percent {pause} error {pause} per digit .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor D&#10;Content: This is obviously not usable ,&#10;Speaker: PhD A&#10;Content: No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer.">
      <data key="d0">1</data>
    </edge>
    <edge source="The potential solution being suggested for addressing degradation in speech databases, according to the discussion between PhD A and Professor D, is to focus on analyzing the noise in the databases and looking at the causes of degradation. They suggest that many errors are within phoneme classes, but when noise is added, the confusion matrices are different compared to clean speech, resulting in more errors between classes for noisy speech. To improve recognition in noisy conditions, they propose focusing on recognizing phoneme classes instead of individual phonemes, which is a simpler problem that could have a large gain in performance. Professor D also mentions the importance of using realistic noise conditions in the databases to better simulate real-world situations and improve the robustness of speech recognition systems." target="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="} which is a s a s a simpler problem , perhaps , but {disfmarker} which is perhaps important for noisy speech .&#10;Speaker: Professor D&#10;Content: The other thing that strikes me , just looking at these numbers is , just taking the best cases , I mean , some of these , of course , even with all of our {disfmarker} our wonderful processing , still are horrible kinds of numbers . But just take the best case , the well - matched {pause} uh , German case after {disfmarker} er well - matched Danish after we {disfmarker}&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: the kind of numbers we 're getting are about eight or nine {pause} uh {pause} p percent {pause} error {pause} per digit .&#10;Speaker: PhD A&#10;Content: Mm - hmm . Yeah .&#10;Speaker: Professor D&#10;Content: This is obviously not usable ,&#10;Speaker: PhD A&#10;Content: No .&#10;Speaker: Professor D&#10;Content: right ?&#10;Speaker: PhD A&#10;Content: Sure .&#10;Speaker: Professor D&#10;Content" target="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="&#10;Content: Mmm . Yeah .&#10;Speaker: Professor D&#10;Content: Good , OK . So , um So , we 'll {disfmarker} we 'll hold off on that a little bit . I mean , even with these results as they are , it 's {disfmarker} it 's {disfmarker} it 's really not that bad . But {disfmarker} but , uh , um And it looks like the overall result as they are now , even without , you know , any {disfmarker} any bugs being fixed is that , uh , on the {disfmarker} the other tasks , we had this average of , uh , forty uh {disfmarker} nine percent , or so , improvement . And here we have somewhat better than that than the Danish , and somewhat worse than that on the German , but I mean , it sounds like , uh , one way or another , the methods that we 're doing can reduce the error rate from {disfmarker} from mel ceptrum {pause} down by , you know {pause} a fourth of them to , uh , a half of them . Somewhere in there , depending on the">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the filtering method used by French Telecom and Alcatel systems has shown promising results in reducing error rates. The speaker mentions an average improvement of around 49.9% (forty nine percent) on other tasks. However, it's important to note that this performance varies between languages; specifically, the filtering method performs somewhat better than the current standard for Danish and slightly worse for German.&#10;&#10;In addition to the filtering method, there is also a proposal to focus on recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance. The speakers highlight that many errors are within phoneme classes, but when noise is added, the confusion matrices change significantly, causing more errors between classes for noisy speech.&#10;&#10;Lastly, it's worth noting that the best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, these are not final evaluation set results yet, and there is still room for improvement." target="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="aker: Professor D&#10;Content: So , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind the different languages , just having acoustic conditions rather than training them all up in one , would it be helpful to have different ones ? So , um That was a question that was kind of raised by Mike Shire 's thesis , and on {disfmarker} in that case in terms of reverberation . Right ? That {disfmarker} that sometimes it might be better to do that . But , um , {vocalsound} I don't think we know for sure . So , um Right . So , next week , we , uh , won't meet because you 'll be in Europe . Whe - when are you two getting back ?&#10;Speaker: PhD E&#10;Content: Um , I 'm&#10;Speaker: PhD A&#10;Content: You on Friday or S on Saturday or {pause} ?&#10;Speaker: PhD E&#10;Content: Sunday&#10;Speaker: PhD A&#10;Content: S oh yeah , Sunday , yeah .&#10;Speaker: PhD E&#10;Content: because it 's {disfmarker} it 's less expensive , the price {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target=" Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Uh , so , yeah . I don't know if we can get some hand - labeled data from other languages .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It 's not so easy to find .&#10;Speaker: PhD C&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: But {pause} that would be something interesting t to {disfmarker} to see .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Also , uh , {vocalsound} I mean , there was just the whole notion of having multiple nets that were trained on different data . So one form of different data was {disfmarker} is from different languages , but the other Well , i in fact , uh , m in those experiments it wasn't so much combining multiple nets , it was a single net that had different&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="&#10;Speaker: PhD A&#10;Content: So , training is done {vocalsound} on different conditions and different microphones , and testing also is done {pause} on different microphone and conditions . So , probably if we only take the close microphones , {vocalsound} I guess the results should be much much better than this .&#10;Speaker: Professor D&#10;Content: I see .&#10;Speaker: PhD A&#10;Content: Mmm .&#10;Speaker: Professor D&#10;Content: Oh , OK ,&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: that explains it partially . Wha - what about i in {disfmarker} so the {disfmarker} the {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , so {disfmarker} there is this , the mismatched is , um {pause} the same kind of thing ,&#10;Speaker: Professor D&#10;Content: go ahead .&#10;Speaker: PhD A&#10;Content: but {pause} the driving conditions , I mean the speed and the kind of road , is different for training and testing , is that right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target=" A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's real noise condition . And , um , {vocalsound} the {disfmarker} the training {disfmarker} the training , I guess , is always done on the close talking&#10;Speaker: PhD A&#10;Content: No , actually {disfmarker} actually the well - matched condition {pause} is {pause} still quite di still quite difficult .&#10;Speaker: Professor D&#10;Content: No ?&#10;Speaker: PhD A&#10;Content: I mean , it 's {disfmarker} they have all these data from the close mike and from the distant mike , {vocalsound} from different driving condition , open window , closed window ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: and they take all of this and they take seventy percent , I think , for training and thirty percent for testing .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: So , training is done {vocalsound} on different conditions and different microphones , and testing also is done {">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for discussing the possibility of using multiple nets with different acoustic conditions during training is that it might be beneficial to have separate nets trained under various reverberation conditions, as suggested by Mike Shire's thesis. This could potentially improve speech recognition performance in diverse acoustic environments. However, it remains unclear if this approach would indeed yield better results.&#10;2. Speakers A and E will return from Europe on Sunday." target="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Uh , so , yeah . I don't know if we can get some hand - labeled data from other languages .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It 's not so easy to find .&#10;Speaker: PhD C&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: But {pause} that would be something interesting t to {disfmarker} to see .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Also , uh , {vocalsound} I mean , there was just the whole notion of having multiple nets that were trained on different data . So one form of different data was {disfmarker} is from different languages , but the other Well , i in fact , uh , m in those experiments it wasn't so much combining multiple nets , it was a single net that had different&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind" target="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Uh , so , yeah . I don't know if we can get some hand - labeled data from other languages .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It 's not so easy to find .&#10;Speaker: PhD C&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: But {pause} that would be something interesting t to {disfmarker} to see .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Also , uh , {vocalsound} I mean , there was just the whole notion of having multiple nets that were trained on different data . So one form of different data was {disfmarker} is from different languages , but the other Well , i in fact , uh , m in those experiments it wasn't so much combining multiple nets , it was a single net that had different&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: So , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind" target="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="&#10;Speaker: PhD A&#10;Content: So , training is done {vocalsound} on different conditions and different microphones , and testing also is done {pause} on different microphone and conditions . So , probably if we only take the close microphones , {vocalsound} I guess the results should be much much better than this .&#10;Speaker: Professor D&#10;Content: I see .&#10;Speaker: PhD A&#10;Content: Mmm .&#10;Speaker: Professor D&#10;Content: Oh , OK ,&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: that explains it partially . Wha - what about i in {disfmarker} so the {disfmarker} the {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , so {disfmarker} there is this , the mismatched is , um {pause} the same kind of thing ,&#10;Speaker: Professor D&#10;Content: go ahead .&#10;Speaker: PhD A&#10;Content: but {pause} the driving conditions , I mean the speed and the kind of road , is different for training and testing , is that right ?&#10;Speaker: PhD E&#10;Content: Yeah .&#10;" target="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet." target="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet." target="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet." target="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining the efficiency of the test. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;4. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results. However, there is still room for improvement as these are not final evaluation set results yet." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target=" best single numbers , {vocalsound} it was just {disfmarker} you know , it wasn't good enough for {disfmarker} for {pause} a {disfmarker} a {disfmarker} for a real system .&#10;Speaker: PhD A&#10;Content: Mmm . Mm - hmm .&#10;Speaker: Professor D&#10;Content: You {disfmarker} you {disfmarker} you , {vocalsound} um So , uh , we still have stuff to do .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , and , uh I don't know So , looking at the data , where , you know {disfmarker} what 's the {disfmarker} what 's {disfmarker} what 's th what 's characteristic i e yeah , I think that 's {disfmarker} that 's a good thing . Does a any you have any thoughts about what else {vocalsound} y you 're thinking that you didn't get to that you would like to do if you had more time ? Uh&#10;Speaker: PhD E">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Speaker A's opinion on the adequacy of a single number for a real system is not explicitly stated in the transcript. However, they do agree with Professor D's points regarding the current system's performance.&#10;&#10;2. Speaker D expresses their concern about relying on a single number for a real system, stating that &quot;it wasn't good enough for a real system&quot; and later adding that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable.&#10;&#10;3. Speaker E does not express any opinions regarding the adequacy of a single number for a real system in the provided transcript. However, when asked if they have any thoughts about what else they would like to explore given more time, Speaker E brings up the idea of recognizing phoneme classes instead of individual phonemes in noisy conditions as a potential area for improvement." target="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work." target=" Sunday , yeah .&#10;Speaker: PhD E&#10;Content: because it 's {disfmarker} it 's less expensive , the price {disfmarker} the price the ticket .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor D&#10;Content: Yeah , that 's right . You 've gotta S have a Saturday overnight , right ?&#10;Speaker: PhD A&#10;Content: I 'll be back on Tuesday .&#10;Speaker: Professor D&#10;Content: Tuesday .&#10;Speaker: PhD C&#10;Content: Where {disfmarker} where 's the meeting ?&#10;Speaker: Professor D&#10;Content: Uh , Amsterdam , I think , yeah ?&#10;Speaker: PhD A&#10;Content: Yeah , Amsterdam .&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah , yeah . Yep . Um {pause} So , we 'll skip next week , and we 'll meet two weeks from now . And , uh , I guess the main topic will be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work." target=" the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably the day after they leave , but we 'll have to {disfmarker} {vocalsound} we 'll have to stop it the day before {comment} we leave .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . So&#10;Speaker: PhD C&#10;Content: Huh .&#10;Speaker: Professor D&#10;Content: I think tha I think the {disfmarker} the meeting is on the thirteenth or something .&#10;Speaker: PhD A&#10;Content: Yeah , this Tuesday , yeah .&#10;Speaker: Professor D&#10;Content: And , uh , they , uh Right . And the {disfmarker} the , uh , results are due like the day before the meeting or something . So&#10;Speaker: PhD A&#10;Content: Yeah , probably , well&#10;Speaker: Professor D&#10;Content: I th I think {disfmarker} I I think they are ,&#10;Speaker: PhD A&#10;Content: Yeah , well&#10;Speaker: Professor D&#10;Content: yeah . So {pause} {vocals">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work." target="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time. The location for this meeting is confirmed as Amsterdam.&#10;2. The primary topic of discussion during the next meeting will be an update on the experiences and results from Speaker A's recent trip to Europe, as well as any new features they might have obtained from Sunil for further development. Additionally, there seems to be interest in discussing potential future directions for the project now that Speaker A is &quot;basically done&quot; with their current work." target="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source=" Sunday , yeah .&#10;Speaker: PhD E&#10;Content: because it 's {disfmarker} it 's less expensive , the price {disfmarker} the price the ticket .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor D&#10;Content: Yeah , that 's right . You 've gotta S have a Saturday overnight , right ?&#10;Speaker: PhD A&#10;Content: I 'll be back on Tuesday .&#10;Speaker: Professor D&#10;Content: Tuesday .&#10;Speaker: PhD C&#10;Content: Where {disfmarker} where 's the meeting ?&#10;Speaker: Professor D&#10;Content: Uh , Amsterdam , I think , yeah ?&#10;Speaker: PhD A&#10;Content: Yeah , Amsterdam .&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah , yeah . Yep . Um {pause} So , we 'll skip next week , and we 'll meet two weeks from now . And , uh , I guess the main topic will be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah ." target="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Sunday , yeah .&#10;Speaker: PhD E&#10;Content: because it 's {disfmarker} it 's less expensive , the price {disfmarker} the price the ticket .&#10;Speaker: PhD C&#10;Content: &#10;Speaker: Professor D&#10;Content: Yeah , that 's right . You 've gotta S have a Saturday overnight , right ?&#10;Speaker: PhD A&#10;Content: I 'll be back on Tuesday .&#10;Speaker: Professor D&#10;Content: Tuesday .&#10;Speaker: PhD C&#10;Content: Where {disfmarker} where 's the meeting ?&#10;Speaker: Professor D&#10;Content: Uh , Amsterdam , I think , yeah ?&#10;Speaker: PhD A&#10;Content: Yeah , Amsterdam .&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah , yeah . Yep . Um {pause} So , we 'll skip next week , and we 'll meet two weeks from now . And , uh , I guess the main topic will be , uh , you telling us what happened .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Yeah ." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably the day after they leave , but we 'll have to {disfmarker} {vocalsound} we 'll have to stop it the day before {comment} we leave .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . So&#10;Speaker: PhD C&#10;Content: Huh .&#10;Speaker: Professor D&#10;Content: I think tha I think the {disfmarker} the meeting is on the thirteenth or something .&#10;Speaker: PhD A&#10;Content: Yeah , this Tuesday , yeah .&#10;Speaker: Professor D&#10;Content: And , uh , they , uh Right . And the {disfmarker} the , uh , results are due like the day before the meeting or something . So&#10;Speaker: PhD A&#10;Content: Yeah , probably , well&#10;Speaker: Professor D&#10;Content: I th I think {disfmarker} I I think they are ,&#10;Speaker: PhD A&#10;Content: Yeah , well&#10;Speaker: Professor D&#10;Content: yeah . So {pause} {vocals" target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the , uh , uh , test set results due ? Like the day before you leave or something ?&#10;Speaker: Professor D&#10;Content: Uh , probably the day after they leave , but we 'll have to {disfmarker} {vocalsound} we 'll have to stop it the day before {comment} we leave .&#10;Speaker: PhD A&#10;Content: Yeah , yeah . So&#10;Speaker: PhD C&#10;Content: Huh .&#10;Speaker: Professor D&#10;Content: I think tha I think the {disfmarker} the meeting is on the thirteenth or something .&#10;Speaker: PhD A&#10;Content: Yeah , this Tuesday , yeah .&#10;Speaker: Professor D&#10;Content: And , uh , they , uh Right . And the {disfmarker} the , uh , results are due like the day before the meeting or something . So&#10;Speaker: PhD A&#10;Content: Yeah , probably , well&#10;Speaker: Professor D&#10;Content: I th I think {disfmarker} I I think they are ,&#10;Speaker: PhD A&#10;Content: Yeah , well&#10;Speaker: Professor D&#10;Content: yeah . So {pause} {vocals" target="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800." target=" in the modulation spectrum , which allows us to downsample . So , uh , as a result of that we have a reduced , um , transmission rate for the bits .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: That was misreported the first time out . It {disfmarker} it said the same amount because for convenience sake in the particular way that this is being tested , uh , they were repeating the packets . So it was {disfmarker} they were s they {disfmarker} they had twenty - four hundred bits per second , but they were literally creating forty - eight hundred bits per second , {vocalsound} um , even though y it was just repeated .&#10;Speaker: PhD C&#10;Content: Oh . Mm - hmm . Right .&#10;Speaker: Professor D&#10;Content: So , uh , in practice&#10;Speaker: PhD C&#10;Content: So you could 've had a repeat count in there or something .&#10;Speaker: Professor D&#10;Content: Well , n I mean , this was just a ph phoney thing just to {disfmarker} to fit into the {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="The transmission rate was reported as double the actual rate in the modulation spectrum because, during testing, packets were being repeated for convenience. This meant that even though there were 2400 bits per second, they were creating 4800 bits per second by repeating the packets. However, this was just a &quot;phoney&quot; situation created to fit into the software that was testing channel errors and other issues. In reality, if this system were to be implemented in the field, it would have a transmission rate of 2400 bits per second, not 4800." target="s being real conscious of how much memory and how much CPU they 're using&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: because these , {vocalsound} {vocalsound} {vocalsound} uh , standards are supposed to go on cell phones with m moderate resources in both respects .&#10;Speaker: PhD C&#10;Content: Did anybody , uh , do anything with the models as a {disfmarker} an experiment ? Or&#10;Speaker: Professor D&#10;Content: Uh , they didn't report it , if they did .&#10;Speaker: PhD C&#10;Content: N nobody reported it ?&#10;Speaker: Professor D&#10;Content: Yeah . I think everybody was focused elsewhere . Um , now , one of the things that 's nice about what we did is , we do have a {disfmarker} a , uh {disfmarker} a filtering , which leads to a {disfmarker} a , uh {disfmarker} a reduction in the bandwidth in the modulation spectrum , which allows us to downsample . So , uh , as a result of that we have a reduced , um , transmission rate for the">
      <data key="d0">1</data>
    </edge>
    <edge source="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages.">
      <data key="d0">1</data>
    </edge>
    <edge source="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer.">
      <data key="d0">1</data>
    </edge>
    <edge source="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="PhD A and Professor D suggest focusing on analyzing the noise in the speech databases and understanding the causes of degradation. They propose recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This is a simpler problem that could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript." target="marker} just in computer time is just a day or so , right ?&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor D&#10;Content: So&#10;Speaker: PhD A&#10;Content: it 's very short interval .&#10;Speaker: Professor D&#10;Content: yeah . So , I think the who the whole reason for having as long as we have , which was {pause} like a week and a half , is {disfmarker} is because of bugs like that . So Huh So , we 're gonna end up with these same kind of sheets that have the {pause} the percentages and so on just for the {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , so there are two more columns in the sheets ,&#10;Speaker: Professor D&#10;Content: Oh , I guess it 's the same sheets ,&#10;Speaker: PhD A&#10;Content: two . Yeah , it 's the same sheets ,&#10;Speaker: Professor D&#10;Content: yeah , yeah {disfmarker}&#10;Speaker: PhD A&#10;Content: yeah .&#10;Speaker: Professor D&#10;Content: just with the missing columns filled in .&#10;Speaker: PhD A">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript." target=" are ,&#10;Speaker: PhD A&#10;Content: Yeah , well&#10;Speaker: Professor D&#10;Content: yeah . So {pause} {vocalsound} um , since we have a bit farther to travel than {vocalsound} some of the others , {vocalsound} uh , we 'll have to get done a little quicker . But , um , I mean , it 's just tracing down these bugs . I mean , just exactly this sort of thing of , you know , why {disfmarker} why these features seem to be behaving differently , uh , in California than in Oregon .&#10;Speaker: PhD C&#10;Content:  Hmm .&#10;Speaker: Professor D&#10;Content: Might have something to do with electricity shortage . Uh , we didn't {disfmarker} we didn't have enough electrons here and Uh , but , um Uh , I think , you know , the main reason for having {disfmarker} I mean , it only takes w to run the {disfmarker} the two test sets in {disfmarker} just in computer time is just a day or so , right ?&#10;Speaker: PhD A&#10;Content: Yeah ,&#10;Speaker: Professor">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript." target="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The reason for having a week and a half interval between meetings, as mentioned by the speakers, is due to the possibility of bugs and issues arising that require time to resolve. This duration was initially chosen to allow for addressing such problems.&#10;2. During the meeting, it is agreed that two more columns need to be added to certain sheets. However, the specific details about these columns or why they are needed are not discussed in the provided transcript. Speaker A mentions that there will be two additional columns, and Professor D confirms this, stating that the sheets will have &quot;the missing columns filled in.&quot;&#10;&#10;In summary, a week and a half interval between meetings is to account for potential bugs or issues that may arise during the development process. The need to fill in two more columns in the sheets is agreed upon by the speakers, but their specific purpose is not addressed in the transcript." target="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications." target="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language.">
      <data key="d0">1</data>
    </edge>
    <edge source="The overall evaluation of the &quot;optimistic view on using different cars&quot; refers to the proposal where French Telecom and Alcatel systems have shown promising results in reducing error rates with their filtering methods. However, this performance varies between languages, as seen with slightly worse results for German compared to the current standard but better results for Danish. The best system has achieved a reduction of around 54% (fifty-four percent) in word error rate so far, based on development set results.&#10;&#10;The reason even the best single numbers from Alcatel's development set don't meet expectations is not explicitly stated in the transcript. Professor D mentions that &quot;it wasn't good enough for a real system&quot; and later adds that even under ideal conditions, the error rate is around 8-9% per digit, which they consider not usable. This suggests that there might be some limitations or challenges with Alcatel's development set numbers that make them insufficient for practical applications." target="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features." target=" we 're interested in . Kind of inspired by the stuff by Larry Saul with the , uh {pause} uh , learning articulatory feature in {disfmarker} I think , in the case of his paper {disfmarker} with sonorance based on , uh , multi - band information where you have a {disfmarker} a combination of gradient learning an and , uh , EM .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Um , and {pause} {vocalsound} {vocalsound} Um , so , I think that , you know , this is a , uh {disfmarker} this is a neat data set . Um , and then , uh , as we mentioned before , we also have the {disfmarker} the new , uh , digit set coming up from recordings in this room . So , there 's a lot of things to work with . Um and , uh what I like about it , in a way , is that , uh , the results are still so terrible . Uh {pause} {vocalsound} Uh {pause} {vocalsound} I mean , they 're much better">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Filter Experiment and Multi-Band Things: During the discussion, it is mentioned that there was a filter experiment where only one filter was tried. Professor D suggests working on it further, as it might be an important idea. They also discussed multi-band issues and Barry continuing to work on them. This implies that they are considering refining their filter experiment and addressing multi-band related challenges.&#10;&#10;2. Learning Articulatory Features: The group also talked about some work inspired by Larry Saul's study on learning articulatory features, specifically referencing a paper where sonorance is based on multi-band information using a combination of gradient learning and EM (Expectation Maximization). This indicates that they are interested in exploring how to apply and improve the implementation of learning articulatory features in their own experiment.&#10;&#10;Overall, the discussion revolves around refining their filter experiment, addressing multi-band issues, and incorporating ideas from Larry Saul's study on learning articulatory features." target=" {disfmarker} but there 're {disfmarker} there 're {disfmarker} there 're some other differences , too . Uh , and {disfmarker} and , uh , they both did very well ,&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: you know ? So , {vocalsound} um , my impression is they also did very well on {disfmarker} on the {disfmarker} the , uh , evaluation set , but , um , I {disfmarker} I we haven't seen {disfmarker} you 've - you haven't seen any final results for that&#10;Speaker: PhD C&#10;Content: And they used {disfmarker} the main thing that {disfmarker} that they used was spectral subtraction ?&#10;Speaker: Professor D&#10;Content: yeah .&#10;Speaker: PhD C&#10;Content: Or&#10;Speaker: Professor D&#10;Content: There is a couple pieces to it . There 's a spectral subtraction style piece {disfmarker} it was basically , you know , Wiener filtering . And then {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The next meeting is agreed to take place two weeks from the previous one, with the specific date being either the 13th or around that time, in Amsterdam.&#10;2. Speaker A will be sharing their experiences in the meeting, as they are returning from a trip to Europe on the day before the meeting and have explored potential new features for further development." target="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages." target=" Professor D&#10;Content: S b&#10;Speaker: PhD A&#10;Content: Again , it 's the kind of {disfmarker} of thing that , uh , we were thin thinking {disfmarker} thinking that it would work , but it didn't work . And , eh , so there is kind of {disfmarker} of {pause} not a bug , but something wrong in what we are doing , perhaps .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Right . Right .&#10;Speaker: PhD A&#10;Content: Uh , something wrong , perhaps in the {disfmarker} just in the {disfmarker} the fact that the labels are {disfmarker}&#10;Speaker: PhD C&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: well&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: What worked best is the hand - labeled data .&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Uh , so , yeah . I don't know if we can get some hand">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages." target="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the current approach, as mentioned by PhD A, is that there seems to be &quot;something wrong&quot; in the labeling of the data, possibly indicating inconsistencies or errors in the labels. This could lead to poorer performance and misleading results.&#10;2. Hand-labeled data is more effective because it ensures accurate and consistent labeling. In this discussion, hand-labeled data has shown better results in reducing error rates compared to other methods. However, collecting hand-labeled data can be difficult due to its scarcity. It is also worth noting that the filtering method used by French Telecom and Alcatel systems has demonstrated promising results, although performance varies between languages." target="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language." target=" the {disfmarker} the ICSI OGI one .&#10;Speaker: PhD A&#10;Content: Oh yeah .&#10;Speaker: Professor D&#10;Content: So {pause} um , I wan wanna {disfmarker} wanna see what that is . But , uh , you know , so we 'll see what it is comparatively later . But {pause} it looks like , um&#10;Speaker: PhD A&#10;Content: M yeah .&#10;Speaker: Professor D&#10;Content: You know most of the time , even {disfmarker} I mean even though it 's true that the overall number for Danish {disfmarker} we didn't improve it If you look at it individually , what it really says is that there 's , um , uh Looks like out of the six cases , between the different kinds of , uh , matching conditions {pause} out of the six cases , there 's basically , um , a couple where it stays about the same , uh , three where it gets better , and one where it gets worse .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language." target="Speaker: Professor D&#10;Content: OK . So , uh You can fill those out , uh {pause} after , actually , so So , I got , uh {pause} these results from , uh , Stephane . Also , um , I think that , uh {pause} um {pause} we might hear later today , about other results . I think s that , uh , there were some other very good results that we 're gonna wanna compare to . But , {vocalsound} r our results from other {disfmarker} other places , yeah .&#10;Speaker: PhD A&#10;Content: I I 'm sorry ? I didn't&#10;Speaker: Professor D&#10;Content: Um , I got this from you&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: and then I sent a note to Sunil about the {disfmarker} cuz he has been running some other systems&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: other than the {disfmarker} the ICSI OGI one .&#10;Speaker: PhD A&#10;Content: Oh yeah .&#10;Speaker: Professor">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The issue with the Danish dataset in relation to the ICSI OGI one is that when using straight features from OGI, the desired results (ninety-three seventy-eight) cannot be achieved. Instead, the result is eighty-nine forty-four.&#10;   &#10;2. To address this issue, PhD E and Sunil are working on checking everything related to these features to identify and correct any problems. This includes further investigation into the differences between the Danish dataset and the ICSI OGI one, as well as ensuring that the filtering method used by French Telecom and Alcatel systems is compatible with the Danish language." target="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems.">
      <data key="d0">1</data>
    </edge>
    <edge source=" the {disfmarker} the ICSI OGI one .&#10;Speaker: PhD A&#10;Content: Oh yeah .&#10;Speaker: Professor D&#10;Content: So {pause} um , I wan wanna {disfmarker} wanna see what that is . But , uh , you know , so we 'll see what it is comparatively later . But {pause} it looks like , um&#10;Speaker: PhD A&#10;Content: M yeah .&#10;Speaker: Professor D&#10;Content: You know most of the time , even {disfmarker} I mean even though it 's true that the overall number for Danish {disfmarker} we didn't improve it If you look at it individually , what it really says is that there 's , um , uh Looks like out of the six cases , between the different kinds of , uh , matching conditions {pause} out of the six cases , there 's basically , um , a couple where it stays about the same , uh , three where it gets better , and one where it gets worse .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , go ahead .&#10;Speaker: PhD A&#10;Content" target="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="Speaker: Professor D&#10;Content: OK . So , uh You can fill those out , uh {pause} after , actually , so So , I got , uh {pause} these results from , uh , Stephane . Also , um , I think that , uh {pause} um {pause} we might hear later today , about other results . I think s that , uh , there were some other very good results that we 're gonna wanna compare to . But , {vocalsound} r our results from other {disfmarker} other places , yeah .&#10;Speaker: PhD A&#10;Content: I I 'm sorry ? I didn't&#10;Speaker: Professor D&#10;Content: Um , I got this from you&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: and then I sent a note to Sunil about the {disfmarker} cuz he has been running some other systems&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: other than the {disfmarker} the ICSI OGI one .&#10;Speaker: PhD A&#10;Content: Oh yeah .&#10;Speaker: Professor" target="Professionor D is referring to the results of speech recognition performance on the Danish dataset, in comparison to the ICSI OGI dataset. These results were obtained using straight features from OGI, but the desired results (9378) could not be achieved with these features for the Danish dataset. The actual result was 8944, which is lower than the target and different from the results on the ICSI OGI dataset. Professor D sent a note to Sunil, who is working on other systems beyond the ICSI OGI one, to investigate any potential issues or inconsistencies related to these features, particularly in comparison to the Danish dataset and its compatibility with the filtering method used by French Telecom and Alcatel systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The two systems with the lowest results on the development set are the French Telecom system and the Alcatel system, which both use different filtering methods to reduce error rates in speech recognition. These systems have shown promising results, achieving an average improvement of around 49.9% (forty nine percent) on other tasks.&#10;&#10;2. The major differences between the French Telecom Alcatel System and the Alcatel French Telecom System lie in their approach to voice activity detection (VAD) and online normalization within the filtering method. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;It is essential to note that while these systems perform better than the current standard for Danish, they show slightly worse results for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech." target="1. Hand-labeled data from other languages: The main benefit of using hand-labeled data from other languages is its effectiveness in reducing error rates compared to other methods due to accurate and consistent labeling. However, collecting such data can be challenging due to its scarcity. In this particular experiment, the feasibility might be limited by the availability of hand-labeled data in relevant languages.&#10;&#10;2. Combining multiple networks trained on different data, including language-based data: The idea comes from Mike Shire's thesis, suggesting that separate nets trained under various reverberation conditions could improve speech recognition performance in diverse acoustic environments. For the given experiment, combining multiple networks trained on different data, such as language-based data, might yield better results. However, it is unclear if this approach would indeed provide improvements.&#10;&#10;In summary, using hand-labeled data from other languages and combining multiple networks trained on different data, including language-based data, could potentially bring benefits to the experiment. The feasibility of the first option depends mainly on the availability of such labeled data in relevant languages. The second approach, while promising, requires further investigation to determine its effectiveness for this specific experiment.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The suggestion for investigating the degradation in speech from the databases, proposed by PhD A and agreed upon by Professor D, is to analyze the noise in the databases and understand the causes of degradation. They suggest recognizing phoneme classes instead of individual phonemes, as many errors are within phoneme classes. This simpler problem could lead to significant performance improvements, especially in noisy conditions.&#10;2. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems, as adding noise can result in more errors between classes for noisy speech and cause confusion matrices to be very different compared to clean speech." target="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The attendees, Speakers A and E, plan to leave for their trip on Sunday. This information is deduced from Professor D's question &quot;You folks leave?&quot; and PhD A's response &quot;Uh, Sunday.&quot;&#10;2. It is agreed that Hynek should be notified once the plans are finalized. This conclusion comes from Professor D's statement &quot;when whenever anybody figures it out they should also ... email Hynek because Hynek will be over there telling people what we did, so he should know.&quot;" target=" A&#10;Content: Hmm ?&#10;Speaker: Professor D&#10;Content: We have a little bit of time on that , actually .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: We have a day or so , so When {disfmarker} when {disfmarker} when do you folks leave ?&#10;Speaker: PhD A&#10;Content: Uh , Sunday .&#10;Speaker: Professor D&#10;Content: Sunday ? So So , uh Yeah , until Saturday midnight , or something , we have W we {disfmarker} we have time , yeah . Well , that would be good . That 'd be good .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Uh , and , you know , i u when whenever anybody figures it out they should also , for sure , email Hynek because Hynek will be over there {vocalsound} telling people {vocalsound} what we did , so he should know .&#10;Speaker: PhD A&#10;Content: Mmm . Yeah .&#10;Speaker: Professor D&#10;Content: Good , OK . So , um So , we 'll {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes." target="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. The VAD method is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Analyzing these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. Combining the best ideas from both systems without significantly increasing resource usage is crucial for maintaining efficiency. This may involve recognizing phoneme classes instead of individual phonemes in noisy conditions, which could potentially lead to improvements in speech recognition performance.&#10;&#10;In summary, examining the differences in VAD and online normalization approaches between the French Telecom and Alcatel systems could lead to a more effective standard with minimal resource usage increase. The combined filtering method should be tested for compatibility with other languages like German and Danish and assessed for real-world performance before implementing any changes." target="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer." target="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer." target="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided meeting transcripts, there is no direct information about the specific differences in driving conditions between the training and testing phases of the speech recognition system. The discussion primarily focuses on analyzing noise in speech databases, understanding degradation causes, recognizing phoneme classes instead of individual phonemes, and using realistic noise conditions for better system robustness.&#10;&#10;However, one point that might be indirectly related to your question is the mention of a thesis by Mike Shire suggesting the possibility of training separate nets under various reverberation conditions. This suggests that different acoustic environments could have been simulated during the training phase. Any changes in acoustic environments between training and testing could potentially affect the system's performance, and addressing this issue through separate net training may improve speech recognition results in diverse acoustic environments.&#10;&#10;Without further information about the specific driving conditions mentioned in your question, it is difficult to provide a more precise answer." target="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The primary difference in the filtering methods between the French Telecom and Alcatel systems lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase, potentially reducing the data rate by half and improving overall system performance and efficiency.&#10;&#10;2. Both companies use filtering methods that have shown promising results in reducing error rates in speech recognition. However, their performance varies between languages; the French Telecom system performs better than the current standard for Danish but slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;3. The filtering method used by both companies has shown promising results in reducing error rates, but its performance varies between languages. It performs better than the current standard for Danish and slightly worse for German. Therefore, any changes to the existing standard should be tested for compatibility with other languages like German and Danish.&#10;&#10;Regarding memory and CPU usage, the speakers briefly discuss these requirements for implementing the filtering and VAD methods. Any changes or additions to the filtering method should be evaluated based on their resource usage since they might affect the overall performance of the system. However, specific details about how each filtering method affects memory and CPU usage are not provided in the transcripts. To answer this question completely, an analysis of the resource usage for both filtering methods would be necessary." target="1. Differences in filtering methods: The primary difference in the filtering methods between the French Telecom and Alcatel systems on the terminal side lies in their approach to voice activity detection (VAD) and online normalization. VAD is responsible for detecting speech segments in an audio signal, while online normalization adjusts parameters based on real-time input. Examining these differences could lead to a more effective standard with minimal resource usage increase.&#10;&#10;2. Memory and CPU requirements: The speakers briefly discuss the memory and CPU requirements for implementing the filtering and VAD methods but do not provide specific details about how each filtering method affects memory and CPU usage. However, they mention that adding the new filtering method on the terminal's side should not take a lot of memory or CPU resources.&#10;&#10;Without more information from the transcripts, it is difficult to provide a precise answer regarding the exact differences in the filtering methods between what was discussed for the terminal's side and the server's side. The transcript mainly focuses on discussing the potential benefits and challenges of combining the filtering methods used by French Telecom and Alcatel systems on the terminal side, with some mention of possible improvements to the overall system performance and efficiency.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling." target=" results are still so terrible . Uh {pause} {vocalsound} Uh {pause} {vocalsound} I mean , they 're much better than they were , you know . We 're talking about thirty to sixty percent , uh , error rate reduction . That 's {disfmarker} that 's really great stuff to {disfmarker} to do that in relatively short time . But even after that it 's still , you know , so poor that {disfmarker} that , uh , no one could really use it . So , um I think that 's great that {disfmarker} because {disfmarker} and y also because again , it 's not something {disfmarker} sometimes we 've gotten terrible results by taking some data , and artificially , you know , convolving it with some room response , or something {disfmarker} we take a very {disfmarker} Uh , at one point , uh , Brian and I went downstairs into the {disfmarker} the basement where it was {disfmarker} it was in a hallway where it was very reverberant and we {disfmarker} we made some recordings">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Realism: The reverberant hallway recordings are considered more realistic as they represent natural room acoustics with real noise conditions. On the other hand, the Aurora data is also described as having realistic room situations and acoustic conditions, including terms like noise, reflections, and other factors that contribute to a relatively authentic environment.&#10;&#10;2. Difficulty in achieving high-quality results: Both the reverberant hallway recordings and the Aurora data present significant challenges when it comes to achieving very good results due to their realistic acoustic conditions. According to Professor D, even with the Aurora data's more realistic settings, it remains difficult to achieve high-quality outcomes. Speaker A agrees with this assessment, attributing the difficulty to working with a different kind of data that they are not used to handling." target=" so on and n n And , uh , uh , with something that 's still relatively realistic , it 's still very very hard to do very well . So Yeah .&#10;Speaker: PhD A&#10;Content: Yeah , so d well Actually , this is {disfmarker} tha that 's why we {disfmarker} well , it 's a different kind of data . We 're not {disfmarker} we 're not used to work with this kind of data . That 's why we should have a loo more closer look at what 's going on .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Um Yeah . So this would be the first thing , and then , of course , try to {disfmarker} well , {vocalsound} kind of debug what was wrong , eh , when we do Aurora test on the MSG {pause} particularly , and on the multi - band .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: Uh&#10;Speaker: Professor D&#10;Content: Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="Yes, that's correct. The suggestion is to analyze the noise in the speech databases, understand the causes of degradation, and focus on recognizing phoneme classes instead of individual phonemes. This simpler problem could lead to significant performance improvements, especially in noisy conditions. They also emphasize the importance of using realistic noise conditions in the databases to improve the robustness of speech recognition systems." target="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The signal-dependent modification of cepstral parameters discussed in the meeting transcript is a method similar to cepstral mean subtraction (CMS). However, instead of using a fixed or sliding window mean subtraction, this technique adapts the mean during speech and not during silence. This approach results in a signal-dependent adaptation of cepstral parameters that is close to CMS but has some differences. The primary goal of this modification is to improve the robustness of speech recognition systems, especially in noisy conditions.&#10;&#10;This method focuses on recognizing phoneme classes instead of individual phonemes since many errors occur within phoneme classes. By simplifying the problem and concentrating on distinguishing between phoneme classes rather than specific phonemes, significant performance improvements can be achieved, particularly in noisy environments. Furthermore, using realistic noise conditions in the databases is essential to enhancing the robustness of speech recognition systems.&#10;&#10;Mike Shire's thesis, as mentioned by PhD A and Professor D, suggests that training separate nets under various reverberation conditions could be helpful in diverse acoustic environments. Although the details about driving conditions are not provided in the transcript, this approach could potentially improve speech recognition performance across different acoustic conditions." target=" it . There 's a spectral subtraction style piece {disfmarker} it was basically , you know , Wiener filtering . And then {disfmarker} then there was some p some modification of the cepstral parameters , where they {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah , actually , something that 's close to cepstral mean subtraction . But , uh , the way the mean is adapted {disfmarker} um , it 's signal dependent . I 'm {disfmarker} I 'm , uh So , basically , the mean is adapted during speech and not during silence .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: But it 's very close to {disfmarker} to cepstral mean subtraction .&#10;Speaker: Professor D&#10;Content: But some people have done {vocalsound} {pause} exactly that sort of thing , of {disfmarker} of {disfmarker} and the {disfmarker} I mean it 's not {disfmarker} To {disfmarker} to look in {pause}">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
