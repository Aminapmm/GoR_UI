<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="long" />
  <graph edgedefault="undirected">
    <node id="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." />
    <node id="aker: PhD A&#10;Content: Right . Right . OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: So , this is all pretty early stages .&#10;Speaker: PhD A&#10;Content: I see .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah , yeah , yeah .&#10;Speaker: Professor D&#10;Content: But no , you 're absolutely right . That 's {pause} a good thing to consider .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: There {disfmarker} there is a complication though , and that is if a person turns their back to the {disfmarker} to the PDA , then some of the positional information goes away ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Well , it {disfmarker} it {disfmarker} it does , i it d it does , but the {disfmarker} the {disfmarker} the issue is that {disfmarker} that {disfmarker}&#10;Speaker: PhD A&#10;Content: No ," />
    <node id=" B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: Yeah , it 's timing difference . It - it 's not amplitude ,&#10;Speaker: Postdoc E&#10;Content: Oh yeah ! Oh I agree ! And we use it ourselves .&#10;Speaker: Professor D&#10;Content: right ? S Right .&#10;Speaker: Postdoc E&#10;Content: I mean , I know {disfmarker} I n I know that 's a very important cue .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: But I 'm just {disfmarker} I 'm just saying that the way we 're seated around a table , is not the same with respect to each {disfmarker} to each person with respect to the PDA ,&#10;Speaker: PhD C&#10;Content: No . No . No , no , no .&#10;Speaker: Postdoc E&#10;Content: so we 're gonna have a lot of differences with ref respect to the speaker .&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} That 's fine .&#10;Speaker" />
    <node id="Speaker: PhD C&#10;Content: I {disfmarker} I {disfmarker} Yeah .&#10;Speaker: PhD A&#10;Content: I don't {disfmarker} I don't know ho&#10;Speaker: PhD C&#10;Content: I {disfmarker} I {disfmarker} I think {disfmarker} Sorry . I {disfmarker} I {disfmarker} I think because the the the distance between the two microph eh , microphone , eh , in the PDA is very near . But it 's uh {disfmarker} from my opinion , it 's an interesting idea to {disfmarker} to try to study the binaural eh problem eh , with information , because I {disfmarker} I found difference between the {disfmarker} the speech from {disfmarker} from each micro eh , in the PDA .&#10;Speaker: PhD A&#10;Content: I would guess {disfmarker}&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: Yeah , it 's timing difference . It - it 's not amplitude ,&#10;" />
    <node id="&#10;Content: It was {disfmarker} yeah , it was interesting .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But , the reason why I haven't focused on that as the fir my first concern is because um , I 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . And you can't just always go , &quot; well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up &quot; .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: No , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It has all these mikes and it has a plug - in jack to the PDA .&#10;Speaker: Postdoc E&#10;Content: Interesting .&#10;Speaker: Grad B&#10;Content: But I think {disfmarker}&#10;Speaker: Professor D&#10;Content: The other thing actually , that gets at this a" />
    <node id="Speaker: Professor D&#10;Content: It 's spread out .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Well , let me ask you , if {disfmarker} if both people were over there , it would be less effective than if one was there and one was across , catty - corner ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . The - the {disfmarker} Oh , I 'm sorry ,&#10;Speaker: Postdoc E&#10;Content: No ?&#10;Speaker: Professor D&#10;Content: if they 're right next to one another ?&#10;Speaker: PhD A&#10;Content: If I was {disfmarker} if I was here and Morgan was there and we were both talking , it wouldn't work .&#10;Speaker: Professor D&#10;Content: i i&#10;Speaker: Postdoc E&#10;Content: Next {disfmarker} next one over n over {comment} on this side of the P {disfmarker} PDA .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;" />
    <node id=" any means . I just wanted to point out that {disfmarker} that weakness , that it 's topo topologically impossible to get it perfect for everybody .&#10;Speaker: Professor D&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Grad B&#10;Content: And I think Dan is still working on it . So . He actually {disfmarker} he wrote me about it a little bit , so .&#10;Speaker: Postdoc E&#10;Content: Great . No , I don't mean to discourage that at all .&#10;Speaker: Professor D&#10;Content: I mean , the other thing you can do {disfmarker} uh , if {disfmarker} I mean , i We 're assuming that it would be a big deal just to get somebody {disfmarker} convince somebody to put two microphones in the PDA . But if you h put a third in , {vocalsound} you could put in the other axis . And then you know {disfmarker} then you 're sort of {disfmarker} Yeah , then {disfmarker} then you pretty much could cover {disfmarker}&#10;Speaker: PhD A" />
    <node id="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." />
    <node id=" , OK , @ @ {comment} So , uh , then I guess th the last thing I 'd had on my {disfmarker} my agenda was just to hear {disfmarker} hear an update on {vocalsound} what {disfmarker} what Jose has been doing ,&#10;Speaker: PhD C&#10;Content: Uh - huh . OK .&#10;Speaker: Professor D&#10;Content: so&#10;Speaker: PhD C&#10;Content: I have , eh , {vocalsound} The result of my work during the last days .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Thank you for your information because I {disfmarker} I read . Eh , and the {disfmarker} the last , eh , days , eh , I work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the {disfmarker} the Meeting Recording project .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: And I have , eh , some ideas . Eh , this" />
    <node id=" - two {disfmarker}&#10;Speaker: Grad B&#10;Content: Sure but , h then you have to know that Jose is speaker - one and {disfmarker}&#10;Speaker: PhD A&#10;Content: Why do you have to know his name ?&#10;Speaker: Professor D&#10;Content: OK , so suppose someone says , &quot; well I don't know if I really heard what {disfmarker} uh , what Jose said . &quot;&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And then , Jose responds .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And part of your learning about the dialogue is Jose responding to it . But it doesn't say &quot; Jose &quot; , it says &quot; speaker - five &quot; .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: So {pause} uh {pause} u&#10;Speaker: PhD A&#10;Content: Oh , I see , you wanna associated the word &quot; Jose &quot; in the dialogue with the fact that" />
    <node id="disfmarker} Yeah . But eh I {disfmarker} I {disfmarker} Is my my {disfmarker} my own vision , {vocalsound} of the {disfmarker} of the project .&#10;Speaker: Grad B&#10;Content: So , some sort of {disfmarker} That 's {disfmarker}&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: I {disfmarker} eh the {disfmarker} the Meeting Recorder project , for me , has eh , two {vocalsound} eh , w has eh several parts , several p {vocalsound} objective&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: eh , because it 's a {disfmarker} a great project . But eh , at the first , in the acoustic , eh , eh , parts of the project , eh I think {pause} you eh {disfmarker} we have eh {vocalsound} {pause} two main eh objective . One {disfmarker} one of" />
    <node id=" about some {pause} new proposed work in this area , sort of a separate issue from what the student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who didn't attend to {pause} listen to . And in that uh , regard , I thought we definitely w will need {disfmarker} it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . So this {disfmarker} this meeting is one of them , although I 'm not sure I can participate if I {disfmarker} You know , I would feel very strange being part of a meeting that you were then analysing later for things like summarization .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um ," />
    <node id=" uh , agenda items that they were interested in and I 'll {disfmarker} I 'll take the role of organizing them uh , into {disfmarker} into the agenda ,&#10;Speaker: Postdoc E&#10;Content: OK . Sure .&#10;Speaker: Professor D&#10;Content: but I 'd be very pleased to have everyone else {vocalsound} completely make up the agenda . I 've no desire to {disfmarker} {vocalsound} to make it up , but if {disfmarker} if no one 's told me things , then I 'm just proceeding from my {disfmarker} my guesses , and {disfmarker} and uh , and i ye yeah , I {disfmarker} I 'm sorry it ended up with your out your time to {disfmarker} I mean , I 'm just always asking Jose what he 's doing , you know , and {disfmarker} {vocalsound} and so it 's {disfmarker} {pause} There 's uh , there 's obviously other things going on .&#10;Speaker: Grad B&#10;Content: Mm - hmm" />
    <node id=" your clothing .&#10;Speaker: Grad B&#10;Content: in terms of {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah !&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Hats ?&#10;Speaker: Grad B&#10;Content: In terms of the research {pause} th research , it 's really {disfmarker} it 's whatever the person who is doing the research wants to do .&#10;Speaker: PhD A&#10;Content: Shirts .&#10;Speaker: Grad B&#10;Content: So if {disfmarker} if Jose is interested in that , that 's great . But if {disfmarker} if he 's not , that 's great too .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Um , I {disfmarker} i I {disfmarker} i I would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there .&#10;Speaker: Grad B&#10;Content: Catch some tea" />
    <node id="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." />
    <node id="&#10;Content: OK . &#10;Speaker: Professor D&#10;Content: Uh , I think {disfmarker} you don't wanna have their full name to be uh , listed .&#10;Speaker: Postdoc E&#10;Content: Yeah , and {disfmarker} and in the form that they sign , it does say &quot; your first name may arise in the course of the meetings &quot; .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And so {disfmarker}&#10;Speaker: PhD A&#10;Content: Well {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah . So again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , &quot; Frank said this &quot; and then you wanna connect it to something later , you 've gotta have this part where that 's &quot; Frank colon &quot; .&#10;Speaker: Postdoc E&#10;Content: Or &quot; your name &quot; .&#10;Speaker: Grad B&#10;Content: Yeah , shoot !&#10;Speaker: Professor D&#10;Content: Right ?&#10;Speaker: Postdoc E&#10;Content: Yeah , and {disfmarker} and {" />
    <node id="aker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But that {disfmarker}&#10;Speaker: Postdoc E&#10;Content: That 'd be very efficient .&#10;Speaker: Grad B&#10;Content: The p It 's a good point , &quot; which {disfmarker} what do you do for discourse tracking ? &quot;&#10;Speaker: PhD C&#10;Content: Because y y you don't know to know , eh {disfmarker} you don't need to know what i what is the iden identification of the {disfmarker} of the speakers . You only eh want to know {disfmarker}&#10;Speaker: Grad B&#10;Content: Hmm . For {disfmarker} for acoustics you don't but for discourse you do .&#10;Speaker: Professor D&#10;Content: Well , you do .&#10;Speaker: PhD C&#10;Content: Ah , for discourse , yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . If {disfmarker} if {disfmarker} if {disfmarker} if someone says , uh , &quot; what {disfmarker} what is Jose" />
    <node id=" D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So you 're ignoring overlapping events unless they 're speech with speech .&#10;Speaker: PhD C&#10;Content: Yeah , be Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's fine .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: &quot; Why ? Why ? What 's the reason ? &quot; because {pause} i it 's the first study . the first&#10;Speaker: Professor D&#10;Content: Oh , no {disfmarker} no , it 's a perfectly sensible way to go . We just wondered {disfmarker} trying to understand what {disfmarker} what you were doing .&#10;Speaker: Postdoc E&#10;Content: We 're just&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Yeah cuz you 've talked about other overlapping events in the past .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content:" />
    <node id=" I wanted to make the point that {disfmarker} that discourse is gonna be more than just looking at a transcript .&#10;Speaker: Grad B&#10;Content: Yeah , ab absolutely . Oh , yeah , sure .&#10;Speaker: Postdoc E&#10;Content: It 's gonna be looking at a t You know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this {disfmarker} confronting this problem .&#10;Speaker: PhD A&#10;Content: Maybe we should just not allow anybody to do research on discourse ,&#10;Speaker: Postdoc E&#10;Content: So .&#10;Speaker: PhD A&#10;Content: and then , we wouldn't have to worry about it .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Yeah , we should just market it to non - English speaking countries .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Uh , maybe we should only have meetings between people who don't know one another and who are also amnesiacs who don't know their own name .&#10;Speaker: Grad B" />
    <node id=": PhD A&#10;Content: Well , one thing to to take into consideration is w are there any um {disfmarker} For example , the people who are funding this work , they want this work to get out and be useful for discourse .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: If we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , depending on how much editing we do , you might be able to {pause} still have it useful . because for discourse you don't need the audio . Right ? So you could bleep out the names in the audio .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: and use the anonymized one through the transcript .&#10;Speaker: PhD A&#10;Content: But if you release both {disfmarker}&#10;Speaker: Professor D&#10;Content: Uh .&#10;Speaker: Postdoc E&#10;Content: Excuse me . We {disfmarker} we do need audio for discourse .&#10;Speaker" />
    <node id="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." />
    <node id="aker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD F&#10;Content: It has to be a {disfmarker} a pre - existing meeting , {pause} like a meeting that would otherwise happen anyway .&#10;Speaker: Professor D&#10;Content: so&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Yeah , yeah .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: So I was {disfmarker} I was thinking more in terms of talking to professors uh , and {disfmarker} and {disfmarker} and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their {disfmarker} hold their meeting down here .&#10;Speaker: PhD F&#10;Content: That 's I think what we {disfmarker} and I agree with .&#10;Speaker: Postdoc E&#10;Content: Oh , interesting !&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Oh , I see . Oh ," />
    <node id=" mean to summarize ,&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {disfmarker} rather we should have different meetings by the same group but hopefully that have different summaries . And then we need a couple that {disfmarker} of {disfmarker} {pause} We don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .&#10;Speaker: Grad B&#10;Content: Yeah , we have a lot of overlap between this meeting and the morning meeting .&#10;Speaker: Professor D&#10;Content: S So {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: See , I 've never listened to the data for the front - end {pause} meeting .&#10;Speaker: Grad B&#10;Content: Yeah , we {disfmarker} we 've only had three .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: PhD F&#10;Content: OK . But maybe that 's enough . So , in general , I was thinking more data" />
    <node id=" As many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . I 'd like to have many different speakers . So , um I think I would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and {disfmarker} and uh ,&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: I mean , sure , if we can get more from them , fine ,&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people .&#10;Speaker: PhD F&#10;Content: Yeah , I definitely agree with that .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Definitely .&#10;Speaker: PhD C&#10;Content: Yeah" />
    <node id="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion." />
    <node id=" for things like summarization .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um , and then there are some others that menti that Morgan mentioned , like the front - end meeting {pause} and maybe a networking {pause} group meeting .&#10;Speaker: Grad B&#10;Content: Right . Yep . Yeah , we 're {disfmarker} we 're hoping that they 'll let us start recording regularly .&#10;Speaker: PhD F&#10;Content: So {disfmarker} So if that were the case then I think we 'd have enough .&#10;Speaker: Grad B&#10;Content: So . Mm - hmm .&#10;Speaker: PhD F&#10;Content: But basically , for anything where you 're trying to get a summarization of some kind of meeting {disfmarker} {comment} {pause} meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we didn't really have a good grasp on what does it mean to summarize ,&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {disfmarker} rather" />
    <node id="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." />
    <node id="aker: PhD C&#10;Content: OK ? It 's the control set . It 's pure si pure silence {comment} with the {disfmarker} with the machine on the {disfmarker} on the roof .&#10;Speaker: Professor D&#10;Content: What you {disfmarker} Well {disfmarker} w {vocalsound} I {disfmarker} I think what you m I think what you mean {vocalsound} is that it 's nonspeech segments that don't have impulsive noises .&#10;Speaker: Grad B&#10;Content: With the fan .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Right ? Cuz you 're calling {disfmarker} what you 're calling &quot; event &quot; is somebody coughing {vocalsound} or clicking , or rustling paper , or hitting something , which are impulsive noises .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But steady - state noises are part of the background .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Which , are being , included" />
    <node id=" are part of the background .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Which , are being , included in that . Right ?&#10;Speaker: PhD C&#10;Content: h here yet , yet I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I think {disfmarker} I {disfmarker} I think , eh , there are {disfmarker} that {disfmarker} some kind of noises that , eh , don't {disfmarker} don't wanted to {disfmarker} to be in that , eh , in that control set .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So it 's like a signal - noise situation . Yeah .&#10;Speaker: Professor D&#10;Content: Well {disfmarker} Yeah .&#10;Speaker: PhD C&#10;Content: But I prefer , I prefer at {disfmarker} at the first , eh , the {disfmarker} the silence with eh , this eh this kind of the {disfmarker}" />
    <node id=" with something overlapping , which could be speech but doesn't need to be .&#10;Speaker: PhD C&#10;Content: No , no , es especially {pause} eh , overlapping speech {pause} from , eh , different eh , eh , speaker . Eh {disfmarker}&#10;Speaker: Professor D&#10;Content: No , but there 's {disfmarker} but , I think she 's saying &quot; Where do you {disfmarker} In these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? &quot;&#10;Speaker: PhD C&#10;Content: Ah !&#10;Speaker: Professor D&#10;Content: Which category do you put that in ?&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's right . That 's my question .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah , he here I {disfmarker} I put eh speech from eh , from , eh , one speaker {pause} without , eh , eh , any {disfmarker} any {disfmarker} any events more .&#10;Speaker: Postdoc E&#10;Content: Oh !&#10;Speaker: Professor D&#10;" />
    <node id=" 've talked about other overlapping events in the past .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So , this is {disfmarker} this is {disfmarker} a subset .&#10;Speaker: PhD C&#10;Content: Yeah . In the {disfmarker} in the future , the {disfmarker} the idea is to {disfmarker} to extend {pause} the class ,&#10;Speaker: PhD A&#10;Content: Is {disfmarker} is {disfmarker}&#10;Speaker: PhD C&#10;Content: to consider all the {disfmarker} all the information , you {disfmarker} you mentioned before&#10;Speaker: Professor D&#10;Content: Yeah . Yeah , I {disfmarker} I don't think we were asking for that .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: but eh , the {disfmarker} the first idea {disfmarker} Because eh , I don't know {pause} what hap what will happen {comment} with the study .&#10;Speaker: Professor D" />
    <node id=" PhD A&#10;Content: Mmm .&#10;Speaker: PhD C&#10;Content: And my idea is eh , it would be interesting to {disfmarker} to have eh , {vocalsound} a control set . And my control set eh , will be the eh , silence , silence without eh , any {disfmarker} any noise .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: Which means that we 'd still {disfmarker} You 'd hear the {disfmarker}&#10;Speaker: Grad B&#10;Content: Yeah , fans .&#10;Speaker: PhD C&#10;Content: Yeah , acoustic with this . {comment} With {disfmarker} with , yeah , the background .&#10;Speaker: Postdoc E&#10;Content: Yeah . {comment} That 's interesting . This is like a ground level , with {disfmarker} It 's not it 's not total silence .&#10;Speaker: PhD C&#10;Content: Eh , I {disfmarker} I mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh ,&#10;Speaker:" />
    <node id="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA." />
    <node id=" I mean , we can we 'll be {disfmarker} all of this is there for us to study .&#10;Speaker: Grad B&#10;Content: Then they 're much broader . Yeah , we can do whatever we want .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But {disfmarker} {vocalsound} but {disfmarker} but the thing is , uh , one of the {disfmarker} at least one of the things I was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a PDA .&#10;Speaker: Grad B&#10;Content: Whatever you 're interested in .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: That 's what I was asking about , what are the constraints ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Right . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Well , that 's {disfmarker}" />
    <node id="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" />
    <node id="vocalsound} eh the , nnn {disfmarker} the {disfmarker} {nonvocalsound} the system {pause} eh will have two models .&#10;Speaker: Postdoc E&#10;Content: Clustering .&#10;Speaker: PhD C&#10;Content: A model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh {disfmarker} the mark , the change and another {disfmarker} another model will @ @ {pause} or several models , to try s but {disfmarker} eh several model eh robust models , sample models to try to classify the difference class .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: I 'm {disfmarker} I 'm {disfmarker} I 'm sorry , I didn't understand you {disfmarker} what you said . What {disfmarker} what model ?&#10;Speaker: Postdoc E&#10;Content: &#10;Speaker: PhD C&#10;Content: Eh , the {disfmarker} the classifiers of the of the n to detect the different class to the different" />
    <node id="marker} the {disfmarker} the front - end approach to classify eh , the different , eh , frames of each class {pause} eh and what is the {disfmarker} the , nnn , nnn , nnn , eh , what is the , the error {pause} eh , of the data&#10;Speaker: Grad B&#10;Content: Supervised clustering . Mm - hmm .&#10;Speaker: PhD C&#10;Content: This is the {disfmarker} the eh , first idea&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: and the second {pause} is try to {disfmarker} eh , to use {pause} some ideas eh , similar to the linear discriminant analysis .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Eh ? Eh , similar , because the the idea is to {disfmarker} to study {pause} what is the contribution of eh , each parameter to the process of classify correctly the different {disfmarker} the different parameters .&#10;Speaker: Grad B&#10;Content: Mm" />
    <node id=" , each parameter to the process of classify correctly the different {disfmarker} the different parameters .&#10;Speaker: Grad B&#10;Content: Mm - hmm . What sort of classifier ar ?&#10;Speaker: PhD C&#10;Content: Eh , the {disfmarker} the {disfmarker} the classifier is {disfmarker} nnn by the moment is eh {disfmarker} is eh , similar , nnn , that the classifier used eh , in a quantifier {disfmarker} vectorial quantifier is eh , used to {disfmarker} to eh , some distance {pause} to {disfmarker} to put eh , a vector eh , in {disfmarker} in a class different .&#10;Speaker: Grad B&#10;Content: Unimodal ?&#10;Speaker: PhD C&#10;Content: Is {disfmarker} Yeah ? W with a model , is {disfmarker} is only to cluster using a eh , @ @ or a similarity .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: So is it just one cluster per" />
    <node id=" interesting question .&#10;Speaker: PhD A&#10;Content: I mean , is {disfmarker} is that violation of the {disfmarker}&#10;Speaker: PhD C&#10;Content: Oh . No . Yeah .&#10;Speaker: Professor D&#10;Content: I mean , I think you wanna know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two .&#10;Speaker: PhD A&#10;Content: Mm - hmm&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But , we don't n even know yet what the effect of detecting {disfmarker} having the ability to detect overlaps is . You know , maybe it doesn't matter too much .&#10;Speaker: PhD A&#10;Content: Right . Right . OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D" />
    <node id=" Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: I 'm {disfmarker} I {disfmarker} what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of {disfmarker} of central corp things that people generally use corpora for and which are , you know , used in computational linguistics .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: That 's {disfmarker} that 's my point . Which {disfmarker} which includes both top - down and bottom - up .&#10;Speaker: PhD C&#10;Content: It 's difficult .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK , well , i i let 's {disfmarker} let 's see what we can get . I mean , it {disfmarker} it {disfmarker} I think that if we 're aiming at {disfmarker} at" />
    <node id="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." />
    <node id=": Yeah .&#10;Speaker: PhD F&#10;Content: Um , at the previous {disfmarker} at last week 's meeting , this meeting I was griping {vocalsound} about wanting to get more data and I {disfmarker} I talked about this with Jane and Adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new {disfmarker} this new student di does wanna work with us ,&#10;Speaker: PhD A&#10;Content: Well , great .&#10;Speaker: PhD F&#10;Content: th the guy that was at the last meeting .&#10;Speaker: PhD A&#10;Content: Great .&#10;Speaker: PhD F&#10;Content: And he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time ,&#10;Speaker: PhD A&#10;Content: What a deal .&#10;Speaker: PhD F&#10;Content: uh {disfmarker} Yeah .&#10;Speaker: Grad B&#10;Content: And what 's he interested in , specifically ?&#10;Speaker: PhD F&#10;Content: So he 's {disfmark" />
    <node id=" you mean .&#10;Speaker: Professor D&#10;Content: You actually don't .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Yea - yeah yeah , you actually don't really even need any fancy microphone .&#10;Speaker: Postdoc E&#10;Content: Which one did you mean ?&#10;Speaker: Professor D&#10;Content: You d You don't ne it doesn't {disfmarker} you just need some microphone , somewhere .&#10;Speaker: Grad B&#10;Content: Ye - Yeah . Yep .&#10;Speaker: PhD F&#10;Content: You can use found data .&#10;Speaker: Grad B&#10;Content: Tape recorder .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: You {disfmarker} you can .&#10;Speaker: Professor D&#10;Content: You need some microphone ,&#10;Speaker: PhD F&#10;Content: You can&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content" />
    <node id="aker: PhD F&#10;Content: You can&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: but I mean {disfmarker}&#10;Speaker: PhD F&#10;Content: use {disfmarker} Um , but I think that any {pause} data that we spend a lot of effort {nonvocalsound} to collect ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: you know , each person who 's interested in {disfmarker} I mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: And {disfmarker} So in my case , um , I think there w there is enough data for some kinds of projects and not enough for others .&#10;Speaker: Grad B&#10;Content: Not enough for others , right .&#10;Speaker: PhD F&#10;Content: And so {non" />
    <node id=" PhD F&#10;Content: and I guess it depends of what kind of audience you 're talking to , but {disfmarker} {vocalsound} You know , I personally {nonvocalsound} would not want a {nonvocalsound} CD {comment} of my meeting ,&#10;Speaker: Grad B&#10;Content: Mmm . Of the meeting ?&#10;Speaker: PhD F&#10;Content: but {vocalsound} maybe {disfmarker} yeah , {pause} maybe you 're&#10;Speaker: Professor D&#10;Content: If you 're having some planning meeting of some sort and uh you 'd like {disfmarker}&#10;Speaker: PhD F&#10;Content: right . {comment} Right . Right .&#10;Speaker: PhD A&#10;Content: Oh , that 's a good idea .&#10;Speaker: Grad B&#10;Content: It 'd be fun . I think it would just be fun , you know , if nothing else , you know .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad B&#10;Content: It 's a" />
    <node id="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." />
    <node id=" if they 're all normalized .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Um , but {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , using something simpler first I think is probably fine .&#10;Speaker: Professor D&#10;Content: Well , this isn't tru if {disfmarker} if {disfmarker} if you really wonder what different if {disfmarker} if {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Decision tree .&#10;Speaker: PhD C&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah , then a decision tree is really good , but the thing is here he 's {disfmarker} he 's not {disfmarker} he 's not like he has one you know , a bunch of very distinct variables , like pitch and this {disfmarker} he 's talking about , like , a all these cepstral coefficients , and so forth ,&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C" />
    <node id="er} you can't eh , eh put up with your hand {comment} in the different parameter ,&#10;Speaker: Grad B&#10;Content: Right , you can't analyse it .&#10;Speaker: PhD C&#10;Content: but eh {disfmarker} If you use a neural net is {disfmarker} is a good idea , but eh you don't know what happened in the interior of the neural net .&#10;Speaker: Professor D&#10;Content: Well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: It 's hard to {disfmarker} w w what you {disfmarker} It 's hard to tell on a neural net is what 's going on internally .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Um , but" />
    <node id="aker: PhD C&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: And so {vocalsound} I {disfmarker} i again , if you take a few of these things that are {disfmarker} are {vocalsound} prob um {comment} {pause} promising features and look at them in pairs , {vocalsound} uh , I think you 'll have much more of a sense of &quot; OK , I now have {disfmarker} {vocalsound} uh , doing a bunch of these analyses , I now have ten likely candidates . &quot; And then you can do decision trees or whatever to see how they combine .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: I 've got a question .&#10;Speaker: PhD C&#10;Content: Yeah . This&#10;Speaker: Postdoc E&#10;Content: Interesting .&#10;Speaker: PhD C&#10;Content: Sorry .&#10;Speaker: Postdoc E&#10;Content: Hmm .&#10;Speaker: PhD C&#10;Content: but eh , eh {vocalsound} eh eh eh I don't know it is the first eh way to {d" />
    <node id=" in preparing the data ,&#10;Speaker: Professor D&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: if you have a choice between people who are pr more proficient in {disfmarker} {nonvocalsound} um , i more fluent , more {disfmarker} more close to being academic English , then it would seem to me to be a good thing .&#10;Speaker: Professor D&#10;Content: I guess {disfmarker} I maybe {disfmarker} Hmm . I&#10;Speaker: Postdoc E&#10;Content: Because otherwise y you don't have the ability to have {disfmarker} Uh , so if {disfmarker} if you have a bunch of idiolects that 's the worst possible case . If you have people who are using English as a {disfmarker} as an interlanguage because they {disfmarker} they don't {disfmarker} uh , they can't speak in their native languages and {disfmarker} but their interlanguage isn't really a match to any existing , uh , language model ,&#10;Speaker: Professor D&#10;Content" />
    <node id="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." />
    <node id=": Is it ?&#10;Speaker: Postdoc E&#10;Content: I mean , it {disfmarker} it {disfmarker} it {disfmarker} The other direction is fast , but this direction is really slow .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: Well , especially because I 'm generating a clone , also .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So . And that takes a while .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah , OK .&#10;Speaker: PhD A&#10;Content: Generating a clone ?&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's a good point .&#10;Speaker: Grad B&#10;Content: Two copies .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Oh !&#10;Speaker: Grad B&#10;Content: One offsite , one onsite .&#10;Speaker: PhD A&#10;Content: Oh ! Hunh !&#10;Speaker: Professor D&#10;Content:" />
    <node id=": One offsite , one onsite .&#10;Speaker: PhD A&#10;Content: Oh ! Hunh !&#10;Speaker: Professor D&#10;Content: S&#10;Speaker: Postdoc E&#10;Content: Now , what will uh {disfmarker} Is the plan to g {pause} to {disfmarker} So {pause} stuff will be saved , it 's just that you 're relocating it ? I mean , so we 're gonna get more disk space ? Or did I {disfmarker} ?&#10;Speaker: Grad B&#10;Content: No , the {disfmarker} the {disfmarker} these are the P - files from Broadcast News , which are regeneratable {disfmarker} regeneratable&#10;Speaker: Postdoc E&#10;Content: OK . Oh , good . I see .&#10;Speaker: Grad B&#10;Content: um , if we really need to , but we had a lot of them . And {disfmarker} for the full , uh , hundred forty hour sets .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: And so they {disfmarker} they were two gig" />
    <node id="&#10;Speaker: PhD A&#10;Content: Wow !&#10;Speaker: PhD C&#10;Content: Oh .&#10;Speaker: Postdoc E&#10;Content: Yeah , the archiving m {pause} program does take a long time .&#10;Speaker: Grad B&#10;Content: And {disfmarker} and {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yep . And so one That {disfmarker} that will be done , like , in about two hours . And so uh , {vocalsound} at that point we 'll be able to record five more meetings . So .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: One thing {disfmarker} The good news about that {disfmarker} that is that once {disfmarker} once it 's archived , it 's pretty quick to get back .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Is it ?&#10;Speaker: Postdoc E&#10;Content: I mean , it {disfmarker} it {disfmarker} it" />
    <node id="} {pause} There 's uh , there 's obviously other things going on .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: Oh , it 's not a problem . Not a problem . Yeah . I just {disfmarker} I just couldn't do it in two minutes .&#10;Speaker: Grad B&#10;Content: How will we {disfmarker} how would the person who 's doing the transcript even know who they 're talking about ? Do you know what I 'm saying ?&#10;Speaker: PhD A&#10;Content: &quot; The person who 's doing the transcript {disfmarker} &quot; {comment} The IBM people ?&#10;Speaker: Grad B&#10;Content: Yeah . I mean , so so {disfmarker} how is that information gonna get labeled anyway ?&#10;Speaker: Postdoc E&#10;Content: How do you mean , who {disfmarker} what they 're {disfmarker} who they 're talking about ?&#10;Speaker: Grad B&#10;Content: I mean , so if I 'm saying in a meeting , &quot; oh and Bob , by the way , wanted" />
    <node id=" not yet sat down with {disfmarker} been able to get that error message in a point where I can sit down and find out where it 's occurring in the code .&#10;Speaker: PhD A&#10;Content: Next time you get it maybe we should write it down .&#10;Speaker: Grad B&#10;Content: Yep , we will . One of these days .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Was it a pause , or {disfmarker} ? OK . Was it on &quot; pause &quot; or something ?&#10;Speaker: Grad B&#10;Content: No .&#10;Speaker: Postdoc E&#10;Content: OK . Don't know .&#10;Speaker: Professor D&#10;Content: So uh {disfmarker} so the uh , the new procedural change that just got suggested , which I think is a good idea is that um , we do the digit recordings at the end . And that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and don't have the time , uh , then they can run off . It 'll mean we 'll get somewhat fewer uh" />
    <node id="Speaker: Grad B&#10;Content: OK ,&#10;Speaker: PhD F&#10;Content: That 's looks strange .&#10;Speaker: Grad B&#10;Content: now we 're on and it seems to be working .&#10;Speaker: Postdoc E&#10;Content: Oh there we go .&#10;Speaker: PhD C&#10;Content: One two three four five six&#10;Speaker: PhD A&#10;Content: That is weird .&#10;Speaker: Postdoc E&#10;Content: This looks good .&#10;Speaker: PhD A&#10;Content: It 's like when it 's been sitting for a long time or something .&#10;Speaker: Grad B&#10;Content: So , I mean {disfmarker} I don't know what it is . But all {disfmarker} all I know is that it seems like every time I am up here after a meeting , and I start it , it works fine . And if I 'm up here and I start it and we 're all sitting here waiting to have a meeting , it gives me that error message and I have not yet sat down with {disfmarker} been able to get that error message in a point where I can sit down and find out where it '" />
    <node id="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." />
    <node id=" {disfmarker} uh , um , question . Well , Morgan , you were mentioning that Mari may not use the k equipment from IBM if they found something else , cuz there 's a {disfmarker}&#10;Speaker: Professor D&#10;Content: They 're {disfmarker} they 're {disfmarker} yeah , they 're d they 're uh {disfmarker} assessing whether they should do that or y do something else , hopefully over the next few weeks .&#10;Speaker: PhD F&#10;Content: Cuz I mean , one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up a room in the linguistics department ? And {disfmarker} and I mean , there {disfmarker} there may be a lot more {disfmarker} or {disfmarker} or in psych , or in comp wherever , in another building where we could um , record people there . I think we 'd have a better chance&#10;Speaker: Grad B&#10;Content: I think we 'd need a real motivated partner to do that . We 'd need to find someone on campus who" />
    <node id=" , &quot; is Mari gonna use the equipment ? &quot; I mean , how would you say that ?&#10;Speaker: Postdoc E&#10;Content: Yeah ?&#10;Speaker: PhD A&#10;Content: I mean , you have to really think , you know , about what you 're saying bef&#10;Speaker: Grad B&#10;Content: if you wanted to anonymize .&#10;Speaker: PhD C&#10;Content: Yeah . {vocalsound} Yeah , is {disfmarker}&#10;Speaker: Professor D&#10;Content: &quot; Is you know who up in you know where ? &quot;&#10;Speaker: PhD A&#10;Content: Yeah . Yeah .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Right ? Use the {disfmarker}&#10;Speaker: PhD A&#10;Content: I think it would be really hard if we made a policy where we didn't say names , plus we 'd have to tell everybody else .&#10;Speaker: Grad B&#10;Content: Yeah , darn ! I mean , what I was gonna say is that the other option is that we could bleep out the names .&#10;Speaker: Postdoc E&#10;Content: Well , it" />
    <node id="&#10;Content: Grads and professors , fine .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: Professor D&#10;Content: Oh , you age - ist !&#10;Speaker: Grad B&#10;Content: What 's that ? Well , age - ist . {comment} The &quot; eighteen &quot; is because of the consent form .&#10;Speaker: Postdoc E&#10;Content: Age - ist .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right , Yeah .&#10;Speaker: Grad B&#10;Content: We 'd hafta get {disfmarker} find their parent to sign for them .&#10;Speaker: PhD C&#10;Content: &quot; Age - ist &quot; . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Yes .&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's true .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: PhD F&#10;Content: I have a {disfmarker} uh , um , question . Well , Morgan , you were mentioning that Mari may not use the k equipment from IBM if they found" />
    <node id="Speaker: Grad B&#10;Content: I think we 'd need a real motivated partner to do that . We 'd need to find someone on campus who was interested in this .&#10;Speaker: PhD F&#10;Content: Right , but {disfmarker} Right . But if there were such a {disfmarker} I mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: So it 's just a just a thought if they end up not using the {disfmarker} the hardware .&#10;Speaker: Professor D&#10;Content: Well , the other thing {disfmarker} Yeah , I mean the other thing that I was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Uh . But . Um , and {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , I know that space" />
    <node id=" D&#10;Content: Uh . But . Um , and {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , I know that space is really scarce on {disfmarker} at least in CS . You know , to {disfmarker} to actually find a room that we could use regularly might actually be very difficult .&#10;Speaker: Professor D&#10;Content: Uh {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: But you may not need a separate room , you know ,&#10;Speaker: Grad B&#10;Content: That 's true .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something {disfmarker}&#10;Speaker: Grad B&#10;Content: True . Mm - hmm . Yep .&#10;Speaker: Professor D&#10;Content: Well , maybe John would let us put it into the phonology lab or something .&#10;Speaker: PhD F&#10;Content: Huh .&#10;Speaker: Grad B&#10;" />
    <node id="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings." />
    <node id=" and , eh , hierarchical clustering process . I {disfmarker} I {disfmarker} I put , eh , eh , for each frame {nonvocalsound} a label indicating what is th the type , what is the class , eh , which it belong .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Eh , I mean , the class you will {nonvocalsound} overlapping speech &quot; overlapping &quot; is a class , eh , &quot; speech &quot; {nonvocalsound} @ @ the class {pause} that 's&#10;Speaker: Grad B&#10;Content: Nonspeech .&#10;Speaker: PhD A&#10;Content: These will be assigned by hand ?&#10;Speaker: PhD C&#10;Content: a I {disfmarker} I {disfmarker} I ha I h I {disfmarker} I put the mark by hand ,&#10;Speaker: PhD A&#10;Content: Based on the {disfmarker} Uh - huh .&#10;Speaker: PhD C&#10;Content: because , eh , {vocalsound} my idea is , eh , in {disfmarker} in the first" />
    <node id="aker: PhD C&#10;Content: because , eh , {vocalsound} my idea is , eh , in {disfmarker} in the first session , I need , eh , {pause} I {disfmarker} I need , eh , to be sure that the information eh , that , eh , I {disfmarker} I will cluster , is {disfmarker} is right . Because , eh , eh , if not , eh , I will {disfmarker} I will , eh , return to the speech file to analyze eh , what is the problems ,&#10;Speaker: Grad B&#10;Content: Well , training , and validation . Sure . Mm - hmm .&#10;Speaker: PhD C&#10;Content: eh . And {vocalsound} I {disfmarker} I 'd prefer {disfmarker} I would prefer , the to {disfmarker} to have , eh , this labeled automatically , but , eh , eh , fro th I need truth .&#10;Speaker: PhD A&#10;Content: You need truth . Hmm .&#10;Speaker: Grad B&#10;Content: Yeah , but this is what you 're starting with .&#10;Speaker:" />
    <node id="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning." />
    <node id="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." />
    <node id="uates um in computer science uh , have language skills that make , you know {disfmarker} that their {disfmarker} their fluency and writing skills are not so strong .&#10;Speaker: Professor D&#10;Content: Oh ! You 're not talking about foreign language at all .&#10;Speaker: Grad B&#10;Content: Yeah . Yeah , just talking about .&#10;Speaker: Professor D&#10;Content: You 're just talking about {disfmarker}&#10;Speaker: Postdoc E&#10;Content: Well , e I just think ,&#10;Speaker: Grad B&#10;Content: We all had the same thought .&#10;Speaker: Postdoc E&#10;Content: but you know , it 's like when you get into the graduate level , uh , no problem . I mean , I 'm not saying accents .&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah , then we 're completely gone .&#10;Speaker: Postdoc E&#10;Content: I 'm say I 'm saying fluency .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's {disf" />
    <node id=" Oh , interesting !&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Oh , I see . Oh , interesting !&#10;Speaker: Professor D&#10;Content: Uh , that 's the first point . The second point is um I think that for some time now , going back through BeRP I think that we have had speakers that we 've worked with who had non - native accents and I th I think that {disfmarker}&#10;Speaker: Postdoc E&#10;Content: Oh , oh . I 'm not saying accents . u The accent 's not the problem .&#10;Speaker: Professor D&#10;Content: Oh , OK .&#10;Speaker: Postdoc E&#10;Content: No , it 's more a matter of uh , proficiency , e e just simply fluency .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: I mean , I deal with people on {disfmarker} on campus who {disfmarker} I think sometimes people , undergraduates um in computer science uh , have language skills that make , you know {disfmarker} that their {disfmarker} their fluency" />
    <node id=" doing each time .&#10;Speaker: PhD A&#10;Content: Yeah , yeah .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: Well , I was thinking that it must get kind of boring for the people who are gonna have to transcribe this&#10;Speaker: Postdoc E&#10;Content: and I {disfmarker}&#10;Speaker: PhD A&#10;Content: They may as well throw in some interesting intonations .&#10;Speaker: Grad B&#10;Content: Well , except ,&#10;Speaker: Postdoc E&#10;Content: I like your question intonation .&#10;Speaker: Grad B&#10;Content: yeah .&#10;Speaker: Postdoc E&#10;Content: That 's very funny . I haven't heard that one .&#10;Speaker: Grad B&#10;Content: We have the transcript . We have the actual numbers they 're reading , so we 're not necessarily depending on that . OK , I 'm gonna go off ." />
    <node id="disfmarker} can I say the other aspect of this from my perspective which is that um , there 's {disfmarker} there 's this {disfmarker} this issue , you have a corpus out there , it should be used for {disfmarker} for multiple things cuz it 's so expensive to put together .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: Postdoc E&#10;Content: And if people want to approach {disfmarker} Um , i so I know {pause} e e {pause} You know this {disfmarker} The idea of computational linguistics and probabilistic grammars and all may not be the focus of this group ,&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: Postdoc E&#10;Content: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data ,&#10;Speaker: Professor D&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Postdoc" />
    <node id=" {disfmarker} but their interlanguage isn't really a match to any existing , uh , language model ,&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: Postdoc E&#10;Content: this is the worst case scenario .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Well , that 's pretty much what you 're going to have in the networking group .&#10;Speaker: Postdoc E&#10;Content: And {disfmarker}&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: because {disfmarker} because they {disfmarker} most {disfmarker} the network group is almost entirely Germans and Spaniards .&#10;Speaker: Postdoc E&#10;Content: Well Oh . But the thing is , I think that these people are of high enough level in their {disfmarker} in their language proficiency that {disfmarker}&#10;Speaker: Professor D&#10;Content: I see .&#10;Speaker: Postdoc E&#10;Content: And I 'm not objecting to accents .&#10;Speaker: Professor D&#10;Content: OK .&#10;" />
    <node id="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." />
    <node id=" really what makes this corpus powerful .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Special ? Yep .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I agree .&#10;Speaker: PhD F&#10;Content: Otherwise , you know , lots of other sites can propose {disfmarker} individual studies , so {disfmarker}&#10;Speaker: Professor D&#10;Content: Uh but I {disfmarker} I think that the uh {vocalsound} i We can't really underestimate the difficulty {disfmarker} shouldn't really u underestimate the difficulty of getting a setup like this up .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: And so , {disfmarker} uh it took quite a while to get that together and to say , &quot; Oh , we 'll just do it up there , &quot; {disfmarker}&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: If you 're talking about something simple , where" />
    <node id=" , it 's not necessarily true that we need all of the corpus to satisfy all of it . So , a a as per the example that we wanna have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings But we can also have another part that 's , uh , just one or two meetings of each of a {disfmarker} of a range of them and that 's OK too . Uh , i We realized in discussion that the other thing is , what about this business of distant and close microphones ? I mean , we really wanna have a substantial amount recorded this way , that 's why we did it . But {pause} what about {disfmarker} For th for these issues of summarization , a lot of these higher level things you don't really need the distant microphone .&#10;Speaker: PhD F&#10;Content: Right , I mean , I c I think there 's {disfmarker}&#10;Speaker: Grad B&#10;Content: And you don't really need the close microphone , you mean .&#10;Speaker: Professor D&#10;Content: You actually don't .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker:" />
    <node id=" Yeah , but {disfmarker} I think if we {disfmarker} if we wanna just record with the tabletop microphones , that 's easy .&#10;Speaker: PhD C&#10;Content: Oh - yeah .&#10;Speaker: Grad B&#10;Content: Right ? That 's very easy ,&#10;Speaker: PhD C&#10;Content: Ye - Yeah , yeah .&#10;Speaker: Grad B&#10;Content: but that 's not the corpus that we 're collecting .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . We realized that , um , when we were talking about this that , OK , there 's these different things that we want to do with it . So , um , it 's true that we wanna be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . But on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . So , a a as per the example that we wanna have" />
    <node id="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." />
    <node id="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." />
    <node id=" I need t true eh , silence for that , because my {disfmarker} my idea is to {disfmarker} to study the nnn {disfmarker} the {disfmarker} {vocalsound} the set of parameters eh , what , eh , are more m more discriminant to eh , classify .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: the overlapping zones in cooperation with the speech {pause} eh zones . The idea is {pause} to eh {disfmarker} to use {disfmarker} eh , I 'm not sure to {disfmarker} eh yet , but eh my idea is to use a {disfmarker} a cluster {pause} {vocalsound} eh algorithm or , nnn , a person strong in neural net algorithm to eh {disfmarker} to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech .&#10;Speaker: PhD A&#10;Content: Mmm .&#10;Speaker: PhD C&#10;Content: And my idea is eh , it would be interesting to {disfmark" />
    <node id="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis." />
    <node id="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns." />
    <node id=" correlation .&#10;Speaker: Grad B&#10;Content: Cross - co cross - correlation .&#10;Speaker: PhD C&#10;Content: Correlation , yeah .&#10;Speaker: Professor D&#10;Content: Just cross - correlation between two sides .&#10;Speaker: PhD A&#10;Content: Did - Sorry , b uh I 'm not sure what Dan 's page is that you mean . He was looking at the two {disfmarker}&#10;Speaker: Professor D&#10;Content: So cross - correlation is pretty sensitive .&#10;Speaker: Postdoc E&#10;Content: Uh , his a web page .&#10;Speaker: Professor D&#10;Content: You take the signal from the two microphones and you cros and you cross - correlate them with different lags .&#10;Speaker: Grad B&#10;Content: Subtract them .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And you find {disfmarker} They get peaks .&#10;Speaker: Professor D&#10;Content: OK . So" />
    <node id="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." />
    <node id="Speaker: Postdoc E&#10;Content: Well , OK .&#10;Speaker: Grad B&#10;Content: going and dealing with it .&#10;Speaker: Postdoc E&#10;Content: It 's just {disfmarker} Yeah . OK . I {disfmarker} I 'll give you the short version , but I do think it 's an issue that we can't resolve in five minutes .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: OK , so {disfmarker} the {disfmarker} the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . Those we won't be able to change . If someone says &quot; Hey , Roger so - and - so &quot; .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Postdoc E&#10;Content: So that 's gonna stay that person 's name .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Postdoc E&#10;Content: Now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether" />
    <node id="disfmarker} what I said .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: So {disfmarker} uh , so in {disfmarker} within the context of an utterance , someone says &quot; So , Roger , what do you think ? &quot; OK . Then , uh , it seems to me that {disfmarker} Well , maybe I {disfmarker} uh it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that .&#10;Speaker: PhD A&#10;Content: Right , you don't wanna do that .&#10;Speaker: Grad B&#10;Content: We don't {disfmarker} we wanna {disfmarker} we ha we want the transcript to be &quot; Roger &quot; .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Because if we made the {disfmarker} the transcript be the tag that we 're using for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that ." />
    <node id=" E&#10;Content: Now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says &quot; Hey Roger &quot; or are we gonna put that person 's anonymized name in instead ?&#10;Speaker: Grad B&#10;Content: No , because then that would give you a mapping , and you don't wanna have a mapping .&#10;Speaker: Postdoc E&#10;Content: OK , so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned .&#10;Speaker: PhD A&#10;Content: I don't {disfmarker}&#10;Speaker: Grad B&#10;Content: No . Because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want {disfmarker}&#10;Speaker: Postdoc E&#10;Content: I {disfmarker} I don't think you understood what I {disfmarker} what I said .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: So {" />
    <node id="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data." />
    <node id=" I can see the value o&#10;Speaker: Professor D&#10;Content: Oh , ideal would be to have the wall filled with them , but I mean {disfmarker} {vocalsound} But the thing is just having two mikes {disfmarker} If you looked at that thing on {disfmarker} on Dan 's page , it was {disfmarker} When {disfmarker} when there were two people speaking , and it looked really really different .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah , OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Postdoc E&#10;Content: Oh yeah yeah . OK .&#10;Speaker: PhD A&#10;Content: What looked different ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , well , basic he was looking at correlation .&#10;Speaker: Grad B&#10;Content: Cross - co cross - correlation .&#10;Speaker: PhD C&#10;Content: Correlation , yeah ." />
    <node id="aker: Grad B&#10;Content: And you find {disfmarker} They get peaks .&#10;Speaker: Professor D&#10;Content: OK . So when one person is speaking , then wherever they happen to be at the point when they 're speaking , {vocalsound} then there 's a pretty big maximum right around that point in the l in {disfmarker} in the lag .&#10;Speaker: PhD A&#10;Content: OK . OK .&#10;Speaker: Professor D&#10;Content: So if {disfmarker} at whatever angle you are , {vocalsound} at some lag corresponding to the time difference between the two there , you get this boost in the {disfmarker} in {disfmarker} in the cross - correlation value {disfmarker} function .&#10;Speaker: PhD A&#10;Content: So {disfmarker} so if there 's two {disfmarker}&#10;Speaker: Grad B&#10;Content: And if there are multiple people talking , you 'll see two peaks .&#10;Speaker: Professor D&#10;Content: It 's spread out .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E" />
    <node id="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results." />
    <node id="disfmarker} you don't see the spectrum {disfmarker} the spectrogram .&#10;Speaker: Grad B&#10;Content: Right . Yeah , they 're totally hidden .&#10;Speaker: PhD C&#10;Content: Is very difficult to apply eh , eh a parameter to detect change when you don't see .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . Well , that {disfmarker} that {disfmarker} that 's another reason why very simple features , things like energy , and things {disfmarker} things like harmonicity , and {vocalsound} residual energy are uh , yeah are {disfmarker} are better to use than very complex ones because they 'll be more reliable .&#10;Speaker: PhD C&#10;Content: But I suppose {disfmarker}&#10;Speaker: Grad B&#10;Content: Are probably better , yep .&#10;Speaker: PhD C&#10;Content: Yeah , yeah yeah , I {disfmarker} I {disfmarker} I will put eh the energy here . Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Ch - Chuck was gonna ask something I guess .&#10;Spe" />
    <node id=" ref respect to the speaker .&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} That 's fine .&#10;Speaker: PhD A&#10;Content: But th I don't think that matters , though .&#10;Speaker: PhD C&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} So {disfmarker} so i @ @ {comment} I think the issue is , &quot; Is there a clean signal coming from only one direction ? &quot;&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: If it 's not coming from just one direction , if it {disfmarker} if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: wherever they are .&#10;Speaker: PhD A&#10;Content: So it 's sort of like how {disfmarker} how confused is it about where the beam is .&#10;Speaker: Professor D&#10;Content: Is it a {disfmarker} is" />
    <node id=" eh the energy here . Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Ch - Chuck was gonna ask something I guess .&#10;Speaker: PhD C&#10;Content: You have a question .&#10;Speaker: PhD A&#10;Content: Yeah , I {pause} maybe this is a dumb question , but w I thought it would be {disfmarker} {vocalsound} I thought it would be easier if you used a PDA&#10;Speaker: Professor D&#10;Content: Nah .&#10;Speaker: PhD A&#10;Content: because can't you , couldn't you like use beam - forming or something to detect speaker overlaps ? I mean {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , if you used the array , rather than the signal from just one .&#10;Speaker: PhD A&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah , no , you you 're {disfmarker} you 're right&#10;Speaker: Grad B&#10;Content: But that 's {disfmarker}&#10;Speaker: Professor D&#10;Content: that {disfmarker} In fact , if we made use of the fact that" />
    <node id="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion." />
    <node id="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy." />
    <node id=" {disfmarker} it would be a sticky limitation .&#10;Speaker: Postdoc E&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: You know , like {disfmarker} Well , we can talk about that later .&#10;Speaker: Postdoc E&#10;Content: I think that 's risky . I think that the public should be the same . I think that when we do that world release , it should be the same .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I agree . I {disfmarker} I agree with Jane .&#10;Speaker: Postdoc E&#10;Content: For a bunch of reasons , legal .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I think that we {disfmarker} we have a {disfmarker} need to have a consistent licensing policy of some sort , and {disfmarker}&#10;Speaker: Postdoc E&#10;Content: But I also think a consistent licensing policy is important .&#10;Speaker: PhD A&#10;Content: Well , one thing to to take into consideration is w are there any um {disfmarker} For example , the people" />
    <node id="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting." />
    <node id="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation." />
    <node id=" for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that .&#10;Speaker: Postdoc E&#10;Content: OK , well , but then there 's this issue of if we 're gonna use this for a discourse type of thing , then {disfmarker} and , you know , Liz was mentioning stuff in a previous meeting about gaze direction and who 's {disfmarker} who 's the addressee and all , then to have &quot; Roger &quot; be the thing in the utterance and then actually have the speaker identifier who was &quot; Roger &quot; be &quot; Frank &quot; , that 's going to be really confusing and make it pretty much useless for discourse analysis .&#10;Speaker: Grad B&#10;Content: Oh . Ugh ! That 's a good point .&#10;Speaker: Postdoc E&#10;Content: Now , if you want to , you know , I mean , in some cases , I {disfmarker} I {disfmarker} I know that Susan Ervin - Tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name" />
    <node id=" Susan Ervin - Tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except&#10;Speaker: Professor D&#10;Content: Yeah Yeah , once you get to the publication you can certainly do that .&#10;Speaker: Postdoc E&#10;Content: And {disfmarker} and I {disfmarker} cer and I {disfmarker} So , I mean , the question then becomes one level back . Um , how important is it for a person to be identified by first name versus full name ? Well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to {disfmarker} they 'll be reviewing the transcripts , to see if there 's something they don't like {disfmarker} {comment} OK . So , maybe , uh , maybe that 's enough protection . On the other hand , this is a small {disfmarker} this is a small pool , and people who say things about topic X e who are researchers and well - known" />
    <node id="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine." />
    <node id="isfmarker} I mean I have some results to present , but I mean I guess we won't have time to do that this time . But it seems like um the anonymization is uh , is also something that we might wanna discuss in greater length .&#10;Speaker: Professor D&#10;Content: Um . I mean , wha what {disfmarker}&#10;Speaker: Postdoc E&#10;Content: If {disfmarker} if we 're about to wind down , I think {disfmarker} what I would prefer is that we uh , delay the anonymization thing till next week , and I would like to present the results that I have on the overlaps .&#10;Speaker: PhD A&#10;Content: We still have to do this , too , right ?&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Digits ?&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: Grad B&#10;Content: No - well , we don't have to do digits .&#10;Speaker: Professor D&#10;Content: Well , why don't we {disfmarker} Uh , so @ @ OK . @ @ {comment} It sounds like u uh" />
    <node id="&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Right ? So again , I think the first thing to do to detect the overlaps is to look at these uh , in {disfmarker} in {disfmarker} in {disfmarker} in {disfmarker}&#10;Speaker: Grad B&#10;Content: Features ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Well , I {disfmarker} again , the things you 've written up there I think are way too {disfmarker} way too big .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK ? If you 're talking about , say , twelfth {disfmarker} twelfth - order uh MFCC 's or something like that it 's just way too much .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: You won't be able to look at it . All you 'll be able to do is put it into a classifier and see how well it does .&#10;Speaker: PhD C&#10;" />
    <node id="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data." />
    <node id="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public." />
    <node id=" it 's a matter of {disfmarker} between now and then of d of deciding how {disfmarker}&#10;Speaker: Grad B&#10;Content: Making some decisions ?&#10;Speaker: Postdoc E&#10;Content: i i it {disfmarker} You know , it may be s that we we 'll need to do something like actually X out that part of the um {disfmarker} the audio , and just put in brackets &quot; speaker - one &quot; .&#10;Speaker: Grad B&#10;Content: Yeah . For the public one .&#10;Speaker: PhD C&#10;Content: the ? ?&#10;Speaker: Grad B&#10;Content: You know , what we could do also is have more than one version of release .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: You know .&#10;Speaker: Grad B&#10;Content: One that 's public and one {disfmarker} one that requires licensing . And so the licensed one would {disfmarker} w we could {disfmarker} it would be a sticky limitation .&#10;Speaker: Postdoc E&#10;Content: Uh - huh .&#10;Speaker: Grad" />
    <node id=" ,&#10;Speaker: Grad B&#10;Content: That 's a good point . Right , it can't be the internal one .&#10;Speaker: PhD F&#10;Content: right ?&#10;Speaker: Professor D&#10;Content: Although it 's {disfmarker}&#10;Speaker: PhD F&#10;Content: Otherwise they 're not allowed to play it for anyone .&#10;Speaker: Postdoc E&#10;Content: There we go .&#10;Speaker: Grad B&#10;Content: That 's right .&#10;Speaker: Postdoc E&#10;Content: Oh , I like that . Well put . Well put . So , after the transcript screening phase .&#10;Speaker: Grad B&#10;Content: Yeah , that 's true .&#10;Speaker: Postdoc E&#10;Content: Things have been weeded out .&#10;Speaker: PhD F&#10;Content: Otherwise we 'd need two lawyer stages .&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's right , say {comment} &quot; Yeah , well , I got this CD , and , Your Honor , I {disfmarker} &quot;&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: That 's a good" />
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target="aker: PhD A&#10;Content: Right . Right . OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: So , this is all pretty early stages .&#10;Speaker: PhD A&#10;Content: I see .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah , yeah , yeah .&#10;Speaker: Professor D&#10;Content: But no , you 're absolutely right . That 's {pause} a good thing to consider .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: There {disfmarker} there is a complication though , and that is if a person turns their back to the {disfmarker} to the PDA , then some of the positional information goes away ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Well , it {disfmarker} it {disfmarker} it does , i it d it does , but the {disfmarker} the {disfmarker} the issue is that {disfmarker} that {disfmarker}&#10;Speaker: PhD A&#10;Content: No ,">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target=" B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: Yeah , it 's timing difference . It - it 's not amplitude ,&#10;Speaker: Postdoc E&#10;Content: Oh yeah ! Oh I agree ! And we use it ourselves .&#10;Speaker: Professor D&#10;Content: right ? S Right .&#10;Speaker: Postdoc E&#10;Content: I mean , I know {disfmarker} I n I know that 's a very important cue .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: But I 'm just {disfmarker} I 'm just saying that the way we 're seated around a table , is not the same with respect to each {disfmarker} to each person with respect to the PDA ,&#10;Speaker: PhD C&#10;Content: No . No . No , no , no .&#10;Speaker: Postdoc E&#10;Content: so we 're gonna have a lot of differences with ref respect to the speaker .&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} That 's fine .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target="Speaker: PhD C&#10;Content: I {disfmarker} I {disfmarker} Yeah .&#10;Speaker: PhD A&#10;Content: I don't {disfmarker} I don't know ho&#10;Speaker: PhD C&#10;Content: I {disfmarker} I {disfmarker} I think {disfmarker} Sorry . I {disfmarker} I {disfmarker} I think because the the the distance between the two microph eh , microphone , eh , in the PDA is very near . But it 's uh {disfmarker} from my opinion , it 's an interesting idea to {disfmarker} to try to study the binaural eh problem eh , with information , because I {disfmarker} I found difference between the {disfmarker} the speech from {disfmarker} from each micro eh , in the PDA .&#10;Speaker: PhD A&#10;Content: I would guess {disfmarker}&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: Yeah , it 's timing difference . It - it 's not amplitude ,&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target="&#10;Content: It was {disfmarker} yeah , it was interesting .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But , the reason why I haven't focused on that as the fir my first concern is because um , I 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . And you can't just always go , &quot; well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up &quot; .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: No , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: It has all these mikes and it has a plug - in jack to the PDA .&#10;Speaker: Postdoc E&#10;Content: Interesting .&#10;Speaker: Grad B&#10;Content: But I think {disfmarker}&#10;Speaker: Professor D&#10;Content: The other thing actually , that gets at this a">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target="Speaker: Professor D&#10;Content: It 's spread out .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Well , let me ask you , if {disfmarker} if both people were over there , it would be less effective than if one was there and one was across , catty - corner ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . The - the {disfmarker} Oh , I 'm sorry ,&#10;Speaker: Postdoc E&#10;Content: No ?&#10;Speaker: Professor D&#10;Content: if they 're right next to one another ?&#10;Speaker: PhD A&#10;Content: If I was {disfmarker} if I was here and Morgan was there and we were both talking , it wouldn't work .&#10;Speaker: Professor D&#10;Content: i i&#10;Speaker: Postdoc E&#10;Content: Next {disfmarker} next one over n over {comment} on this side of the P {disfmarker} PDA .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target=" any means . I just wanted to point out that {disfmarker} that weakness , that it 's topo topologically impossible to get it perfect for everybody .&#10;Speaker: Professor D&#10;Content: Yeah . Mm - hmm .&#10;Speaker: Grad B&#10;Content: And I think Dan is still working on it . So . He actually {disfmarker} he wrote me about it a little bit , so .&#10;Speaker: Postdoc E&#10;Content: Great . No , I don't mean to discourage that at all .&#10;Speaker: Professor D&#10;Content: I mean , the other thing you can do {disfmarker} uh , if {disfmarker} I mean , i We 're assuming that it would be a big deal just to get somebody {disfmarker} convince somebody to put two microphones in the PDA . But if you h put a third in , {vocalsound} you could put in the other axis . And then you know {disfmarker} then you 're sort of {disfmarker} Yeah , then {disfmarker} then you pretty much could cover {disfmarker}&#10;Speaker: PhD A">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Loss of Positional Information: If a person turns their back to the PDA, some of the positional information is lost because the device relies on detecting the position and orientation of the individuals speaking. When someone turns away from the PDA, the device can no longer accurately capture the person's position and may result in poor data quality or loss of valuable information.&#10;2. Variation in Positional Data: With multiple people seated around a table, there will be differences in each person's distance and orientation relative to the PDA, leading to inconsistencies in the positional data collected from each individual. This can make it difficult to analyze and interpret the information accurately.&#10;3. Non-ideal Seating Arrangements: The seating arrangement around a table may not be optimal for capturing accurate positional data from all participants. This issue is compounded when people are seated diagonally or at an angle relative to the PDA, reducing its ability to effectively capture positional information and potentially affecting the quality of the recorded data." target="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA.">
      <data key="d0">1</data>
    </edge>
    <edge source=" B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: Yeah , it 's timing difference . It - it 's not amplitude ,&#10;Speaker: Postdoc E&#10;Content: Oh yeah ! Oh I agree ! And we use it ourselves .&#10;Speaker: Professor D&#10;Content: right ? S Right .&#10;Speaker: Postdoc E&#10;Content: I mean , I know {disfmarker} I n I know that 's a very important cue .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: But I 'm just {disfmarker} I 'm just saying that the way we 're seated around a table , is not the same with respect to each {disfmarker} to each person with respect to the PDA ,&#10;Speaker: PhD C&#10;Content: No . No . No , no , no .&#10;Speaker: Postdoc E&#10;Content: so we 're gonna have a lot of differences with ref respect to the speaker .&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} That 's fine .&#10;Speaker" target="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target=" , OK , @ @ {comment} So , uh , then I guess th the last thing I 'd had on my {disfmarker} my agenda was just to hear {disfmarker} hear an update on {vocalsound} what {disfmarker} what Jose has been doing ,&#10;Speaker: PhD C&#10;Content: Uh - huh . OK .&#10;Speaker: Professor D&#10;Content: so&#10;Speaker: PhD C&#10;Content: I have , eh , {vocalsound} The result of my work during the last days .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Thank you for your information because I {disfmarker} I read . Eh , and the {disfmarker} the last , eh , days , eh , I work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the {disfmarker} the Meeting Recording project .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: And I have , eh , some ideas . Eh , this">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target=" - two {disfmarker}&#10;Speaker: Grad B&#10;Content: Sure but , h then you have to know that Jose is speaker - one and {disfmarker}&#10;Speaker: PhD A&#10;Content: Why do you have to know his name ?&#10;Speaker: Professor D&#10;Content: OK , so suppose someone says , &quot; well I don't know if I really heard what {disfmarker} uh , what Jose said . &quot;&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And then , Jose responds .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And part of your learning about the dialogue is Jose responding to it . But it doesn't say &quot; Jose &quot; , it says &quot; speaker - five &quot; .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: So {pause} uh {pause} u&#10;Speaker: PhD A&#10;Content: Oh , I see , you wanna associated the word &quot; Jose &quot; in the dialogue with the fact that">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="disfmarker} Yeah . But eh I {disfmarker} I {disfmarker} Is my my {disfmarker} my own vision , {vocalsound} of the {disfmarker} of the project .&#10;Speaker: Grad B&#10;Content: So , some sort of {disfmarker} That 's {disfmarker}&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: I {disfmarker} eh the {disfmarker} the Meeting Recorder project , for me , has eh , two {vocalsound} eh , w has eh several parts , several p {vocalsound} objective&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: eh , because it 's a {disfmarker} a great project . But eh , at the first , in the acoustic , eh , eh , parts of the project , eh I think {pause} you eh {disfmarker} we have eh {vocalsound} {pause} two main eh objective . One {disfmarker} one of">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target=" about some {pause} new proposed work in this area , sort of a separate issue from what the student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who didn't attend to {pause} listen to . And in that uh , regard , I thought we definitely w will need {disfmarker} it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . So this {disfmarker} this meeting is one of them , although I 'm not sure I can participate if I {disfmarker} You know , I would feel very strange being part of a meeting that you were then analysing later for things like summarization .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um ,">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target=" uh , agenda items that they were interested in and I 'll {disfmarker} I 'll take the role of organizing them uh , into {disfmarker} into the agenda ,&#10;Speaker: Postdoc E&#10;Content: OK . Sure .&#10;Speaker: Professor D&#10;Content: but I 'd be very pleased to have everyone else {vocalsound} completely make up the agenda . I 've no desire to {disfmarker} {vocalsound} to make it up , but if {disfmarker} if no one 's told me things , then I 'm just proceeding from my {disfmarker} my guesses , and {disfmarker} and uh , and i ye yeah , I {disfmarker} I 'm sorry it ended up with your out your time to {disfmarker} I mean , I 'm just always asking Jose what he 's doing , you know , and {disfmarker} {vocalsound} and so it 's {disfmarker} {pause} There 's uh , there 's obviously other things going on .&#10;Speaker: Grad B&#10;Content: Mm - hmm">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target=" your clothing .&#10;Speaker: Grad B&#10;Content: in terms of {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah !&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Hats ?&#10;Speaker: Grad B&#10;Content: In terms of the research {pause} th research , it 's really {disfmarker} it 's whatever the person who is doing the research wants to do .&#10;Speaker: PhD A&#10;Content: Shirts .&#10;Speaker: Grad B&#10;Content: So if {disfmarker} if Jose is interested in that , that 's great . But if {disfmarker} if he 's not , that 's great too .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Um , I {disfmarker} i I {disfmarker} i I would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there .&#10;Speaker: Grad B&#10;Content: Catch some tea">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. PhD C has been working on the Meeting Recording project and has developed some ideas. However, they mention that they are not sure if they can participate in the meeting as it would feel strange to be analyzed later for things like summarization.&#10;2. There is no explicit mention of what updates or ideas Jose has been working on in relation to the Meeting Recording project during the past few days while staying at home. The conversation revolves around identifying speakers in a recording and ensuring that everyone participates in making up the agenda." target="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers.">
      <data key="d0">1</data>
    </edge>
    <edge source=" - two {disfmarker}&#10;Speaker: Grad B&#10;Content: Sure but , h then you have to know that Jose is speaker - one and {disfmarker}&#10;Speaker: PhD A&#10;Content: Why do you have to know his name ?&#10;Speaker: Professor D&#10;Content: OK , so suppose someone says , &quot; well I don't know if I really heard what {disfmarker} uh , what Jose said . &quot;&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And then , Jose responds .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And part of your learning about the dialogue is Jose responding to it . But it doesn't say &quot; Jose &quot; , it says &quot; speaker - five &quot; .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: So {pause} uh {pause} u&#10;Speaker: PhD A&#10;Content: Oh , I see , you wanna associated the word &quot; Jose &quot; in the dialogue with the fact that" target="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings.">
      <data key="d0">1</data>
    </edge>
    <edge source=" about some {pause} new proposed work in this area , sort of a separate issue from what the student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who didn't attend to {pause} listen to . And in that uh , regard , I thought we definitely w will need {disfmarker} it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . So this {disfmarker} this meeting is one of them , although I 'm not sure I can participate if I {disfmarker} You know , I would feel very strange being part of a meeting that you were then analysing later for things like summarization .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um ," target="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable.">
      <data key="d0">1</data>
    </edge>
    <edge source=" about some {pause} new proposed work in this area , sort of a separate issue from what the student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who didn't attend to {pause} listen to . And in that uh , regard , I thought we definitely w will need {disfmarker} it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . So this {disfmarker} this meeting is one of them , although I 'm not sure I can participate if I {disfmarker} You know , I would feel very strange being part of a meeting that you were then analysing later for things like summarization .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um ," target="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source=" your clothing .&#10;Speaker: Grad B&#10;Content: in terms of {disfmarker}&#10;Speaker: PhD A&#10;Content: Yeah !&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Hats ?&#10;Speaker: Grad B&#10;Content: In terms of the research {pause} th research , it 's really {disfmarker} it 's whatever the person who is doing the research wants to do .&#10;Speaker: PhD A&#10;Content: Shirts .&#10;Speaker: Grad B&#10;Content: So if {disfmarker} if Jose is interested in that , that 's great . But if {disfmarker} if he 's not , that 's great too .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD C&#10;Content: Yeah , yeah .&#10;Speaker: Professor D&#10;Content: Yeah . Um , I {disfmarker} i I {disfmarker} i I would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there .&#10;Speaker: Grad B&#10;Content: Catch some tea" target="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers.">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="&#10;Content: OK . &#10;Speaker: Professor D&#10;Content: Uh , I think {disfmarker} you don't wanna have their full name to be uh , listed .&#10;Speaker: Postdoc E&#10;Content: Yeah , and {disfmarker} and in the form that they sign , it does say &quot; your first name may arise in the course of the meetings &quot; .&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: And so {disfmarker}&#10;Speaker: PhD A&#10;Content: Well {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah . So again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , &quot; Frank said this &quot; and then you wanna connect it to something later , you 've gotta have this part where that 's &quot; Frank colon &quot; .&#10;Speaker: Postdoc E&#10;Content: Or &quot; your name &quot; .&#10;Speaker: Grad B&#10;Content: Yeah , shoot !&#10;Speaker: Professor D&#10;Content: Right ?&#10;Speaker: Postdoc E&#10;Content: Yeah , and {disfmarker} and {">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="aker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But that {disfmarker}&#10;Speaker: Postdoc E&#10;Content: That 'd be very efficient .&#10;Speaker: Grad B&#10;Content: The p It 's a good point , &quot; which {disfmarker} what do you do for discourse tracking ? &quot;&#10;Speaker: PhD C&#10;Content: Because y y you don't know to know , eh {disfmarker} you don't need to know what i what is the iden identification of the {disfmarker} of the speakers . You only eh want to know {disfmarker}&#10;Speaker: Grad B&#10;Content: Hmm . For {disfmarker} for acoustics you don't but for discourse you do .&#10;Speaker: Professor D&#10;Content: Well , you do .&#10;Speaker: PhD C&#10;Content: Ah , for discourse , yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Yeah . If {disfmarker} if {disfmarker} if {disfmarker} if someone says , uh , &quot; what {disfmarker} what is Jose">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target=" D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So you 're ignoring overlapping events unless they 're speech with speech .&#10;Speaker: PhD C&#10;Content: Yeah , be Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's fine .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: &quot; Why ? Why ? What 's the reason ? &quot; because {pause} i it 's the first study . the first&#10;Speaker: Professor D&#10;Content: Oh , no {disfmarker} no , it 's a perfectly sensible way to go . We just wondered {disfmarker} trying to understand what {disfmarker} what you were doing .&#10;Speaker: Postdoc E&#10;Content: We 're just&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Yeah cuz you 've talked about other overlapping events in the past .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target=" I wanted to make the point that {disfmarker} that discourse is gonna be more than just looking at a transcript .&#10;Speaker: Grad B&#10;Content: Yeah , ab absolutely . Oh , yeah , sure .&#10;Speaker: Postdoc E&#10;Content: It 's gonna be looking at a t You know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this {disfmarker} confronting this problem .&#10;Speaker: PhD A&#10;Content: Maybe we should just not allow anybody to do research on discourse ,&#10;Speaker: Postdoc E&#10;Content: So .&#10;Speaker: PhD A&#10;Content: and then , we wouldn't have to worry about it .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Yeah , we should just market it to non - English speaking countries .&#10;Speaker: PhD C&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: Uh , maybe we should only have meetings between people who don't know one another and who are also amnesiacs who don't know their own name .&#10;Speaker: Grad B">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target=": PhD A&#10;Content: Well , one thing to to take into consideration is w are there any um {disfmarker} For example , the people who are funding this work , they want this work to get out and be useful for discourse .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: If we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , depending on how much editing we do , you might be able to {pause} still have it useful . because for discourse you don't need the audio . Right ? So you could bleep out the names in the audio .&#10;Speaker: PhD A&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: and use the anonymized one through the transcript .&#10;Speaker: PhD A&#10;Content: But if you release both {disfmarker}&#10;Speaker: Professor D&#10;Content: Uh .&#10;Speaker: Postdoc E&#10;Content: Excuse me . We {disfmarker} we do need audio for discourse .&#10;Speaker">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable.">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA.">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="Including the names of speakers when tracking discourse in a meeting is important because it helps to accurately attribute statements and ideas to the correct person. This becomes crucial when trying to analyze or understand the discussion, especially in cases where multiple individuals are speaking over each other or interrupting one another. By associating specific comments with identified speakers, it enables clearer interpretation of the conversation flow, enhances the overall analysis process, and ensures proper recognition for each participant's contributions." target="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source=" D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So you 're ignoring overlapping events unless they 're speech with speech .&#10;Speaker: PhD C&#10;Content: Yeah , be Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's fine .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: &quot; Why ? Why ? What 's the reason ? &quot; because {pause} i it 's the first study . the first&#10;Speaker: Professor D&#10;Content: Oh , no {disfmarker} no , it 's a perfectly sensible way to go . We just wondered {disfmarker} trying to understand what {disfmarker} what you were doing .&#10;Speaker: Postdoc E&#10;Content: We 're just&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Yeah cuz you 've talked about other overlapping events in the past .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content:" target="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;">
      <data key="d0">1</data>
    </edge>
    <edge source=" D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So you 're ignoring overlapping events unless they 're speech with speech .&#10;Speaker: PhD C&#10;Content: Yeah , be Yeah .&#10;Speaker: Professor D&#10;Content: Yeah , that 's fine .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: &quot; Why ? Why ? What 's the reason ? &quot; because {pause} i it 's the first study . the first&#10;Speaker: Professor D&#10;Content: Oh , no {disfmarker} no , it 's a perfectly sensible way to go . We just wondered {disfmarker} trying to understand what {disfmarker} what you were doing .&#10;Speaker: Postdoc E&#10;Content: We 're just&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Yeah cuz you 've talked about other overlapping events in the past .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content:" target="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target="aker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD F&#10;Content: It has to be a {disfmarker} a pre - existing meeting , {pause} like a meeting that would otherwise happen anyway .&#10;Speaker: Professor D&#10;Content: so&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Yeah , yeah .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: So I was {disfmarker} I was thinking more in terms of talking to professors uh , and {disfmarker} and {disfmarker} and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their {disfmarker} hold their meeting down here .&#10;Speaker: PhD F&#10;Content: That 's I think what we {disfmarker} and I agree with .&#10;Speaker: Postdoc E&#10;Content: Oh , interesting !&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Oh , I see . Oh ,">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target=" mean to summarize ,&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {disfmarker} rather we should have different meetings by the same group but hopefully that have different summaries . And then we need a couple that {disfmarker} of {disfmarker} {pause} We don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .&#10;Speaker: Grad B&#10;Content: Yeah , we have a lot of overlap between this meeting and the morning meeting .&#10;Speaker: Professor D&#10;Content: S So {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: See , I 've never listened to the data for the front - end {pause} meeting .&#10;Speaker: Grad B&#10;Content: Yeah , we {disfmarker} we 've only had three .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: PhD F&#10;Content: OK . But maybe that 's enough . So , in general , I was thinking more data">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target=" As many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . I 'd like to have many different speakers . So , um I think I would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and {disfmarker} and uh ,&#10;Speaker: PhD C&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: I mean , sure , if we can get more from them , fine ,&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people .&#10;Speaker: PhD F&#10;Content: Yeah , I definitely agree with that .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Definitely .&#10;Speaker: PhD C&#10;Content: Yeah">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers were discussing the idea of having various groups hold their meetings in a specific location, possibly to collect data for analysis. Professor D proposed that they could approach professors and senior doctoral students who are leading projects and offer them the opportunity to hold their meetings in that location. PhD F agreed with this suggestion, finding it an effective way to gather diverse perspectives from multiple speakers.&#10;&#10;To ensure a variety of viewpoints, PhD F expressed interest in having many different speakers across several scattered meetings. This would allow for closer and more distant microphones to capture the discussions, providing useful acoustic data even if there are only one or two representatives from each group. The professors agreed with this approach, acknowledging that more participants would be beneficial but also noting that a smaller number of attendees could still provide valuable acoustic data.&#10;&#10;PhD C mentioned a new proposed work involving summarization of meetings and identifying cues in both the utterances and interaction patterns to highlight important moments for someone who didn't attend or listen to the meeting. For this purpose, having diverse data from various domains or types of meetings would be helpful. However, PhD C expressed concern about participating in a meeting that they would then analyze later for things like summarization, as it would make them feel uncomfortable." target="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns.">
      <data key="d0">1</data>
    </edge>
    <edge source=" mean to summarize ,&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {disfmarker} rather we should have different meetings by the same group but hopefully that have different summaries . And then we need a couple that {disfmarker} of {disfmarker} {pause} We don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .&#10;Speaker: Grad B&#10;Content: Yeah , we have a lot of overlap between this meeting and the morning meeting .&#10;Speaker: Professor D&#10;Content: S So {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: See , I 've never listened to the data for the front - end {pause} meeting .&#10;Speaker: Grad B&#10;Content: Yeah , we {disfmarker} we 've only had three .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: PhD F&#10;Content: OK . But maybe that 's enough . So , in general , I was thinking more data" target="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source=" mean to summarize ,&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {disfmarker} rather we should have different meetings by the same group but hopefully that have different summaries . And then we need a couple that {disfmarker} of {disfmarker} {pause} We don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .&#10;Speaker: Grad B&#10;Content: Yeah , we have a lot of overlap between this meeting and the morning meeting .&#10;Speaker: Professor D&#10;Content: S So {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: See , I 've never listened to the data for the front - end {pause} meeting .&#10;Speaker: Grad B&#10;Content: Yeah , we {disfmarker} we 've only had three .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: PhD F&#10;Content: OK . But maybe that 's enough . So , in general , I was thinking more data" target="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion." target=" for things like summarization .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD F&#10;Content: Um , and then there are some others that menti that Morgan mentioned , like the front - end meeting {pause} and maybe a networking {pause} group meeting .&#10;Speaker: Grad B&#10;Content: Right . Yep . Yeah , we 're {disfmarker} we 're hoping that they 'll let us start recording regularly .&#10;Speaker: PhD F&#10;Content: So {disfmarker} So if that were the case then I think we 'd have enough .&#10;Speaker: Grad B&#10;Content: So . Mm - hmm .&#10;Speaker: PhD F&#10;Content: But basically , for anything where you 're trying to get a summarization of some kind of meeting {disfmarker} {comment} {pause} meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we didn't really have a good grasp on what does it mean to summarize ,&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: but {disfmarker} rather">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion." target="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion." target="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion." target="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns.">
      <data key="d0">1</data>
    </edge>
    <edge source="The suggestion being made regarding meetings involves having several distinct meetings by the same group, aiming for varied summaries. This approach is motivated by the observation of content overlap between this meeting and another morning meeting, as well as limited participation from some groups. By having multiple meetings with different focuses or topics, the team can gather diverse data that could be useful for summarization and analysis purposes. This proposal was made by PhD F and agreed upon by other participants in the discussion." target="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." target="aker: PhD C&#10;Content: OK ? It 's the control set . It 's pure si pure silence {comment} with the {disfmarker} with the machine on the {disfmarker} on the roof .&#10;Speaker: Professor D&#10;Content: What you {disfmarker} Well {disfmarker} w {vocalsound} I {disfmarker} I think what you m I think what you mean {vocalsound} is that it 's nonspeech segments that don't have impulsive noises .&#10;Speaker: Grad B&#10;Content: With the fan .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Right ? Cuz you 're calling {disfmarker} what you 're calling &quot; event &quot; is somebody coughing {vocalsound} or clicking , or rustling paper , or hitting something , which are impulsive noises .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But steady - state noises are part of the background .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Which , are being , included">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." target=" are part of the background .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Which , are being , included in that . Right ?&#10;Speaker: PhD C&#10;Content: h here yet , yet I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I think {disfmarker} I {disfmarker} I think , eh , there are {disfmarker} that {disfmarker} some kind of noises that , eh , don't {disfmarker} don't wanted to {disfmarker} to be in that , eh , in that control set .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So it 's like a signal - noise situation . Yeah .&#10;Speaker: Professor D&#10;Content: Well {disfmarker} Yeah .&#10;Speaker: PhD C&#10;Content: But I prefer , I prefer at {disfmarker} at the first , eh , the {disfmarker} the silence with eh , this eh this kind of the {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." target=" with something overlapping , which could be speech but doesn't need to be .&#10;Speaker: PhD C&#10;Content: No , no , es especially {pause} eh , overlapping speech {pause} from , eh , different eh , eh , speaker . Eh {disfmarker}&#10;Speaker: Professor D&#10;Content: No , but there 's {disfmarker} but , I think she 's saying &quot; Where do you {disfmarker} In these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? &quot;&#10;Speaker: PhD C&#10;Content: Ah !&#10;Speaker: Professor D&#10;Content: Which category do you put that in ?&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's right . That 's my question .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah , he here I {disfmarker} I put eh speech from eh , from , eh , one speaker {pause} without , eh , eh , any {disfmarker} any {disfmarker} any events more .&#10;Speaker: Postdoc E&#10;Content: Oh !&#10;Speaker: Professor D&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." target=" 've talked about other overlapping events in the past .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So , this is {disfmarker} this is {disfmarker} a subset .&#10;Speaker: PhD C&#10;Content: Yeah . In the {disfmarker} in the future , the {disfmarker} the idea is to {disfmarker} to extend {pause} the class ,&#10;Speaker: PhD A&#10;Content: Is {disfmarker} is {disfmarker}&#10;Speaker: PhD C&#10;Content: to consider all the {disfmarker} all the information , you {disfmarker} you mentioned before&#10;Speaker: Professor D&#10;Content: Yeah . Yeah , I {disfmarker} I don't think we were asking for that .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: but eh , the {disfmarker} the first idea {disfmarker} Because eh , I don't know {pause} what hap what will happen {comment} with the study .&#10;Speaker: Professor D">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." target=" PhD A&#10;Content: Mmm .&#10;Speaker: PhD C&#10;Content: And my idea is eh , it would be interesting to {disfmarker} to have eh , {vocalsound} a control set . And my control set eh , will be the eh , silence , silence without eh , any {disfmarker} any noise .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: Which means that we 'd still {disfmarker} You 'd hear the {disfmarker}&#10;Speaker: Grad B&#10;Content: Yeah , fans .&#10;Speaker: PhD C&#10;Content: Yeah , acoustic with this . {comment} With {disfmarker} with , yeah , the background .&#10;Speaker: Postdoc E&#10;Content: Yeah . {comment} That 's interesting . This is like a ground level , with {disfmarker} It 's not it 's not total silence .&#10;Speaker: PhD C&#10;Content: Eh , I {disfmarker} I mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh ,&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Type of sounds in the control set: The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state noises like the sound of a fan, which are part of the background. However, there is a mention of wanting to exclude some kind of noises that are not desired in the control set.&#10;2. Difference between sounds in the control set and &quot;events&quot;: Events refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest." target="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD C&#10;Content: OK ? It 's the control set . It 's pure si pure silence {comment} with the {disfmarker} with the machine on the {disfmarker} on the roof .&#10;Speaker: Professor D&#10;Content: What you {disfmarker} Well {disfmarker} w {vocalsound} I {disfmarker} I think what you m I think what you mean {vocalsound} is that it 's nonspeech segments that don't have impulsive noises .&#10;Speaker: Grad B&#10;Content: With the fan .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Right ? Cuz you 're calling {disfmarker} what you 're calling &quot; event &quot; is somebody coughing {vocalsound} or clicking , or rustling paper , or hitting something , which are impulsive noises .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But steady - state noises are part of the background .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Which , are being , included" target="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning.">
      <data key="d0">1</data>
    </edge>
    <edge source=" are part of the background .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Which , are being , included in that . Right ?&#10;Speaker: PhD C&#10;Content: h here yet , yet I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I think {disfmarker} I {disfmarker} I think , eh , there are {disfmarker} that {disfmarker} some kind of noises that , eh , don't {disfmarker} don't wanted to {disfmarker} to be in that , eh , in that control set .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: So it 's like a signal - noise situation . Yeah .&#10;Speaker: Professor D&#10;Content: Well {disfmarker} Yeah .&#10;Speaker: PhD C&#10;Content: But I prefer , I prefer at {disfmarker} at the first , eh , the {disfmarker} the silence with eh , this eh this kind of the {disfmarker}" target="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning.">
      <data key="d0">1</data>
    </edge>
    <edge source=" with something overlapping , which could be speech but doesn't need to be .&#10;Speaker: PhD C&#10;Content: No , no , es especially {pause} eh , overlapping speech {pause} from , eh , different eh , eh , speaker . Eh {disfmarker}&#10;Speaker: Professor D&#10;Content: No , but there 's {disfmarker} but , I think she 's saying &quot; Where do you {disfmarker} In these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? &quot;&#10;Speaker: PhD C&#10;Content: Ah !&#10;Speaker: Professor D&#10;Content: Which category do you put that in ?&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's right . That 's my question .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah , he here I {disfmarker} I put eh speech from eh , from , eh , one speaker {pause} without , eh , eh , any {disfmarker} any {disfmarker} any events more .&#10;Speaker: Postdoc E&#10;Content: Oh !&#10;Speaker: Professor D&#10;" target="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning.">
      <data key="d0">1</data>
    </edge>
    <edge source=" with something overlapping , which could be speech but doesn't need to be .&#10;Speaker: PhD C&#10;Content: No , no , es especially {pause} eh , overlapping speech {pause} from , eh , different eh , eh , speaker . Eh {disfmarker}&#10;Speaker: Professor D&#10;Content: No , but there 's {disfmarker} but , I think she 's saying &quot; Where do you {disfmarker} In these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? &quot;&#10;Speaker: PhD C&#10;Content: Ah !&#10;Speaker: Professor D&#10;Content: Which category do you put that in ?&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's right . That 's my question .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah , he here I {disfmarker} I put eh speech from eh , from , eh , one speaker {pause} without , eh , eh , any {disfmarker} any {disfmarker} any events more .&#10;Speaker: Postdoc E&#10;Content: Oh !&#10;Speaker: Professor D&#10;" target="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" PhD A&#10;Content: Mmm .&#10;Speaker: PhD C&#10;Content: And my idea is eh , it would be interesting to {disfmarker} to have eh , {vocalsound} a control set . And my control set eh , will be the eh , silence , silence without eh , any {disfmarker} any noise .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: Which means that we 'd still {disfmarker} You 'd hear the {disfmarker}&#10;Speaker: Grad B&#10;Content: Yeah , fans .&#10;Speaker: PhD C&#10;Content: Yeah , acoustic with this . {comment} With {disfmarker} with , yeah , the background .&#10;Speaker: Postdoc E&#10;Content: Yeah . {comment} That 's interesting . This is like a ground level , with {disfmarker} It 's not it 's not total silence .&#10;Speaker: PhD C&#10;Content: Eh , I {disfmarker} I mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh ,&#10;Speaker:" target="The control set consists of pure silence or nonspeech segments that don't have impulsive noises like somebody coughing, clicking, rustling paper, or hitting something. It also includes steady-state background noises like the sound of a fan. The &quot;events&quot; mentioned in the conversation refer to impulsive noises such as coughing, clicking, rustling paper, or hitting something. These types of sounds differ from the sounds in the control set as they are not part of the background noise and can interfere with the analysis of speech or other sounds of interest. &#10;&#10;Additionally, it is mentioned that there might be some kind of noises that are not desired in the control set, but no specifics are given about what those noises might be. PhD C also mentions the idea of having a control set of silence without any noise, including background noises like fans or air conditioning.">
      <data key="d0">1</data>
    </edge>
    <edge source="The participants are discussing the possibilities and constraints of using a PDA (Personal Digital Assistant) to record and summarize meetings, specifically when only one person in the group has the device. They bring up several issues related to data quality and positioning.&#10;&#10;1. Positional Data Issues: When individuals turn their backs or are seated diagonally or at an angle relative to the PDA, some positional information is lost, leading to poor data quality or loss of valuable information. Additionally, there will be variations in positional data due to differences in each person's distance and orientation relative to the PDA, making it difficult to analyze and interpret the information accurately.&#10;&#10;2. Meeting Frequency and Participation: The group suggests having several distinct meetings with different focuses or topics to gather diverse data for summarization and analysis purposes. This approach is motivated by content overlap between meetings and limited participation from some groups.&#10;&#10;3. Speaker Identification: Including the names of speakers when tracking discourse in a meeting is important for accurate attribution, clarity in conversation flow, enhanced analysis, and proper recognition of contributions.&#10;&#10;4. Participant Concerns: PhD C, who has been working on the Meeting Recording project, expresses uncertainty about participating in the meeting due to feeling uncomfortable being analyzed later for things like summarization. There is no explicit mention of updates or ideas Jose has contributed to the project during their time at home.&#10;&#10;5. Practical Issues: The group acknowledges that seating arrangements around a table may not be optimal for capturing accurate positional data from all participants, and they recognize the challenge of accounting for variations in speaker positioning relative to the PDA." target=" I mean , we can we 'll be {disfmarker} all of this is there for us to study .&#10;Speaker: Grad B&#10;Content: Then they 're much broader . Yeah , we can do whatever we want .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But {disfmarker} {vocalsound} but {disfmarker} but the thing is , uh , one of the {disfmarker} at least one of the things I was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a PDA .&#10;Speaker: Grad B&#10;Content: Whatever you 're interested in .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: That 's what I was asking about , what are the constraints ?&#10;Speaker: PhD C&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Right . Yeah .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Well , that 's {disfmarker}">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="vocalsound} eh the , nnn {disfmarker} the {disfmarker} {nonvocalsound} the system {pause} eh will have two models .&#10;Speaker: Postdoc E&#10;Content: Clustering .&#10;Speaker: PhD C&#10;Content: A model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh {disfmarker} the mark , the change and another {disfmarker} another model will @ @ {pause} or several models , to try s but {disfmarker} eh several model eh robust models , sample models to try to classify the difference class .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: I 'm {disfmarker} I 'm {disfmarker} I 'm sorry , I didn't understand you {disfmarker} what you said . What {disfmarker} what model ?&#10;Speaker: Postdoc E&#10;Content: &#10;Speaker: PhD C&#10;Content: Eh , the {disfmarker} the classifiers of the of the n to detect the different class to the different">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="marker} the {disfmarker} the front - end approach to classify eh , the different , eh , frames of each class {pause} eh and what is the {disfmarker} the , nnn , nnn , nnn , eh , what is the , the error {pause} eh , of the data&#10;Speaker: Grad B&#10;Content: Supervised clustering . Mm - hmm .&#10;Speaker: PhD C&#10;Content: This is the {disfmarker} the eh , first idea&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: and the second {pause} is try to {disfmarker} eh , to use {pause} some ideas eh , similar to the linear discriminant analysis .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Eh ? Eh , similar , because the the idea is to {disfmarker} to study {pause} what is the contribution of eh , each parameter to the process of classify correctly the different {disfmarker} the different parameters .&#10;Speaker: Grad B&#10;Content: Mm">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target=" , each parameter to the process of classify correctly the different {disfmarker} the different parameters .&#10;Speaker: Grad B&#10;Content: Mm - hmm . What sort of classifier ar ?&#10;Speaker: PhD C&#10;Content: Eh , the {disfmarker} the {disfmarker} the classifier is {disfmarker} nnn by the moment is eh {disfmarker} is eh , similar , nnn , that the classifier used eh , in a quantifier {disfmarker} vectorial quantifier is eh , used to {disfmarker} to eh , some distance {pause} to {disfmarker} to put eh , a vector eh , in {disfmarker} in a class different .&#10;Speaker: Grad B&#10;Content: Unimodal ?&#10;Speaker: PhD C&#10;Content: Is {disfmarker} Yeah ? W with a model , is {disfmarker} is only to cluster using a eh , @ @ or a similarity .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: Grad B&#10;Content: So is it just one cluster per">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target=" interesting question .&#10;Speaker: PhD A&#10;Content: I mean , is {disfmarker} is that violation of the {disfmarker}&#10;Speaker: PhD C&#10;Content: Oh . No . Yeah .&#10;Speaker: Professor D&#10;Content: I mean , I think you wanna know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two .&#10;Speaker: PhD A&#10;Content: Mm - hmm&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But , we don't n even know yet what the effect of detecting {disfmarker} having the ability to detect overlaps is . You know , maybe it doesn't matter too much .&#10;Speaker: PhD A&#10;Content: Right . Right . OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target=" Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: I 'm {disfmarker} I {disfmarker} what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of {disfmarker} of central corp things that people generally use corpora for and which are , you know , used in computational linguistics .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: That 's {disfmarker} that 's my point . Which {disfmarker} which includes both top - down and bottom - up .&#10;Speaker: PhD C&#10;Content: It 's difficult .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK , well , i i let 's {disfmarker} let 's see what we can get . I mean , it {disfmarker} it {disfmarker} I think that if we 're aiming at {disfmarker} at">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model is designed to detect changes as accurately as possible and is based on supervised clustering. This model will identify different classes or categories within the data.&#10;2. The second model aims to classify differences by using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data. It will determine which parameters are most important for accurate classification. This is the initial idea presented during the discussion.&#10;&#10;Quote from transcript:&#10;Speaker: PhD C&#10;Content: &quot;This is the eh , first idea and the second is try to eh , to use some ideas similar to the linear discriminant analysis .&quot;" target="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data.">
      <data key="d0">1</data>
    </edge>
    <edge source="marker} the {disfmarker} the front - end approach to classify eh , the different , eh , frames of each class {pause} eh and what is the {disfmarker} the , nnn , nnn , nnn , eh , what is the , the error {pause} eh , of the data&#10;Speaker: Grad B&#10;Content: Supervised clustering . Mm - hmm .&#10;Speaker: PhD C&#10;Content: This is the {disfmarker} the eh , first idea&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: and the second {pause} is try to {disfmarker} eh , to use {pause} some ideas eh , similar to the linear discriminant analysis .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Eh ? Eh , similar , because the the idea is to {disfmarker} to study {pause} what is the contribution of eh , each parameter to the process of classify correctly the different {disfmarker} the different parameters .&#10;Speaker: Grad B&#10;Content: Mm" target="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech.">
      <data key="d0">1</data>
    </edge>
    <edge source=" interesting question .&#10;Speaker: PhD A&#10;Content: I mean , is {disfmarker} is that violation of the {disfmarker}&#10;Speaker: PhD C&#10;Content: Oh . No . Yeah .&#10;Speaker: Professor D&#10;Content: I mean , I think you wanna know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two .&#10;Speaker: PhD A&#10;Content: Mm - hmm&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But , we don't n even know yet what the effect of detecting {disfmarker} having the ability to detect overlaps is . You know , maybe it doesn't matter too much .&#10;Speaker: PhD A&#10;Content: Right . Right . OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D" target="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: I 'm {disfmarker} I {disfmarker} what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of {disfmarker} of central corp things that people generally use corpora for and which are , you know , used in computational linguistics .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: That 's {disfmarker} that 's my point . Which {disfmarker} which includes both top - down and bottom - up .&#10;Speaker: PhD C&#10;Content: It 's difficult .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK , well , i i let 's {disfmarker} let 's see what we can get . I mean , it {disfmarker} it {disfmarker} I think that if we 're aiming at {disfmarker} at" target="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: I 'm {disfmarker} I {disfmarker} what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of {disfmarker} of central corp things that people generally use corpora for and which are , you know , used in computational linguistics .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: That 's {disfmarker} that 's my point . Which {disfmarker} which includes both top - down and bottom - up .&#10;Speaker: PhD C&#10;Content: It 's difficult .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK , well , i i let 's {disfmarker} let 's see what we can get . I mean , it {disfmarker} it {disfmarker} I think that if we 're aiming at {disfmarker} at" target="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source=" Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: I 'm {disfmarker} I {disfmarker} what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of {disfmarker} of central corp things that people generally use corpora for and which are , you know , used in computational linguistics .&#10;Speaker: Professor D&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: That 's {disfmarker} that 's my point . Which {disfmarker} which includes both top - down and bottom - up .&#10;Speaker: PhD C&#10;Content: It 's difficult .&#10;Speaker: Professor D&#10;Content: OK .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK , well , i i let 's {disfmarker} let 's see what we can get . I mean , it {disfmarker} it {disfmarker} I think that if we 're aiming at {disfmarker} at" target="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." target=": Yeah .&#10;Speaker: PhD F&#10;Content: Um , at the previous {disfmarker} at last week 's meeting , this meeting I was griping {vocalsound} about wanting to get more data and I {disfmarker} I talked about this with Jane and Adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new {disfmarker} this new student di does wanna work with us ,&#10;Speaker: PhD A&#10;Content: Well , great .&#10;Speaker: PhD F&#10;Content: th the guy that was at the last meeting .&#10;Speaker: PhD A&#10;Content: Great .&#10;Speaker: PhD F&#10;Content: And he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time ,&#10;Speaker: PhD A&#10;Content: What a deal .&#10;Speaker: PhD F&#10;Content: uh {disfmarker} Yeah .&#10;Speaker: Grad B&#10;Content: And what 's he interested in , specifically ?&#10;Speaker: PhD F&#10;Content: So he 's {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." target=" you mean .&#10;Speaker: Professor D&#10;Content: You actually don't .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Yea - yeah yeah , you actually don't really even need any fancy microphone .&#10;Speaker: Postdoc E&#10;Content: Which one did you mean ?&#10;Speaker: Professor D&#10;Content: You d You don't ne it doesn't {disfmarker} you just need some microphone , somewhere .&#10;Speaker: Grad B&#10;Content: Ye - Yeah . Yep .&#10;Speaker: PhD F&#10;Content: You can use found data .&#10;Speaker: Grad B&#10;Content: Tape recorder .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Oh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: You {disfmarker} you can .&#10;Speaker: Professor D&#10;Content: You need some microphone ,&#10;Speaker: PhD F&#10;Content: You can&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." target="aker: PhD F&#10;Content: You can&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: but I mean {disfmarker}&#10;Speaker: PhD F&#10;Content: use {disfmarker} Um , but I think that any {pause} data that we spend a lot of effort {nonvocalsound} to collect ,&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: you know , each person who 's interested in {disfmarker} I mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD F&#10;Content: And {disfmarker} So in my case , um , I think there w there is enough data for some kinds of projects and not enough for others .&#10;Speaker: Grad B&#10;Content: Not enough for others , right .&#10;Speaker: PhD F&#10;Content: And so {non">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." target=" PhD F&#10;Content: and I guess it depends of what kind of audience you 're talking to , but {disfmarker} {vocalsound} You know , I personally {nonvocalsound} would not want a {nonvocalsound} CD {comment} of my meeting ,&#10;Speaker: Grad B&#10;Content: Mmm . Of the meeting ?&#10;Speaker: PhD F&#10;Content: but {vocalsound} maybe {disfmarker} yeah , {pause} maybe you 're&#10;Speaker: Professor D&#10;Content: If you 're having some planning meeting of some sort and uh you 'd like {disfmarker}&#10;Speaker: PhD F&#10;Content: right . {comment} Right . Right .&#10;Speaker: PhD A&#10;Content: Oh , that 's a good idea .&#10;Speaker: Grad B&#10;Content: It 'd be fun . I think it would just be fun , you know , if nothing else , you know .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right .&#10;Speaker: Grad B&#10;Content: It 's a">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." target="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Details about the person PhD F is interested in: They are a new student who attended the last meeting and will be working with the team part-time, already being funded for half of the normal part-time position. Their specific interests were not mentioned in the conversation.&#10;2. Considerations regarding data collection for this individual's research: PhD F wants to gather more data for research purposes, as they believe that there is enough data for some projects but not enough for others. She emphasizes the need for each person to take charge of collecting the kind of data they want and mentions that she personally would not want a CD of her meeting, suggesting that she values privacy and discretion in certain contexts.&#10;&#10;In summary, PhD F is interested in involving a new student in their research and ensuring that there is sufficient data for various projects. She highlights the importance of respecting individual preferences when it comes to data collection, indicating an awareness of potential ethical considerations in this process." target="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." target=" if they 're all normalized .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Um , but {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , using something simpler first I think is probably fine .&#10;Speaker: Professor D&#10;Content: Well , this isn't tru if {disfmarker} if {disfmarker} if you really wonder what different if {disfmarker} if {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Decision tree .&#10;Speaker: PhD C&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: Yeah , then a decision tree is really good , but the thing is here he 's {disfmarker} he 's not {disfmarker} he 's not like he has one you know , a bunch of very distinct variables , like pitch and this {disfmarker} he 's talking about , like , a all these cepstral coefficients , and so forth ,&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." target="er} you can't eh , eh put up with your hand {comment} in the different parameter ,&#10;Speaker: Grad B&#10;Content: Right , you can't analyse it .&#10;Speaker: PhD C&#10;Content: but eh {disfmarker} If you use a neural net is {disfmarker} is a good idea , but eh you don't know what happened in the interior of the neural net .&#10;Speaker: Professor D&#10;Content: Well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: It 's hard to {disfmarker} w w what you {disfmarker} It 's hard to tell on a neural net is what 's going on internally .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Um , but">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." target="aker: PhD C&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: And so {vocalsound} I {disfmarker} i again , if you take a few of these things that are {disfmarker} are {vocalsound} prob um {comment} {pause} promising features and look at them in pairs , {vocalsound} uh , I think you 'll have much more of a sense of &quot; OK , I now have {disfmarker} {vocalsound} uh , doing a bunch of these analyses , I now have ten likely candidates . &quot; And then you can do decision trees or whatever to see how they combine .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: I 've got a question .&#10;Speaker: PhD C&#10;Content: Yeah . This&#10;Speaker: Postdoc E&#10;Content: Interesting .&#10;Speaker: PhD C&#10;Content: Sorry .&#10;Speaker: Postdoc E&#10;Content: Hmm .&#10;Speaker: PhD C&#10;Content: but eh , eh {vocalsound} eh eh eh I don't know it is the first eh way to {d">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." target=" in preparing the data ,&#10;Speaker: Professor D&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: if you have a choice between people who are pr more proficient in {disfmarker} {nonvocalsound} um , i more fluent , more {disfmarker} more close to being academic English , then it would seem to me to be a good thing .&#10;Speaker: Professor D&#10;Content: I guess {disfmarker} I maybe {disfmarker} Hmm . I&#10;Speaker: Postdoc E&#10;Content: Because otherwise y you don't have the ability to have {disfmarker} Uh , so if {disfmarker} if you have a bunch of idiolects that 's the worst possible case . If you have people who are using English as a {disfmarker} as an interlanguage because they {disfmarker} they don't {disfmarker} uh , they can't speak in their native languages and {disfmarker} but their interlanguage isn't really a match to any existing , uh , language model ,&#10;Speaker: Professor D&#10;Content">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." target="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The first model mentioned in the transcript is a supervised clustering model that aims to detect changes and identify different categories within the data. This model is based on the idea of using supervised clustering to accurately classify data into different groups or classes.&#10;2. The second model discussed is similar to linear discriminant analysis, which will analyze the contribution of each parameter towards correctly classifying different types of data. The goal is to determine which parameters are most important for accurate classification. This was the initial idea presented during the discussion.&#10;3. During the discussion, it was mentioned that using a decision tree might not be suitable when there are numerous indistinct variables involved, as opposed to having a few distinct ones. The issue with using a decision tree in this context is that it may not be able to effectively handle the complexity and overlap of the numerous indistinct variables, making it difficult to accurately analyze their effects on the model's predictions. Additionally, decision trees can become very complex and difficult to interpret when there are many input variables, making it challenging to understand what is happening internally within the model. Instead, sensitivity analyses may be performed to better understand the importance of different input variables in the context of a neural network.&#10;&#10;In summary, while a decision tree can be a good tool for analyzing data with distinct variables, it might not be the best option when dealing with numerous indistinct variables due to its limitations in handling complexity and overlaps." target="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} you can't eh , eh put up with your hand {comment} in the different parameter ,&#10;Speaker: Grad B&#10;Content: Right , you can't analyse it .&#10;Speaker: PhD C&#10;Content: but eh {disfmarker} If you use a neural net is {disfmarker} is a good idea , but eh you don't know what happened in the interior of the neural net .&#10;Speaker: Professor D&#10;Content: Well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: It 's hard to {disfmarker} w w what you {disfmarker} It 's hard to tell on a neural net is what 's going on internally .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Um , but" target="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results.">
      <data key="d0">1</data>
    </edge>
    <edge source="er} you can't eh , eh put up with your hand {comment} in the different parameter ,&#10;Speaker: Grad B&#10;Content: Right , you can't analyse it .&#10;Speaker: PhD C&#10;Content: but eh {disfmarker} If you use a neural net is {disfmarker} is a good idea , but eh you don't know what happened in the interior of the neural net .&#10;Speaker: Professor D&#10;Content: Well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: It 's hard to {disfmarker} w w what you {disfmarker} It 's hard to tell on a neural net is what 's going on internally .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: But it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Um , but" target="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine.">
      <data key="d0">1</data>
    </edge>
    <edge source="aker: PhD C&#10;Content: Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: And so {vocalsound} I {disfmarker} i again , if you take a few of these things that are {disfmarker} are {vocalsound} prob um {comment} {pause} promising features and look at them in pairs , {vocalsound} uh , I think you 'll have much more of a sense of &quot; OK , I now have {disfmarker} {vocalsound} uh , doing a bunch of these analyses , I now have ten likely candidates . &quot; And then you can do decision trees or whatever to see how they combine .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: PhD A&#10;Content: I 've got a question .&#10;Speaker: PhD C&#10;Content: Yeah . This&#10;Speaker: Postdoc E&#10;Content: Interesting .&#10;Speaker: PhD C&#10;Content: Sorry .&#10;Speaker: Postdoc E&#10;Content: Hmm .&#10;Speaker: PhD C&#10;Content: but eh , eh {vocalsound} eh eh eh I don't know it is the first eh way to {d" target="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine.">
      <data key="d0">1</data>
    </edge>
    <edge source=" in preparing the data ,&#10;Speaker: Professor D&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: if you have a choice between people who are pr more proficient in {disfmarker} {nonvocalsound} um , i more fluent , more {disfmarker} more close to being academic English , then it would seem to me to be a good thing .&#10;Speaker: Professor D&#10;Content: I guess {disfmarker} I maybe {disfmarker} Hmm . I&#10;Speaker: Postdoc E&#10;Content: Because otherwise y you don't have the ability to have {disfmarker} Uh , so if {disfmarker} if you have a bunch of idiolects that 's the worst possible case . If you have people who are using English as a {disfmarker} as an interlanguage because they {disfmarker} they don't {disfmarker} uh , they can't speak in their native languages and {disfmarker} but their interlanguage isn't really a match to any existing , uh , language model ,&#10;Speaker: Professor D&#10;Content" target="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target=": Is it ?&#10;Speaker: Postdoc E&#10;Content: I mean , it {disfmarker} it {disfmarker} it {disfmarker} The other direction is fast , but this direction is really slow .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Hmm .&#10;Speaker: Grad B&#10;Content: Well , especially because I 'm generating a clone , also .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So . And that takes a while .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah , OK .&#10;Speaker: PhD A&#10;Content: Generating a clone ?&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's a good point .&#10;Speaker: Grad B&#10;Content: Two copies .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: PhD A&#10;Content: Oh !&#10;Speaker: Grad B&#10;Content: One offsite , one onsite .&#10;Speaker: PhD A&#10;Content: Oh ! Hunh !&#10;Speaker: Professor D&#10;Content:">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target=": One offsite , one onsite .&#10;Speaker: PhD A&#10;Content: Oh ! Hunh !&#10;Speaker: Professor D&#10;Content: S&#10;Speaker: Postdoc E&#10;Content: Now , what will uh {disfmarker} Is the plan to g {pause} to {disfmarker} So {pause} stuff will be saved , it 's just that you 're relocating it ? I mean , so we 're gonna get more disk space ? Or did I {disfmarker} ?&#10;Speaker: Grad B&#10;Content: No , the {disfmarker} the {disfmarker} these are the P - files from Broadcast News , which are regeneratable {disfmarker} regeneratable&#10;Speaker: Postdoc E&#10;Content: OK . Oh , good . I see .&#10;Speaker: Grad B&#10;Content: um , if we really need to , but we had a lot of them . And {disfmarker} for the full , uh , hundred forty hour sets .&#10;Speaker: Postdoc E&#10;Content: OK .&#10;Speaker: Grad B&#10;Content: And so they {disfmarker} they were two gig">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="&#10;Speaker: PhD A&#10;Content: Wow !&#10;Speaker: PhD C&#10;Content: Oh .&#10;Speaker: Postdoc E&#10;Content: Yeah , the archiving m {pause} program does take a long time .&#10;Speaker: Grad B&#10;Content: And {disfmarker} and {disfmarker}&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Yep . And so one That {disfmarker} that will be done , like , in about two hours . And so uh , {vocalsound} at that point we 'll be able to record five more meetings . So .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: One thing {disfmarker} The good news about that {disfmarker} that is that once {disfmarker} once it 's archived , it 's pretty quick to get back .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Is it ?&#10;Speaker: Postdoc E&#10;Content: I mean , it {disfmarker} it {disfmarker} it">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="} {pause} There 's uh , there 's obviously other things going on .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: Oh , it 's not a problem . Not a problem . Yeah . I just {disfmarker} I just couldn't do it in two minutes .&#10;Speaker: Grad B&#10;Content: How will we {disfmarker} how would the person who 's doing the transcript even know who they 're talking about ? Do you know what I 'm saying ?&#10;Speaker: PhD A&#10;Content: &quot; The person who 's doing the transcript {disfmarker} &quot; {comment} The IBM people ?&#10;Speaker: Grad B&#10;Content: Yeah . I mean , so so {disfmarker} how is that information gonna get labeled anyway ?&#10;Speaker: Postdoc E&#10;Content: How do you mean , who {disfmarker} what they 're {disfmarker} who they 're talking about ?&#10;Speaker: Grad B&#10;Content: I mean , so if I 'm saying in a meeting , &quot; oh and Bob , by the way , wanted">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target=" not yet sat down with {disfmarker} been able to get that error message in a point where I can sit down and find out where it 's occurring in the code .&#10;Speaker: PhD A&#10;Content: Next time you get it maybe we should write it down .&#10;Speaker: Grad B&#10;Content: Yep , we will . One of these days .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Was it a pause , or {disfmarker} ? OK . Was it on &quot; pause &quot; or something ?&#10;Speaker: Grad B&#10;Content: No .&#10;Speaker: Postdoc E&#10;Content: OK . Don't know .&#10;Speaker: Professor D&#10;Content: So uh {disfmarker} so the uh , the new procedural change that just got suggested , which I think is a good idea is that um , we do the digit recordings at the end . And that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and don't have the time , uh , then they can run off . It 'll mean we 'll get somewhat fewer uh">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="Speaker: Grad B&#10;Content: OK ,&#10;Speaker: PhD F&#10;Content: That 's looks strange .&#10;Speaker: Grad B&#10;Content: now we 're on and it seems to be working .&#10;Speaker: Postdoc E&#10;Content: Oh there we go .&#10;Speaker: PhD C&#10;Content: One two three four five six&#10;Speaker: PhD A&#10;Content: That is weird .&#10;Speaker: Postdoc E&#10;Content: This looks good .&#10;Speaker: PhD A&#10;Content: It 's like when it 's been sitting for a long time or something .&#10;Speaker: Grad B&#10;Content: So , I mean {disfmarker} I don't know what it is . But all {disfmarker} all I know is that it seems like every time I am up here after a meeting , and I start it , it works fine . And if I 'm up here and I start it and we 're all sitting here waiting to have a meeting , it gives me that error message and I have not yet sat down with {disfmarker} been able to get that error message in a point where I can sit down and find out where it '">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers are discussing a process of generating a clone of Broadcast News P-files, which will result in two copies - one stored offsite and another onsite. This process involves archiving the files, which can take a significant amount of time. The archived files can be accessed quickly once the archiving is completed. The speakers are also discussing some technical issues related to recording meetings and transcriptions." target="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy.">
      <data key="d0">1</data>
    </edge>
    <edge source="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." target=" {disfmarker} uh , um , question . Well , Morgan , you were mentioning that Mari may not use the k equipment from IBM if they found something else , cuz there 's a {disfmarker}&#10;Speaker: Professor D&#10;Content: They 're {disfmarker} they 're {disfmarker} yeah , they 're d they 're uh {disfmarker} assessing whether they should do that or y do something else , hopefully over the next few weeks .&#10;Speaker: PhD F&#10;Content: Cuz I mean , one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up a room in the linguistics department ? And {disfmarker} and I mean , there {disfmarker} there may be a lot more {disfmarker} or {disfmarker} or in psych , or in comp wherever , in another building where we could um , record people there . I think we 'd have a better chance&#10;Speaker: Grad B&#10;Content: I think we 'd need a real motivated partner to do that . We 'd need to find someone on campus who">
      <data key="d0">1</data>
    </edge>
    <edge source="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." target=" , &quot; is Mari gonna use the equipment ? &quot; I mean , how would you say that ?&#10;Speaker: Postdoc E&#10;Content: Yeah ?&#10;Speaker: PhD A&#10;Content: I mean , you have to really think , you know , about what you 're saying bef&#10;Speaker: Grad B&#10;Content: if you wanted to anonymize .&#10;Speaker: PhD C&#10;Content: Yeah . {vocalsound} Yeah , is {disfmarker}&#10;Speaker: Professor D&#10;Content: &quot; Is you know who up in you know where ? &quot;&#10;Speaker: PhD A&#10;Content: Yeah . Yeah .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: Right ? Use the {disfmarker}&#10;Speaker: PhD A&#10;Content: I think it would be really hard if we made a policy where we didn't say names , plus we 'd have to tell everybody else .&#10;Speaker: Grad B&#10;Content: Yeah , darn ! I mean , what I was gonna say is that the other option is that we could bleep out the names .&#10;Speaker: Postdoc E&#10;Content: Well , it">
      <data key="d0">1</data>
    </edge>
    <edge source="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." target="&#10;Content: Grads and professors , fine .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: Professor D&#10;Content: Oh , you age - ist !&#10;Speaker: Grad B&#10;Content: What 's that ? Well , age - ist . {comment} The &quot; eighteen &quot; is because of the consent form .&#10;Speaker: Postdoc E&#10;Content: Age - ist .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: Right , Yeah .&#10;Speaker: Grad B&#10;Content: We 'd hafta get {disfmarker} find their parent to sign for them .&#10;Speaker: PhD C&#10;Content: &quot; Age - ist &quot; . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Yes .&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's true .&#10;Speaker: Grad B&#10;Content: So .&#10;Speaker: PhD F&#10;Content: I have a {disfmarker} uh , um , question . Well , Morgan , you were mentioning that Mari may not use the k equipment from IBM if they found">
      <data key="d0">1</data>
    </edge>
    <edge source="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." target="Speaker: Grad B&#10;Content: I think we 'd need a real motivated partner to do that . We 'd need to find someone on campus who was interested in this .&#10;Speaker: PhD F&#10;Content: Right , but {disfmarker} Right . But if there were such a {disfmarker} I mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD F&#10;Content: So it 's just a just a thought if they end up not using the {disfmarker} the hardware .&#10;Speaker: Professor D&#10;Content: Well , the other thing {disfmarker} Yeah , I mean the other thing that I was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Uh . But . Um , and {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , I know that space">
      <data key="d0">1</data>
    </edge>
    <edge source="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." target=" D&#10;Content: Uh . But . Um , and {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , I know that space is really scarce on {disfmarker} at least in CS . You know , to {disfmarker} to actually find a room that we could use regularly might actually be very difficult .&#10;Speaker: Professor D&#10;Content: Uh {disfmarker} Yeah .&#10;Speaker: PhD F&#10;Content: But you may not need a separate room , you know ,&#10;Speaker: Grad B&#10;Content: That 's true .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something {disfmarker}&#10;Speaker: Grad B&#10;Content: True . Mm - hmm . Yep .&#10;Speaker: Professor D&#10;Content: Well , maybe John would let us put it into the phonology lab or something .&#10;Speaker: PhD F&#10;Content: Huh .&#10;Speaker: Grad B&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="If Mari decides not to use the &quot;k&quot; equipment from IBM, one possibility is that the equipment could be set up in a room in the linguistics department for recording people. This idea was brought up as a remote possibility, and it was noted that finding a suitable room might be challenging, especially in departments like Computer Science where space is scarce. However, if there is a meeting room in another department where the equipment can be safely kept and used regularly, it could be an option. It was also suggested that a motivated partner on campus could help accomplish this. The professors and grad students discussed the possibility of finding someone interested in using the equipment and having one of them record meetings as needed. Overall, the group seems open to exploring different options for using the equipment if Mari decides not to use it." target="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings." target=" and , eh , hierarchical clustering process . I {disfmarker} I {disfmarker} I put , eh , eh , for each frame {nonvocalsound} a label indicating what is th the type , what is the class , eh , which it belong .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: PhD C&#10;Content: Eh , I mean , the class you will {nonvocalsound} overlapping speech &quot; overlapping &quot; is a class , eh , &quot; speech &quot; {nonvocalsound} @ @ the class {pause} that 's&#10;Speaker: Grad B&#10;Content: Nonspeech .&#10;Speaker: PhD A&#10;Content: These will be assigned by hand ?&#10;Speaker: PhD C&#10;Content: a I {disfmarker} I {disfmarker} I ha I h I {disfmarker} I put the mark by hand ,&#10;Speaker: PhD A&#10;Content: Based on the {disfmarker} Uh - huh .&#10;Speaker: PhD C&#10;Content: because , eh , {vocalsound} my idea is , eh , in {disfmarker} in the first">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings." target="aker: PhD C&#10;Content: because , eh , {vocalsound} my idea is , eh , in {disfmarker} in the first session , I need , eh , {pause} I {disfmarker} I need , eh , to be sure that the information eh , that , eh , I {disfmarker} I will cluster , is {disfmarker} is right . Because , eh , eh , if not , eh , I will {disfmarker} I will , eh , return to the speech file to analyze eh , what is the problems ,&#10;Speaker: Grad B&#10;Content: Well , training , and validation . Sure . Mm - hmm .&#10;Speaker: PhD C&#10;Content: eh . And {vocalsound} I {disfmarker} I 'd prefer {disfmarker} I would prefer , the to {disfmarker} to have , eh , this labeled automatically , but , eh , eh , fro th I need truth .&#10;Speaker: PhD A&#10;Content: You need truth . Hmm .&#10;Speaker: Grad B&#10;Content: Yeah , but this is what you 're starting with .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings." target="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. In the transcript, PhD C expresses the need to ensure that the information they will use for clustering in their first session is correct. This means that the data they work with should be accurate and reliable, as any errors could negatively impact their results.&#10;2. Additionally, PhD C mentions their preference for having the data labeled automatically. However, they recognize that they currently require &quot;truth&quot; (ground truth annotation) to achieve this goal. This implies that PhD C needs manually labeled data to train and validate an automatic labeling system in the future.&#10;3. When PhD A responds with &quot;You need truth,&quot; it suggests that accurate annotation is crucial for the success of PhD C's work. Manually labeled data, or ground truth annotation, is essential to create a reliable automated labeling system.&#10;4. The discussion around this topic highlights the importance of accurate data collection and annotation in research projects like PhD C's hierarchical clustering process for analyzing meeting recordings." target="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target="uates um in computer science uh , have language skills that make , you know {disfmarker} that their {disfmarker} their fluency and writing skills are not so strong .&#10;Speaker: Professor D&#10;Content: Oh ! You 're not talking about foreign language at all .&#10;Speaker: Grad B&#10;Content: Yeah . Yeah , just talking about .&#10;Speaker: Professor D&#10;Content: You 're just talking about {disfmarker}&#10;Speaker: Postdoc E&#10;Content: Well , e I just think ,&#10;Speaker: Grad B&#10;Content: We all had the same thought .&#10;Speaker: Postdoc E&#10;Content: but you know , it 's like when you get into the graduate level , uh , no problem . I mean , I 'm not saying accents .&#10;Speaker: PhD C&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah , then we 're completely gone .&#10;Speaker: Postdoc E&#10;Content: I 'm say I 'm saying fluency .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Professor D&#10;Content: It 's {disf">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target=" Oh , interesting !&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Oh , I see . Oh , interesting !&#10;Speaker: Professor D&#10;Content: Uh , that 's the first point . The second point is um I think that for some time now , going back through BeRP I think that we have had speakers that we 've worked with who had non - native accents and I th I think that {disfmarker}&#10;Speaker: Postdoc E&#10;Content: Oh , oh . I 'm not saying accents . u The accent 's not the problem .&#10;Speaker: Professor D&#10;Content: Oh , OK .&#10;Speaker: Postdoc E&#10;Content: No , it 's more a matter of uh , proficiency , e e just simply fluency .&#10;Speaker: Professor D&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: I mean , I deal with people on {disfmarker} on campus who {disfmarker} I think sometimes people , undergraduates um in computer science uh , have language skills that make , you know {disfmarker} that their {disfmarker} their fluency">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target=" doing each time .&#10;Speaker: PhD A&#10;Content: Yeah , yeah .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: PhD A&#10;Content: Well , I was thinking that it must get kind of boring for the people who are gonna have to transcribe this&#10;Speaker: Postdoc E&#10;Content: and I {disfmarker}&#10;Speaker: PhD A&#10;Content: They may as well throw in some interesting intonations .&#10;Speaker: Grad B&#10;Content: Well , except ,&#10;Speaker: Postdoc E&#10;Content: I like your question intonation .&#10;Speaker: Grad B&#10;Content: yeah .&#10;Speaker: Postdoc E&#10;Content: That 's very funny . I haven't heard that one .&#10;Speaker: Grad B&#10;Content: We have the transcript . We have the actual numbers they 're reading , so we 're not necessarily depending on that . OK , I 'm gonna go off .">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target="disfmarker} can I say the other aspect of this from my perspective which is that um , there 's {disfmarker} there 's this {disfmarker} this issue , you have a corpus out there , it should be used for {disfmarker} for multiple things cuz it 's so expensive to put together .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: Postdoc E&#10;Content: And if people want to approach {disfmarker} Um , i so I know {pause} e e {pause} You know this {disfmarker} The idea of computational linguistics and probabilistic grammars and all may not be the focus of this group ,&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: Postdoc E&#10;Content: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data ,&#10;Speaker: Professor D&#10;Content: Mm - hmm . Mm - hmm .&#10;Speaker: Postdoc">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target=" {disfmarker} but their interlanguage isn't really a match to any existing , uh , language model ,&#10;Speaker: Professor D&#10;Content: Uh - huh .&#10;Speaker: Postdoc E&#10;Content: this is the worst case scenario .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Well , that 's pretty much what you 're going to have in the networking group .&#10;Speaker: Postdoc E&#10;Content: And {disfmarker}&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: because {disfmarker} because they {disfmarker} most {disfmarker} the network group is almost entirely Germans and Spaniards .&#10;Speaker: Postdoc E&#10;Content: Well Oh . But the thing is , I think that these people are of high enough level in their {disfmarker} in their language proficiency that {disfmarker}&#10;Speaker: Professor D&#10;Content: I see .&#10;Speaker: Postdoc E&#10;Content: And I 'm not objecting to accents .&#10;Speaker: Professor D&#10;Content: OK .&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes.">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="based on the transcript, it is suggested that some computer science graduates may not have a strong level of proficiency in written and spoken English fluency. However, it is also noted that this tends to improve as they progress to graduate level studies. The discussion revolves around the impact of language skills, including accent and fluency, on the use and preparation of a corpus for multiple purposes. There is no definitive answer given in the transcript regarding the typical level of proficiency in written and spoken English for computer science graduates." target="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." target=" really what makes this corpus powerful .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Special ? Yep .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I agree .&#10;Speaker: PhD F&#10;Content: Otherwise , you know , lots of other sites can propose {disfmarker} individual studies , so {disfmarker}&#10;Speaker: Professor D&#10;Content: Uh but I {disfmarker} I think that the uh {vocalsound} i We can't really underestimate the difficulty {disfmarker} shouldn't really u underestimate the difficulty of getting a setup like this up .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: And so , {disfmarker} uh it took quite a while to get that together and to say , &quot; Oh , we 'll just do it up there , &quot; {disfmarker}&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: If you 're talking about something simple , where">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." target=" , it 's not necessarily true that we need all of the corpus to satisfy all of it . So , a a as per the example that we wanna have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings But we can also have another part that 's , uh , just one or two meetings of each of a {disfmarker} of a range of them and that 's OK too . Uh , i We realized in discussion that the other thing is , what about this business of distant and close microphones ? I mean , we really wanna have a substantial amount recorded this way , that 's why we did it . But {pause} what about {disfmarker} For th for these issues of summarization , a lot of these higher level things you don't really need the distant microphone .&#10;Speaker: PhD F&#10;Content: Right , I mean , I c I think there 's {disfmarker}&#10;Speaker: Grad B&#10;Content: And you don't really need the close microphone , you mean .&#10;Speaker: Professor D&#10;Content: You actually don't .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker:">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." target=" Yeah , but {disfmarker} I think if we {disfmarker} if we wanna just record with the tabletop microphones , that 's easy .&#10;Speaker: PhD C&#10;Content: Oh - yeah .&#10;Speaker: Grad B&#10;Content: Right ? That 's very easy ,&#10;Speaker: PhD C&#10;Content: Ye - Yeah , yeah .&#10;Speaker: Grad B&#10;Content: but that 's not the corpus that we 're collecting .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . We realized that , um , when we were talking about this that , OK , there 's these different things that we want to do with it . So , um , it 's true that we wanna be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . But on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . So , a a as per the example that we wanna have">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." target="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." target="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the transcript, there are two main goals for the corpus collection mentioned. The first goal is to design a model that can detect changes as accurately as possible. This model will use supervised clustering to identify different classes or categories within the data. The second goal is to classify differences using methods similar to linear discriminant analysis. This model will analyze the contribution of each parameter to correctly classify the different types of data and determine which parameters are most important for accurate classification.&#10;&#10;The transcript also suggests that it is not necessary for the entire corpus to satisfy all of the goals for the corpus collection. For example, when discussing the microphone setup for recording the corpus, it is mentioned that for some higher-level tasks like summarization, a close microphone may not be necessary, and recording with only tabletop microphones would be easier. This implies that the corpus can be used for different purposes, and not all parts of the corpus need to be collected in the same way or satisfy all goals.&#10;&#10;In summary, the two main goals for the corpus collection are to design a model that can detect changes accurately using supervised clustering and to classify differences using methods similar to linear discriminant analysis. The entire corpus does not need to satisfy all of the goals, as different parts of the corpus can be used for different purposes." target="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source=" really what makes this corpus powerful .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Special ? Yep .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I agree .&#10;Speaker: PhD F&#10;Content: Otherwise , you know , lots of other sites can propose {disfmarker} individual studies , so {disfmarker}&#10;Speaker: Professor D&#10;Content: Uh but I {disfmarker} I think that the uh {vocalsound} i We can't really underestimate the difficulty {disfmarker} shouldn't really u underestimate the difficulty of getting a setup like this up .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Professor D&#10;Content: And so , {disfmarker} uh it took quite a while to get that together and to say , &quot; Oh , we 'll just do it up there , &quot; {disfmarker}&#10;Speaker: PhD F&#10;Content: OK .&#10;Speaker: Professor D&#10;Content: If you 're talking about something simple , where" target="1. The power of the corpus comes from its ability to provide a special setup for collecting and analyzing data, which allows for in-depth research on various tasks such as summarization or classification. This is due to the careful planning and consideration given to the design of the corpus, including the microphone setup and annotation methods.&#10;2. Setting up this corpus was challenging, as it required a significant amount of time and effort to bring all the components together. The difficulty lies in the complexity of coordinating various elements such as microphone placement, data collection, annotation, and ensuring compatibility with different research goals.&#10;3. While other sites can propose individual studies, they may not have the same level of control or customization over their data collection process, limiting their ability to tailor the dataset for specific tasks. In contrast, this corpus's careful setup enables more versatile and accurate analysis for computational linguistics applications.&#10;&#10;In summary, the power of the corpus comes from its specialized design and the effort required to set it up. The difficulty in setting up the corpus is attributed to the coordination of various elements and the ability to create a customizable dataset that caters to specific research needs. This unique setup sets the corpus apart from other individual study proposals on other sites, allowing for more accurate and versatile data analysis.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." target="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." target="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." target="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." target="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." target="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the provided transcript, there is no substantial discussion or expression of opinions from the speakers regarding the topic of what type of clothing researchers like to wear. The transcript primarily focuses on the process of generating a clone of Broadcast News P-files, technical issues related to recording meetings and transcriptions, data collection for analysis, summarization of meetings, and identifying cues in both utterances and interaction patterns. While the speakers do briefly mention hats and shirts, it does not indicate their opinions or preferences regarding clothing for researchers." target="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target=" I need t true eh , silence for that , because my {disfmarker} my idea is to {disfmarker} to study the nnn {disfmarker} the {disfmarker} {vocalsound} the set of parameters eh , what , eh , are more m more discriminant to eh , classify .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: PhD C&#10;Content: the overlapping zones in cooperation with the speech {pause} eh zones . The idea is {pause} to eh {disfmarker} to use {disfmarker} eh , I 'm not sure to {disfmarker} eh yet , but eh my idea is to use a {disfmarker} a cluster {pause} {vocalsound} eh algorithm or , nnn , a person strong in neural net algorithm to eh {disfmarker} to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech .&#10;Speaker: PhD A&#10;Content: Mmm .&#10;Speaker: PhD C&#10;Content: And my idea is eh , it would be interesting to {disfmark">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. The speakers are discussing the idea of using a cluster algorithm or a neural network algorithm to study the properties of different features that can better classify speech and overlapping speech. This is mentioned as the first speaker's (PhD C) idea during the discussion.&#10;2. They are also discussing how to handle instances where there is one person speaking with other non-speech sounds present in the background. The question is posed about which category such instances should be placed in, suggesting a need for more nuanced classification that can handle overlapping speech and non-speech sounds.&#10;3. While not explicitly stated in the provided transcript, it seems likely that this discussion is related to the first model mentioned earlier, where the goal is to design a supervised clustering model that can detect changes and identify different categories within the data, with a focus on accurately classifying speech and overlapping speech." target="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns." target=" correlation .&#10;Speaker: Grad B&#10;Content: Cross - co cross - correlation .&#10;Speaker: PhD C&#10;Content: Correlation , yeah .&#10;Speaker: Professor D&#10;Content: Just cross - correlation between two sides .&#10;Speaker: PhD A&#10;Content: Did - Sorry , b uh I 'm not sure what Dan 's page is that you mean . He was looking at the two {disfmarker}&#10;Speaker: Professor D&#10;Content: So cross - correlation is pretty sensitive .&#10;Speaker: Postdoc E&#10;Content: Uh , his a web page .&#10;Speaker: Professor D&#10;Content: You take the signal from the two microphones and you cros and you cross - correlate them with different lags .&#10;Speaker: Grad B&#10;Content: Subtract them .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And you find {disfmarker} They get peaks .&#10;Speaker: Professor D&#10;Content: OK . So">
      <data key="d0">1</data>
    </edge>
    <edge source="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns." target="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data.">
      <data key="d0">1</data>
    </edge>
    <edge source="Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech. The procedure for conducting cross-correlation involves several steps:&#10;&#10;1. Capture the signals: Record or obtain the audio signals from the two microphones that you want to compare.&#10;2. Choose the lag: Decide on a range of lags (time delays) to apply when comparing the two signals. This range will determine how much time difference you're willing to accept between similar features in the signals.&#10;3. Correlate the signals: Compute the cross-correlation between the two signals for each chosen lag value. This is done by multiplying corresponding samples of the two signals and summing these products across all possible pairs. The resulting correlation value indicates how well the signals match at that particular lag.&#10;4. Find peaks in the cross-correlation: Identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;5. Interpret results: Based on the identified peaks and their corresponding lags, make conclusions about the relationship between the two signals, such as the presence of overlapping speech or consistent sound patterns." target="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data.">
      <data key="d0">1</data>
    </edge>
    <edge source=" correlation .&#10;Speaker: Grad B&#10;Content: Cross - co cross - correlation .&#10;Speaker: PhD C&#10;Content: Correlation , yeah .&#10;Speaker: Professor D&#10;Content: Just cross - correlation between two sides .&#10;Speaker: PhD A&#10;Content: Did - Sorry , b uh I 'm not sure what Dan 's page is that you mean . He was looking at the two {disfmarker}&#10;Speaker: Professor D&#10;Content: So cross - correlation is pretty sensitive .&#10;Speaker: Postdoc E&#10;Content: Uh , his a web page .&#10;Speaker: Professor D&#10;Content: You take the signal from the two microphones and you cros and you cross - correlate them with different lags .&#10;Speaker: Grad B&#10;Content: Subtract them .&#10;Speaker: PhD A&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: Mm - hmm .&#10;Speaker: PhD A&#10;Content: Uh - huh .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: And you find {disfmarker} They get peaks .&#10;Speaker: Professor D&#10;Content: OK . So" target="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target="Speaker: Postdoc E&#10;Content: Well , OK .&#10;Speaker: Grad B&#10;Content: going and dealing with it .&#10;Speaker: Postdoc E&#10;Content: It 's just {disfmarker} Yeah . OK . I {disfmarker} I 'll give you the short version , but I do think it 's an issue that we can't resolve in five minutes .&#10;Speaker: Grad B&#10;Content: Mm - hmm .&#10;Speaker: Postdoc E&#10;Content: OK , so {disfmarker} the {disfmarker} the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . Those we won't be able to change . If someone says &quot; Hey , Roger so - and - so &quot; .&#10;Speaker: Grad B&#10;Content: Right .&#10;Speaker: Postdoc E&#10;Content: So that 's gonna stay that person 's name .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Postdoc E&#10;Content: Now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target="disfmarker} what I said .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: So {disfmarker} uh , so in {disfmarker} within the context of an utterance , someone says &quot; So , Roger , what do you think ? &quot; OK . Then , uh , it seems to me that {disfmarker} Well , maybe I {disfmarker} uh it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that .&#10;Speaker: PhD A&#10;Content: Right , you don't wanna do that .&#10;Speaker: Grad B&#10;Content: We don't {disfmarker} we wanna {disfmarker} we ha we want the transcript to be &quot; Roger &quot; .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Because if we made the {disfmarker} the transcript be the tag that we 're using for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that .">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target=" E&#10;Content: Now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says &quot; Hey Roger &quot; or are we gonna put that person 's anonymized name in instead ?&#10;Speaker: Grad B&#10;Content: No , because then that would give you a mapping , and you don't wanna have a mapping .&#10;Speaker: Postdoc E&#10;Content: OK , so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned .&#10;Speaker: PhD A&#10;Content: I don't {disfmarker}&#10;Speaker: Grad B&#10;Content: No . Because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want {disfmarker}&#10;Speaker: Postdoc E&#10;Content: I {disfmarker} I don't think you understood what I {disfmarker} what I said .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: So {">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion, the consensus seems to be that they will anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned. This decision is made to avoid providing a mapping between the speaker's real name and the tag used in the transcript. Therefore, a unique identifier or a pseudonym could be used in the transcript to represent everyone's names." target="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="disfmarker} what I said .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: So {disfmarker} uh , so in {disfmarker} within the context of an utterance , someone says &quot; So , Roger , what do you think ? &quot; OK . Then , uh , it seems to me that {disfmarker} Well , maybe I {disfmarker} uh it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that .&#10;Speaker: PhD A&#10;Content: Right , you don't wanna do that .&#10;Speaker: Grad B&#10;Content: We don't {disfmarker} we wanna {disfmarker} we ha we want the transcript to be &quot; Roger &quot; .&#10;Speaker: PhD A&#10;Content: Yeah .&#10;Speaker: Grad B&#10;Content: Because if we made the {disfmarker} the transcript be the tag that we 're using for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that ." target="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source=" E&#10;Content: Now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says &quot; Hey Roger &quot; or are we gonna put that person 's anonymized name in instead ?&#10;Speaker: Grad B&#10;Content: No , because then that would give you a mapping , and you don't wanna have a mapping .&#10;Speaker: Postdoc E&#10;Content: OK , so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned .&#10;Speaker: PhD A&#10;Content: I don't {disfmarker}&#10;Speaker: Grad B&#10;Content: No . Because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want {disfmarker}&#10;Speaker: Postdoc E&#10;Content: I {disfmarker} I don't think you understood what I {disfmarker} what I said .&#10;Speaker: Grad B&#10;Content: OK .&#10;Speaker: Postdoc E&#10;Content: So {" target="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data." target=" I can see the value o&#10;Speaker: Professor D&#10;Content: Oh , ideal would be to have the wall filled with them , but I mean {disfmarker} {vocalsound} But the thing is just having two mikes {disfmarker} If you looked at that thing on {disfmarker} on Dan 's page , it was {disfmarker} When {disfmarker} when there were two people speaking , and it looked really really different .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah , OK .&#10;Speaker: PhD C&#10;Content: Yeah . Yeah .&#10;Speaker: Grad B&#10;Content: Yep .&#10;Speaker: Postdoc E&#10;Content: Oh yeah yeah . OK .&#10;Speaker: PhD A&#10;Content: What looked different ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Uh , well , basic he was looking at correlation .&#10;Speaker: Grad B&#10;Content: Cross - co cross - correlation .&#10;Speaker: PhD C&#10;Content: Correlation , yeah .">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data." target="aker: Grad B&#10;Content: And you find {disfmarker} They get peaks .&#10;Speaker: Professor D&#10;Content: OK . So when one person is speaking , then wherever they happen to be at the point when they 're speaking , {vocalsound} then there 's a pretty big maximum right around that point in the l in {disfmarker} in the lag .&#10;Speaker: PhD A&#10;Content: OK . OK .&#10;Speaker: Professor D&#10;Content: So if {disfmarker} at whatever angle you are , {vocalsound} at some lag corresponding to the time difference between the two there , you get this boost in the {disfmarker} in {disfmarker} in the cross - correlation value {disfmarker} function .&#10;Speaker: PhD A&#10;Content: So {disfmarker} so if there 's two {disfmarker}&#10;Speaker: Grad B&#10;Content: And if there are multiple people talking , you 'll see two peaks .&#10;Speaker: Professor D&#10;Content: It 's spread out .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Cross-correlation is a technique used to measure the similarity between two signals as a function of the time lag applied to one of them. In this discussion, the speakers are referring to performing cross-correlation on signals from two microphones to analyze speech and overlapping speech.&#10;2. The speakers explain that by capturing the signals from two microphones and cross-correlating them with different lags, it is possible to identify points with high correlation values, which correspond to instances where the signals are most similar after applying a time lag. These peaks may indicate synchronized speech or other relevant features in the audio.&#10;3. The significance of cross-correlation in this context is that it can help researchers detect and analyze overlapping speech and consistent sound patterns. By interpreting the results of the cross-correlation analysis, they can make conclusions about the relationship between the two signals and improve the classification of different features in the audio data." target="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results." target="disfmarker} you don't see the spectrum {disfmarker} the spectrogram .&#10;Speaker: Grad B&#10;Content: Right . Yeah , they 're totally hidden .&#10;Speaker: PhD C&#10;Content: Is very difficult to apply eh , eh a parameter to detect change when you don't see .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . Well , that {disfmarker} that {disfmarker} that 's another reason why very simple features , things like energy , and things {disfmarker} things like harmonicity , and {vocalsound} residual energy are uh , yeah are {disfmarker} are better to use than very complex ones because they 'll be more reliable .&#10;Speaker: PhD C&#10;Content: But I suppose {disfmarker}&#10;Speaker: Grad B&#10;Content: Are probably better , yep .&#10;Speaker: PhD C&#10;Content: Yeah , yeah yeah , I {disfmarker} I {disfmarker} I will put eh the energy here . Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Ch - Chuck was gonna ask something I guess .&#10;Spe">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results." target=" ref respect to the speaker .&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} That 's fine .&#10;Speaker: PhD A&#10;Content: But th I don't think that matters , though .&#10;Speaker: PhD C&#10;Content: But {disfmarker}&#10;Speaker: Professor D&#10;Content: That 's {disfmarker} So {disfmarker} so i @ @ {comment} I think the issue is , &quot; Is there a clean signal coming from only one direction ? &quot;&#10;Speaker: PhD A&#10;Content: Right .&#10;Speaker: Professor D&#10;Content: If it 's not coming from just one direction , if it {disfmarker} if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking ,&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: wherever they are .&#10;Speaker: PhD A&#10;Content: So it 's sort of like how {disfmarker} how confused is it about where the beam is .&#10;Speaker: Professor D&#10;Content: Is it a {disfmarker} is">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results." target=" eh the energy here . Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Ch - Chuck was gonna ask something I guess .&#10;Speaker: PhD C&#10;Content: You have a question .&#10;Speaker: PhD A&#10;Content: Yeah , I {pause} maybe this is a dumb question , but w I thought it would be {disfmarker} {vocalsound} I thought it would be easier if you used a PDA&#10;Speaker: Professor D&#10;Content: Nah .&#10;Speaker: PhD A&#10;Content: because can't you , couldn't you like use beam - forming or something to detect speaker overlaps ? I mean {disfmarker}&#10;Speaker: Grad B&#10;Content: Well , if you used the array , rather than the signal from just one .&#10;Speaker: PhD A&#10;Content: Uh - huh .&#10;Speaker: Professor D&#10;Content: Yeah , no , you you 're {disfmarker} you 're right&#10;Speaker: Grad B&#10;Content: But that 's {disfmarker}&#10;Speaker: Professor D&#10;Content: that {disfmarker} In fact , if we made use of the fact that">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Interpretability: Simple parameters like energy and harmonicity are more interpretable and easier to understand compared to complex ones. This makes them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible.&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple parameters are less likely to suffer from this issue, as they capture more general characteristics of the signal.&#10;3. Computational efficiency: Simple parameters are generally faster and computationally less demanding to extract compared to complex ones. This can be beneficial for real-time processing or large datasets.&#10;4. Robustness: Simple parameters tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability.&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. This can make it simpler to ensure that the parameter extraction process is functioning correctly and producing accurate results." target="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data.">
      <data key="d0">1</data>
    </edge>
    <edge source="disfmarker} you don't see the spectrum {disfmarker} the spectrogram .&#10;Speaker: Grad B&#10;Content: Right . Yeah , they 're totally hidden .&#10;Speaker: PhD C&#10;Content: Is very difficult to apply eh , eh a parameter to detect change when you don't see .&#10;Speaker: Professor D&#10;Content: Yeah . Yeah . Well , that {disfmarker} that {disfmarker} that 's another reason why very simple features , things like energy , and things {disfmarker} things like harmonicity , and {vocalsound} residual energy are uh , yeah are {disfmarker} are better to use than very complex ones because they 'll be more reliable .&#10;Speaker: PhD C&#10;Content: But I suppose {disfmarker}&#10;Speaker: Grad B&#10;Content: Are probably better , yep .&#10;Speaker: PhD C&#10;Content: Yeah , yeah yeah , I {disfmarker} I {disfmarker} I will put eh the energy here . Yeah . Yeah . Yeah .&#10;Speaker: Professor D&#10;Content: Ch - Chuck was gonna ask something I guess .&#10;Spe" target="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion." target="Based on the information provided in the meeting transcripts, the decision on how to label or identify the speakers in the transcript is typically made by the transcription team or the person responsible for creating the transcript. This decision is usually aimed at ensuring anonymity for all participants, as agreed upon during the discussion. The transcription team determines the unique identifiers or pseudonyms used to represent each speaker consistently throughout the conversation and in any references to their contributions.&#10;&#10;In this particular case, it appears that the speakers were not explicitly mentioned by name in the transcript excerpts provided. However, when speaker identities are not explicitly mentioned during the discussion, the transcription team would still be responsible for assigning appropriate unique identifiers or pseudonyms to each speaker based on their understanding of the conversation flow and the number of distinct speakers participating in the meeting.">
      <data key="d0">1</data>
    </edge>
    <edge source="Based on the discussion transcript, the decision is to anonymize the speaker identifiers and any mentions of their names in the text. This means that instead of using the real names of the speakers, a unique identifier or pseudonym will be used to represent each person throughout the transcript. This approach ensures that there is no mapping between the speaker's real name and the tag used in the transcript, providing anonymity for all participants.&#10;&#10;By consistently using the same identifier for each speaker, it becomes possible to accurately attribute statements and ideas to the correct individual. This is important for understanding the flow of the conversation, analyzing discussions (especially when multiple people are speaking over each other or interrupting), and giving proper recognition to each participant's contributions. Therefore, the transcript person will use the assigned unique identifiers to label the speakers throughout the conversation and identify who is being referred to during the discussion." target="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation.">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy." target=" {disfmarker} it would be a sticky limitation .&#10;Speaker: Postdoc E&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: You know , like {disfmarker} Well , we can talk about that later .&#10;Speaker: Postdoc E&#10;Content: I think that 's risky . I think that the public should be the same . I think that when we do that world release , it should be the same .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I agree . I {disfmarker} I agree with Jane .&#10;Speaker: Postdoc E&#10;Content: For a bunch of reasons , legal .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I think that we {disfmarker} we have a {disfmarker} need to have a consistent licensing policy of some sort , and {disfmarker}&#10;Speaker: Postdoc E&#10;Content: But I also think a consistent licensing policy is important .&#10;Speaker: PhD A&#10;Content: Well , one thing to to take into consideration is w are there any um {disfmarker} For example , the people">
      <data key="d0">1</data>
    </edge>
    <edge source="The speakers, Postdoc E and Professor D, expressed their concern about having a consistent licensing policy in the context of releasing Broadcast News P-files to the public. They believe that maintaining consistency in licensing will be important, as it can have legal implications. This consensus was reached after a discussion where Postdoc E mentioned several reasons why having a consistent licensing policy is crucial, and Professor D agreed with their perspective. However, the transcript does not provide further details about what specific concerns or recommendations were discussed regarding this consistent licensing policy." target="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public.">
      <data key="d0">1</data>
    </edge>
    <edge source=" {disfmarker} it would be a sticky limitation .&#10;Speaker: Postdoc E&#10;Content: Uh - huh .&#10;Speaker: Grad B&#10;Content: You know , like {disfmarker} Well , we can talk about that later .&#10;Speaker: Postdoc E&#10;Content: I think that 's risky . I think that the public should be the same . I think that when we do that world release , it should be the same .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I agree . I {disfmarker} I agree with Jane .&#10;Speaker: Postdoc E&#10;Content: For a bunch of reasons , legal .&#10;Speaker: Professor D&#10;Content: I {disfmarker} I think that we {disfmarker} we have a {disfmarker} need to have a consistent licensing policy of some sort , and {disfmarker}&#10;Speaker: Postdoc E&#10;Content: But I also think a consistent licensing policy is important .&#10;Speaker: PhD A&#10;Content: Well , one thing to to take into consideration is w are there any um {disfmarker} For example , the people" target="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation." target=" for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that .&#10;Speaker: Postdoc E&#10;Content: OK , well , but then there 's this issue of if we 're gonna use this for a discourse type of thing , then {disfmarker} and , you know , Liz was mentioning stuff in a previous meeting about gaze direction and who 's {disfmarker} who 's the addressee and all , then to have &quot; Roger &quot; be the thing in the utterance and then actually have the speaker identifier who was &quot; Roger &quot; be &quot; Frank &quot; , that 's going to be really confusing and make it pretty much useless for discourse analysis .&#10;Speaker: Grad B&#10;Content: Oh . Ugh ! That 's a good point .&#10;Speaker: Postdoc E&#10;Content: Now , if you want to , you know , I mean , in some cases , I {disfmarker} I {disfmarker} I know that Susan Ervin - Tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Confusion and loss of context: If the speaker identifier &quot;Roger&quot; is used when the actual speaker is &quot;Frank,&quot; it can create confusion for anyone analyzing or reading the transcript, making it difficult to understand the flow of conversation and attribute statements correctly. This issue is particularly significant in discourse analysis, where identifying the addressee and understanding gaze direction are important factors.&#10;&#10;2. Uselessness for discourse analysis: Continuing with the above example, such confusion would render the transcript almost useless for discourse analysis since it would be difficult to track who the speaker is addressing or their non-verbal cues like gaze direction.&#10;&#10;Susan Ervin-Tripp addressed similar issues in her work by implementing a filter on the s signal (possibly audio or video recordings) that filtered out the person's name whenever it was mentioned. This allowed for anonymization of names within the conversation itself, ensuring that there was no direct mapping between real names and the tags used in the transcript. However, this method may not be feasible in all cases, especially when the discussion revolves around specific individuals or their work, as mentioned in the meeting transcript.&#10;&#10;Therefore, it is essential to decide on an appropriate level of anonymity and consistently apply it throughout the transcripts while keeping in mind the potential impact on discourse analysis and overall understanding of the conversation." target=" Susan Ervin - Tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except&#10;Speaker: Professor D&#10;Content: Yeah Yeah , once you get to the publication you can certainly do that .&#10;Speaker: Postdoc E&#10;Content: And {disfmarker} and I {disfmarker} cer and I {disfmarker} So , I mean , the question then becomes one level back . Um , how important is it for a person to be identified by first name versus full name ? Well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to {disfmarker} they 'll be reviewing the transcripts , to see if there 's something they don't like {disfmarker} {comment} OK . So , maybe , uh , maybe that 's enough protection . On the other hand , this is a small {disfmarker} this is a small pool , and people who say things about topic X e who are researchers and well - known">
      <data key="d0">1</data>
    </edge>
    <edge source="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine." target="isfmarker} I mean I have some results to present , but I mean I guess we won't have time to do that this time . But it seems like um the anonymization is uh , is also something that we might wanna discuss in greater length .&#10;Speaker: Professor D&#10;Content: Um . I mean , wha what {disfmarker}&#10;Speaker: Postdoc E&#10;Content: If {disfmarker} if we 're about to wind down , I think {disfmarker} what I would prefer is that we uh , delay the anonymization thing till next week , and I would like to present the results that I have on the overlaps .&#10;Speaker: PhD A&#10;Content: We still have to do this , too , right ?&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: PhD A&#10;Content: Digits ?&#10;Speaker: Professor D&#10;Content: Right .&#10;Speaker: Grad B&#10;Content: No - well , we don't have to do digits .&#10;Speaker: Professor D&#10;Content: Well , why don't we {disfmarker} Uh , so @ @ OK . @ @ {comment} It sounds like u uh">
      <data key="d0">1</data>
    </edge>
    <edge source="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine." target="&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Right ? So again , I think the first thing to do to detect the overlaps is to look at these uh , in {disfmarker} in {disfmarker} in {disfmarker} in {disfmarker}&#10;Speaker: Grad B&#10;Content: Features ?&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: Well , I {disfmarker} again , the things you 've written up there I think are way too {disfmarker} way too big .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: OK ? If you 're talking about , say , twelfth {disfmarker} twelfth - order uh MFCC 's or something like that it 's just way too much .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Professor D&#10;Content: You won't be able to look at it . All you 'll be able to do is put it into a classifier and see how well it does .&#10;Speaker: PhD C&#10;">
      <data key="d0">1</data>
    </edge>
    <edge source="Profession D suggests that if one takes a few promising features and looks at them in pairs, they will have a better sense of which are the ten most likely candidates. After this, decision trees or other methods can be used to see how these features combine." target="1. Interpretability: Simple features like energy and harmonicity are more straightforward to understand compared to complex ones, making them more reliable in situations where visual inspection of the spectrum or spectrogram is not possible. This interpretability allows researchers to easily grasp their significance without requiring extensive expertise or analysis.&#10;&#10;2. Less susceptible to overfitting: Complex parameters may be more sensitive to specific patterns or noise in the data, leading to overfitting and reduced reliability. Simple features are less likely to suffer from this issue since they capture more general characteristics of the signal. Overfitting can lead to poor performance on unseen data, while simple features tend to generalize better due to their robustness.&#10;&#10;3. Computational efficiency: Simple parameters, such as energy and harmonicity, are generally faster and computationally less demanding to extract compared to complex ones. This computational advantage is particularly important when working with large datasets or real-time processing applications where quick results are necessary.&#10;&#10;4. Robustness: Simple features tend to be more robust against changes in the signal, such as variations in background noise or subtle differences between categories. In contrast, complex parameters may be more sensitive to these changes, leading to reduced reliability. This increased robustness ensures that simple features perform consistently across different conditions and maintain their accuracy in detecting changes within a spectrogram.&#10;&#10;5. Easier validation and troubleshooting: Due to their simplicity, energy and harmonicity are easier to validate and troubleshoot compared to complex parameters. Ensuring the parameter extraction process functions correctly is essential for producing accurate results. Simple features simplify this task by reducing the number of variables involved and making it easier to identify any issues that may arise.&#10;&#10;In summary, simple features like energy and harmonicity are more reliable than complex parameters when detecting changes in a spectrogram with hidden components because they are interpretable, less susceptible to overfitting, computationally efficient, robust, and simpler to validate and troubleshoot. These advantages make them better suited for analyzing audio signals and extracting meaningful information from the data.">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public." target=" it 's a matter of {disfmarker} between now and then of d of deciding how {disfmarker}&#10;Speaker: Grad B&#10;Content: Making some decisions ?&#10;Speaker: Postdoc E&#10;Content: i i it {disfmarker} You know , it may be s that we we 'll need to do something like actually X out that part of the um {disfmarker} the audio , and just put in brackets &quot; speaker - one &quot; .&#10;Speaker: Grad B&#10;Content: Yeah . For the public one .&#10;Speaker: PhD C&#10;Content: the ? ?&#10;Speaker: Grad B&#10;Content: You know , what we could do also is have more than one version of release .&#10;Speaker: PhD C&#10;Content: Yeah .&#10;Speaker: Postdoc E&#10;Content: You know .&#10;Speaker: Grad B&#10;Content: One that 's public and one {disfmarker} one that requires licensing . And so the licensed one would {disfmarker} w we could {disfmarker} it would be a sticky limitation .&#10;Speaker: Postdoc E&#10;Content: Uh - huh .&#10;Speaker: Grad">
      <data key="d0">1</data>
    </edge>
    <edge source="1. Consistency in Licensing: Both Postdoc E and Professor D agree on the importance of having a consistent licensing policy when releasing Broadcast News P-files to the public. This consistency is considered crucial for legal reasons.&#10;2. Public Access and Licensing: They discuss the idea of having two versions of the release, one that is public and does not require licensing and another that requires licensing for access.&#10;3. Internal Use: The speakers also mention that the internal version cannot be the same as the public version, emphasizing the need to protect certain information for privacy and discretion.&#10;4. Data Collection: Postdoc E raises concerns about data collection, suggesting that they might need to redact or anonymize certain parts of the audio in order to protect individual's privacy. This indicates a consideration for ethical implications when collecting and releasing data to the public." target=" ,&#10;Speaker: Grad B&#10;Content: That 's a good point . Right , it can't be the internal one .&#10;Speaker: PhD F&#10;Content: right ?&#10;Speaker: Professor D&#10;Content: Although it 's {disfmarker}&#10;Speaker: PhD F&#10;Content: Otherwise they 're not allowed to play it for anyone .&#10;Speaker: Postdoc E&#10;Content: There we go .&#10;Speaker: Grad B&#10;Content: That 's right .&#10;Speaker: Postdoc E&#10;Content: Oh , I like that . Well put . Well put . So , after the transcript screening phase .&#10;Speaker: Grad B&#10;Content: Yeah , that 's true .&#10;Speaker: Postdoc E&#10;Content: Things have been weeded out .&#10;Speaker: PhD F&#10;Content: Otherwise we 'd need two lawyer stages .&#10;Speaker: Postdoc E&#10;Content: Yeah , that 's right , say {comment} &quot; Yeah , well , I got this CD , and , Your Honor , I {disfmarker} &quot;&#10;Speaker: Grad B&#10;Content: Yeah .&#10;Speaker: PhD F&#10;Content: That 's a good">
      <data key="d0">1</data>
    </edge>
  </graph>
</graphml>
